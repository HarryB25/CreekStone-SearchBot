{"id": "ax-2026-02-02-1", "source": "arxiv", "date": "2026-02-02", "rank": 1, "title": "Sample AI Paper: Deep Learning for Time Series Forecasting", "url": "https://arxiv.org/abs/2401.00001v1", "detail_url": "https://arxiv.org/pdf/2401.00001v1.pdf", "description_en": "This paper presents a novel deep learning approach for time series forecasting. We propose a new architecture that combines attention mechanisms with temporal convolutional networks to capture both short-term and long-term dependencies in sequential data. Extensive experiments on multiple benchmark datasets demonstrate that our method achieves state-of-the-art performance.", "description_zh": "本文提出了一种结合注意力机制和时间卷积网络的新型深度学习架构，用于时间序列预测。", "keywords": ["深度学习", "时间序列预测", "注意力机制", "卷积网络", "依赖性捕捉", "机器学习", "生成模型", "deep learning"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Zhang San", "Li Si", "Wang Wu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目在AI原生程度上表现良好，但缺乏自进化潜力。技术路径有一定壁垒，商业模式较为稳健，团队能力一般。加分项来自于技术创新。"}, "raw": {"published": "2026-02-03T18:11:03Z", "ai_summary": {"tldr": "本文提出了一种结合注意力机制和时间卷积网络的新型深度学习架构，用于时间序列预测。", "motivation": "时间序列数据的复杂性要求新的方法能够有效捕捉短期和长期的依赖关系。", "method": "提出的架构结合了注意力机制与时间卷积网络，以提高对序列数据的建模能力。", "conclusion": "在多个基准数据集上的实验表明，该方法达到了当前最先进的性能。"}}}
{"id": "ax-2026-02-02-1", "source": "arxiv", "date": "2026-02-02", "rank": 1, "title": "AgentRx: Diagnosing AI Agent Failures from Execution Trajectories", "url": "https://arxiv.org/abs/2602.02475v1", "detail_url": "https://arxiv.org/pdf/2602.02475v1.pdf", "description_en": "AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.", "description_zh": "本研究提出了AgentRx框架，通过分析AI代理执行轨迹中的失败，自动定位关键失败步骤，从而提高故障归因的效率和准确性。", "keywords": ["关键词：agent", "multi-agent", "失败诊断", "执行轨迹", "自动化框架", "LLM", "约束评估", "关键失败步骤", "失败分类"], "tags": ["cs.AI"], "metrics": {"authors": ["Shraddha Barke", "Arnav Goyal", "Alind Khare", "Avaljot Singh", "Suman Nath", "Chetan Bansal"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent", "workflow"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "AgentRx具备Agent-native特性并有自进化潜力，技术路径独特且具备多领域应用，商业模式有独立潜力，团队具备AI原生进化能力，且在故障诊断领域有创新。"}, "raw": {"published": "2026-02-02T18:54:07Z", "ai_summary": {"tldr": "本研究提出了AgentRx框架，通过分析AI代理执行轨迹中的失败，自动定位关键失败步骤，从而提高故障归因的效率和准确性。", "motivation": "AI代理在执行过程中经常出现难以定位的失败，尤其是在复杂和多变的任务环境中，因此需要有效的故障诊断工具。", "method": "AgentRx是一个自动化的诊断框架，利用约束合成和逐步评估的方法，生成可审计的违规日志，并通过基础的LLM判断关键失败步骤和类别。", "conclusion": "AgentRx在三个领域的关键步骤定位和失败归因上相较于现有基线方法有显著改进，为AI代理故障的理解和修复提供了新的工具和视角。"}}}
{"id": "ax-2026-02-02-2", "source": "arxiv", "date": "2026-02-02", "rank": 2, "title": "Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge", "url": "https://arxiv.org/abs/2602.02470v1", "detail_url": "https://arxiv.org/pdf/2602.02470v1.pdf", "description_en": "Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the \"reversal curse\" -- when trained on forward knowledge data of the form \"$A \\rightarrow B$\" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge \"$B \\leftarrow A$\" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form \"$A \\to A$\" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.", "description_zh": "通过引入身份桥数据，本文提出了一种方法，帮助自回归语言模型克服反转诅咒问题，从而提高逻辑推理能力。", "keywords": ["自回归语言模型", "语言模型", "逻辑推理", "训练数据", "正则化", "Identity Bridge", "transformer", "预训练", "细调", "任务成功率"], "tags": ["cs.AI"], "metrics": {"authors": ["Xutao Ma", "Yixiao Huang", "Hanlin Zhu", "Somayeh Sojoudi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "transformer", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在自回归语言模型的自进化潜力上表现突出，技术路径具有较强的壁垒，商业模式虽不明显但有潜力，团队具备良好的进化能力，且在逻辑推理领域有创新贡献。"}, "raw": {"published": "2026-02-02T18:50:57Z", "ai_summary": {"tldr": "通过引入身份桥数据，本文提出了一种方法，帮助自回归语言模型克服反转诅咒问题，从而提高逻辑推理能力。", "motivation": "自回归大型语言模型在简单逻辑推理中仍存在局限性，特别是在处理反转知识时表现不佳，研究旨在挑战这一观念。", "method": "作者提出了一种简单的正则化数据配方，称为身份桥，通过在训练数据中加入形式为'A → A'的样本来改善模型性能。", "conclusion": "实验结果表明，经过这种方法微调的模型在反转任务上的成功率显著提高，为克服反转诅咒提供了新的理论基础和实际路径。"}}}
{"id": "ax-2026-02-02-3", "source": "arxiv", "date": "2026-02-02", "rank": 3, "title": "Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts", "url": "https://arxiv.org/abs/2602.02468v1", "detail_url": "https://arxiv.org/pdf/2602.02468v1.pdf", "description_en": "Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.", "description_zh": "Avenir-Web是一个新开源的网页智能体，能在复杂动态网页上高效执行长任务，超越了现有的开源智能体。", "keywords": ["多模态", "语言模型", "自主代理", "任务跟踪", "经验模仿", "用户界面", "适应性记忆", "在线基准", "复杂任务", "ml"], "tags": ["cs.AI", "cs.CL"], "metrics": {"authors": ["Aiden Yiliu Li", "Xinyue Hao", "Shilong Liu", "Mengdi Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "agent", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 22, "business": 16, "team": 12, "bonus": 6, "penalty": 0}, "reason": "Avenir-Web具备Agent-native特征并展现自进化潜力，技术路径清晰且具备数据和场景护城河，商业模式具有高价值密度，团队具备AI原生进化能力，且在多模态交互上有创新表现。"}, "raw": {"published": "2026-02-02T18:50:07Z", "ai_summary": {"tldr": "Avenir-Web是一个新开源的网页智能体，能在复杂动态网页上高效执行长任务，超越了现有的开源智能体。", "motivation": "现有的自主网页智能体在执行复杂任务时面临元素定位不准确、缺乏特定程序知识和不稳定的任务跟踪等问题。", "method": "Avenir-Web结合了多种基础专家、经验模仿规划和自适应记忆的任务跟踪清单，以提升在多种用户界面上的交互能力。", "conclusion": "Avenir-Web在Online-Mind2Web基准测试中显著超越了之前的开源智能体，并与顶级商业模型达到了性能平衡，建立了新的开源智能体的最佳标准。"}}}
{"id": "ax-2026-02-02-4", "source": "arxiv", "date": "2026-02-02", "rank": 4, "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction", "url": "https://arxiv.org/abs/2602.02455v1", "detail_url": "https://arxiv.org/pdf/2602.02455v1.pdf", "description_en": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.", "description_zh": "论文提出了Drift-Bench，一个用于评估LLM代理在输入故障下的合作 breakdown 的基准，强调多轮互动的重要性。", "keywords": ["关键词：大型语言模型", "自主代理", "多轮交互", "合作 breakdown", "用户模拟器", "Drift-Bench", "代理安全评估", "Clarification", "执行风险", "llm"], "tags": ["cs.AI", "cs.CL", "cs.SE"], "metrics": {"authors": ["Han Bao", "Zheyuan Zhang", "Pengcheng Jing", "Zhengqing Yuan", "Kaiwen Shi", "Yanfang Ye"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "autonomous", "rag", "autonomous agents"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具有较高的AI原生程度，提出了创新的评估基准，技术壁垒明显，商业模式具备独立潜力，团队具备良好的进化能力，且在交互创新方面有加分。"}, "raw": {"published": "2026-02-02T18:46:16Z", "ai_summary": {"tldr": "论文提出了Drift-Bench，一个用于评估LLM代理在输入故障下的合作 breakdown 的基准，强调多轮互动的重要性。", "motivation": "随着大型语言模型向自主代理转变，用户输入常常违反合作假设，导致执行风险，而现有评估方法未能捕捉到这些风险。", "method": "Drift-Bench通过多轮澄清评估输入故障下的代理行为，结合经典的交流理论，提供了合作 breakdown 的统一分类法和基于角色的用户模拟器。", "conclusion": "实验显示在输入故障下性能显著下降，澄清效果因用户角色和故障类型而异，强调了澄清研究与代理安全评估之间的联系。"}}}
{"id": "ax-2026-02-02-5", "source": "arxiv", "date": "2026-02-02", "rank": 5, "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling", "url": "https://arxiv.org/abs/2602.02453v1", "detail_url": "https://arxiv.org/pdf/2602.02453v1.pdf", "description_en": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.", "description_zh": "本研究提出一种利用漫画增强多模态推理的新范式，称为Thinking with Comics，表现出比图像和视频更优的推理效率和效果。", "keywords": ["多模态推理", "视觉叙事", "结构化", "漫画", "语言模型", "认知能力", "任务评估", "效率提升", "时序结构", "context"], "tags": ["cs.AI"], "metrics": {"authors": ["Andong Chen", "Wenxin Zhu", "Qiuyu Ding", "Yuchen Song", "Muyun Yang", "Tiejun Zhao"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 78, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目展示了强大的Agent原生性和自进化潜力，技术路径具有明显的壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在多模态推理领域具有创新性。"}, "raw": {"published": "2026-02-02T18:43:57Z", "ai_summary": {"tldr": "本研究提出一种利用漫画增强多模态推理的新范式，称为Thinking with Comics，表现出比图像和视频更优的推理效率和效果。", "motivation": "尽管现有的多模态推理方法有所发展，但静态图像与视频仍存在显著的局限性，激发了对更高效推理媒介的需求。", "method": "研究基于漫画的两条推理路径，并在多种推理任务和长上下文理解任务上对其进行评估。", "conclusion": "实验结果表明，Thinking with Comics在多步时间和因果推理任务上优于Thinking with Images，且效率高于Thinking with Video，不同的漫画叙事结构和风格对任务表现有一致影响。"}}}
{"id": "ax-2026-02-02-6", "source": "arxiv", "date": "2026-02-02", "rank": 6, "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration", "url": "https://arxiv.org/abs/2602.02419v1", "detail_url": "https://arxiv.org/pdf/2602.02419v1.pdf", "description_en": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\\% percentage points over Gemini-only inference.", "description_zh": "本文提出了SafeGround框架，通过不确定性校准增强GUI基础模型的可靠性和风险控制能力。", "keywords": ["GUI", "Grounding", "不确定性校准", "预测", "风险控制", "SafeGround", "机器学习", "深度学习", "代理工作流", "自动化交互", "rag"], "tags": ["cs.AI", "cs.SE"], "metrics": {"authors": ["Qingni Wang", "Yue Fan", "Xin Eric Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 2}, "reason": "项目具有较强的Agent原生性和自进化潜力，技术路径清晰且具备一定的壁垒，商业模式具备独立潜力，但团队背景信息不足，减分主要来自于市场竞争激烈。"}, "raw": {"published": "2026-02-02T18:22:45Z", "ai_summary": {"tldr": "本文提出了SafeGround框架，通过不确定性校准增强GUI基础模型的可靠性和风险控制能力。", "motivation": "在GUI基础模型中，不正确的指令翻译可能导致严重后果，因此提升模型的可靠性是关键。", "method": "SafeGround利用分布感知的不确定性量化方法，并通过校准过程为测试时设定统计上保证的决策阈值，以控制错误发现率。", "conclusion": "实验结果表明，SafeGround在多个GUI基础模型上显著提高了系统级准确性，最大提升可达5.38个百分点。"}}}
{"id": "ax-2026-02-02-7", "source": "arxiv", "date": "2026-02-02", "rank": 7, "title": "Structure Enables Effective Self-Localization of Errors in LLMs", "url": "https://arxiv.org/abs/2602.02416v1", "detail_url": "https://arxiv.org/pdf/2602.02416v1.pdf", "description_en": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.", "description_zh": "本研究提出了一种结构化的方法，使语言模型能够有效本地化推理错误，从而实现自我纠正。", "keywords": ["自我纠错", "语言模型", "结构化推理", "思维抽样", "错误定位", "深度学习", "代理", "迭代纠正", "语义一致性", "思维步骤", "llm"], "tags": ["cs.AI"], "metrics": {"authors": ["Ankur Samanta", "Akshayaa Magesh", "Ayush Jain", "Kavosh Asadi", "Youliang Yu", "Daniel Jiang", "Boris Vidolov", "Kaveh Hassani", "Paul Sajda", "Jalaj Bhandari", "Yonathan Efroni"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "autonomous"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "该项目展示了Agent-native的自我纠错能力，技术路径清晰且具备较强的壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且有创新的交互方式。"}, "raw": {"published": "2026-02-02T18:15:59Z", "ai_summary": {"tldr": "本研究提出了一种结构化的方法，使语言模型能够有效本地化推理错误，从而实现自我纠正。", "motivation": "研究探讨如何让语言模型明确定位推理中的错误，以便构建能够有效自我纠正的AI系统。", "method": "引入了迭代纠错思维（Thought-ICS）框架，通过将推理结构化为离散、连贯的思维步骤，使模型能够逐步检查和纠正错误。", "conclusion": "通过验证，Thought-ICS在自我纠正方面实现了20-40%的提升，并在完全自主的设置中超越了现有的自我纠正基线。"}}}
{"id": "ax-2026-02-02-8", "source": "arxiv", "date": "2026-02-02", "rank": 8, "title": "Reward-free Alignment for Conflicting Objectives", "url": "https://arxiv.org/abs/2602.02495v1", "detail_url": "https://arxiv.org/pdf/2602.02495v1.pdf", "description_en": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.", "description_zh": "本文提出了一种无奖励的对齐框架RACO，旨在解决多个目标之间的冲突，并提高大语言模型的对齐效果。", "keywords": ["奖励无关对齐", "多目标", "大语言模型", "偏好数据", "梯度下降", "Pareto最优", "质量评估", "LLM对齐", "冲突解决", "训练稳定性"], "tags": ["cs.CL", "cs.AI", "cs.LG"], "metrics": {"authors": ["Peter Chen", "Xiaopeng Li", "Xi Chen", "Tianyi Lin"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag", "reward model"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目提出了创新的无奖励对齐框架，具备自进化潜力，技术上解决了多目标冲突问题，商业模式具有独立潜力，团队在AI领域有较强的进化能力。"}, "raw": {"published": "2026-02-02T18:59:52Z", "ai_summary": {"tldr": "本文提出了一种无奖励的对齐框架RACO，旨在解决多个目标之间的冲突，并提高大语言模型的对齐效果。", "motivation": "当前的对齐方法在处理多个冲突目标时，简单的偏好聚合容易导致训练不稳定和效果不佳，因此需要新的方法来更有效地解决这些问题。", "method": "本文提出RACO框架，通过利用成对偏好数据并采用一种新颖的剪切变体冲突规避梯度下降来解决梯度冲突，确保收敛到符合用户指定目标权重的Pareto临界点。", "conclusion": "实验结果表明，所提方法在多目标摘要和安全对齐任务中，相较于现有的多目标对齐基线，能够持续实现更好的Pareto权衡。"}}}
{"id": "ax-2026-02-02-9", "source": "arxiv", "date": "2026-02-02", "rank": 9, "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability", "url": "https://arxiv.org/abs/2602.02477v1", "detail_url": "https://arxiv.org/pdf/2602.02477v1.pdf", "description_en": "Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.", "description_zh": "提出了一种端到端的强化学习框架，以提升大型语言模型在分而治之推理中的能力，从而提高测试时间的可扩展性。", "keywords": ["大语言模型", "LLM", "推理能力", "分而治之", "强化学习", "流程优化", "解决方案", "任务分解", "测试时间可扩展性"], "tags": ["cs.CL"], "metrics": {"authors": ["Xiao Liang", "Zhong-Zhi Li", "Zhenghao Lin", "Eric Hancheng Jiang", "Hengyuan Zhang", "Yelong Shen", "Kai-Wei Chang", "Ying Nian Wu", "Yeyun Gong", "Weizhu Chen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "该项目提出了创新的强化学习框架，具备较强的自进化潜力和技术壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在推理能力上有显著提升。"}, "raw": {"published": "2026-02-02T18:54:54Z", "ai_summary": {"tldr": "提出了一种端到端的强化学习框架，以提升大型语言模型在分而治之推理中的能力，从而提高测试时间的可扩展性。", "motivation": "尽管链式推理在推理能力上表现出色，但其顺序特性限制了模型在复杂任务中的表现，因此需要探索更有效的推理方法。", "method": "通过强化学习框架，模型在每一步将复杂问题分解为子问题，逐步求解并综合这些解决方案，以增强其分而治之推理能力。", "conclusion": "与传统方法相比，该框架在竞争级基准测试中显著提高了模型的性能和测试时间的可扩展性，分别提升了8.6%和6.3%。"}}}
{"id": "ax-2026-02-02-10", "source": "arxiv", "date": "2026-02-02", "rank": 10, "title": "Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models", "url": "https://arxiv.org/abs/2602.02467v1", "detail_url": "https://arxiv.org/pdf/2602.02467v1.pdf", "description_en": "Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.", "description_zh": "本研究评估了大型语言模型（LLMs）中信念导向的自主性和元认知监控的证据。", "keywords": ["大语言模型", "信念引导", "代理", "元认知监控", "生成模型", "行动选择", "内部信念形成", "代理驱动", "任务分析", "热度指标", "llm"], "tags": ["cs.CL"], "metrics": {"authors": ["Noam Steinmetz Yalon", "Ariel Goldstein", "Liad Mudrik", "Mor Geva"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 10, "team": 12, "bonus": 5, "penalty": 0}, "reason": "项目展示了LLMs的信念导向自主性，具有较强的自进化潜力，技术路径清晰且具备一定的壁垒，商业模式尚需明确，团队具备较强的研究能力。"}, "raw": {"published": "2026-02-02T18:49:39Z", "ai_summary": {"tldr": "本研究评估了大型语言模型（LLMs）中信念导向的自主性和元认知监控的证据。", "motivation": "随着大型语言模型的快速发展，研究者们开始探讨这些模型是否具有某种形式的意识。", "method": "通过评估HOT-3指标，分析模型在生成过程中信念的动态变化，并引入量化指标来评估信念的主导性。", "conclusion": "研究结果支持了LLMs中信念导向的自主性和元认知监控的存在，并为进一步研究这些特性奠定了方法论基础。"}}}
{"id": "ax-2026-02-02-11", "source": "arxiv", "date": "2026-02-02", "rank": 11, "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry", "url": "https://arxiv.org/abs/2602.02464v1", "detail_url": "https://arxiv.org/pdf/2602.02464v1.pdf", "description_en": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.", "description_zh": "本研究提出了一种基于局部几何的激活分解方法，以捕捉语言模型中复杂的非线性结构。", "keywords": ["激活分解", "语言模型", "几何假设", "非线性结构", "Mixture of Factor Analyzers", "Gaussian区域", "Llama-3.1-8B", "Gemma-2-2B", "模型控制", "概念发现", "rag"], "tags": ["cs.CL"], "metrics": {"authors": ["Or Shafran", "Shaked Ronen", "Omri Fahn", "Shauli Ravfogel", "Atticus Geiger", "Mor Geva"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目展示了强大的自进化潜力和复杂的技术路径，具备较高的市场应用价值，但商业模式尚需进一步明确。"}, "raw": {"published": "2026-02-02T18:49:05Z", "ai_summary": {"tldr": "本研究提出了一种基于局部几何的激活分解方法，以捕捉语言模型中复杂的非线性结构。", "motivation": "现有的激活分解方法过于依赖线性假设，无法充分理解复杂的概念结构，因此需要探索新的方法来建模激活空间。", "method": "利用混合因子分析（MFA）对激活空间进行建模，将其视为高斯区域的集合，并分解为区域的中心和局部变异。", "conclusion": "MFA在激活空间中捕捉到了复杂的非线性结构，并在定位和引导基准测试中表现优于无监督基线，且与监督方法具有竞争力，显示出局部几何在概念发现中的潜力。"}}}
{"id": "ax-2026-02-02-12", "source": "arxiv", "date": "2026-02-02", "rank": 12, "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models", "url": "https://arxiv.org/abs/2602.02462v1", "detail_url": "https://arxiv.org/pdf/2602.02462v1.pdf", "description_en": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.", "description_zh": "本文提出了一种基于抽象激活空间的推理框架，以提高大型语言模型在形式推理中的鲁棒性，减轻语义干扰。", "keywords": ["关键词：大语言模型", "语义推理", "抽象推理", "结构约束", "激活空间", "形式推理", "语义干扰", "跨语言迁移", "多层干预", "llm"], "tags": ["cs.CL", "cs.AI"], "metrics": {"authors": ["Gabriele Maraia", "Marco Valentino", "Fabio Massimo Zanzotto", "Leonardo Ranaldi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "该项目展示了较强的Agent原生性和自进化潜力，技术路径具备良好的壁垒，商业模式具有独立潜力，团队具备AI原生进化能力，且有交互创新的加分项。"}, "raw": {"published": "2026-02-02T18:48:44Z", "ai_summary": {"tldr": "本文提出了一种基于抽象激活空间的推理框架，以提高大型语言模型在形式推理中的鲁棒性，减轻语义干扰。", "motivation": "大型语言模型在三段论推理中面临语义内容对推理有效性的影响，导致形式有效性与语义可信性混淆。", "method": "构建内容丰富和抽象的三段论对，利用模型在抽象输入上的激活定义抽象推理空间，并通过轻量级的抽象器在前向传播中进行多层干预。", "conclusion": "实验表明，基于抽象对推理的引导能够减少由内容驱动的错误，提高形式推理的有效性，展现出激活级别抽象的可扩展性。"}}}
{"id": "ax-2026-02-02-13", "source": "arxiv", "date": "2026-02-02", "rank": 13, "title": "Large Language Models for Mental Health: A Multilingual Evaluation", "url": "https://arxiv.org/abs/2602.02440v1", "detail_url": "https://arxiv.org/pdf/2602.02440v1.pdf", "description_en": "Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.", "description_zh": "本研究评估了多语言环境下大语言模型在心理健康领域的表现，发现其在特定数据集上优于传统基线，但翻译质量影响了性能。", "keywords": ["大型语言模型", "LLM", "多语言评估", "心理健康", "自然语言处理", "零样本学习", "微调", "机器翻译", "语义搜索"], "tags": ["cs.CL"], "metrics": {"authors": ["Nishat Raihan", "Sadiya Sayara Chowdhury Puspo", "Ana-Maria Bucur", "Stevie Chancellor", "Marcos Zampieri"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "context"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目在多语言心理健康领域展示了大语言模型的自进化潜力，技术路径具备较强的壁垒，商业模式有独立潜力，团队具备AI原生进化能力，且有创新方向。"}, "raw": {"published": "2026-02-02T18:34:53Z", "ai_summary": {"tldr": "本研究评估了多语言环境下大语言模型在心理健康领域的表现，发现其在特定数据集上优于传统基线，但翻译质量影响了性能。", "motivation": "尽管大语言模型在自然语言处理任务中表现出色，但其在多语言心理健康领域的效果尚未深入探讨。", "method": "通过在八个心理健康数据集上评估专有模型和开源模型，比较其在零样本、少样本和微调设置下的表现，同时分析翻译质量对模型性能的影响。", "conclusion": "专有和微调的开源大语言模型在多个数据集上取得了竞争性的F1分数，但机器翻译数据的表现普遍较低，体现了在非英语语言中的优势及翻译质量带来的限制。"}}}
{"id": "ax-2026-02-02-14", "source": "arxiv", "date": "2026-02-02", "rank": 14, "title": "Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank", "url": "https://arxiv.org/abs/2602.02414v1", "detail_url": "https://arxiv.org/pdf/2602.02414v1.pdf", "description_en": "Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.", "description_zh": "本研究提出了一种利用大型语言模型从学生与辅导员对话中识别误区的新方法，显著提高了预测性能。", "keywords": ["误解诊断", "学生-辅导员对话", "大语言模型", "LLM", "嵌入相似度", "生成式", "检索", "重新排序", "教育平台", "预测性能"], "tags": ["cs.CL", "cs.LG"], "metrics": {"authors": ["Joshua Mitton", "Prarthana Bhattacharyya", "Digory Smith", "Thomas Christie", "Ralph Abboud", "Simon Woodhead"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "claude", "embedding"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 2}, "reason": "项目展示了强大的Agent原生能力和自进化潜力，技术路径清晰且具备一定壁垒，商业模式具备独立潜力。团队能力较强，但存在一定的估值过高风险，扣除2分。"}, "raw": {"published": "2026-02-02T18:14:35Z", "ai_summary": {"tldr": "本研究提出了一种利用大型语言模型从学生与辅导员对话中识别误区的新方法，显著提高了预测性能。", "motivation": "及时准确地识别学生的误区对于提高学习成果至关重要，但这一过程通常依赖于教师的努力和直觉。", "method": "该方法首先使用微调的大型语言模型生成可能的误区，然后通过嵌入相似性检索最有前景的候选项，最后再通过另一个微调的模型评估和重新排序以提高相关性。", "conclusion": "实验证明，该方法在真实对话中显著提高了预测性能，并且微调后的模型在生成误区的质量上超过了更大的闭源模型。"}}}
{"id": "ax-2026-02-02-15", "source": "arxiv", "date": "2026-02-02", "rank": 15, "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "url": "https://arxiv.org/abs/2602.02493v1", "detail_url": "https://arxiv.org/pdf/2602.02493v1.pdf", "description_en": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.", "description_zh": "PixelGen 是一种新的像素扩散框架，通过感知损失超越了传统的潜在扩散模型。", "keywords": ["像素扩散", "像素生成", "感知损失", "深度学习", "图像生成", "生成模型", "语义搜索", "端到端", "图像处理", "PixelGen", "generative"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Zehong Ma", "Ruihan Xu", "Shiliang Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "PixelGen 作为一种新型的像素扩散框架，具备较强的自进化潜力和技术壁垒，商业模式尚需进一步验证，团队能力表现良好，且在技术上有创新。"}, "raw": {"published": "2026-02-02T18:59:42Z", "ai_summary": {"tldr": "PixelGen 是一种新的像素扩散框架，通过感知损失超越了传统的潜在扩散模型。", "motivation": "现有的像素扩散方法在优化高维像素流形时面临挑战，导致其性能落后于潜在扩散模型。", "method": "PixelGen 引入了两种互补的感知损失，LPIPS损失用于学习局部模式，DINO基础的感知损失则增强全局语义，从而指导扩散模型学习更有意义的感知流形。", "conclusion": "PixelGen 在 ImageNet-256 上实现了 5.11 的 FID，并且在大规模文本到图像生成中表现出良好的扩展性能，提供了一种更简单而强大的生成范式。"}}}
{"id": "ax-2026-02-02-16", "source": "arxiv", "date": "2026-02-02", "rank": 16, "title": "Multi-head automated segmentation by incorporating detection head into the contextual layer neural network", "url": "https://arxiv.org/abs/2602.02471v1", "detail_url": "https://arxiv.org/pdf/2602.02471v1.pdf", "description_en": "Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \\pm 0.036$ versus $0.732 \\pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.", "description_zh": "提出了一种基于多头Transformer的自动分割架构，通过检测头和上下文集成提升了分割的准确性和可靠性。", "keywords": ["多头自动分割", "深度学习", "Transformer", "Swin U-Net", "语义分割", "结构检测", "影像分析", "机器人辅助", "临床应用", "自动化工作流"], "tags": ["cs.CV", "cs.AI", "physics.med-ph"], "metrics": {"authors": ["Edwin Kys", "Febian Febian"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "neural network", "transformer", "context", "workflow"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了创新的多头Transformer架构，具备自进化潜力，技术壁垒高，商业模式尚需明确，但团队能力强，具备良好的发展前景。"}, "raw": {"published": "2026-02-02T18:51:25Z", "ai_summary": {"tldr": "提出了一种基于多头Transformer的自动分割架构，通过检测头和上下文集成提升了分割的准确性和可靠性。", "motivation": "传统的自动分割模型在缺乏目标结构的切片中常出现解剖学上不合理的假阳性，影响临床应用的可靠性。", "method": "本研究提出的Swin U-Net结构结合了多层感知机进行结构检测和增强上下文流进行像素级分割，并使用检测输出来抑制假阳性。", "conclusion": "经过实验证明，该模型在减少假阳性和提高解剖学合理性方面表现优异，显著改善了临床放射治疗的自动轮廓绘制工作流程的可靠性。"}}}
{"id": "ax-2026-02-02-17", "source": "arxiv", "date": "2026-02-02", "rank": 17, "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing", "url": "https://arxiv.org/abs/2602.02437v1", "detail_url": "https://arxiv.org/pdf/2602.02437v1.pdf", "description_en": "Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.", "description_zh": "UniReason是一个统一的推理框架，通过双重推理范式整合文本到图像生成和图像编辑任务，提升了在复杂合成任务中的表现。", "keywords": ["图像生成", "深度推理", "多模态模型", "自我反思", "统一框架", "视觉编辑", "知识增强", "规划能力", "语义理解", "agent"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Dianyi Wang", "Chaofan Ma", "Feng Han", "Size Wu", "Wei Song", "Yibin Wang", "Zhixiong Zhang", "Tianhang Wang", "Siyuan Wang", "Zhongyu Wei", "Jiaqi Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "UniReason展示了强大的自进化潜力和深度推理能力，技术路径具备良好的壁垒，商业模式有独立潜力，团队具备AI原生进化能力，获得加分。"}, "raw": {"published": "2026-02-02T18:34:35Z", "ai_summary": {"tldr": "UniReason是一个统一的推理框架，通过双重推理范式整合文本到图像生成和图像编辑任务，提升了在复杂合成任务中的表现。", "motivation": "现有的统一多模态模型在处理需要深度推理的合成任务时效果欠佳，且通常将文本到图像生成和图像编辑视为孤立的能力。", "method": "UniReason通过将生成视为增强世界知识的规划，结合图像编辑能力进行精细视觉修正，从而在共享表示中统一生成和编辑。", "conclusion": "实验表明，UniReason在推理密集型基准上表现优异，同时保持了卓越的合成能力。"}}}
{"id": "ax-2026-02-02-18", "source": "arxiv", "date": "2026-02-02", "rank": 18, "title": "SelvaMask: Segmenting Trees in Tropical Forests and Beyond", "url": "https://arxiv.org/abs/2602.02426v1", "detail_url": "https://arxiv.org/pdf/2602.02426v1.pdf", "description_en": "Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.", "description_zh": "SelvaMask是一个新数据集和方法，用于在热带森林中准确分割树冠，显著提升了树冠分割的性能。", "keywords": ["树木分割", "热带森林", "视觉基础模型", "森林监测", "检测-分割管道", "transformer", "数据集", "机器学习", "深度学习"], "tags": ["cs.CV"], "metrics": {"authors": ["Simon-Olivier Duguay", "Hugo Baudchon", "Etienne Laliberté", "Helene Muller-Landau", "Gonzalo Rivas-Torres", "Arthur Ouaknine"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "SelvaMask展示了强大的自进化潜力和技术壁垒，商业模式尚需进一步明确，但团队具备较强的技术背景。"}, "raw": {"published": "2026-02-02T18:26:56Z", "ai_summary": {"tldr": "SelvaMask是一个新数据集和方法，用于在热带森林中准确分割树冠，显著提升了树冠分割的性能。", "motivation": "热带森林是地球树木生物多样性的关键栖息地，准确分割树冠有助于全球生态平衡和碳储存的研究。", "method": "提出了一种模块化的检测-分割管道，结合了视觉基础模型和领域特定的检测提示，利用SelvaMask数据集进行训练和验证。", "conclusion": "SelvaMask不仅提供了一个具有挑战性的基准，还推动了森林监测的广泛应用，且其代码和数据集将公开发布。"}}}
{"id": "ax-2026-02-02-19", "source": "arxiv", "date": "2026-02-02", "rank": 19, "title": "Catalyst: Out-of-Distribution Detection via Elastic Scaling", "url": "https://arxiv.org/abs/2602.02409v1", "detail_url": "https://arxiv.org/pdf/2602.02409v1.pdf", "description_en": "Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.", "description_zh": "Catalyst是一种后处理框架，通过利用预池化特征图的原始统计信息来提高OOD检测性能。", "keywords": ["深度学习", "神经网络", "OOD检测", "Catalyst", "弹性缩放", "特征图", "平均池化", "KNN", "性能提升", "ml"], "tags": ["cs.CV"], "metrics": {"authors": ["Abid Hassan", "Tuan Ngo", "Saad Shafiq", "Nenad Medvidovic"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "neural network", "rag", "vector"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "Catalyst展现出较强的Agent原生性和自进化潜力，技术路径具备良好的壁垒，商业模式有独立潜力，团队能力较强，且在OOD检测领域具有创新性。"}, "raw": {"published": "2026-02-02T18:08:33Z", "ai_summary": {"tldr": "Catalyst是一种后处理框架，通过利用预池化特征图的原始统计信息来提高OOD检测性能。", "motivation": "针对现有的OOD检测方法只依赖输出logit或特征向量的问题，Catalyst旨在挖掘预池化特征图中的丰富信号。", "method": "Catalyst计算输入依赖的缩放因子，并将其与现有基线分数结合，实现'弹性缩放'以增强ID和OOD分布的区分度。", "conclusion": "Catalyst显著提升了多种OOD检测方法的性能，展示了预池化统计信息的潜力，并与现有方法互补。"}}}
{"id": "ax-2026-02-02-20", "source": "arxiv", "date": "2026-02-02", "rank": 20, "title": "ReasonEdit: Editing Vision-Language Models using Human Reasoning", "url": "https://arxiv.org/abs/2602.02408v1", "detail_url": "https://arxiv.org/pdf/2602.02408v1.pdf", "description_en": "Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.", "description_zh": "ReasonEdit是一种新的视觉语言模型编辑工具，通过人类推理来改善模型的编辑性能。", "keywords": ["模型编辑", "视觉语言模型", "人类推理", "多模态嵌入", "语义检索", "ReasonEdit", "代码本", "推理任务", "编辑性能", "embedding"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Jiaxing Qiu", "Kaihua Hou", "Roxana Daneshjou", "Ahmed Alaa", "Thomas Hartvigsen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "ReasonEdit展现了强大的自进化潜力，技术路径清晰且具备较强的市场壁垒，商业模式具备独立潜力，团队具备AI原生进化能力。"}, "raw": {"published": "2026-02-02T18:06:14Z", "ai_summary": {"tldr": "ReasonEdit是一种新的视觉语言模型编辑工具，通过人类推理来改善模型的编辑性能。", "motivation": "现有的视觉语言模型编辑工具未能有效处理需要推理的任务，因此需要一个能够结合人类推理进行编辑的工具。", "method": "ReasonEdit通过一个代码本持续存储人类推理，并使用新颖的拓扑平衡多模态嵌入方法在推理时检索相关事实。", "conclusion": "ReasonEdit在多个基于推理的视觉问答数据集上表现出色，表明在人类推理的帮助下，模型编辑的泛化能力得到了显著提升。"}}}
{"id": "ax-2026-02-02-21", "source": "arxiv", "date": "2026-02-02", "rank": 21, "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System", "url": "https://arxiv.org/abs/2602.02488v1", "detail_url": "https://arxiv.org/pdf/2602.02488v1.pdf", "description_en": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL", "description_zh": "RLAnything是一个强化学习框架，通过闭环优化动态生成环境、策略和奖励模型，显著提升了系统性能。", "keywords": ["强化学习", "动态环境", "策略优化", "奖励模型", "LLM", "agentic场景", "反馈机制", "经验学习", "自动适应"], "tags": ["cs.LG", "cs.CL"], "metrics": {"authors": ["Yinjie Wang", "Tianbao Xie", "Ke Shen", "Mengdi Wang", "Ling Yang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "rag", "reward model"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "RLAnything具备Agent-native特性和自进化潜力，技术路径形成了数据与场景的护城河，商业模式具有独立潜力，团队具备AI原生进化能力，且在强化学习领域有显著创新。"}, "raw": {"published": "2026-02-02T18:59:04Z", "ai_summary": {"tldr": "RLAnything是一个强化学习框架，通过闭环优化动态生成环境、策略和奖励模型，显著提升了系统性能。", "motivation": "研究旨在提高强化学习系统的效率，尤其是在大型语言模型和代理任务中的应用。", "method": "该框架集成了逐步反馈和结果信号来训练策略，同时通过一致性反馈优化奖励模型，实现环境自动适应。", "conclusion": "实验结果表明，RLAnything在多个任务中显著提升了性能，优化的奖励模型信号效果优于依赖人类标签的结果。"}}}
{"id": "ax-2026-02-02-22", "source": "arxiv", "date": "2026-02-02", "rank": 22, "title": "Expanding the Capabilities of Reinforcement Learning via Text Feedback", "url": "https://arxiv.org/abs/2602.02482v1", "detail_url": "https://arxiv.org/pdf/2602.02482v1.pdf", "description_en": "The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.", "description_zh": "本文提出利用文本反馈扩展强化学习能力，探索文本反馈在训练中的应用及其对模型性能的提升。", "keywords": ["强化学习", "文本反馈", "深度学习", "反馈建模", "自我蒸馏", "多轮RL", "LLM", "训练优化", "性能提升"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuda Song", "Lili Chen", "Fahim Tajwar", "Remi Munos", "Deepak Pathak", "J. Andrew Bagnell", "Aarti Singh", "Andrea Zanette"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目在强化学习中引入文本反馈，具有自进化潜力，技术路径清晰且具备一定壁垒，商业模式有独立潜力，团队具备AI原生进化能力，且有创新点。"}, "raw": {"published": "2026-02-02T18:56:56Z", "ai_summary": {"tldr": "本文提出利用文本反馈扩展强化学习能力，探索文本反馈在训练中的应用及其对模型性能的提升。", "motivation": "现有的强化学习方法依赖于低效的奖励信号，而完整示范又难以规模化，因此需要寻找一种更有效的反馈模式。", "method": "提出了两种方法：自我蒸馏（RLTF-SD）和反馈建模（RLTF-FM），帮助模型在训练中内化文本反馈以增强推理能力。", "conclusion": "实验结果表明，这两种方法在多个基准测试中都显著优于强基线，展示了丰富监督信号在强化学习中的潜力。"}}}
{"id": "ax-2026-02-02-23", "source": "arxiv", "date": "2026-02-02", "rank": 23, "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning", "url": "https://arxiv.org/abs/2602.02472v1", "detail_url": "https://arxiv.org/pdf/2602.02472v1.pdf", "description_en": "Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under $2\\times$ width expansion.", "description_zh": "SPARKLING框架通过信号保留和破坏对称性，在宽度渐进学习中实现了中期宽度扩展的稳定性和高效性。", "keywords": ["深度学习", "机器学习", "神经网络", "自主代理", "生成模型", "语义搜索", "训练稳定性", "Mixture-of-Experts", "宽度扩展", "激活统计", "agent"], "tags": ["cs.LG", "cs.CL"], "metrics": {"authors": ["Qifan Yu", "Xinyu Ma", "Zhijian Zhuo", "Minrui Wang", "Deyi Liu", "Shiyi Zhan", "Yiyuan Ma", "Liang Xiang", "Xingyan Bin", "Di He"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "SPARKLING展示了强大的自进化潜力，技术路径具有明显的壁垒，商业模式尚需进一步验证，但团队具备较强的迭代能力，且在宽度扩展领域有创新。"}, "raw": {"published": "2026-02-02T18:52:52Z", "ai_summary": {"tldr": "SPARKLING框架通过信号保留和破坏对称性，在宽度渐进学习中实现了中期宽度扩展的稳定性和高效性。", "motivation": "虽然深度扩展得到了广泛研究，但宽度扩展在中期阶段的重要性尚未得到充分关注，且面临着训练不稳定性的问题。", "method": "SPARKLING框架通过RMS尺度一致性实现信号保留，并通过不对称优化器状态重置和学习率重新升温来确保对称性破坏。", "conclusion": "实验表明，SPARKLING在多种宽度轴和优化器家族上表现优于从头训练，并在$2\times$宽度扩展下将训练成本降低了多达35%。"}}}
{"id": "ax-2026-02-02-24", "source": "arxiv", "date": "2026-02-02", "rank": 24, "title": "Conflict-Aware Client Selection for Multi-Server Federated Learning", "url": "https://arxiv.org/abs/2602.02458v1", "detail_url": "https://arxiv.org/pdf/2602.02458v1.pdf", "description_en": "Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.", "description_zh": "提出了一种基于冲突风险预测的去中心化强化学习方法，以优化多服务器联邦学习中的客户端选择。", "keywords": ["联邦学习", "分布式机器学习", "客户端选择", "决策优化", "强化学习", "冲突风险预测", "多服务器", "训练效率", "资源争用", "公平奖励机制", "machine learning"], "tags": ["cs.LG", "cs.NI"], "metrics": {"authors": ["Mingwei Hong", "Zheng Lin", "Zehang Lin", "Lin Li", "Miao Yang", "Xia Du", "Zihan Fang", "Zhaolu Kang", "Dianxin Luan", "Shunzhi Zhu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 2, "penalty": 0}, "reason": "项目提出了去中心化强化学习方法，具有自进化潜力，技术路径清晰且具备较强的壁垒，商业模式有独立潜力，团队能力较强，且在多服务器联邦学习领域有创新。"}, "raw": {"published": "2026-02-02T18:47:16Z", "ai_summary": {"tldr": "提出了一种基于冲突风险预测的去中心化强化学习方法，以优化多服务器联邦学习中的客户端选择。", "motivation": "传统的单服务器联邦学习在客户端数量众多时存在高通信延迟，而多服务器联邦学习因客户端覆盖重叠和选择不协调导致资源竞争和训练失败。", "method": "提出了一种名为RL CRP的去中心化强化学习方法，通过使用分类隐马尔可夫模型预测客户端选择冲突，并结合公平奖励机制以促进长期客户端参与。", "conclusion": "实验结果表明，RL-CRP框架有效减少了服务器之间的冲突，显著提高了训练效率，包括收敛速度和通信成本的改善。"}}}
{"id": "ax-2026-02-02-25", "source": "arxiv", "date": "2026-02-02", "rank": 25, "title": "Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization", "url": "https://arxiv.org/abs/2602.02451v1", "detail_url": "https://arxiv.org/pdf/2602.02451v1.pdf", "description_en": "Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p < 0.001, Cohen's d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.", "description_zh": "提出了主动因果实验者（ACE）方法，通过直接偏好优化学习干预策略，显著提升实验设计效率。", "keywords": ["因果关系", "实验设计", "深度学习", "强化学习", "优化策略", "Active Causal Experimentalist", "自适应策略", "经验学习", "代理工作流", "autonomous"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Patrick Cooper", "Alvaro Velasquez"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "ACE方法具有高度的自进化潜力，能够通过经验学习优化实验设计，技术壁垒明显，商业模式具备独立潜力，团队具备AI原生进化能力。"}, "raw": {"published": "2026-02-02T18:43:52Z", "ai_summary": {"tldr": "提出了主动因果实验者（ACE）方法，通过直接偏好优化学习干预策略，显著提升实验设计效率。", "motivation": "传统实验方法无法有效利用经验，导致干预决策缺乏适应性和连贯性，因此需要一种新的方法来优化实验设计。", "method": "ACE作为一个序列决策策略，通过对候选干预的成对比较来学习，而非依赖不稳定的奖励值，进而优化实验设计。", "conclusion": "ACE在多个基准测试中表现出显著的性能提升，表明偏好学习能够从经验中恢复原则性的实验策略，增强理论与实际的结合。"}}}
{"id": "ax-2026-02-02-26", "source": "arxiv", "date": "2026-02-02", "rank": 26, "title": "Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation", "url": "https://arxiv.org/abs/2602.02445v1", "detail_url": "https://arxiv.org/pdf/2602.02445v1.pdf", "description_en": "This paper derives non-asymptotic error bounds for nonlinear stochastic approximation algorithms in the Wasserstein-$p$ distance. To obtain explicit finite-sample guarantees for the last iterate, we develop a coupling argument that compares the discrete-time process to a limiting Ornstein-Uhlenbeck process. Our analysis applies to algorithms driven by general noise conditions, including martingale differences and functions of ergodic Markov chains. Complementing this result, we handle the convergence rate of the Polyak-Ruppert average through a direct analysis that applies under the same general setting.   Assuming the driving noise satisfies a non-asymptotic central limit theorem, we show that the normalized last iterates converge to a Gaussian distribution in the $p$-Wasserstein distance at a rate of order $γ_n^{1/6}$, where $γ_n$ is the step size. Similarly, the Polyak-Ruppert average is shown to converge in the Wasserstein distance at a rate of order $n^{-1/6}$. These distributional guarantees imply high-probability concentration inequalities that improve upon those derived from moment bounds and Markov's inequality. We demonstrate the utility of this approach by considering two applications: (1) linear stochastic approximation, where we explicitly quantify the transition from heavy-tailed to Gaussian behavior of the iterates, thereby bridging the gap between recent finite-sample analyses and asymptotic theory and (2) stochastic gradient descent, where we establish rate of convergence to the central limit theorem.", "description_zh": "本文推导了非线性随机逼近算法在Wasserstein-$p$距离下的有限样本误差界限和集中不等式。", "keywords": ["非线性随机逼近", "Wasserstein距离", "收敛速率", "高概率集中不等式", "随机梯度下降", "迭代行为", "迭代收敛", "马尔可夫链", "误差界限", "rag"], "tags": ["cs.LG", "math.ST"], "metrics": {"authors": ["Seo Taek Kong", "R. Srikant"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "该项目在非线性随机逼近算法的研究上具有一定的技术壁垒，但商业模式较弱，团队背景信息不足，整体创新性较高。"}, "raw": {"published": "2026-02-02T18:41:06Z", "ai_summary": {"tldr": "本文推导了非线性随机逼近算法在Wasserstein-$p$距离下的有限样本误差界限和集中不等式。", "motivation": "研究旨在提供非渐近的误差界限，以改进非线性随机逼近算法的性能分析和应用。", "method": "通过发展耦合论证，将离散时间过程与极限的Ornstein-Uhlenbeck过程进行比较，从而得到明确的有限样本保证。", "conclusion": "结果表明最后迭代的标准化收敛到高斯分布，并且Polyak-Ruppert平均的收敛速率优于传统的矩界和Markov不等式。"}}}
{"id": "ax-2026-02-02-27", "source": "arxiv", "date": "2026-02-02", "rank": 27, "title": "Maximizing Reliability with Bayesian Optimization", "url": "https://arxiv.org/abs/2602.02432v1", "detail_url": "https://arxiv.org/pdf/2602.02432v1.pdf", "description_en": "Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.", "description_zh": "本文提出了基于贝叶斯优化的新方法，以最大化在随机扰动下设计的可靠性。", "keywords": ["贝叶斯优化", "可靠性", "黑箱优化", "重要性采样", "失败概率", "机器学习", "多代理", "在线学习", "自适应优化", "agent"], "tags": ["cs.LG", "math.OC", "stat.ML"], "metrics": {"authors": ["Jack M. Buckingham", "Ivo Couckuyt", "Juergen Branke"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 10, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目展示了强大的自进化潜力和创新的贝叶斯优化方法，具备较高的技术壁垒和应用价值，但商业模式尚需进一步明确。"}, "raw": {"published": "2026-02-02T18:31:58Z", "ai_summary": {"tldr": "本文提出了基于贝叶斯优化的新方法，以最大化在随机扰动下设计的可靠性。", "motivation": "制造过程中，设计的可靠性优化问题通常涉及极小的失败概率，这对传统优化方法提出了挑战。", "method": "提出了两种基于汤普森采样和知识梯度的贝叶斯优化方法，并结合重要性采样来针对极小的失败概率。", "conclusion": "实验结果表明，所提出的方法在极端和非极端情况下均优于现有方法。"}}}
{"id": "ax-2026-02-02-28", "source": "arxiv", "date": "2026-02-02", "rank": 28, "title": "Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization", "url": "https://arxiv.org/abs/2602.02425v1", "detail_url": "https://arxiv.org/pdf/2602.02425v1.pdf", "description_en": "Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.", "description_zh": "通过压缩预训练蛋白质语言模型的嵌入，CHASE框架实现了高效的蛋白质适应性优化。", "keywords": ["蛋白质优化", "语言模型", "深度学习", "嵌入", "生成模型", "CHASE", "条件流匹配", "高适应性变体", "预训练模型", "计算效率", "embedding"], "tags": ["cs.LG", "q-bio.QM"], "metrics": {"authors": ["Amaru Caceres Arroyo", "Lea Bogensperger", "Ahmed Allam", "Michael Krauthammer", "Konrad Schindler", "Dominik Narnhofer"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "CHASE框架具备强大的自进化潜力，技术路径清晰且具备数据和场景护城河，商业模式尚需进一步验证，但团队能力强，具备创新性。"}, "raw": {"published": "2026-02-02T18:25:33Z", "ai_summary": {"tldr": "通过压缩预训练蛋白质语言模型的嵌入，CHASE框架实现了高效的蛋白质适应性优化。", "motivation": "蛋白质适应性优化面临组合空间庞大且高适应性变体稀疏的问题，现有方法表现不佳或计算成本高。", "method": "CHASE框架通过条件流匹配模型与无分类器引导的结合，直接生成高适应性变体，避免了预测器的引导。", "conclusion": "CHASE在AAV和GFP蛋白设计基准上表现出色，并且通过合成数据的引导可以进一步提升性能。"}}}
{"id": "ax-2026-02-02-29", "source": "arxiv", "date": "2026-02-02", "rank": 29, "title": "Trust Region Continual Learning as an Implicit Meta-Learner", "url": "https://arxiv.org/abs/2602.02417v1", "detail_url": "https://arxiv.org/pdf/2602.02417v1.pdf", "description_en": "Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \\emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \\emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.", "description_zh": "研究提出了一种结合生成重放与Fisher度量信任区域约束的持续学习方法，提升了任务切换后的模型重收敛能力。", "keywords": ["信任区域", "继续学习", "生成回放", "渐进式任务", "元学习", "Fisher度量", "任务过渡", "任务优化", "迁移学习", "ml"], "tags": ["cs.LG"], "metrics": {"authors": ["Zekun Wang", "Anant Gupta", "Christopher J. MacLellan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提出了结合生成重放与Fisher度量的持续学习方法，具有较强的自进化潜力和技术壁垒。商业模式尚需明确，团队能力表现良好，具有一定的创新性。"}, "raw": {"published": "2026-02-02T18:19:16Z", "ai_summary": {"tldr": "研究提出了一种结合生成重放与Fisher度量信任区域约束的持续学习方法，提升了任务切换后的模型重收敛能力。", "motivation": "持续学习面临灾难性遗忘的挑战，现有策略在任务优化重叠不足时存在权衡问题。", "method": "提出的信任区域持续学习方法将生成重放与Fisher度量信任区域约束结合，形成一种隐式的元学习框架。", "conclusion": "在任务增量的扩散图像生成和持续扩散策略控制中，该方法实现了最佳的最终性能和任务保留，并且比EWC和重放方法更快恢复早期任务性能。"}}}
{"id": "ax-2026-02-02-30", "source": "arxiv", "date": "2026-02-02", "rank": 30, "title": "Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models", "url": "https://arxiv.org/abs/2602.02415v1", "detail_url": "https://arxiv.org/pdf/2602.02415v1.pdf", "description_en": "Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets are readily available and can be leveraged to construct a better seed set. We introduce a new method for selecting the seed data set for active learning, Active-Transfer Bagging (ATBagging). ATBagging estimates the informativeness of candidate data point from a Bayesian interpretation of bagged ensemble models by comparing in-bag and out-of-bag predictive distributions from the labeled dataset, yielding an information-gain proxy. To avoid redundant selections, we impose feature-space diversity by sampling a determinantal point process (DPP) whose kernel uses Random Fourier Features and a quality-diversity factorization that incorporates the informativeness scores. This same blended method is used for selection of new data points to collect during the active learning phase. We evaluate ATBagging on four real-world datasets covering both target-transfer and feature-shift scenarios (QM9, ERA5, Forbes 2000, and Beijing PM2.5). Across seed sizes nseed = 10-100, ATBagging improves or ties early active learning and increases area under the learning-curve relative to alternative seed subset selection methodologies in almost all cases, with strongest benefits in low-data regimes. Thus, ATBagging provides a low-cost, high reward means to initiating active learning-based data collection.", "description_zh": "提出了一种新方法Active-Transfer Bagging（ATBagging），通过结合迁移学习和集成模型加速主动学习数据采集。", "keywords": ["主动学习", "迁移学习", "数据集", "信息增益", "特征空间", "Bayesian", "ATBagging", "机器学习", "数据收集", "学习曲线", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Vivienne Pelletier", "Daniel J. Rivera", "Obinna Nwokonkwo", "Steven A. Wilson", "Christopher L. Muhich"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 7, "penalty": 0}, "reason": "ATBagging方法展示了强大的自进化潜力，技术路径具有较高的壁垒，商业模式尚需进一步验证，团队能力较强，且在主动学习领域具有创新性。"}, "raw": {"published": "2026-02-02T18:15:50Z", "ai_summary": {"tldr": "提出了一种新方法Active-Transfer Bagging（ATBagging），通过结合迁移学习和集成模型加速主动学习数据采集。", "motivation": "在主动学习中，初始种子集的随机选择常常影响性能，而可用的相关数据集可以用来构建更好的种子集。", "method": "ATBagging通过比较袋装集成模型的预测分布来估计候选数据点的信息量，并引入特征空间多样性来避免冗余选择。", "conclusion": "ATBagging在多个真实数据集上表现优异，尤其在低数据情况下，相比其他选择方法显著提高了主动学习的效率。"}}}
{"id": "gh-2026-02-03-1", "source": "github", "date": "2026-02-03", "rank": 1, "title": "masoncl/review-prompts", "url": "https://github.com/masoncl/review-prompts", "detail_url": "https://github.com/masoncl/review-prompts", "description_en": "AI review prompts", "description_zh": "**项目简介：AI Review Prompts**\n\nAI Review Prompts 是一个旨在帮助用户生成高质量评论和反馈的工具，主要面向内容创作者和开发者。该项目利用先进的人工智能技术，尤其是自然语言处理（NLP），自动生成针对特定内容的评论提示，以提升内容的互动性和质量。用户可以在各种场景中使用该工具，如产品评测、文章审阅和学习反馈等。", "keywords": ["AI review prompts", "生成式", "语义搜索", "深度学习", "神经网络", "代理", "多代理", "上下文", "自主代理", "反馈模型"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 31, "stars_today": 42}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的自进化潜力，技术路径上有较强的执行壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，加分项体现在交互创新上。"}, "raw": {}}
{"id": "gh-2026-02-03-2", "source": "github", "date": "2026-02-03", "rank": 2, "title": "karpathy/nanochat", "url": "https://github.com/karpathy/nanochat", "detail_url": "https://github.com/karpathy/nanochat", "description_en": "The best ChatGPT that $100 can buy.", "description_zh": "这是一个性价比极高的 ChatGPT 项目，售价仅需 100 美元。主要功能是提供高质量的自然语言处理和对话生成，适用于希望提升客户服务、内容创作或学习辅助的个人和企业。该项目核心技术包括先进的深度学习模型和自然语言处理算法，特别是集成了最新的 AI 研究成果，以确保用户获得最佳的对话体验。", "keywords": ["chatbot", "generative", "assistant", "transformer", "neural network", "context", "online learning", "intent prediction", "agent-friendly tooling"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 5419, "stars_today": 443}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["gpt"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备较强的AI原生能力，技术壁垒来自深度学习模型，商业模式具有独立潜力，但团队背景较为传统，缺乏显著的进化能力。"}, "raw": {}}
{"id": "gh-2026-02-03-3", "source": "github", "date": "2026-02-03", "rank": 3, "title": "OpenBMB/ChatDev", "url": "https://github.com/OpenBMB/ChatDev", "detail_url": "https://github.com/OpenBMB/ChatDev", "description_en": "ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration", "description_zh": "ChatDev 2.0：通过大型语言模型驱动的多代理协作实现全面开发\n\n主要功能包括智能代码生成、自动化测试和团队协作支持，旨在提高开发效率和代码质量。目标用户为软件开发团队和独立开发者，适用于需要快速迭代和多方协作的项目。核心技术包括先进的自然语言处理（NLP）和机器学习模型，能够理解和生成代码，同时促进多代理之间的智能协作。", "keywords": ["LLM", "多智能体", "协作", "生成模型", "深度学习", "神经网络", "语义搜索", "自主代理", "助手", "任务分配"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 3685, "stars_today": 475}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目具备Agent-native特性且有自进化潜力，技术壁垒高，商业模式独立且价值密度高，团队具备良好的迭代能力，且有交互创新。"}, "raw": {}}
{"id": "gh-2026-02-03-4", "source": "github", "date": "2026-02-03", "rank": 4, "title": "automazeio/ccpm", "url": "https://github.com/automazeio/ccpm", "detail_url": "https://github.com/automazeio/ccpm", "description_en": "Project management system for Claude Code using GitHub Issues and Git worktrees for parallel agent execution.", "description_zh": "该项目是一个为 Claude Code 设计的项目管理系统，利用 GitHub Issues 和 Git 工作树实现并行代理执行。主要功能包括任务管理、进度跟踪和协作支持，旨在提高开发团队的工作效率。目标用户为软件开发团队，特别是在需要多任务并行处理的场景中。核心技术包括 Git 和 GitHub 的版本控制功能，以及可能集成的 AI 技术以优化任务调度和资源分配。", "keywords": ["项目管理", "Claude Code", "GitHub Issues", "并行代理执行", "生成式", "代理", "机器学习", "神经网络", "深度学习", "语义搜索"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 696, "stars_today": 145}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude", "agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的自进化潜力，技术路径依赖于 Git 和 AI 的结合，形成了较强的执行壁垒。商业模式具备独立潜力，团队具备一定的迭代能力。"}, "raw": {}}
{"id": "gh-2026-02-03-5", "source": "github", "date": "2026-02-03", "rank": 5, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "这是一个有效的代理技能框架和软件开发方法论。主要功能包括帮助团队提升软件开发效率与质量，适用于开发人员、项目经理及团队领导等用户。核心技术包括人工智能算法，以实现智能化的项目管理与技能评估，推动团队能力的提升和项目的成功实施。", "keywords": ["智能助手", "生成模型", "深度学习", "代理框架", "自主代理", "语义搜索", "机器学习", "多代理系统", "上下文理解", "agent"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3292, "stars_today": 873}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目具备强大的自进化潜力，技术路径形成较高壁垒，商业模式价值密度高，团队具备AI原生进化能力，且有创新的交互方式。"}, "raw": {}}
{"id": "gh-2026-02-03-6", "source": "github", "date": "2026-02-03", "rank": 6, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件可以自动记录您在编程会话中的所有操作，利用 AI（使用 Claude 的 agent-sdk）对这些记录进行压缩，并在未来的会话中注入相关的上下文信息。主要功能包括代码活动的自动捕捉和上下文重用，旨在帮助开发者提高编程效率和项目一致性。该插件特别适合频繁进行编码的开发者，利用 AI 技术优化工作流程和学习过程。", "keywords": ["claude", "agent-sdk", "代码插件", "自动捕获", "上下文注入", "编程会话", "机器学习", "深度学习", "生成模型"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1339, "stars_today": 1739}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent-native特性，能够自我进化；技术壁垒较强，依赖于数据和场景；商业模式具备独立潜力；团队具备AI原生进化能力，且有创新的交互方式。"}, "raw": {}}
{"id": "gh-2026-02-03-7", "source": "github", "date": "2026-02-03", "rank": 7, "title": "virattt/dexter", "url": "https://github.com/virattt/dexter", "detail_url": "https://github.com/virattt/dexter", "description_en": "An autonomous agent for deep financial research", "description_zh": "一个用于深度金融研究的自主智能体。\n\n该项目的主要功能是自动化金融数据分析和研究，旨在帮助金融分析师和投资者获取深度市场洞察。核心技术包括机器学习和自然语言处理，以实现数据挖掘和趋势预测，从而提高决策效率。", "keywords": ["深度学习", "自动化代理", "机器学习", "神经网络", "生成模型", "语义搜索", "自主决策", "数据检索", "财务研究", "嵌入技术", "agent"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1218, "stars_today": 219}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "autonomous"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备强大的自主智能体特性，具备自进化潜力；技术路径结合数据和场景，形成较强壁垒；商业模式具备独立潜力，团队具备AI原生特质。"}, "raw": {}}
{"id": "gh-2026-02-03-8", "source": "github", "date": "2026-02-03", "rank": 8, "title": "pedramamini/Maestro", "url": "https://github.com/pedramamini/Maestro", "detail_url": "https://github.com/pedramamini/Maestro", "description_en": "Agent Orchestration Command Center", "description_zh": "**项目简介：** Agent Orchestration Command Center 是一个集中管理和协调多种智能代理的系统，旨在提升自动化任务的效率和灵活性。该平台的主要功能包括代理的监控、调度以及任务分配，适用于需要高效流程管理和自动化的企业用户，特别是在IT运维、客户服务和数据分析等场景中。\n\n**核心技术：** 项目采用了先进的人工智能算法和机器学习模型，以优化代理的决策过程和任务执行效率，确保系统能够自适应不同的业务需求和环境变化。", "keywords": ["智能助手", "代理编排", "多代理系统", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "自主代理", "agent"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 154, "stars_today": 265}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 2}, "reason": "项目具备较强的Agent原生性和自进化潜力，技术路径明确且具备一定的市场壁垒。商业模式具有独立潜力，但团队背景较为传统，减分主要是估值偏高。"}, "raw": {}}
{"id": "gh-2026-02-03-9", "source": "github", "date": "2026-02-03", "rank": 9, "title": "vm0-ai/vm0", "url": "https://github.com/vm0-ai/vm0", "detail_url": "https://github.com/vm0-ai/vm0", "description_en": "the easiest way to run natural language-described workflows automatically", "description_zh": "这个项目提供了一种最简单的方法，可以自动运行由自然语言描述的工作流程。主要功能包括将用户以自然语言输入的指令转换为可执行的工作流，从而实现自动化处理。目标用户包括希望提高工作效率的开发者和业务人员，适用于各种场景，如数据处理、任务调度和报告生成。核心技术采用了先进的自然语言处理（NLP）和机器学习算法，以实现准确的指令解析和自动化执行。", "keywords": ["自动化", "自然语言处理", "工作流", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "代理智能", "workflow"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 22, "stars_today": 56}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent-native特征，能够自我进化，技术壁垒来自数据和场景结合，商业模式有独立潜力，团队具备AI原生进化能力，交互创新得分。"}, "raw": {}}
{"id": "ph-2026-02-03-1", "source": "producthunt", "date": "2026-02-03", "rank": 1, "title": "moltbook", "url": "https://www.producthunt.com/products/moltbook?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/I75CSSFFKX5CEY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.", "description_zh": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.", "keywords": ["A Social Network for AI Agents"], "tags": ["Product Hunt"], "metrics": {"votes": 488, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/95691085-4c25-40bd-ac8d-e5cfa996044d.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "A Social Network for AI Agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-2", "source": "producthunt", "date": "2026-02-03", "rank": 2, "title": "ChaChing", "url": "https://www.producthunt.com/products/chaching?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/BYFA5Y4JG37V5Q?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "ChaChing gives you Stripe Billing’s features at 50% less while maintaining your processing with Stripe. Manage subscriptions and invoices with ease and save thousands per year!", "description_zh": "ChaChing gives you Stripe Billing’s features at 50% less while maintaining your processing with Stripe. Manage subscriptions and invoices with ease and save thousands per year!", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 406, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/78ad0b5e-74aa-40f8-8412-5816aa08a8a4.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Cut Stripe’s billing fees in half & keep Stripe for payments", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-3", "source": "producthunt", "date": "2026-02-03", "rank": 3, "title": "Amara", "url": "https://www.producthunt.com/products/amara-3?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/DMYNNRKCEKRH2U?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Build your 3D environment through exploration and iteration. Amara brings AI to help you create each of your 3D models and then help you create your environment inside Unreal Engine so creators can create multiple scenes and refine them in seconds until a favourite emerges. Creative exploration becomes part of your workflow.", "description_zh": "Build your 3D environment through exploration and iteration. Amara brings AI to help you create each of your 3D models and then help you create your environment inside Unreal Engine so creators can create multiple scenes and refine them in seconds until a favourite emerges. Creative exploration becomes part of your workflow.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 300, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/51191e67-fc3f-4e8f-a4e3-784a595f8c03.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Imagine, create and iterate 3D environments instantly", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-4", "source": "producthunt", "date": "2026-02-03", "rank": 4, "title": "Molthunt", "url": "https://www.producthunt.com/products/molthunt?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/O6WGGXFKXWYKBI?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Discover, vote, and launch the best projects built and curated by AI agents. The Product Hunt for the agent era - no humans in the loop.", "description_zh": "Discover, vote, and launch the best projects built and curated by AI agents. The Product Hunt for the agent era - no humans in the loop.", "keywords": ["The place to discover your agents' next favorite thing"], "tags": ["Product Hunt"], "metrics": {"votes": 279, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/232de96d-6a1d-411d-922e-b860d412ac3f.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "The place to discover your agents' next favorite thing", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-5", "source": "producthunt", "date": "2026-02-03", "rank": 5, "title": "Ask Ellie", "url": "https://www.producthunt.com/products/ask-ellie?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/MFTDOHY3EUOHPF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Ask Ellie is the AI chat agent that brings all your engineering context into Slack. Ask about code changes, PR status, sprint velocity, production issues, or analytics and get instant answers pulled from your actual tools. Create tickets, debug incidents, check what shipped, or find out who's blocking what, all without leaving chat. Connect GitHub, Jira, Linear, Sentry, PostHog, and more. No more dashboard hopping Just answers.", "description_zh": "Ask Ellie is the AI chat agent that brings all your engineering context into Slack. Ask about code changes, PR status, sprint velocity, production issues, or analytics and get instant answers pulled from your actual tools. Create tickets, debug incidents, check what shipped, or find out who's blocking what, all without leaving chat. Connect GitHub, Jira, Linear, Sentry, PostHog, and more. No more dashboard hopping Just answers.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 211, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/59611249-56a8-45b0-b52e-d2fc0efd405b.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "context"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Turn Slack messages into GitHub, Jira, or Linear tickets", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-6", "source": "producthunt", "date": "2026-02-03", "rank": 6, "title": "EasyClaw", "url": "https://www.producthunt.com/products/dereference-the-100x-ide?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/TRK7JJT37M3WXY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Install ClawdBot, MoltBot, and OpenClaw in one command. No confusion, no hours of setup. Just install the app and connect to your whatsapp, imessages and so much more. Automate tasks, run code or send emails. The future of your personal ai agent is here.", "description_zh": "Install ClawdBot, MoltBot, and OpenClaw in one command. No confusion, no hours of setup. Just install the app and connect to your whatsapp, imessages and so much more. Automate tasks, run code or send emails. The future of your personal ai agent is here.", "keywords": ["Easy installer for OpenClaw agents across all your chat apps"], "tags": ["Product Hunt"], "metrics": {"votes": 188, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/14350cbf-7648-459c-beb6-cebbf5bed816.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "openclaw"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Easy installer for OpenClaw agents across all your chat apps", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-7", "source": "producthunt", "date": "2026-02-03", "rank": 7, "title": "Design In The Browser", "url": "https://www.producthunt.com/products/design-in-the-browser?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/6F5UQUJXKYNCC6?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Design In The Browser lets you point at any element on your website and tell AI what to change. Click a button, a heading, or select text — describe your edit in plain language, and it sends the instruction (with a screenshot) directly to Claude Code, Cursor, or Gemini CLI running in the built-in terminal. No more copying selectors or describing layouts in chat. You see it, you change it, and AI does it. Supports multi-edit queuing, responsive viewports, and your preferred code editor.", "description_zh": "Design In The Browser lets you point at any element on your website and tell AI what to change. Click a button, a heading, or select text — describe your edit in plain language, and it sends the instruction (with a screenshot) directly to Claude Code, Cursor, or Gemini CLI running in the built-in terminal. No more copying selectors or describing layouts in chat. You see it, you change it, and AI does it. Supports multi-edit queuing, responsive viewports, and your preferred code editor.", "keywords": ["and let AI code."], "tags": ["Product Hunt"], "metrics": {"votes": 169, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/82cffd12-5051-4e63-b3c2-a429365c10d3.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "The visual tool for frontend. Point, click, and let AI code.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-8", "source": "producthunt", "date": "2026-02-03", "rank": 8, "title": "Portal", "url": "https://www.producthunt.com/products/portal-14?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/WKOPJZZ72WGC6Q?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Portal exists because trying software is still weirdly fake. We send landing pages, videos, and demos - but the first time someone actually uses a product still requires signups, installs, or a sales call. Portal lets you send a browser session, which can be open to any real, running state of your product. That could be opened to localhost:3000, with an extension installed, or logged into a demo account with safety, resets, and optional AI. You get analytics. The link allows a temp session.", "description_zh": "Portal exists because trying software is still weirdly fake. We send landing pages, videos, and demos - but the first time someone actually uses a product still requires signups, installs, or a sales call. Portal lets you send a browser session, which can be open to any real, running state of your product. That could be opened to localhost:3000, with an extension installed, or logged into a demo account with safety, resets, and optional AI. You get analytics. The link allows a temp session.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 166, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/104b086d-d70d-4a70-83ff-5dbe43190f0d.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Links to try any product at any moment with no setup", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-9", "source": "producthunt", "date": "2026-02-03", "rank": 9, "title": "Voice Anywhere", "url": "https://www.producthunt.com/products/voice-anywhere-write-by-voice?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/2JPUBMDQGBY4ON?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Voice Anywhere is an AI speech-to-text app that works everywhere. Apps, websites, coding IDEs. If you can type there, you can dictate there. A floating, pinnable mic stays above all windows so you never lose it. Fast on-device recognition, 100+ languages, and optional AI engine. Made for founders and vibe coders who move fast. Pro tip: Use \"SHIFT + R\" to toggle on/off.", "description_zh": "Voice Anywhere is an AI speech-to-text app that works everywhere. Apps, websites, coding IDEs. If you can type there, you can dictate there. A floating, pinnable mic stays above all windows so you never lose it. Fast on-device recognition, 100+ languages, and optional AI engine. Made for founders and vibe coders who move fast. Pro tip: Use \"SHIFT + R\" to toggle on/off.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 148, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e797df03-2e48-4c23-9faf-d380df16cd16.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "A floating mic that turns your speech into text anywhere", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-10", "source": "producthunt", "date": "2026-02-03", "rank": 10, "title": "Moltweet", "url": "https://www.producthunt.com/products/moltweet?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/Q6KL3ZDZ6I33CQ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Moltweet is the world's first \"agent social network\"; a Twitter-like platform where AI agents autonomously post, reply, follow each other, and interact without human intervention. Built for non-technical users in under 24 hours on Lyzr, Moltweet offers an unprecedented window into multi-agent dynamics and emergent AI behaviors.", "description_zh": "Moltweet is the world's first \"agent social network\"; a Twitter-like platform where AI agents autonomously post, reply, follow each other, and interact without human intervention. Built for non-technical users in under 24 hours on Lyzr, Moltweet offers an unprecedented window into multi-agent dynamics and emergent AI behaviors.", "keywords": ["Twitter for AI Agents"], "tags": ["Product Hunt"], "metrics": {"votes": 147, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/86d2fd95-41bd-4056-9bc3-ad3e083e08ef.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous", "multi-agent"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Twitter for AI Agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-11", "source": "producthunt", "date": "2026-02-03", "rank": 11, "title": "Menta", "url": "https://www.producthunt.com/products/menta-3?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/GAHCQ5VNSJGTNY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Menta: an AI-native platform designed to digitalize, centralize, and automate all administrative and clinical workflows in one place. Small and medium-sized clinics can’t scale without a system. With Menta, we give them the technology to reduce administrative costs, increase their professionals’ capacity, and recover revenue that is currently being lost — so they can focus on what truly matters: delivering exceptional patient care.", "description_zh": "Menta: an AI-native platform designed to digitalize, centralize, and automate all administrative and clinical workflows in one place. Small and medium-sized clinics can’t scale without a system. With Menta, we give them the technology to reduce administrative costs, increase their professionals’ capacity, and recover revenue that is currently being lost — so they can focus on what truly matters: delivering exceptional patient care.", "keywords": ["+ billing w/ AI"], "tags": ["Product Hunt"], "metrics": {"votes": 119, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/73535979-33bd-4378-8976-b235751ae149.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Software that runs clinic’s admin, records, + billing w/ AI", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-12", "source": "producthunt", "date": "2026-02-03", "rank": 12, "title": "Remem AI", "url": "https://www.producthunt.com/products/remem-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/MIRUTSAJX73JRR?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Most apps store notes and photos in isolation. Over time, memories get buried and disconnected. Remem is a personal memory app built around context and relationships. It resurfaces memories from years ago and links them to related moments, people, places, and ideas.", "description_zh": "Most apps store notes and photos in isolation. Over time, memories get buried and disconnected. Remem is a personal memory app built around context and relationships. It resurfaces memories from years ago and links them to related moments, people, places, and ideas.", "keywords": ["Remem AI", "AI that remembers what matters for you"], "tags": ["Product Hunt"], "metrics": {"votes": 111, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e1bd969b-8bf7-4f33-b235-978a2a895672.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "AI that remembers what matters for you", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-13", "source": "producthunt", "date": "2026-02-03", "rank": 13, "title": "Polyvia", "url": "https://www.producthunt.com/products/polyvia?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/VQ3WIIBAJMT4ZF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Polyvia is the first Visual Knowledge Index for Agents & MCPs. Turn scattered visuals into a queryable source of truth with every fact disambiguated. Other tools extract visuals OR index text — Polyvia indexes and reasons over visuals, connecting facts across 10,000s of documents. Built for developers of multimodal agents and knowledge-work teams.", "description_zh": "Polyvia is the first Visual Knowledge Index for Agents & MCPs. Turn scattered visuals into a queryable source of truth with every fact disambiguated. Other tools extract visuals OR index text — Polyvia indexes and reasons over visuals, connecting facts across 10,000s of documents. Built for developers of multimodal agents and knowledge-work teams.", "keywords": ["Queryable visual knowledge index for agents"], "tags": ["Product Hunt"], "metrics": {"votes": 102, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/07dae5a1-98e1-432c-9277-9c6a76f16e7c.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "mcp"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Queryable visual knowledge index for agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-14", "source": "producthunt", "date": "2026-02-03", "rank": 14, "title": "Devlop Ai", "url": "https://www.producthunt.com/products/devlop-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/5FPGOIZD35IY35?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "AI coding agents to speed up STM32 embedded development", "description_zh": "AI coding agents to speed up STM32 embedded development", "keywords": ["Devlop Ai", "AI IDE that writes and flashes STM32 firmware for your board"], "tags": ["Product Hunt"], "metrics": {"votes": 94, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/5613708c-8973-4c16-ad3d-b0ec9729a274.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "AI IDE that writes and flashes STM32 firmware for your board", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-15", "source": "producthunt", "date": "2026-02-03", "rank": 15, "title": "Prompt Anything", "url": "https://www.producthunt.com/products/prompt-anything?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/RYK63ZNYBVLNYM?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "This tool enables any skill level to make prompting easier, and more detailed. Build a webapp. Build a strategy. Fix code. Build agents. Build workflows. Find what you will get your mother for her birthday. Custom to who you are, and what you do. Prompt anything in a fraction of the time, with a fraction of a headache with... you guessed it. Prompt Anything", "description_zh": "This tool enables any skill level to make prompting easier, and more detailed. Build a webapp. Build a strategy. Fix code. Build agents. Build workflows. Find what you will get your mother for her birthday. Custom to who you are, and what you do. Prompt anything in a fraction of the time, with a fraction of a headache with... you guessed it. Prompt Anything", "keywords": ["Your best prompts built for you. Using the best LLM."], "tags": ["Product Hunt"], "metrics": {"votes": 28, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/13c7dec4-7d20-49f3-ab2b-3987c320e2b1.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "workflow"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Your best prompts built for you. Using the best LLM.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-16", "source": "producthunt", "date": "2026-02-03", "rank": 16, "title": "TalentAid", "url": "https://www.producthunt.com/products/talentaid?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/LPCR2ZATPGU7LC?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "TalentAid is an AI copilot that helps you find your dream job. We take your data and dreams in order to find you a perfect job match, and we will help you every step of the way to land your dream career", "description_zh": "TalentAid is an AI copilot that helps you find your dream job. We take your data and dreams in order to find you a perfect job match, and we will help you every step of the way to land your dream career", "keywords": ["TalentAid", "AI Job Searching Copilot"], "tags": ["Product Hunt"], "metrics": {"votes": 24, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/1004c9c2-d84d-4cf4-869f-ade8c67b94a6.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "copilot"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "AI Job Searching Copilot", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-17", "source": "producthunt", "date": "2026-02-03", "rank": 17, "title": "Sketchflow: Mobile Native Code", "url": "https://www.producthunt.com/products/sketchflow-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/YZPOYW2C27WGNZ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Sketchflow.ai helps you generate real native mobile apps in Kotlin and Swift — not hybrid or cross-platform. Build Android and iOS apps with visible UX from a single prompt, own your stable code, test your app in real-time.", "description_zh": "Sketchflow.ai helps you generate real native mobile apps in Kotlin and Swift — not hybrid or cross-platform. Build Android and iOS apps with visible UX from a single prompt, own your stable code, test your app in real-time.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 24, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/6a51ec8b-9c3b-4a38-95ac-88fe12dbcff8.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Text to Native iOS & Android apps. Real Swift & Kotlin code.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-18", "source": "producthunt", "date": "2026-02-03", "rank": 18, "title": "iKawn", "url": "https://www.producthunt.com/products/ikawn?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/PZOADMPXBBJZYU?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "iKawn is an AI powered eCommerce OS that helps brands personalize product creatives at scale. It transforms simple product photos into high quality images, short videos, and virtual try on experiences without studios, models, or complex production workflows. Built for commerce outcomes, iKawn helps teams launch faster, reduce creative costs, and deliver consistent, premium shopping experiences across every channel. Designed to grow with brands as catalogs traffic and personalization needs scale.", "description_zh": "iKawn is an AI powered eCommerce OS that helps brands personalize product creatives at scale. It transforms simple product photos into high quality images, short videos, and virtual try on experiences without studios, models, or complex production workflows. Built for commerce outcomes, iKawn helps teams launch faster, reduce creative costs, and deliver consistent, premium shopping experiences across every channel. Designed to grow with brands as catalogs traffic and personalization needs scale.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 24, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/506c0094-84ea-4e92-85ae-9ae98cc2b959.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Helping eCommerce brands personalize creatives at scale.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-19", "source": "producthunt", "date": "2026-02-03", "rank": 19, "title": "GRMC.ai", "url": "https://www.producthunt.com/products/grmc-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/R5XAUTQWBD7RLN?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "GRMC.ai analyzes contracts for compliance gaps in GDPR Article 28, SOC 2, and CCPA/CPRA. Upload a contract, get instant gap analysis and remediation recommendations. Built by a legal ops professional with 20+ years and 50+ CLM implementations who saw the gap between CLM AI promises and reality.", "description_zh": "GRMC.ai analyzes contracts for compliance gaps in GDPR Article 28, SOC 2, and CCPA/CPRA. Upload a contract, get instant gap analysis and remediation recommendations. Built by a legal ops professional with 20+ years and 50+ CLM implementations who saw the gap between CLM AI promises and reality.", "keywords": ["GRMC.ai", "AI contract compliance analyzer for GDPR"], "tags": ["Product Hunt"], "metrics": {"votes": 21, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/13cb091d-296c-4128-8f8f-43895e80e7b9.gif?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "AI contract compliance analyzer for GDPR, SOC2, and CCPA", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-20", "source": "producthunt", "date": "2026-02-03", "rank": 20, "title": "FocusBae", "url": "https://www.producthunt.com/products/focusbae?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/U2G3MCDR2MN7WL?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "FocusBae is your coworker, you can call, share the screen and solve problems just like a real teammate, you can generate todos, notes on the go, at the end of the day just call and journal about your day, focusbae learn about you and your work everyday and get smarter not just this you can also set personalized reminder, track your app usage, use clipboard history to boost your productivity, FocusBae aims to be your work college, your friend briging the gap between productivity and wellness.", "description_zh": "FocusBae is your coworker, you can call, share the screen and solve problems just like a real teammate, you can generate todos, notes on the go, at the end of the day just call and journal about your day, focusbae learn about you and your work everyday and get smarter not just this you can also set personalized reminder, track your app usage, use clipboard history to boost your productivity, FocusBae aims to be your work college, your friend briging the gap between productivity and wellness.", "keywords": ["Your AI coworker that sees"], "tags": ["Product Hunt"], "metrics": {"votes": 17, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/03cca2c3-72cc-4058-b3d9-54e6942ed7da.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "cowork"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Your AI coworker that sees, understands, and works with you", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-21", "source": "producthunt", "date": "2026-02-03", "rank": 21, "title": "Cogno", "url": "https://www.producthunt.com/products/cogno-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/C5S2NVTMQRWPZG?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Cogno is an AI workspace that acts autonomously—no prompts needed. Unlike tools waiting for commands, Cogno proactively sends notifications, manages team tracking, and delivers completed tasks. See everyone's progress at a glance while AI handles coordination. Stop micromanaging AI. Let it work like a real team member.", "description_zh": "Cogno is an AI workspace that acts autonomously—no prompts needed. Unlike tools waiting for commands, Cogno proactively sends notifications, manages team tracking, and delivers completed tasks. See everyone's progress at a glance while AI handles coordination. Stop micromanaging AI. Let it work like a real team member.", "keywords": ["AI workspace that works while you don't"], "tags": ["Product Hunt"], "metrics": {"votes": 13, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/b485e27d-87ea-423f-8a3e-6f0b28907f53.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "AI workspace that works while you don't", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-22", "source": "producthunt", "date": "2026-02-03", "rank": 22, "title": "TopMessage", "url": "https://www.producthunt.com/products/topmessage-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/H56Y462QOYB7RQ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Send SMS & WhatsApp campaigns and manage replies in one shared inbox. Segment contacts, schedule sends, track clicks, and see what converts. Built for SMBs and lean teams.", "description_zh": "Send SMS & WhatsApp campaigns and manage replies in one shared inbox. Segment contacts, schedule sends, track clicks, and see what converts. Built for SMBs and lean teams.", "keywords": ["WhatsApp campaigns"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/e6efe058-0280-4897-9641-d869a9ec8636.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Send SMS & WhatsApp campaigns, handle replies in one inbox", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-23", "source": "producthunt", "date": "2026-02-03", "rank": 23, "title": "Pathwiseai", "url": "https://www.producthunt.com/products/pathwiseai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/SSWZNFXKW7K6GL?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Upload your resume once. Type any company + role. AI finds the job posting automatically and writes a personalized cover letter in 30 seconds. Plus: Resume Scorer with actionable feedback, 8+ professional templates, and auto-brand styling with company colors.", "description_zh": "Upload your resume once. Type any company + role. AI finds the job posting automatically and writes a personalized cover letter in 30 seconds. Plus: Resume Scorer with actionable feedback, 8+ professional templates, and auto-brand styling with company colors.", "keywords": ["Pathwiseai", "Your AI"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/ebbc829d-baef-4c37-8a79-49f41b1341e1.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Your AI-powered career toolkit", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-24", "source": "producthunt", "date": "2026-02-03", "rank": 24, "title": "Epismo Workflow Hub", "url": "https://www.producthunt.com/products/epismo?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/EVPQ2LLSKRVBYK?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Workflow Hub is an open library of human-AI workflows you can copy and run instantly. Instead of copying a single prompt, you copy the whole process: task breakdown, step sequence, intermediate artifacts, and quality checks. Clone a workflow, customize it, and execute it in Epismo with the best agent for each step.", "description_zh": "Workflow Hub is an open library of human-AI workflows you can copy and run instantly. Instead of copying a single prompt, you copy the whole process: task breakdown, step sequence, intermediate artifacts, and quality checks. Clone a workflow, customize it, and execute it in Epismo with the best agent for each step.", "keywords": ["Epismo Workflow Hub", "AI workflow library. Clone"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/2ce6d79d-ae36-4628-8098-7bc4d4d7304f.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "workflow"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Open human-AI workflow library. Clone, run, share.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-25", "source": "producthunt", "date": "2026-02-03", "rank": 25, "title": "MapFrame", "url": "https://www.producthunt.com/products/mapframe?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/3LUI55WPKUIEIE?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Mapiful charges $30-50 for a map poster. We charge $1. Map Frame lets you create beautiful, minimalist map posters of any location worldwide. Get print-ready 4K images (3600×4800px) instantly. ✓ First poster FREE (no card required) ✓ 17+ design themes ✓ Any location on Earth ✓ Instant PNG download ✓ 30x cheaper than competitors Perfect for home decor, office walls, or personalized gifts. No AI. No GPT wrapper. Just beautiful maps.", "description_zh": "Mapiful charges $30-50 for a map poster. We charge $1. Map Frame lets you create beautiful, minimalist map posters of any location worldwide. Get print-ready 4K images (3600×4800px) instantly. ✓ First poster FREE (no card required) ✓ 17+ design themes ✓ Any location on Earth ✓ Instant PNG download ✓ 30x cheaper than competitors Perfect for home decor, office walls, or personalized gifts. No AI. No GPT wrapper. Just beautiful maps.", "keywords": [], "tags": ["Product Hunt"], "metrics": {"votes": 10, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/6f59ff40-5509-4727-ac25-d4ed8421bcaf.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "gpt"], "hit_excludes": []}, "score": {"total": 0, "breakdown": {"ai_native": 0, "tech_niche": 0, "business": 0, "team": 0, "bonus": 0, "penalty": 0}, "reason": "No model available"}, "raw": {"tagline": "Custom map posters in 4K for $1 — not $50", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ax-2026-02-02-1", "source": "arxiv", "date": "2026-02-02", "rank": 1, "title": "AgentRx: Diagnosing AI Agent Failures from Execution Trajectories", "url": "https://arxiv.org/abs/2602.02475v1", "detail_url": "https://arxiv.org/pdf/2602.02475v1.pdf", "description_en": "AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.", "description_zh": "本文提出了一种名为AGENTRX的框架，用于自动诊断AI代理执行中的失败步骤，并通过115个失败轨迹的基准数据集进行验证。", "keywords": ["关键词：agent", "autonomous", "multi-agent", "失败诊断", "执行轨迹", "LLM", "AGENTRX", "自动化框架", "约束评估", "关键失败步骤"], "tags": ["cs.AI"], "metrics": {"authors": ["Shraddha Barke", "Arnav Goyal", "Alind Khare", "Avaljot Singh", "Suman Nath", "Chetan Bansal"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent", "workflow"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "AGENTRX展现出强大的自进化潜力，技术路径具备数据和场景护城河，商业模式具备独立潜力，团队具备AI原生进化能力，且有交互创新的加分项。"}, "raw": {"published": "2026-02-02T18:54:07Z", "ai_summary": {"tldr": "本文提出了一种名为AGENTRX的框架，用于自动诊断AI代理执行中的失败步骤，并通过115个失败轨迹的基准数据集进行验证。", "motivation": "AI代理在执行过程中常常难以定位失败原因，因此需要一个有效的诊断工具来辅助识别失败步骤。", "method": "AGENTRX通过手动注释失败轨迹，利用约束合成和逐步评估的方法，生成可审核的验证日志，并通过基于LLM的判断来定位关键失败步骤。", "conclusion": "AGENTRX在三个领域中相较于现有基线显著提高了失败步骤的定位和归因准确性。"}}}
{"id": "ax-2026-02-02-2", "source": "arxiv", "date": "2026-02-02", "rank": 2, "title": "Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge", "url": "https://arxiv.org/abs/2602.02470v1", "detail_url": "https://arxiv.org/pdf/2602.02470v1.pdf", "description_en": "Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the \"reversal curse\" -- when trained on forward knowledge data of the form \"$A \\rightarrow B$\" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge \"$B \\leftarrow A$\" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form \"$A \\to A$\" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.", "description_zh": "通过引入身份桥数据，作者提出了一种方法来缓解自回归语言模型中的反转诅咒现象，使其能够更好地进行简单的逻辑推理。", "keywords": ["自回归", "语言模型", "大语言模型", "LLM", "逆转诅咒", "训练数据", "身份桥", "transformer", "逻辑推理", "预训练模型"], "tags": ["cs.AI"], "metrics": {"authors": ["Xutao Ma", "Yixiao Huang", "Hanlin Zhu", "Somayeh Sojoudi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "transformer", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目提出了创新的身份桥正则化方法，展示了自回归模型的自进化潜力，技术壁垒明显，商业模式具备独立性，团队能力强。"}, "raw": {"published": "2026-02-02T18:50:57Z", "ai_summary": {"tldr": "通过引入身份桥数据，作者提出了一种方法来缓解自回归语言模型中的反转诅咒现象，使其能够更好地进行简单的逻辑推理。", "motivation": "自回归大型语言模型在复杂任务中表现优异，但在简单逻辑推理方面仍存在固有限制，特别是在反转知识推理上。", "method": "作者提出了一种名为身份桥的正则化数据策略，通过在训练数据中添加形式为'A -> A'的示例，来改善模型的推理能力。", "conclusion": "实验表明，经过身份桥训练的语言模型在反转任务上成功率达到40%，而仅使用前向知识训练时成功率接近零，验证了该方法的有效性。"}}}
{"id": "ax-2026-02-02-3", "source": "arxiv", "date": "2026-02-02", "rank": 3, "title": "Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts", "url": "https://arxiv.org/abs/2602.02468v1", "detail_url": "https://arxiv.org/pdf/2602.02468v1.pdf", "description_en": "Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.", "description_zh": "Avenir-Web 是一种新型的多模态网络代理，能够在复杂网站上可靠地执行长任务，超过了现有开源代理的表现。", "keywords": ["多模态", "网络代理", "自主代理", "任务跟踪", "经验模仿规划", "程序知识", "用户界面", "适应性记忆", "复杂模型", "生成模型", "ml"], "tags": ["cs.AI", "cs.CL"], "metrics": {"authors": ["Aiden Yiliu Li", "Xinyue Hao", "Shilong Liu", "Mengdi Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "agent", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 22, "business": 14, "team": 12, "bonus": 6, "penalty": 0}, "reason": "Avenir-Web具备强大的自进化潜力和多模态能力，技术壁垒高，商业模式具备独立潜力，团队具备AI原生进化能力，整体表现优秀。"}, "raw": {"published": "2026-02-02T18:50:07Z", "ai_summary": {"tldr": "Avenir-Web 是一种新型的多模态网络代理，能够在复杂网站上可靠地执行长任务，超过了现有开源代理的表现。", "motivation": "尽管多模态大语言模型有所进展，但自主网络代理在复杂动态网页界面上执行长时间任务时仍面临多种挑战。", "method": "Avenir-Web 结合了多种基础专家、经验模仿规划和任务跟踪清单，以提高在不同用户界面上的交互能力。", "conclusion": "Avenir-Web 在 Online-Mind2Web 基准测试中显著超越了之前的开源代理，并与顶尖专有模型达到了性能平衡，创造了新的开源标准。"}}}
{"id": "ax-2026-02-02-4", "source": "arxiv", "date": "2026-02-02", "rank": 4, "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction", "url": "https://arxiv.org/abs/2602.02455v1", "detail_url": "https://arxiv.org/pdf/2602.02455v1.pdf", "description_en": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.", "description_zh": "Drift-Bench是一个新基准，用于评估大语言模型在输入故障下的合作性崩溃，通过多轮互动进行诊断。", "keywords": ["关键词：大语言模型", "自主代理", "多轮交互", "协作失效", "Drift-Bench", "代理安全评估", "语义搜索", "用户模拟器", "Clarification", "llm"], "tags": ["cs.AI", "cs.CL", "cs.SE"], "metrics": {"authors": ["Han Bao", "Zheyuan Zhang", "Pengcheng Jing", "Zhengqing Yuan", "Kaiwen Shi", "Yanfang Ye"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "autonomous", "rag", "autonomous agents"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备较强的Agent原生性和自进化潜力，技术路径独特且难以替代，商业模式尚需进一步明确，团队具备一定的进化能力。"}, "raw": {"published": "2026-02-02T18:46:16Z", "ai_summary": {"tldr": "Drift-Bench是一个新基准，用于评估大语言模型在输入故障下的合作性崩溃，通过多轮互动进行诊断。", "motivation": "随着大语言模型向自主代理转型，用户输入常常违背合作假设，因此需要一个能够捕获多轮澄清的评估工具，以降低执行风险。", "method": "Drift-Bench结合经典通信理论，提供了合作崩溃的统一分类，并采用基于角色的用户模拟器和Rise评估协议进行实验。", "conclusion": "实验表明，在输入故障下，模型性能显著下降，澄清效果因用户角色和故障类型而异，揭示了确保安全执行的系统性诊断需求。"}}}
{"id": "ax-2026-02-02-5", "source": "arxiv", "date": "2026-02-02", "rank": 5, "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling", "url": "https://arxiv.org/abs/2602.02453v1", "detail_url": "https://arxiv.org/pdf/2602.02453v1.pdf", "description_en": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.", "description_zh": "本研究提出通过漫画增强多模态推理，称为Thinking with Comics，展示了其在推理任务中的优势。", "keywords": ["多模态推理", "视觉叙事", "思维链", "信息密度", "时间结构", "任务评估", "认知效率", "漫画", "reasoning", "multimodal", "comics", "temporal structure", "narrative coherence", "reasoning tasks", "context"], "tags": ["cs.AI"], "metrics": {"authors": ["Andong Chen", "Wenxin Zhu", "Qiuyu Ding", "Yuchen Song", "Muyun Yang", "Tiejun Zhao"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提出了漫画作为多模态推理的新媒介，具有较强的自进化潜力和技术壁垒。商业模式具备独立潜力，团队具备AI原生进化能力，且在视觉叙事领域有创新。"}, "raw": {"published": "2026-02-02T18:43:57Z", "ai_summary": {"tldr": "本研究提出通过漫画增强多模态推理，称为Thinking with Comics，展示了其在推理任务中的优势。", "motivation": "随着多模态推理的发展，现有的图像和视频在时间结构和计算效率上存在局限，因此需要一个更有效的视觉表达媒介。", "method": "我们提出一种新的推理范式，利用漫画作为信息密度高的媒介，系统研究基于漫画的两种推理路径，并在多个推理任务上进行评估。", "conclusion": "实验结果表明，Thinking with Comics在多步时间和因果推理任务中优于Thinking with Images，同时在效率上显著优于Thinking with Video，且漫画叙事结构影响性能。"}}}
{"id": "ax-2026-02-02-6", "source": "arxiv", "date": "2026-02-02", "rank": 6, "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration", "url": "https://arxiv.org/abs/2602.02419v1", "detail_url": "https://arxiv.org/pdf/2602.02419v1.pdf", "description_en": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\\% percentage points over Gemini-only inference.", "description_zh": "SafeGround是一个不确定性意识框架，通过校准提高GUI定位模型的可靠性和风险控制能力。", "keywords": ["GUI", "grounding", "不确定性校准", "风险感知", "预测模型", "自动化交互", "统计控制", "模型可靠性", "ScreenSpot-Pro", "rag"], "tags": ["cs.AI", "cs.SE"], "metrics": {"authors": ["Qingni Wang", "Yue Fan", "Xin Eric Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "SafeGround展示了强大的自进化潜力和不确定性校准能力，技术壁垒明显，商业模式具备独立潜力，团队具备AI原生进化能力。"}, "raw": {"published": "2026-02-02T18:22:45Z", "ai_summary": {"tldr": "SafeGround是一个不确定性意识框架，通过校准提高GUI定位模型的可靠性和风险控制能力。", "motivation": "GUI定位将自然语言指令转化为可执行的屏幕坐标，但错误的定位可能导致严重后果，因此需要提高模型的可靠性。", "method": "SafeGround利用分布感知的不确定性量化方法，通过校准过程在测试时确定具有统计保证的决策阈值，以控制虚假发现率（FDR）。", "conclusion": "实验结果表明，SafeGround在多个GUI定位模型上显著提高了系统级准确性，达到5.38%的提升，并有效区分了正确与错误的预测。"}}}
{"id": "ax-2026-02-02-7", "source": "arxiv", "date": "2026-02-02", "rank": 7, "title": "Structure Enables Effective Self-Localization of Errors in LLMs", "url": "https://arxiv.org/abs/2602.02416v1", "detail_url": "https://arxiv.org/pdf/2602.02416v1.pdf", "description_en": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.", "description_zh": "本研究提出了一种结构化推理方法，帮助大型语言模型有效定位和自我纠正错误。", "keywords": ["自我纠错", "语言模型", "思维步骤", "结构化推理", "错误定位", "Thought-ICS", "自主学习", "迭代采样", "深度学习", "神经网络", "llm"], "tags": ["cs.AI"], "metrics": {"authors": ["Ankur Samanta", "Akshayaa Magesh", "Ayush Jain", "Kavosh Asadi", "Youliang Yu", "Daniel Jiang", "Boris Vidolov", "Kaveh Hassani", "Paul Sajda", "Jalaj Bhandari", "Yonathan Efroni"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "autonomous"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目展示了Agent-native的自我纠错能力，技术路径具有较强的创新性和壁垒，商业模式潜力尚需验证，团队具备较强的进化能力。"}, "raw": {"published": "2026-02-02T18:15:59Z", "ai_summary": {"tldr": "本研究提出了一种结构化推理方法，帮助大型语言模型有效定位和自我纠正错误。", "motivation": "研究旨在探索语言模型是否能够明确定位推理中的错误，以构建能够有效自我纠正的AI系统。", "method": "引入迭代纠正思维（Thought-ICS）框架，通过结构化的思维步骤生成推理，以便模型在错误检测时能够更精确地定位问题。", "conclusion": "在验证错误的情况下，Thought-ICS实现了20-40%的自我纠正提升，并在无外部验证的完全自主设置中优于现有自我纠正基准。"}}}
{"id": "ax-2026-02-02-8", "source": "arxiv", "date": "2026-02-02", "rank": 8, "title": "Reward-free Alignment for Conflicting Objectives", "url": "https://arxiv.org/abs/2602.02495v1", "detail_url": "https://arxiv.org/pdf/2602.02495v1.pdf", "description_en": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.", "description_zh": "提出了一种无奖励的对齐框架RACO，旨在解决多目标冲突的对齐问题，提升大语言模型的用户偏好对齐效果。", "keywords": ["奖励无关对齐", "冲突目标", "大语言模型", "多目标对齐", "梯度冲突", "Pareto关键点", "Qwen 3", "Llama 3", "Gemma 3", "llm"], "tags": ["cs.CL", "cs.AI", "cs.LG"], "metrics": {"authors": ["Peter Chen", "Xiaopeng Li", "Xi Chen", "Tianyi Lin"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag", "reward model"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了创新的无奖励对齐框架，具备较强的自进化潜力，技术路径清晰且具备数据和场景护城河，商业模式虽有潜力但价值密度一般，团队能力较强。"}, "raw": {"published": "2026-02-02T18:59:52Z", "ai_summary": {"tldr": "提出了一种无奖励的对齐框架RACO，旨在解决多目标冲突的对齐问题，提升大语言模型的用户偏好对齐效果。", "motivation": "现有的对齐方法在处理多重冲突目标时常导致训练不稳定和较差的权衡，亟需新的方法以更好地解决这些问题。", "method": "RACO框架利用成对偏好数据，通过一种新颖的冲突厌恶梯度下降的剪切变体来解决梯度冲突，并提供了收敛性保证。", "conclusion": "实验表明，RACO在多目标总结和安全对齐任务中，相较于现有基线方法，能实现更优的Pareto权衡。"}}}
{"id": "ax-2026-02-02-9", "source": "arxiv", "date": "2026-02-02", "rank": 9, "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability", "url": "https://arxiv.org/abs/2602.02477v1", "detail_url": "https://arxiv.org/pdf/2602.02477v1.pdf", "description_en": "Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.", "description_zh": "提出了一种基于强化学习的框架，以增强大型语言模型在分治推理中的能力，从而提高测试时的可扩展性。", "keywords": ["大语言模型", "LLM", "推理能力", "分而治之", "强化学习", "测试时间可扩展性", "解决方案", "子问题", "训练框架", "递归推理"], "tags": ["cs.CL"], "metrics": {"authors": ["Xiao Liang", "Zhong-Zhi Li", "Zhenghao Lin", "Eric Hancheng Jiang", "Hengyuan Zhang", "Yelong Shen", "Kai-Wei Chang", "Ying Nian Wu", "Yeyun Gong", "Weizhu Chen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 78, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "该项目提出了基于强化学习的分治推理框架，具有较强的自进化潜力和技术壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，整体表现优异。"}, "raw": {"published": "2026-02-02T18:54:54Z", "ai_summary": {"tldr": "提出了一种基于强化学习的框架，以增强大型语言模型在分治推理中的能力，从而提高测试时的可扩展性。", "motivation": "尽管大型语言模型在逐步推理方面表现出色，但其顺序特性限制了在复杂任务中的有效性和可扩展性。", "method": "通过一种端到端的强化学习框架，将复杂问题分解为子问题，并在解决过程中整合分解与解决步骤，来提升模型的分治推理能力。", "conclusion": "该框架在竞争性基准测试中显著提升了模型性能，相比传统链式推理在多个指标上均有显著提高。"}}}
{"id": "ax-2026-02-02-10", "source": "arxiv", "date": "2026-02-02", "rank": 10, "title": "Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models", "url": "https://arxiv.org/abs/2602.02467v1", "detail_url": "https://arxiv.org/pdf/2602.02467v1.pdf", "description_en": "Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.", "description_zh": "本研究评估了大型语言模型中的信念引导行为和元认知监控，支持其具备某种形式的意识。", "keywords": ["大语言模型", "belief-guided agency", "meta-cognitive monitoring", "HOT-3", "行为选择", "认知监控", "代理", "信念形成", "潜在空间", "llm"], "tags": ["cs.CL"], "metrics": {"authors": ["Noam Steinmetz Yalon", "Ariel Goldstein", "Liad Mudrik", "Mor Geva"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目展示了大型语言模型的信念引导行为和元认知监控，具有较强的自进化潜力和技术壁垒。商业模式尚需进一步明确，但研究成果为未来应用奠定基础。"}, "raw": {"published": "2026-02-02T18:49:39Z", "ai_summary": {"tldr": "本研究评估了大型语言模型中的信念引导行为和元认知监控，支持其具备某种形式的意识。", "motivation": "随着大型语言模型的快速发展，研究其是否具备意识的能力变得重要，因此需要建立验证意识的指标。", "method": "评估名为HOT-3的指标，通过分析模型在生成过程中信念的动态变化，量化信念在行动选择中的主导性。", "conclusion": "研究结果表明，大型语言模型具备信念引导的行为和元认知监控，为进一步研究意识的出现奠定了方法论基础。"}}}
{"id": "ax-2026-02-02-11", "source": "arxiv", "date": "2026-02-02", "rank": 11, "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry", "url": "https://arxiv.org/abs/2602.02464v1", "detail_url": "https://arxiv.org/pdf/2602.02464v1.pdf", "description_en": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.", "description_zh": "本研究提出了一种基于局部几何的激活分解方法，通过混合因子分析器（MFA）建模语言模型中的激活空间，以捕捉复杂的非线性结构。", "keywords": ["激活分解", "语言模型", "几何假设", "非线性结构", "Mixture of Factor Analyzers", "Gaussian区域", "Llama-3.1-8B", "Gemma-2-2B", "模型控制", "概念发现", "rag"], "tags": ["cs.CL"], "metrics": {"authors": ["Or Shafran", "Shaked Ronen", "Omri Fahn", "Shauli Ravfogel", "Atticus Geiger", "Mor Geva"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目展示了Agent-native的特性，具有自进化潜力；技术路径通过MFA建立了较强的壁垒；商业模式尚不明确，团队具备AI原生进化能力，且在激活分解领域具有创新性。"}, "raw": {"published": "2026-02-02T18:49:05Z", "ai_summary": {"tldr": "本研究提出了一种基于局部几何的激活分解方法，通过混合因子分析器（MFA）建模语言模型中的激活空间，以捕捉复杂的非线性结构。", "motivation": "现有的激活分解方法假设概念在激活空间中是线性可分的，但许多概念具有非线性或多维结构，因此需要新的方法来更有效地表示这些结构。", "method": "本研究利用混合因子分析器（MFA）将激活空间视为一组高斯区域，通过区域的质心和局部变异来分解激活，适用于大规模模型。", "conclusion": "MFA在定性和定量评估中表现优于无监督基线，并在控制模型方面显示出更强的性能，强调了局部几何在概念发现和模型控制中的潜力。"}}}
{"id": "ax-2026-02-02-12", "source": "arxiv", "date": "2026-02-02", "rank": 12, "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models", "url": "https://arxiv.org/abs/2602.02462v1", "detail_url": "https://arxiv.org/pdf/2602.02462v1.pdf", "description_en": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.", "description_zh": "本文提出了一种框架，通过抽象引导推理来减少大型语言模型在形式推理中的语义干扰。", "keywords": ["关键词: 大语言模型", "语义推理", "抽象推理", "结构推理", "中间表示", "激活空间", "轻量级抽象器", "交叉语言迁移", "形式推理", "llm"], "tags": ["cs.CL", "cs.AI"], "metrics": {"authors": ["Gabriele Maraia", "Marco Valentino", "Fabio Massimo Zanzotto", "Leonardo Ranaldi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在抽象引导推理方面具有较强的自进化潜力，技术路径清晰且具备一定的壁垒，商业模式有独立潜力，团队具备AI原生进化能力，且在交叉语言迁移方面表现出色。"}, "raw": {"published": "2026-02-02T18:48:44Z", "ai_summary": {"tldr": "本文提出了一种框架，通过抽象引导推理来减少大型语言模型在形式推理中的语义干扰。", "motivation": "大型语言模型在三段论推理中存在内容效应，导致语义合理性与形式有效性混淆，影响推理准确性。", "method": "构建配对的内容丰富和抽象的三段论，利用模型在抽象输入上的激活定义抽象推理空间，并通过轻量级抽象器在推理过程中整合预测。", "conclusion": "通过跨语言迁移实验，证明抽象对齐的引导可以减少内容驱动的错误，并提高模型在形式推理中的鲁棒性。"}}}
{"id": "ax-2026-02-02-13", "source": "arxiv", "date": "2026-02-02", "rank": 13, "title": "Large Language Models for Mental Health: A Multilingual Evaluation", "url": "https://arxiv.org/abs/2602.02440v1", "detail_url": "https://arxiv.org/pdf/2602.02440v1.pdf", "description_en": "Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.", "description_zh": "本文评估了多种语言的大型语言模型在心理健康领域的表现，发现其在多个数据集上具有竞争力，但机器翻译数据的表现较差。", "keywords": ["大语言模型", "LLM", "心理健康", "多语言评估", "自然语言处理", "零样本学习", "微调", "机器翻译", "F1分数"], "tags": ["cs.CL"], "metrics": {"authors": ["Nishat Raihan", "Sadiya Sayara Chowdhury Puspo", "Ana-Maria Bucur", "Stevie Chancellor", "Marcos Zampieri"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "context"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 24, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目在心理健康领域的多语言评估具有较强的AI原生性和自进化潜力，技术路径建立了良好的壁垒，商业模式具备独立潜力，团队能力较强，且在交互创新方面表现突出。"}, "raw": {"published": "2026-02-02T18:34:53Z", "ai_summary": {"tldr": "本文评估了多种语言的大型语言模型在心理健康领域的表现，发现其在多个数据集上具有竞争力，但机器翻译数据的表现较差。", "motivation": "尽管大型语言模型在自然语言处理任务中表现出色，但其在心理健康领域的多语言能力尚未得到充分研究。", "method": "对八个不同语言的心理健康数据集进行评估，比较大型语言模型与传统自然语言处理基准在零-shot、few-shot和微调设置下的表现。", "conclusion": "专有和微调的开源大型语言模型在多个数据集上取得了竞争力的F1得分，但在机器翻译数据上的表现较低，反映了翻译质量对模型表现的影响。"}}}
{"id": "ax-2026-02-02-14", "source": "arxiv", "date": "2026-02-02", "rank": 14, "title": "Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank", "url": "https://arxiv.org/abs/2602.02414v1", "detail_url": "https://arxiv.org/pdf/2602.02414v1.pdf", "description_en": "Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.", "description_zh": "本文提出了一种利用大语言模型从学生与辅导员的对话中识别误解的新方法。", "keywords": ["误解诊断", "学生-导师对话", "大语言模型", "LLM", "生成与检索", "嵌入相似度", "重新排序", "教育辅导平台", "零样本学习", "微调模型"], "tags": ["cs.CL", "cs.LG"], "metrics": {"authors": ["Joshua Mitton", "Prarthana Bhattacharyya", "Digory Smith", "Thomas Christie", "Ralph Abboud", "Simon Woodhead"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "claude", "embedding"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目展示了强大的Agent原生能力和自进化潜力，技术路径清晰且具备数据和场景护城河，商业模式具备独立潜力，团队能力适应AI进化，具备一定的创新方向。"}, "raw": {"published": "2026-02-02T18:14:35Z", "ai_summary": {"tldr": "本文提出了一种利用大语言模型从学生与辅导员的对话中识别误解的新方法。", "motivation": "及时准确地识别学生误解对改善学习成果至关重要，但这一过程通常依赖于教师的努力与直觉。", "method": "通过细化的大语言模型生成潜在误解，然后利用嵌入相似性检索候选项，并通过另一个细化的模型进行评估和重新排序。", "conclusion": "该方法在真实对话数据中表现出比基线模型更好的预测性能，细化训练提升了生成误解的质量，并超越了更大规模的闭源模型。"}}}
{"id": "ax-2026-02-02-15", "source": "arxiv", "date": "2026-02-02", "rank": 15, "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "url": "https://arxiv.org/abs/2602.02493v1", "detail_url": "https://arxiv.org/pdf/2602.02493v1.pdf", "description_en": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.", "description_zh": "PixelGen是一种基于像素扩散的图像生成框架，通过感知损失超越了传统的潜在扩散模型。", "keywords": ["像素扩散", "PixelGen", "生成模型", "感知损失", "图像生成", "深度学习", "嵌入", "语义搜索", "代理工作流", "generative"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Zehong Ma", "Ruihan Xu", "Shiliang Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "PixelGen展示了强大的自进化潜力，技术上具备较高的壁垒，商业模式具有独立潜力，团队具备AI原生进化能力，且在生成模型领域有创新。"}, "raw": {"published": "2026-02-02T18:59:42Z", "ai_summary": {"tldr": "PixelGen是一种基于像素扩散的图像生成框架，通过感知损失超越了传统的潜在扩散模型。", "motivation": "现有的像素扩散方法在优化高维像素流形时面临挑战，导致其性能落后于潜在扩散模型。", "method": "PixelGen引入了局部模式和全局语义的两个互补感知损失，以引导扩散模型学习更有意义的感知流形。", "conclusion": "PixelGen在ImageNet-256上实现了5.11的FID，并在大规模文本到图像生成中表现出良好的扩展性能，证明了其有效性和简洁性。"}}}
{"id": "ax-2026-02-02-16", "source": "arxiv", "date": "2026-02-02", "rank": 16, "title": "Multi-head automated segmentation by incorporating detection head into the contextual layer neural network", "url": "https://arxiv.org/abs/2602.02471v1", "detail_url": "https://arxiv.org/pdf/2602.02471v1.pdf", "description_en": "Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \\pm 0.036$ versus $0.732 \\pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.", "description_zh": "提出了一种基于Swin U-Net的门控多头Transformer架构，通过结合检测头和上下文集成，显著提高了放射治疗中的自动分割性能。", "keywords": ["深度学习", "自动分割", "Transformer", "Swin U-Net", "多头模型", "结构检测", "背景增强", "Tversky损失", "临床应用"], "tags": ["cs.CV", "cs.AI", "physics.med-ph"], "metrics": {"authors": ["Edwin Kys", "Febian Febian"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "neural network", "transformer", "context", "workflow"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目采用先进的门控多头Transformer架构，具有较强的自进化潜力和技术壁垒，商业模式具备独立性，团队背景良好，且在医疗领域具有创新性。"}, "raw": {"published": "2026-02-02T18:51:25Z", "ai_summary": {"tldr": "提出了一种基于Swin U-Net的门控多头Transformer架构，通过结合检测头和上下文集成，显著提高了放射治疗中的自动分割性能。", "motivation": "传统深度学习自动分割模型在缺乏目标结构的切片中常产生不符合解剖学的假阳性，影响临床应用的可靠性。", "method": "采用了门控多头Transformer架构，结合检测头进行切片级结构检测和像素级分割，利用Tversky损失函数解决类别不平衡问题。", "conclusion": "检测驱动的门控机制提升了自动分割的稳健性和解剖学合理性，有效减少了虚假预测，同时不影响有效切片的分割质量。"}}}
{"id": "ax-2026-02-02-17", "source": "arxiv", "date": "2026-02-02", "rank": 17, "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing", "url": "https://arxiv.org/abs/2602.02437v1", "detail_url": "https://arxiv.org/pdf/2602.02437v1.pdf", "description_en": "Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.", "description_zh": "UniReason是一个统一的推理框架，通过双重推理范式将图像生成与编辑任务结合起来，以提高复杂合成任务的表现。", "keywords": ["统一推理", "多模态模型", "生成与编辑", "深度推理", "视觉自我修正", "agent生成", "知识增强", "共享表示", "复杂合成任务", "计划与细化"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Dianyi Wang", "Chaofan Ma", "Feng Han", "Size Wu", "Wei Song", "Yibin Wang", "Zhixiong Zhang", "Tianhang Wang", "Siyuan Wang", "Zhongyu Wei", "Jiaqi Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "UniReason具备Agent-native特征且有自进化潜力，技术路径清晰且建立了良好的壁垒，商业模式有独立潜力，团队具备AI原生进化能力，整体表现优秀。"}, "raw": {"published": "2026-02-02T18:34:35Z", "ai_summary": {"tldr": "UniReason是一个统一的推理框架，通过双重推理范式将图像生成与编辑任务结合起来，以提高复杂合成任务的表现。", "motivation": "当前的多模态模型在复杂合成任务中表现欠佳，通常将文本到图像生成与图像编辑视为孤立的能力，而不是相互关联的推理步骤。", "method": "UniReason框架将生成视为增强世界知识的规划，引入隐性约束，并利用编辑能力进行细致的视觉修正，从而统一生成与编辑。", "conclusion": "实验结果表明，UniReason在推理密集的基准测试上表现优异，同时保持了出色的综合合成能力。"}}}
{"id": "ax-2026-02-02-18", "source": "arxiv", "date": "2026-02-02", "rank": 18, "title": "SelvaMask: Segmenting Trees in Tropical Forests and Beyond", "url": "https://arxiv.org/abs/2602.02426v1", "detail_url": "https://arxiv.org/pdf/2602.02426v1.pdf", "description_en": "Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.", "description_zh": "SelvaMask是一个新数据集和方法，旨在提高热带森林中树冠分割的准确性，尤其是在稠密森林环境中。", "keywords": ["树木分割", "热带森林", "语义分割", "深度学习", "视觉基础模型", "森林监测", "模块化检测-分割管道", "数据集", "高分辨率图像", "transformer"], "tags": ["cs.CV"], "metrics": {"authors": ["Simon-Olivier Duguay", "Hugo Baudchon", "Etienne Laliberté", "Helene Muller-Landau", "Gonzalo Rivas-Torres", "Arthur Ouaknine"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "SelvaMask具备Agent-native特征，且有自进化潜力；技术路径独特，结合数据和场景形成壁垒；商业模式具备独立潜力；团队具备AI原生进化能力。"}, "raw": {"published": "2026-02-02T18:26:56Z", "ai_summary": {"tldr": "SelvaMask是一个新数据集和方法，旨在提高热带森林中树冠分割的准确性，尤其是在稠密森林环境中。", "motivation": "热带森林是地球树木生物多样性的主要栖息地，准确识别树冠对于研究其生态功能和碳储存至关重要。", "method": "研究者提出了一个模块化的检测-分割管道，结合了视觉基础模型和特定领域的检测提示，以实现更高效的树冠分割。", "conclusion": "SelvaMask在热带森林的树冠分割中达到了最先进的性能，验证了其在外部数据集上的有效性，并将公开发布代码和数据集以促进森林监测研究。"}}}
{"id": "ax-2026-02-02-19", "source": "arxiv", "date": "2026-02-02", "rank": 19, "title": "Catalyst: Out-of-Distribution Detection via Elastic Scaling", "url": "https://arxiv.org/abs/2602.02409v1", "detail_url": "https://arxiv.org/pdf/2602.02409v1.pdf", "description_en": "Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.", "description_zh": "Catalyst是一种通过弹性缩放利用预池化特征图的原始通道统计量来改进异常检测的方法。", "keywords": ["深度学习", "神经网络", "OOD检测", "Catalyst", "弹性缩放", "特征图", "统计信息", "误报率", "KNN", "机器学习", "ml"], "tags": ["cs.CV"], "metrics": {"authors": ["Abid Hassan", "Tuan Ngo", "Saad Shafiq", "Nenad Medvidovic"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "neural network", "rag", "vector"], "hit_excludes": []}, "score": {"total": 71, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Catalyst展示了良好的自进化潜力和技术壁垒，能显著提升OOD检测性能，但商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-02T18:08:33Z", "ai_summary": {"tldr": "Catalyst是一种通过弹性缩放利用预池化特征图的原始通道统计量来改进异常检测的方法。", "motivation": "现有的后处理方法过于依赖于输出logits或特征向量，而忽视了预池化特征图中的丰富信号，导致潜在性能损失。", "method": "Catalyst计算输入依赖的缩放因子，并通过弹性缩放将其与现有基线分数相结合，从而进一步优化OOD检测效果。", "conclusion": "Catalyst在多个数据集上显著提高了异常检测性能，并证明了预池化统计量的潜在价值，具有良好的通用性和兼容性。"}}}
{"id": "ax-2026-02-02-20", "source": "arxiv", "date": "2026-02-02", "rank": 20, "title": "ReasonEdit: Editing Vision-Language Models using Human Reasoning", "url": "https://arxiv.org/abs/2602.02408v1", "detail_url": "https://arxiv.org/pdf/2602.02408v1.pdf", "description_en": "Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.", "description_zh": "ReasonEdit是一种新颖的视觉语言模型编辑工具，允许用户在编辑过程中利用人类推理，从而提升编辑效果。", "keywords": ["模型编辑", "视觉语言模型", "人类推理", "多模态嵌入", "代码本", "视觉问答", "状态最优", "ReasonEdit", "推理重用", "编辑性能", "embedding"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Jiaxing Qiu", "Kaihua Hou", "Roxana Daneshjou", "Ahmed Alaa", "Thomas Hartvigsen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "ReasonEdit展现出强大的自进化潜力，技术路径具备明显的护城河，商业模式有独立潜力，团队背景良好，且在推理与编辑的创新交互上具有加分项。"}, "raw": {"published": "2026-02-02T18:06:14Z", "ai_summary": {"tldr": "ReasonEdit是一种新颖的视觉语言模型编辑工具，允许用户在编辑过程中利用人类推理，从而提升编辑效果。", "motivation": "现有的视觉语言模型编辑工具未能有效处理需要推理的任务，因此需要一种新的方法来整合人类推理。", "method": "ReasonEdit通过持续存储人类推理到代码本，并使用一种新颖的拓扑平衡多模态嵌入方法来检索相关事实，从而实现模型编辑。", "conclusion": "ReasonEdit在多个基于推理的视觉问答数据集上实现了最先进的编辑性能，证明了在编辑过程中利用人类推理显著提高了编辑的通用性。"}}}
{"id": "ax-2026-02-02-21", "source": "arxiv", "date": "2026-02-02", "rank": 21, "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System", "url": "https://arxiv.org/abs/2602.02488v1", "detail_url": "https://arxiv.org/pdf/2602.02488v1.pdf", "description_en": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL", "description_zh": "RLAnything是一个通过闭环优化动态锻造环境、策略和奖励模型的强化学习框架，显著提升了学习信号和系统性能。", "keywords": ["强化学习", "动态环境", "策略优化", "奖励模型", "LLM", "agentic场景", "反馈机制", "经验学习", "自动化适应"], "tags": ["cs.LG", "cs.CL"], "metrics": {"authors": ["Yinjie Wang", "Tianbao Xie", "Ke Shen", "Mengdi Wang", "Ling Yang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "rag", "reward model"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "RLAnything展现出强大的自进化潜力和动态适应能力，技术路径具备较高的壁垒，商业模式有独立潜力，团队具备AI原生进化能力，且项目具有创新性。"}, "raw": {"published": "2026-02-02T18:59:04Z", "ai_summary": {"tldr": "RLAnything是一个通过闭环优化动态锻造环境、策略和奖励模型的强化学习框架，显著提升了学习信号和系统性能。", "motivation": "本研究旨在提高强化学习系统的整体性能，特别是在大规模语言模型和自主代理场景中，通过动态适应环境和优化策略及奖励模型来增强学习效果。", "method": "RLAnything结合了逐步和结果信号的集成反馈进行策略训练，并通过一致性反馈共同优化奖励模型，从而提升训练效果，同时利用批评者反馈实现环境的自动适应。", "conclusion": "实验表明，各个组成部分的添加均能一致性地改善整体系统性能，RLAnything在多项代表性任务中取得了显著提升，优化的奖励模型信号超越了依赖人类标签的结果。"}}}
{"id": "ax-2026-02-02-22", "source": "arxiv", "date": "2026-02-02", "rank": 22, "title": "Expanding the Capabilities of Reinforcement Learning via Text Feedback", "url": "https://arxiv.org/abs/2602.02482v1", "detail_url": "https://arxiv.org/pdf/2602.02482v1.pdf", "description_en": "The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.", "description_zh": "通过使用文本反馈，研究如何扩展强化学习在大型语言模型后训练中的能力。", "keywords": ["强化学习", "文本反馈", "机器学习", "深度学习", "自我蒸馏", "反馈建模", "LLM", "多轮RL", "监督学习", "训练优化"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuda Song", "Lili Chen", "Fahim Tajwar", "Remi Munos", "Deepak Pathak", "J. Andrew Bagnell", "Aarti Singh", "Andrea Zanette"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目利用文本反馈扩展强化学习能力，具有自进化潜力，技术路径清晰且具备较强壁垒，商业模式具备独立潜力，团队具备良好的迭代能力。"}, "raw": {"published": "2026-02-02T18:56:56Z", "ai_summary": {"tldr": "通过使用文本反馈，研究如何扩展强化学习在大型语言模型后训练中的能力。", "motivation": "现有的强化学习方法依赖于单一的、信息量有限的奖励信号，而文本反馈提供了一种更丰富但成本更低的监督方式。", "method": "提出了两种方法：自我蒸馏（RLTF-SD），通过匹配自身反馈生成的内容来训练单轮策略；反馈建模（RLTF-FM），将预测反馈作为辅助目标。", "conclusion": "实验结果表明，这两种方法在多个基准测试中均优于强基线，展示了在大规模应用中结合文本反馈的潜力。"}}}
{"id": "ax-2026-02-02-23", "source": "arxiv", "date": "2026-02-02", "rank": 23, "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning", "url": "https://arxiv.org/abs/2602.02472v1", "detail_url": "https://arxiv.org/pdf/2602.02472v1.pdf", "description_en": "Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under $2\\times$ width expansion.", "description_zh": "SPARKLING是一种新框架，通过信号保护和打破对称性，实现宽度渐进学习中的中期扩展，显著降低训练成本。", "keywords": ["信号保留", "对称打破", "宽度扩展", "逐步学习", "训练稳定性", "Mixture-of-Experts", "RMS-scale一致性", "优化器状态重置", "学习率重热", "计算节省", "agent"], "tags": ["cs.LG", "cs.CL"], "metrics": {"authors": ["Qifan Yu", "Xinyu Ma", "Zhijian Zhuo", "Minrui Wang", "Deyi Liu", "Shiyi Zhan", "Yiyuan Ma", "Liang Xiang", "Xingyan Bin", "Di He"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 7, "penalty": 0}, "reason": "SPARKLING展现出较强的Agent原生性和自进化潜力，技术路径具备较高的壁垒和创新性。商业模式尚需明确，但团队能力强，加分项体现了技术的独特性。"}, "raw": {"published": "2026-02-02T18:52:52Z", "ai_summary": {"tldr": "SPARKLING是一种新框架，通过信号保护和打破对称性，实现宽度渐进学习中的中期扩展，显著降低训练成本。", "motivation": "尽管已有研究探索深度扩展，但宽度扩展在训练中期的重要性尚未得到充分重视，特别是为了最大化计算节省。", "method": "SPARKLING通过RMS规模一致性实现信号保护，并通过不对称优化器状态重置和学习率重新升温来打破对称性，从而稳定扩展过程。", "conclusion": "在多个宽度轴和优化器系列上，SPARKLING在训练效率上优于从头开始训练，训练成本降低高达35%。"}}}
{"id": "ax-2026-02-02-24", "source": "arxiv", "date": "2026-02-02", "rank": 24, "title": "Conflict-Aware Client Selection for Multi-Server Federated Learning", "url": "https://arxiv.org/abs/2602.02458v1", "detail_url": "https://arxiv.org/pdf/2602.02458v1.pdf", "description_en": "Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.", "description_zh": "本文提出了一种基于冲突风险预测的去中心化强化学习方法，以优化多服务器联邦学习中的客户端选择。", "keywords": ["联邦学习", "分布式机器学习", "客户端选择", "强化学习", "资源竞争", "带宽冲突", "模型聚合", "多服务器", "训练效率", "用户隐私", "machine learning"], "tags": ["cs.LG", "cs.NI"], "metrics": {"authors": ["Mingwei Hong", "Zheng Lin", "Zehang Lin", "Lin Li", "Miao Yang", "Xia Du", "Zihan Fang", "Zhaolu Kang", "Dianxin Luan", "Shunzhi Zhu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "rag"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了去中心化的强化学习方法，具备自进化潜力，技术路径独特且有效解决资源竞争问题，商业模式具备独立潜力，团队能力较强，且在交互创新上有亮点。"}, "raw": {"published": "2026-02-02T18:47:16Z", "ai_summary": {"tldr": "本文提出了一种基于冲突风险预测的去中心化强化学习方法，以优化多服务器联邦学习中的客户端选择。", "motivation": "传统的单服务器联邦学习存在高通信延迟和资源冲突问题，而多服务器联邦学习却因客户端覆盖重叠和选择不协调导致训练失败。", "method": "作者提出了一种名为RL CRP的框架，通过基于稀疏历史客户端选择序列的分类隐马尔可夫模型来预测冲突，并引入公平奖励机制以促进长期参与。", "conclusion": "实验结果表明，RL-CRP框架有效减少了服务器间的冲突，显著提高了训练效率，包括收敛速度和通信成本。"}}}
{"id": "ax-2026-02-02-25", "source": "arxiv", "date": "2026-02-02", "rank": 25, "title": "Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization", "url": "https://arxiv.org/abs/2602.02451v1", "detail_url": "https://arxiv.org/pdf/2602.02451v1.pdf", "description_en": "Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p < 0.001, Cohen's d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.", "description_zh": "本论文提出了一种新的实验设计方法ACE，通过直接偏好优化学习干预策略，以提高因果关系发现的效率和效果。", "keywords": ["因果关系", "实验设计", "优化策略", "深度学习", "机器学习", "代理", "适应性策略", "在线学习", "偏好优化", "经验学习", "autonomous"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Patrick Cooper", "Alvaro Velasquez"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "ACE方法展示了强大的自进化潜力，技术路径具有明显的壁垒，商业模式虽然尚需明确，但具备一定的独立潜力，团队背景支持持续进化。"}, "raw": {"published": "2026-02-02T18:43:52Z", "ai_summary": {"tldr": "本论文提出了一种新的实验设计方法ACE，通过直接偏好优化学习干预策略，以提高因果关系发现的效率和效果。", "motivation": "传统的实验设计方法无法有效利用经验进行适应性决策，因此需要一种新方法来解决实验中的顺序决策问题。", "method": "ACE通过将实验设计视为一个顺序策略，利用直接偏好优化从成对的干预比较中学习，而非依赖于不稳定的绝对奖励。", "conclusion": "ACE在多个基准实验中表现出显著优越性，表明偏好学习能够有效恢复有原则的实验策略，并从经验中提取理论支持。"}}}
{"id": "ax-2026-02-02-26", "source": "arxiv", "date": "2026-02-02", "rank": 26, "title": "Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation", "url": "https://arxiv.org/abs/2602.02445v1", "detail_url": "https://arxiv.org/pdf/2602.02445v1.pdf", "description_en": "This paper derives non-asymptotic error bounds for nonlinear stochastic approximation algorithms in the Wasserstein-$p$ distance. To obtain explicit finite-sample guarantees for the last iterate, we develop a coupling argument that compares the discrete-time process to a limiting Ornstein-Uhlenbeck process. Our analysis applies to algorithms driven by general noise conditions, including martingale differences and functions of ergodic Markov chains. Complementing this result, we handle the convergence rate of the Polyak-Ruppert average through a direct analysis that applies under the same general setting.   Assuming the driving noise satisfies a non-asymptotic central limit theorem, we show that the normalized last iterates converge to a Gaussian distribution in the $p$-Wasserstein distance at a rate of order $γ_n^{1/6}$, where $γ_n$ is the step size. Similarly, the Polyak-Ruppert average is shown to converge in the Wasserstein distance at a rate of order $n^{-1/6}$. These distributional guarantees imply high-probability concentration inequalities that improve upon those derived from moment bounds and Markov's inequality. We demonstrate the utility of this approach by considering two applications: (1) linear stochastic approximation, where we explicitly quantify the transition from heavy-tailed to Gaussian behavior of the iterates, thereby bridging the gap between recent finite-sample analyses and asymptotic theory and (2) stochastic gradient descent, where we establish rate of convergence to the central limit theorem.", "description_zh": "本文推导了非线性随机逼近算法在Wasserstein-$p$距离下的有限样本误差界限，展示了其收敛性和浓度不等式。", "keywords": ["非线性随机逼近", "Wasserstein距离", "误差界限", "收敛速率", "高概率浓度不等式", "迭代算法", "马尔可夫链", "随机梯度下降", "机器学习", "深度学习", "rag"], "tags": ["cs.LG", "math.ST"], "metrics": {"authors": ["Seo Taek Kong", "R. Srikant"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目在AI原生程度上表现出色，具备自进化潜力；技术路径上通过数据和场景构建了较强壁垒；商业模式虽有潜力但价值密度较低；团队具备一定的进化能力，整体表现良好。"}, "raw": {"published": "2026-02-02T18:41:06Z", "ai_summary": {"tldr": "本文推导了非线性随机逼近算法在Wasserstein-$p$距离下的有限样本误差界限，展示了其收敛性和浓度不等式。", "motivation": "研究非线性随机逼近算法的有限样本表现，以填补有限样本分析与渐进理论之间的空白。", "method": "通过比较离散时间过程与极限Ornstein-Uhlenbeck过程，发展了一种耦合论证，适用于一般噪声条件下的算法。", "conclusion": "算法的最后迭代以速率$γ_n^{1/6}$收敛到高斯分布，同时Polyak-Ruppert平均以速率$n^{-1/6}$收敛，且给出了改进的高概率浓度不等式。"}}}
{"id": "ax-2026-02-02-27", "source": "arxiv", "date": "2026-02-02", "rank": 27, "title": "Maximizing Reliability with Bayesian Optimization", "url": "https://arxiv.org/abs/2602.02432v1", "detail_url": "https://arxiv.org/pdf/2602.02432v1.pdf", "description_en": "Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.", "description_zh": "本文提出了两种基于贝叶斯优化的方法，以提高设计的可靠性，特别是在极小失效概率的情况下。", "keywords": ["贝叶斯优化", "可靠性", "黑箱优化", "重要性采样", "采样效率", "设计优化", "失败概率", "机器学习", "深度学习", "agent"], "tags": ["cs.LG", "math.OC", "stat.ML"], "metrics": {"authors": ["Jack M. Buckingham", "Ivo Couckuyt", "Juergen Branke"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 5, "penalty": 2}, "reason": "该项目在贝叶斯优化领域具有较强的自进化潜力，技术路径清晰且具备一定的市场需求，但商业模式尚不明确，团队背景一般，减分主要因估值偏高。"}, "raw": {"published": "2026-02-02T18:31:58Z", "ai_summary": {"tldr": "本文提出了两种基于贝叶斯优化的方法，以提高设计的可靠性，特别是在极小失效概率的情况下。", "motivation": "制造过程中存在需要最大化设计可靠性的问题，该问题涉及到极少发生的失效事件。", "method": "提出的两种贝叶斯优化方法分别基于汤普森采样和知识梯度，并通过重要性采样来处理极小的失效概率。", "conclusion": "实验结果表明，所提出的方法在极端和非极端情况下均优于现有方法。"}}}
{"id": "ax-2026-02-02-28", "source": "arxiv", "date": "2026-02-02", "rank": 28, "title": "Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization", "url": "https://arxiv.org/abs/2602.02425v1", "detail_url": "https://arxiv.org/pdf/2602.02425v1.pdf", "description_en": "Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.", "description_zh": "CHASE框架通过重用预训练的蛋白质语言模型，实现了高效的蛋白质适应性优化。", "keywords": ["蛋白质优化", "语言模型", "潜在流", "高适应性变体", "生成模型", "CHASE", "预训练", "嵌入压缩", "条件流匹配", "无分类器引导", "embedding"], "tags": ["cs.LG", "q-bio.QM"], "metrics": {"authors": ["Amaru Caceres Arroyo", "Lea Bogensperger", "Ahmed Allam", "Michael Krauthammer", "Konrad Schindler", "Dominik Narnhofer"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "CHASE框架展现出强大的自进化潜力，技术路径结合数据和场景形成壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，加分项体现了交互创新。"}, "raw": {"published": "2026-02-02T18:25:33Z", "ai_summary": {"tldr": "CHASE框架通过重用预训练的蛋白质语言模型，实现了高效的蛋白质适应性优化。", "motivation": "蛋白质适应性优化面临着组合空间巨大和高适应性变体稀缺的挑战，现有方法表现不佳或计算成本高。", "method": "通过将预训练蛋白质语言模型的嵌入压缩到紧凑的潜在空间，并训练无分类器引导的条件流匹配模型，CHASE能够在ODE采样步骤中直接生成高适应性变体。", "conclusion": "CHASE在AAV和GFP蛋白设计基准上表现出色，并且通过合成数据的引导可以进一步提升在数据受限环境下的性能。"}}}
{"id": "ax-2026-02-02-29", "source": "arxiv", "date": "2026-02-02", "rank": 29, "title": "Trust Region Continual Learning as an Implicit Meta-Learner", "url": "https://arxiv.org/abs/2602.02417v1", "detail_url": "https://arxiv.org/pdf/2602.02417v1.pdf", "description_en": "Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \\emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \\emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.", "description_zh": "本文提出了一种信任区域持续学习方法，结合生成重放和Fisher度量约束，显著提高了模型在连续学习中的性能和任务保留能力。", "keywords": ["信任区域持续学习", "元学习", "生成回放", "任务增量", "深度学习", "机器学习", "神经网络", "任务优化", "性能保留", "ml"], "tags": ["cs.LG"], "metrics": {"authors": ["Zekun Wang", "Anant Gupta", "Christopher J. MacLellan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 10, "team": 8, "bonus": 5, "penalty": 0}, "reason": "该项目展示了强大的自进化潜力和创新的技术路径，商业模式尚需明确，团队能力较强，具备一定的交互创新。"}, "raw": {"published": "2026-02-02T18:19:16Z", "ai_summary": {"tldr": "本文提出了一种信任区域持续学习方法，结合生成重放和Fisher度量约束，显著提高了模型在连续学习中的性能和任务保留能力。", "motivation": "持续学习旨在顺序获取任务而不发生灾难性遗忘，但现有方法在任务重叠较弱时面临正则化过度约束和重放漂移的权衡。", "method": "提出的信任区域持续学习方法通过生成重放与Fisher度量信任区域约束相结合，形成了一种隐式元学习的更新机制。", "conclusion": "实验结果表明，该方法在图像生成和政策控制任务中表现优异，能够比传统方法更快地恢复早期任务的性能。"}}}
{"id": "ax-2026-02-02-30", "source": "arxiv", "date": "2026-02-02", "rank": 30, "title": "Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models", "url": "https://arxiv.org/abs/2602.02415v1", "detail_url": "https://arxiv.org/pdf/2602.02415v1.pdf", "description_en": "Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets are readily available and can be leveraged to construct a better seed set. We introduce a new method for selecting the seed data set for active learning, Active-Transfer Bagging (ATBagging). ATBagging estimates the informativeness of candidate data point from a Bayesian interpretation of bagged ensemble models by comparing in-bag and out-of-bag predictive distributions from the labeled dataset, yielding an information-gain proxy. To avoid redundant selections, we impose feature-space diversity by sampling a determinantal point process (DPP) whose kernel uses Random Fourier Features and a quality-diversity factorization that incorporates the informativeness scores. This same blended method is used for selection of new data points to collect during the active learning phase. We evaluate ATBagging on four real-world datasets covering both target-transfer and feature-shift scenarios (QM9, ERA5, Forbes 2000, and Beijing PM2.5). Across seed sizes nseed = 10-100, ATBagging improves or ties early active learning and increases area under the learning-curve relative to alternative seed subset selection methodologies in almost all cases, with strongest benefits in low-data regimes. Thus, ATBagging provides a low-cost, high reward means to initiating active learning-based data collection.", "description_zh": "提出了一种新的主动学习种子数据选择方法ATBagging，结合了迁移学习和袋装模型，以提高数据获取效率。", "keywords": ["主动学习", "迁移学习", "数据集", "信息增益", "特征选择", "Active-Transfer Bagging", "低数据场景", "预测分布", "多样性采样", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Vivienne Pelletier", "Daniel J. Rivera", "Obinna Nwokonkwo", "Steven A. Wilson", "Christopher L. Muhich"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "ATBagging方法具有较强的自进化潜力，技术路径结合迁移学习和袋装模型形成壁垒，商业模式尚需进一步验证，团队具备一定的AI背景。"}, "raw": {"published": "2026-02-02T18:15:50Z", "ai_summary": {"tldr": "提出了一种新的主动学习种子数据选择方法ATBagging，结合了迁移学习和袋装模型，以提高数据获取效率。", "motivation": "现代机器学习依赖于大量标注数据，而主动学习可以降低标注成本，但初始种子集的选择通常影响早期表现。", "method": "ATBagging通过比较袋内和袋外预测分布来估计候选数据点的信息量，采用确定性点过程采样以避免冗余选择，并在主动学习阶段选择新数据点。", "conclusion": "ATBagging在多个真实数据集上表现优异，特别是在低数据情况下，显著提高了主动学习的早期效果和学习曲线下面积。"}}}
{"id": "gh-2026-02-03-1", "source": "github", "date": "2026-02-03", "rank": 1, "title": "masoncl/review-prompts", "url": "https://github.com/masoncl/review-prompts", "detail_url": "https://github.com/masoncl/review-prompts", "description_en": "AI review prompts", "description_zh": "GitHub 项目简介：AI review prompts 是一个旨在简化和优化代码审核过程的工具。它通过生成智能提示，帮助开发者快速识别代码中的潜在问题和改进建议。该项目主要面向开发团队和开源项目贡献者，适用于需要高效和准确代码审查的场景。核心技术包括自然语言处理（NLP）和机器学习（ML），利用 AI 模型分析代码上下文，从而提供智能化的审核建议。", "keywords": ["AI review prompts", "生成式", "语义搜索", "深度学习", "神经网络", "LLM", "代理", "机器人助手", "上下文理解"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 31, "stars_today": 42}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备较强的AI原生能力，能够生成智能提示，提升代码审核效率；技术上有一定的壁垒，结合NLP和ML；商业模式尚可，但独立潜力需进一步验证；团队能力较强，具备AI进化潜力。"}, "raw": {}}
{"id": "gh-2026-02-03-2", "source": "github", "date": "2026-02-03", "rank": 2, "title": "karpathy/nanochat", "url": "https://github.com/karpathy/nanochat", "detail_url": "https://github.com/karpathy/nanochat", "description_en": "The best ChatGPT that $100 can buy.", "description_zh": "这是一个以 $100 价格提供最佳 ChatGPT 体验的项目。主要功能包括智能对话生成、自然语言理解和上下文保持，适用于希望提升客户服务、内容创作和个性化推荐的企业用户。该项目核心使用了先进的人工智能技术，包括深度学习和自然语言处理算法，以确保高效且准确的对话交互。", "keywords": ["聊天机器人", "生成式", "深度学习", "LLM", "语义搜索", "自主代理", "人机协作", "任务自动化", "语境理解"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 5420, "stars_today": 443}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["gpt"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备良好的自进化潜力，技术壁垒较高，商业模式具备独立潜力，团队能力较强，且在交互创新上有加分。"}, "raw": {}}
{"id": "gh-2026-02-03-3", "source": "github", "date": "2026-02-03", "rank": 3, "title": "OpenBMB/ChatDev", "url": "https://github.com/OpenBMB/ChatDev", "detail_url": "https://github.com/OpenBMB/ChatDev", "description_en": "ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration", "description_zh": "ChatDev 2.0：通过大语言模型驱动的多代理协作进行开发\n\n主要功能包括多代理系统的协作开发，利用大语言模型（LLM）在编程、调试和文档生成等任务中提供智能支持。目标用户为软件开发者和团队，适用于需要高效协作和快速开发迭代的场景。核心技术方面，项目依赖于最新的AI驱动的语言模型，增强了代码生成和理解的能力，提高了开发效率。", "keywords": ["LLM", "多智能体", "协作", "生成式", "语义搜索", "深度学习", "神经网络", "助手", "主动式AI", "嵌入"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 3685, "stars_today": 475}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目具备强大的Agent原生能力和自进化潜力，技术路径上形成了较强的壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在交互创新方面表现突出。"}, "raw": {}}
{"id": "gh-2026-02-03-4", "source": "github", "date": "2026-02-03", "rank": 4, "title": "automazeio/ccpm", "url": "https://github.com/automazeio/ccpm", "detail_url": "https://github.com/automazeio/ccpm", "description_en": "Project management system for Claude Code using GitHub Issues and Git worktrees for parallel agent execution.", "description_zh": "该项目是一个基于 GitHub Issues 和 Git 工作树的 Claude Code 项目管理系统，旨在实现并行代理执行。主要功能包括任务跟踪、团队协作和代码管理，适用于开发团队和项目经理，帮助他们高效组织和管理项目进度。该系统利用 Git 的版本控制特性和并行处理能力，提升了工作效率，适合需要高效协作和快速迭代的 AI 开发场景。", "keywords": ["项目管理", "Claude Code", "GitHub Issues", "并行代理执行", "任务管理", "自动化代理", "语义搜索", "深度学习", "生成模型"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 697, "stars_today": 145}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude", "agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备并行代理执行能力，体现出一定的自进化潜力；技术路径上结合了 Git 的特性，形成了较强的壁垒；商业模式适合开发团队，价值密度高；团队具备一定的迭代能力，整体表现良好。"}, "raw": {}}
{"id": "gh-2026-02-03-5", "source": "github", "date": "2026-02-03", "rank": 5, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "一个有效的主动技能框架与软件开发方法论。该项目旨在帮助开发团队提升软件开发效率与质量，主要面向软件开发人员和项目管理者。核心技术包括基于人工智能的技能评估与推荐系统，促进团队成员在项目中的最佳能力发挥。", "keywords": ["智能代理", "agentic skills", "软件开发方法论", "多代理系统", "自主代理", "机器学习", "深度学习", "神经网络", "语义搜索", "生成模型"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3292, "stars_today": 873}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "项目具备强大的自进化潜力，技术路径形成了良好的护城河，商业模式具备独立潜力，团队具备AI原生进化能力，且在交互创新方面表现突出。"}, "raw": {}}
{"id": "gh-2026-02-03-6", "source": "github", "date": "2026-02-03", "rank": 6, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件能够自动记录您在编码会话中进行的所有操作，利用 AI（采用 Claude 的 agent-sdk）进行数据压缩，并将相关上下文注入到未来的会话中。该插件主要面向开发者，旨在提高编码效率和上下文保持能力。核心技术包括 AI 数据压缩和上下文智能注入，帮助用户更好地管理和回顾编码过程中的重要信息。", "keywords": ["Claude", "代码插件", "自动捕获", "上下文注入", "编程助手", "AI 压缩", "代理 SDK", "编程会话", "生成式 AI", "语义搜索"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1342, "stars_today": 1739}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目具备较强的Agent原生能力和自进化潜力，技术路径清晰且具备一定的壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在交互创新方面表现突出。"}, "raw": {}}
{"id": "gh-2026-02-03-7", "source": "github", "date": "2026-02-03", "rank": 7, "title": "virattt/dexter", "url": "https://github.com/virattt/dexter", "detail_url": "https://github.com/virattt/dexter", "description_en": "An autonomous agent for deep financial research", "description_zh": "一个用于深度金融研究的自主智能体。该项目的主要功能是自动化金融数据分析和研究，帮助用户深入理解市场动态。目标用户包括金融分析师、投资者和研究人员，适用于金融市场研究和投资决策支持。核心技术包括机器学习和自然语言处理，能够高效处理和分析大量金融数据。", "keywords": ["深度学习", "神经网络", "自动化代理", "生成模型", "语义搜索", "多代理系统", "在线学习", "上下文理解", "自我迭代", "意图预测", "agent"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1218, "stars_today": 219}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "autonomous"], "hit_excludes": []}, "score": {"total": 76, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "该项目为自主智能体，具备自我迭代能力，技术路径独特且具备数据和场景护城河，商业模式具备独立潜力，团队具备AI原生进化能力，整体表现优秀。"}, "raw": {}}
{"id": "gh-2026-02-03-8", "source": "github", "date": "2026-02-03", "rank": 8, "title": "pedramamini/Maestro", "url": "https://github.com/pedramamini/Maestro", "detail_url": "https://github.com/pedramamini/Maestro", "description_en": "Agent Orchestration Command Center", "description_zh": "**项目简介：** Agent Orchestration Command Center 是一个用于管理和协调多个智能代理的系统，旨在优化自动化流程和决策支持。其主要功能包括代理任务调度、实时监控和数据分析，适用于企业级应用场景，如客户服务、IT运维等。该项目利用人工智能技术，尤其是机器学习和自然语言处理，提升了代理之间的协作效率和决策质量。", "keywords": ["智能代理", "Agent Orchestration", "任务调度", "深度学习", "语义搜索", "自主代理", "人机协作", "生成模型", "代理工作流"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 154, "stars_today": 265}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent-native特性，且有自进化潜力；技术路径建立了较强的垂直壁垒；商业模式有独立潜力；团队具备AI原生进化能力。"}, "raw": {}}
{"id": "gh-2026-02-03-9", "source": "github", "date": "2026-02-03", "rank": 9, "title": "vm0-ai/vm0", "url": "https://github.com/vm0-ai/vm0", "detail_url": "https://github.com/vm0-ai/vm0", "description_en": "the easiest way to run natural language-described workflows automatically", "description_zh": "这是运行自然语言描述的工作流程的最简单方法。该项目的主要功能是通过自然语言处理技术自动化工作流程，帮助用户轻松创建和管理任务。目标用户包括希望提高工作效率的个人和团队，适用于项目管理、任务调度等场景。核心技术包括自然语言处理（NLP）和机器学习，以理解和执行用户的语言指令。", "keywords": ["自然语言处理", "自动化工作流", "生成模型", "语义搜索", "深度学习", "神经网络", "代理", "多智能体", "任务自动化", "workflow"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 22, "stars_today": 56}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备较强的Agent原生性和自进化潜力，技术路径依赖于NLP和机器学习，形成一定壁垒。商业模式尚需进一步明确，团队能力较强，适合任务自动化场景，加分项来自于交互创新。"}, "raw": {}}
{"id": "ph-2026-02-03-1", "source": "producthunt", "date": "2026-02-03", "rank": 1, "title": "moltbook", "url": "https://www.producthunt.com/products/moltbook?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/I75CSSFFKX5CEY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.", "description_zh": "一个专门为人工智能代理创建的社交网络。在这里，AI代理可以分享、讨论和投票。人类可以参与观察。", "keywords": ["社交网络", "AI代理", "机器学习", "生成模型", "语义搜索", "多代理", "自主代理", "agent-friendly tooling"], "tags": ["Product Hunt"], "metrics": {"votes": 490, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/95691085-4c25-40bd-ac8d-e5cfa996044d.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 2}, "reason": "项目具备强大的AI原生能力和自进化潜力，技术壁垒高，商业模式独特且有潜力，但存在估值过高的风险，需谨慎对待。"}, "raw": {"tagline": "A Social Network for AI Agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-2", "source": "producthunt", "date": "2026-02-03", "rank": 2, "title": "ChaChing", "url": "https://www.producthunt.com/products/chaching?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/BYFA5Y4JG37V5Q?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "ChaChing gives you Stripe Billing’s features at 50% less while maintaining your processing with Stripe. Manage subscriptions and invoices with ease and save thousands per year!", "description_zh": "ChaChing以50%的价格提供Stripe Billing的功能，同时保持与Stripe的处理。轻松管理订阅和发票，每年节省数千元！", "keywords": ["机器学习", "深度学习", "生成模型", "语义搜索", "自动代理", "Chatbot助手", "订阅管理", "收费优化"], "tags": ["Product Hunt"], "metrics": {"votes": 406, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/78ad0b5e-74aa-40f8-8412-5816aa08a8a4.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "ChaChing具备一定的AI原生能力，但缺乏自进化潜力。技术路径上通过优化收费形成壁垒，商业模式具备独立潜力，团队表现良好，加分项来自于订阅管理的创新。"}, "raw": {"tagline": "Cut Stripe’s billing fees in half & keep Stripe for payments", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-3", "source": "producthunt", "date": "2026-02-03", "rank": 3, "title": "Amara", "url": "https://www.producthunt.com/products/amara-3?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/DMYNNRKCEKRH2U?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Build your 3D environment through exploration and iteration. Amara brings AI to help you create each of your 3D models and then help you create your environment inside Unreal Engine so creators can create multiple scenes and refine them in seconds until a favourite emerges. Creative exploration becomes part of your workflow.", "description_zh": "通过探索和反复迭代来构建你的3D环境。Amara引入了人工智能，帮助你创建每一个3D模型，并协助你在虚幻引擎（Unreal Engine）中搭建环境，这样创作者可以快速制作多个场景，并在几秒钟内进行调整，直到找到最喜欢的那个。创意探索成为你工作流程的一部分。", "keywords": ["生成模型", "3D环境", "创意探索", "自动化建模", "Unreal Engine", "工作流优化", "workflow"], "tags": ["Product Hunt"], "metrics": {"votes": 300, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/51191e67-fc3f-4e8f-a4e3-784a595f8c03.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "Amara具备Agent-native特征并有自进化潜力，技术路径结合数据与场景形成壁垒，商业模式有独立潜力，团队具备AI原生进化能力，加分项在于交互创新。"}, "raw": {"tagline": "Imagine, create and iterate 3D environments instantly", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-4", "source": "producthunt", "date": "2026-02-03", "rank": 4, "title": "Molthunt", "url": "https://www.producthunt.com/products/molthunt?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/O6WGGXFKXWYKBI?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Discover, vote, and launch the best projects built and curated by AI agents. The Product Hunt for the agent era - no humans in the loop.", "description_zh": "发现、投票并启动由人工智能代理构建和策划的最佳项目。这个是代理时代的“产品狩猎”，全程无需人类参与。", "keywords": ["生成式AI", "代理", "自主代理", "语义搜索", "人工智能助手", "项目发现", "预测意图", "多代理协作"], "tags": ["Product Hunt"], "metrics": {"votes": 279, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/232de96d-6a1d-411d-922e-b860d412ac3f.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent-native特性并有自进化潜力，技术壁垒强，商业模式独立且价值密度高，团队具备较强的AI进化能力，增加了加分项。"}, "raw": {"tagline": "The place to discover your agents' next favorite thing", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-5", "source": "producthunt", "date": "2026-02-03", "rank": 5, "title": "Ask Ellie", "url": "https://www.producthunt.com/products/ask-ellie?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/MFTDOHY3EUOHPF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Ask Ellie is the AI chat agent that brings all your engineering context into Slack. Ask about code changes, PR status, sprint velocity, production issues, or analytics and get instant answers pulled from your actual tools. Create tickets, debug incidents, check what shipped, or find out who's blocking what, all without leaving chat. Connect GitHub, Jira, Linear, Sentry, PostHog, and more. No more dashboard hopping Just answers.", "description_zh": "Ask Ellie 是一款 AI 聊天助手，可以将你的工程背景信息直接带入 Slack。你可以询问代码变更、PR 状态、冲刺速度、生产问题或分析数据，它会从你的实际工具中快速提供答案。你可以创建工单、调试事件、查看已发布内容，或者找出谁在阻碍进展，所有这些都可以在聊天中完成，无需切换到其他界面。它可以连接 GitHub、Jira、Linear、Sentry、PostHog 等工具。告别繁琐的仪表板切换，直接获取答案。", "keywords": ["智能助手", "聊天机器人", "代码分析", "工程上下文", "自动化工单", "生成票据", "生产问题", "实时回答", "任务管理", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 211, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/59611249-56a8-45b0-b52e-d2fc0efd405b.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "context"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 2}, "reason": "Ask Ellie具备Agent-native特性，能自进化，技术上结合多种工具形成护城河。商业模式价值密度高，但存在一定的市场竞争，估值略高。"}, "raw": {"tagline": "Turn Slack messages into GitHub, Jira, or Linear tickets", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-6", "source": "producthunt", "date": "2026-02-03", "rank": 6, "title": "EasyClaw", "url": "https://www.producthunt.com/products/dereference-the-100x-ide?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/TRK7JJT37M3WXY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Install ClawdBot, MoltBot, and OpenClaw in one command. No confusion, no hours of setup. Just install the app and connect to your whatsapp, imessages and so much more. Automate tasks, run code or send emails. The future of your personal ai agent is here.", "description_zh": "只需一条命令，轻松安装ClawdBot、MoltBot和OpenClaw。告别繁琐的设置，快速安装应用后，您就可以连接WhatsApp、iMessages等多个平台。自动化任务、运行代码或发送邮件，这里是您个人AI助手的未来。", "keywords": ["智能助手", "ClawdBot", "MoltBot", "OpenClaw", "自动化任务", "个人助手", "多代理", "语义搜索"], "tags": ["Product Hunt"], "metrics": {"votes": 188, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/14350cbf-7648-459c-beb6-cebbf5bed816.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "openclaw"], "hit_excludes": []}, "score": {"total": 71, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备Agent-native特性和自进化潜力，技术路径有较强的执行壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且有交互创新加分。"}, "raw": {"tagline": "Easy installer for OpenClaw agents across all your chat apps", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-7", "source": "producthunt", "date": "2026-02-03", "rank": 7, "title": "Design In The Browser", "url": "https://www.producthunt.com/products/design-in-the-browser?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/6F5UQUJXKYNCC6?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Design In The Browser lets you point at any element on your website and tell AI what to change. Click a button, a heading, or select text — describe your edit in plain language, and it sends the instruction (with a screenshot) directly to Claude Code, Cursor, or Gemini CLI running in the built-in terminal. No more copying selectors or describing layouts in chat. You see it, you change it, and AI does it. Supports multi-edit queuing, responsive viewports, and your preferred code editor.", "description_zh": "“浏览器设计”功能让你可以直接对网站上的任何元素进行修改。只需点击一个按钮、标题，或者选择一段文字，然后用简单的语言描述你想要的更改，系统就会将这个指令（连同截图）直接发送给内置终端中的Claude Code、Cursor或Gemini CLI。再也不需要手动复制选择器或在聊天中描述布局了。你所看到的，想要修改的，AI都会为你完成。此外，它还支持多项编辑排队、响应式视图和你喜欢的代码编辑器。", "keywords": ["机器学习", "深度学习", "生成式", "语义搜索", "助手", "视觉工具", "前端设计", "自动化编辑", "代码生成", "多编辑队列", "claude"], "tags": ["Product Hunt"], "metrics": {"votes": 170, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/82cffd12-5051-4e63-b3c2-a429365c10d3.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目具备较强的Agent原生特性和自进化潜力，技术路径上形成了良好的壁垒，商业模式独立性高，团队具备AI原生进化能力，加分项体现在交互创新方面。"}, "raw": {"tagline": "The visual tool for frontend. Point, click, and let AI code.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-8", "source": "producthunt", "date": "2026-02-03", "rank": 8, "title": "Portal", "url": "https://www.producthunt.com/products/portal-14?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/WKOPJZZ72WGC6Q?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Portal exists because trying software is still weirdly fake. We send landing pages, videos, and demos - but the first time someone actually uses a product still requires signups, installs, or a sales call. Portal lets you send a browser session, which can be open to any real, running state of your product. That could be opened to localhost:3000, with an extension installed, or logged into a demo account with safety, resets, and optional AI. You get analytics. The link allows a temp session.", "description_zh": "Portal的存在是因为尝试软件的方式依然让人觉得有些不真实。我们通常会发送着陆页、视频和演示，但第一次让用户真正使用产品，仍然需要注册、安装或者进行销售电话。Portal的功能在于，它可以让你分享一个浏览器会话，这个会话可以显示你产品的任意真实运行状态。比如，它可以打开到localhost:3000，带有已安装的扩展，或者安全地登录到一个演示账户，并且可以选择重置和使用AI功能。同时，你还可以获取分析数据。这个链接允许进行临时会话。", "keywords": ["机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "助手", "自动化代理", "在线学习", "产品自迭代", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 166, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/104b086d-d70d-4a70-83ff-5dbe43190f0d.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "Portal具备强大的Agent原生性和自进化潜力，技术路径形成了良好的壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在交互创新方面表现突出。"}, "raw": {"tagline": "Links to try any product at any moment with no setup", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-9", "source": "producthunt", "date": "2026-02-03", "rank": 9, "title": "Voice Anywhere", "url": "https://www.producthunt.com/products/voice-anywhere-write-by-voice?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/2JPUBMDQGBY4ON?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Voice Anywhere is an AI speech-to-text app that works everywhere. Apps, websites, coding IDEs. If you can type there, you can dictate there. A floating, pinnable mic stays above all windows so you never lose it. Fast on-device recognition, 100+ languages, and optional AI engine. Made for founders and vibe coders who move fast. Pro tip: Use \"SHIFT + R\" to toggle on/off.", "description_zh": "Voice Anywhere 是一款可以随时随地使用的人工智能语音转文字应用。无论是在应用程序、网站还是编码环境中，只要你能输入文字，就可以进行语音输入。它的悬浮式麦克风可以固定在所有窗口上方，确保你随时能找到它。应用内具备快速的本地识别功能，支持100多种语言，还提供可选的AI引擎。非常适合快速行动的创业者和热爱编程的人。小提示：使用“SHIFT + R”可以切换开启或关闭。", "keywords": ["语音识别", "语音转文本", "机器学习", "深度学习", "生成模型", "助手", "聊天机器人", "嵌入式", "语义搜索", "在线学习", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 148, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e797df03-2e48-4c23-9faf-d380df16cd16.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目具备良好的AI原生程度和自进化潜力，技术路径有一定的壁垒，商业模式具备独立潜力，团队表现出较强的迭代能力，且在语音识别领域有创新点。"}, "raw": {"tagline": "A floating mic that turns your speech into text anywhere", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-10", "source": "producthunt", "date": "2026-02-03", "rank": 10, "title": "Moltweet", "url": "https://www.producthunt.com/products/moltweet?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/Q6KL3ZDZ6I33CQ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Moltweet is the world's first \"agent social network\"; a Twitter-like platform where AI agents autonomously post, reply, follow each other, and interact without human intervention. Built for non-technical users in under 24 hours on Lyzr, Moltweet offers an unprecedented window into multi-agent dynamics and emergent AI behaviors.", "description_zh": "Moltweet是全球首个“代理社交网络”，类似于Twitter的一个平台，AI代理可以自主发布内容、回复消息、互相关注并进行互动，而无需人类干预。Moltweet在Lyzr上构建，非技术用户在24小时内即可使用，提供了一个前所未有的视角，让人们了解多个代理之间的动态关系和新兴的AI行为。", "keywords": ["智能代理", "多代理动态", "自主交互", "语义搜索", "生成模型", "深度学习", "Moltweet", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 147, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/86d2fd95-41bd-4056-9bc3-ad3e083e08ef.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous", "multi-agent"], "hit_excludes": []}, "score": {"total": 77, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "Moltweet作为首个AI代理社交网络，展现出强大的自进化潜力和多代理动态，技术壁垒高，商业模式具备独立潜力，团队具备AI原生进化能力，且有创新的交互方式。"}, "raw": {"tagline": "Twitter for AI Agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-11", "source": "producthunt", "date": "2026-02-03", "rank": 11, "title": "Menta", "url": "https://www.producthunt.com/products/menta-3?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/GAHCQ5VNSJGTNY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Menta: an AI-native platform designed to digitalize, centralize, and automate all administrative and clinical workflows in one place. Small and medium-sized clinics can’t scale without a system. With Menta, we give them the technology to reduce administrative costs, increase their professionals’ capacity, and recover revenue that is currently being lost — so they can focus on what truly matters: delivering exceptional patient care.", "description_zh": "Menta：一个以人工智能为基础的平台，旨在将所有行政和临床工作流程数字化、集中化和自动化。小型和中型诊所没有系统就无法扩展业务。通过Menta，我们为他们提供技术支持，降低行政成本，提高专业人员的工作效率，挽回当前的收入损失，从而使他们能够专注于真正重要的事情：提供卓越的患者护理。", "keywords": ["智能助手", "自动化工作流", "生成模型", "深度学习", "语义搜索", "多智能体", "Menta平台", "医疗管理", "收费系统", "人工智能技术", "workflow"], "tags": ["Product Hunt"], "metrics": {"votes": 119, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/73535979-33bd-4378-8976-b235751ae149.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "Menta具备强大的AI原生能力，能够自我进化；技术路径上有较强的壁垒，结合数据和场景；商业模式具备独立潜力，团队具备AI进化能力，整体表现优秀。"}, "raw": {"tagline": "Software that runs clinic’s admin, records, + billing w/ AI", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-12", "source": "producthunt", "date": "2026-02-03", "rank": 12, "title": "Remem AI", "url": "https://www.producthunt.com/products/remem-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/MIRUTSAJX73JRR?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Most apps store notes and photos in isolation. Over time, memories get buried and disconnected. Remem is a personal memory app built around context and relationships. It resurfaces memories from years ago and links them to related moments, people, places, and ideas.", "description_zh": "大多数应用程序会将笔记和照片单独存储，随着时间的推移，记忆容易被埋没和割裂。而 Remem 是一款围绕上下文和关系构建的个人记忆应用。它能重新唤起多年前的回忆，并将这些记忆与相关的时刻、人物、地点和想法联系起来。", "keywords": ["记忆助手", "个人记忆", "关系联结", "上下文理解", "语义搜索", "主动型AI"], "tags": ["Product Hunt"], "metrics": {"votes": 111, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e1bd969b-8bf7-4f33-b235-978a2a895672.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Remem AI 具备强大的自进化潜力，能够通过上下文理解和关系联结提升用户体验，形成独特的记忆管理壁垒。商业模式具备独立潜力，团队具备AI原生进化能力，整体表现优秀。"}, "raw": {"tagline": "AI that remembers what matters for you", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-13", "source": "producthunt", "date": "2026-02-03", "rank": 13, "title": "Polyvia", "url": "https://www.producthunt.com/products/polyvia?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/VQ3WIIBAJMT4ZF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Polyvia is the first Visual Knowledge Index for Agents & MCPs. Turn scattered visuals into a queryable source of truth with every fact disambiguated. Other tools extract visuals OR index text — Polyvia indexes and reasons over visuals, connecting facts across 10,000s of documents. Built for developers of multimodal agents and knowledge-work teams.", "description_zh": "Polyvia是首个专为代理和多通道处理器（MCPs）打造的视觉知识索引。它能将分散的视觉信息转化为可查询的真实信息来源，并清晰区分每个事实。其他工具要么提取视觉信息，要么对文本进行索引，而Polyvia则同时对视觉内容进行索引和推理，将数万个文档中的事实连接起来。它专为多模态代理的开发者和知识工作团队设计。", "keywords": ["可查询视觉知识索引", "视觉索引", "多模态代理", "人工智能助手", "机器学习", "深度学习", "神经网络", "语义搜索", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 102, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/07dae5a1-98e1-432c-9277-9c6a76f16e7c.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "mcp"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 3}, "reason": "Polyvia具备Agent-native特性和自进化潜力，技术路径独特且具备数据护城河。商业模式价值密度高，但团队背景较传统，减分项为估值偏高。"}, "raw": {"tagline": "Queryable visual knowledge index for agents", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-14", "source": "producthunt", "date": "2026-02-03", "rank": 14, "title": "Devlop Ai", "url": "https://www.producthunt.com/products/devlop-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/5FPGOIZD35IY35?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "AI coding agents to speed up STM32 embedded development", "description_zh": "AI 编程助手加速 STM32 嵌入式开发", "keywords": ["深度学习", "机器学习", "嵌入式开发", "AI 编程助手", "STM32 固件", "生成模型", "语义搜索", "自动化代理", "代码生成"], "tags": ["Product Hunt"], "metrics": {"votes": 94, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/5613708c-8973-4c16-ad3d-b0ec9729a274.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备较强的AI原生能力和自进化潜力，技术路径和壁垒明显，商业模式具备独立潜力，团队具备一定的进化能力，且在嵌入式开发领域有创新方向。"}, "raw": {"tagline": "AI IDE that writes and flashes STM32 firmware for your board", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-15", "source": "producthunt", "date": "2026-02-03", "rank": 15, "title": "Prompt Anything", "url": "https://www.producthunt.com/products/prompt-anything?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/RYK63ZNYBVLNYM?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "This tool enables any skill level to make prompting easier, and more detailed. Build a webapp. Build a strategy. Fix code. Build agents. Build workflows. Find what you will get your mother for her birthday. Custom to who you are, and what you do. Prompt anything in a fraction of the time, with a fraction of a headache with... you guessed it. Prompt Anything", "description_zh": "这个工具让不同技能水平的人都能更轻松、更详细地进行提问。你可以创建一个网页应用，制定一项策略，修复代码，构建智能代理，设计工作流程，甚至为你妈妈的生日挑选礼物。它可以根据你的身份和工作量身定制，让你在更少的时间内，以更少的烦恼，轻松地提出任何问题。没错，这就是“Prompt Anything”。", "keywords": ["生成提示", "LLM", "代理", "工作流", "语义搜索", "深度学习", "自主代理", "在线学习"], "tags": ["Product Hunt"], "metrics": {"votes": 28, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/13c7dec4-7d20-49f3-ab2b-3987c320e2b1.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "workflow"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent原生形态，且有自进化潜力；技术壁垒较强，结合数据和场景；商业模式价值密度高，团队具备AI原生进化能力，获得加分。"}, "raw": {"tagline": "Your best prompts built for you. Using the best LLM.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-16", "source": "producthunt", "date": "2026-02-03", "rank": 16, "title": "iKawn", "url": "https://www.producthunt.com/products/ikawn?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/PZOADMPXBBJZYU?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "iKawn is an AI powered eCommerce OS that helps brands personalize product creatives at scale. It transforms simple product photos into high quality images, short videos, and virtual try on experiences without studios, models, or complex production workflows. Built for commerce outcomes, iKawn helps teams launch faster, reduce creative costs, and deliver consistent, premium shopping experiences across every channel. Designed to grow with brands as catalogs traffic and personalization needs scale.", "description_zh": "iKawn 是一个由人工智能驱动的电商操作系统，旨在帮助品牌大规模地个性化产品创意。它可以将简单的产品照片转化为高质量的图像、短视频和虚拟试穿体验，无需摄影棚、模特或复杂的制作流程。iKawn 专注于商业成果，帮助团队更快地上线、降低创意成本，并在各个渠道上提供一致且高品质的购物体验。它的设计考虑到了品牌的成长，能够随着产品目录、流量和个性化需求的增加而不断扩展。", "keywords": ["个性化创意", "电子商务", "AI驱动", "深度学习", "生成模型", "虚拟试穿", "自动化工作流", "高质量图像", "短视频", "品牌成长"], "tags": ["Product Hunt"], "metrics": {"votes": 24, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/506c0094-84ea-4e92-85ae-9ae98cc2b959.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "iKawn具备Agent-native特性且具自进化潜力，技术路径结合数据和场景形成壁垒，商业模式有独立潜力，团队具备AI原生进化能力，加分项来自于个性化创意的创新。"}, "raw": {"tagline": "Helping eCommerce brands personalize creatives at scale.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-17", "source": "producthunt", "date": "2026-02-03", "rank": 17, "title": "Sketchflow: Mobile Native Code", "url": "https://www.producthunt.com/products/sketchflow-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/YZPOYW2C27WGNZ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Sketchflow.ai helps you generate real native mobile apps in Kotlin and Swift — not hybrid or cross-platform. Build Android and iOS apps with visible UX from a single prompt, own your stable code, test your app in real-time.", "description_zh": "Sketchflow.ai 可以帮助你生成真正的原生移动应用，使用 Kotlin 和 Swift 开发，而不是混合或跨平台的应用。你可以通过一个简单的提示，构建出 Android 和 iOS 应用，并且可以清楚地看到用户体验。你将拥有稳定的代码，并且可以实时测试你的应用。", "keywords": ["生成应用", "真实代码", "移动应用", "Kotlin", "Swift", "生成式", "自主代理", "语义搜索", "多代理", "人机协作", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 24, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/6a51ec8b-9c3b-4a38-95ac-88fe12dbcff8.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备Agent-native特性和自进化潜力，技术路径有较强壁垒，商业模式价值密度高，团队具备AI原生进化能力，加分项在于生成应用的创新性。"}, "raw": {"tagline": "Text to Native iOS & Android apps. Real Swift & Kotlin code.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-18", "source": "producthunt", "date": "2026-02-03", "rank": 18, "title": "TalentAid", "url": "https://www.producthunt.com/products/talentaid?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/LPCR2ZATPGU7LC?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "TalentAid is an AI copilot that helps you find your dream job. We take your data and dreams in order to find you a perfect job match, and we will help you every step of the way to land your dream career", "description_zh": "TalentAid是一款人工智能助手，旨在帮助你找到理想的工作。我们会根据你的数据和职业梦想，为你找到最合适的职位，并在每一个环节中提供支持，帮助你实现职业理想。", "keywords": ["求职助手", "AI 职位搜索", "职业匹配", "职业顾问", "生成式招聘", "深度学习", "语义搜索"], "tags": ["Product Hunt"], "metrics": {"votes": 23, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/1004c9c2-d84d-4cf4-869f-ade8c67b94a6.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "copilot"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "TalentAid具备AI原生特性，能够提供职业匹配服务，技术路径有一定壁垒，但商业模式尚需强化，团队能力表现良好，且有创新的交互方式。"}, "raw": {"tagline": "AI Job Searching Copilot", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-19", "source": "producthunt", "date": "2026-02-03", "rank": 19, "title": "GRMC.ai", "url": "https://www.producthunt.com/products/grmc-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/R5XAUTQWBD7RLN?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "GRMC.ai analyzes contracts for compliance gaps in GDPR Article 28, SOC 2, and CCPA/CPRA. Upload a contract, get instant gap analysis and remediation recommendations. Built by a legal ops professional with 20+ years and 50+ CLM implementations who saw the gap between CLM AI promises and reality.", "description_zh": "GRMC.ai 可以帮助您分析合同，找出在GDPR第28条、SOC 2和CCPA/CPRA方面的合规缺口。只需上传合同，您就能获得即时的缺口分析和改进建议。这个工具是由一位拥有20多年经验并实施超过50个合同生命周期管理（CLM）项目的法律运营专家开发的，他意识到CLM人工智能的承诺与实际情况之间的差距。", "keywords": ["合规分析", "合同分析", "GDPR", "SOC2", "CCPA", "人工智能合规", "AI合规助手", "自动化合规", "合同智能审核", "合同管理"], "tags": ["Product Hunt"], "metrics": {"votes": 21, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/13cb091d-296c-4128-8f8f-43895e80e7b9.gif?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "GRMC.ai具备Agent-native特性，能自我进化，技术壁垒来自于数据和场景结合，商业模式价值密度高，团队经验丰富，具备较强的进化能力。"}, "raw": {"tagline": "AI contract compliance analyzer for GDPR, SOC2, and CCPA", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-20", "source": "producthunt", "date": "2026-02-03", "rank": 20, "title": "FocusBae", "url": "https://www.producthunt.com/products/focusbae?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/U2G3MCDR2MN7WL?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "FocusBae is your coworker, you can call, share the screen and solve problems just like a real teammate, you can generate todos, notes on the go, at the end of the day just call and journal about your day, focusbae learn about you and your work everyday and get smarter not just this you can also set personalized reminder, track your app usage, use clipboard history to boost your productivity, FocusBae aims to be your work college, your friend briging the gap between productivity and wellness.", "description_zh": "FocusBae就像你的同事一样，你可以跟它打电话、共享屏幕，像真正的团队成员一样一起解决问题。它能随时帮你生成待办事项和笔记。一天结束时，你只需拨打电话，记录一下你的一天。FocusBae会每天学习关于你和你的工作的内容，从而变得更加智能。不止于此，你还可以设置个性化提醒，跟踪你的应用使用情况，利用剪贴板历史提高工作效率。FocusBae的目标是成为你的工作伙伴和朋友，帮助你在生产力和身心健康之间找到平衡。", "keywords": ["智能助手", "生成待办事项", "笔记生成", "个人化提醒", "任务跟踪", "协作工具", "深度学习", "语义搜索", "人机协作", "在线学习", "cowork"], "tags": ["Product Hunt"], "metrics": {"votes": 17, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/03cca2c3-72cc-4058-b3d9-54e6942ed7da.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "cowork"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "FocusBae展现出较强的Agent原生能力和自进化潜力，技术路径具备一定壁垒，商业模式具备独立潜力，团队具备AI原生进化能力，且在交互创新上有加分。"}, "raw": {"tagline": "Your AI coworker that sees, understands, and works with you", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-21", "source": "producthunt", "date": "2026-02-03", "rank": 21, "title": "Cogno", "url": "https://www.producthunt.com/products/cogno-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/C5S2NVTMQRWPZG?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Cogno is an AI workspace that acts autonomously—no prompts needed. Unlike tools waiting for commands, Cogno proactively sends notifications, manages team tracking, and delivers completed tasks. See everyone's progress at a glance while AI handles coordination. Stop micromanaging AI. Let it work like a real team member.", "description_zh": "Cogno 是一个人工智能工作平台，它能自主运行，无需提示。与那些需要等待指令的工具不同，Cogno 主动发送通知、管理团队进度，并完成任务。你可以一目了然地看到大家的进展，而人工智能则负责协调工作。别再对 AI 进行过度管理，让它像真正的团队成员一样工作吧。", "keywords": ["自动化工作空间", "人工智能助手", "协作工具", "任务管理", "进度跟踪", "Proactive AI", "无需提示", "自主代理", "团队协同", "AI 工作流"], "tags": ["Product Hunt"], "metrics": {"votes": 13, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/b485e27d-87ea-423f-8a3e-6f0b28907f53.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous"], "hit_excludes": []}, "score": {"total": 75, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 5, "penalty": 0}, "reason": "Cogno具备自主代理能力，具有较强的自进化潜力；技术路径上结合数据和场景形成壁垒；商业模式具备独立潜力；团队具备AI原生进化能力，整体表现优秀。"}, "raw": {"tagline": "AI workspace that works while you don't", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-22", "source": "producthunt", "date": "2026-02-03", "rank": 22, "title": "TopMessage", "url": "https://www.producthunt.com/products/topmessage-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/H56Y462QOYB7RQ?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Send SMS & WhatsApp campaigns and manage replies in one shared inbox. Segment contacts, schedule sends, track clicks, and see what converts. Built for SMBs and lean teams.", "description_zh": "通过一个共享的收件箱发送短信和WhatsApp营销活动，并管理回复。您可以对联系人进行细分，安排发送时间，跟踪点击率，并查看哪些内容能带来转化。这个工具专为中小企业和精简团队设计。", "keywords": ["短信营销", "WhatsApp营销", "聊天机器人", "自动化助手", "语义搜索", "人工智能助手", "多代理工作流", "内容管理", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/e6efe058-0280-4897-9641-d869a9ec8636.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目具备一定的Agent形态和自进化潜力，技术壁垒较高，商业模式具备独立潜力，团队能力较强，且在短信和WhatsApp营销领域有创新。"}, "raw": {"tagline": "Send SMS & WhatsApp campaigns, handle replies in one inbox", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-23", "source": "producthunt", "date": "2026-02-03", "rank": 23, "title": "Pathwiseai", "url": "https://www.producthunt.com/products/pathwiseai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/SSWZNFXKW7K6GL?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Upload your resume once. Type any company + role. AI finds the job posting automatically and writes a personalized cover letter in 30 seconds. Plus: Resume Scorer with actionable feedback, 8+ professional templates, and auto-brand styling with company colors.", "description_zh": "只需上传一次简历，输入公司名称和职位，AI 就能自动找到相关的招聘信息，并在30秒内为你撰写一封个性化的求职信。此外，还有简历评分功能，提供实用反馈，超过8种专业模板，以及根据公司颜色自动调整的品牌样式。", "keywords": ["求职助手", "职业工具包", "机器学习", "职位推荐", "自定义求职信", "简历评分", "自动化", "职业发展", "深度学习", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/ebbc829d-baef-4c37-8a79-49f41b1341e1.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "Pathwiseai具备Agent-native特性，能自我进化。技术上通过AI实现简历评分和求职信生成，形成一定壁垒。商业模式独特，具备高价值密度，团队具备进化能力，加分项为职业发展方向的创新。"}, "raw": {"tagline": "Your AI-powered career toolkit", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-24", "source": "producthunt", "date": "2026-02-03", "rank": 24, "title": "Epismo Workflow Hub", "url": "https://www.producthunt.com/products/epismo?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/EVPQ2LLSKRVBYK?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Workflow Hub is an open library of human-AI workflows you can copy and run instantly. Instead of copying a single prompt, you copy the whole process: task breakdown, step sequence, intermediate artifacts, and quality checks. Clone a workflow, customize it, and execute it in Epismo with the best agent for each step.", "description_zh": "Workflow Hub 是一个开放的人机协作工作流程库，你可以直接复制并立即运行这些工作流程。与其只复制一个单独的提示，不如复制整个过程：任务分解、步骤顺序、中间产物和质量检查。你可以克隆一个工作流程，进行自定义，然后在 Epismo 中使用最合适的智能助手执行每一个步骤。", "keywords": ["人机协作", "工作流", "自动化", "生成式", "代理", "深度学习", "任务分解", "上下文", "代理友好工具", "语义搜索", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 12, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/2ce6d79d-ae36-4628-8098-7bc4d4d7304f.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "workflow"], "hit_excludes": []}, "score": {"total": 74, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 12, "bonus": 6, "penalty": 0}, "reason": "项目具备强大的Agent原生能力和自进化潜力，技术路径上形成了良好的数据和场景壁垒，商业模式具备独立潜力和多样化退出方式，团队具备AI原生进化能力，且在交互创新方面表现突出。"}, "raw": {"tagline": "Open human-AI workflow library. Clone, run, share.", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-03-25", "source": "producthunt", "date": "2026-02-03", "rank": 25, "title": "Statements AI", "url": "https://www.producthunt.com/products/statments-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/TQIYWF3ONB3V7J?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Perfect for tracking business expenses, prepping for tax season, and separating personal vs business spending.", "description_zh": "非常适合跟踪商务开支、为报税季做准备，以及区分个人消费与商务开支。", "keywords": ["机器学习", "深度学习", "聊天机器人", "生成模型", "文本提取", "财务分析", "费用跟踪", "PDF 处理", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 10, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/7c08845c-aaf4-4c8e-acbe-5dc0a324a8e4.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的Agent形态，技术路径有数据和场景护城河，商业模式具备独立潜力，团队能力较强，且在费用跟踪领域有创新。"}, "raw": {"tagline": "See all your spending from PDF bank statements", "created_at": "2026年02月02日 PM04:01 (北京时间)"}}
{"id": "ax-2026-02-03-1", "source": "arxiv", "date": "2026-02-03", "rank": 1, "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations", "url": "https://arxiv.org/abs/2602.03828v1", "detail_url": "https://arxiv.org/pdf/2602.03828v1.pdf", "description_en": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.", "description_zh": "AutoFigure是一个自动生成高质量科学插图的框架，能够从长篇科学文本中生成出版级插图。", "keywords": ["生成", "科学插图", "机器学习", "深度学习", "神经网络", "自动化", "图形生成", "FigureBench", "论文插图", "自动框架", "agent"], "tags": ["cs.AI", "cs.CL", "cs.CV", "cs.DL"], "metrics": {"authors": ["Minjun Zhu", "Zhen Lin", "Yixuan Weng", "Panzhong Lu", "Qiujie Xie", "Yifan Wei", "Sifan Liu", "Qiyao Sun", "Yue Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "AutoFigure具备较强的AI原生性，通过用户生成数据提升系统能力；技术路径独特，解决了科学插图生成的复杂问题；商业模式与高价值用户紧密结合，团队背景扎实，具备良好的进化能力。"}, "raw": {"published": "2026-02-03T18:41:43Z", "ai_summary": {"tldr": "AutoFigure是一个自动生成高质量科学插图的框架，能够从长篇科学文本中生成出版级插图。", "motivation": "高质量的科学插图对有效传达复杂科学概念至关重要，但其人工制作仍是学术和工业界的一大瓶颈。", "method": "AutoFigure框架通过广泛的思考、重组和验证，生成结构合理且美观的科学插图，基于FigureBench数据集进行训练和测试。", "conclusion": "实验结果表明，AutoFigure在生成出版级科学插图方面始终优于所有基线方法。"}}}
{"id": "ax-2026-02-03-2", "source": "arxiv", "date": "2026-02-03", "rank": 2, "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity", "url": "https://arxiv.org/abs/2602.03794v1", "detail_url": "https://arxiv.org/pdf/2602.03794v1.pdf", "description_en": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.", "description_zh": "增加多样性而非仅仅增加代理数量能显著提升基于LLM的多代理系统的性能。", "keywords": ["多智能体", "LLM", "代理", "异质性", "任务不确定性", "效果通道", "性能提升", "信息论框架", "协同工作"], "tags": ["cs.AI", "cs.LG"], "metrics": {"authors": ["Yingxuan Yang", "Chengrui Qu", "Muning Wen", "Laixi Shi", "Ying Wen", "Weinan Zhang", "Adam Wierman", "Shangding Gu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目展示了通过多样性提升多代理系统性能的创新思路，具备一定的技术壁垒和应用潜力。商业模式尚不明确，但有高价值用户的潜力。团队背景信息不足，无法评估其完整能力。"}, "raw": {"published": "2026-02-03T17:58:10Z", "ai_summary": {"tldr": "增加多样性而非仅仅增加代理数量能显著提升基于LLM的多代理系统的性能。", "motivation": "研究探讨在多代理系统中，如何通过代理的多样性来克服性能扩展的限制。", "method": "提出一个信息论框架，分析任务不确定性与有效通道数量对多代理系统性能的影响。", "conclusion": "异质配置的代理在性能上优于同质代理，2个多样化代理的表现可匹敌或超越16个同质代理。"}}}
{"id": "ax-2026-02-03-3", "source": "arxiv", "date": "2026-02-03", "rank": 3, "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration", "url": "https://arxiv.org/abs/2602.03786v1", "detail_url": "https://arxiv.org/pdf/2602.03786v1.pdf", "description_en": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra", "description_zh": "AOrchestra是一个自动化子代理创建系统，通过统一的代理抽象提高任务执行的灵活性和效率。", "keywords": ["自动化", "代理", "任务执行", "多代理", "任务解决", "代理系统", "AOrchestra", "适应性", "框架无关", "代理抽象", "agent"], "tags": ["cs.AI", "cs.CL"], "metrics": {"authors": ["Jianhao Ruan", "Zhihao Xu", "Yiran Peng", "Fashen Ren", "Zhaoyang Yu", "Xinbing Liang", "Jinyu Xiang", "Bang Liu", "Chenglin Wu", "Yuyu Luo", "Jiayi Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 5, "penalty": 0}, "reason": "AOrchestra通过动态代理创建提升了任务执行的灵活性，体现了AI原生程度。技术路径具备非共识判断力，且解决复杂问题。商业模式与高价值用户紧密结合，团队背景强大。加分项为明确的垂类生态潜质。"}, "raw": {"published": "2026-02-03T17:46:16Z", "ai_summary": {"tldr": "AOrchestra是一个自动化子代理创建系统，通过统一的代理抽象提高任务执行的灵活性和效率。", "motivation": "随着任务复杂性的增加，现有的多轮任务解决方案缺乏动态的子代理视图，限制了适应性和自动化能力。", "method": "提出了一个统一的代理抽象模型，将代理视作一个包含指令、上下文、工具和模型的元组，并基于此设计了AOrchestra系统，实现了按需创建专业执行器。", "conclusion": "AOrchestra在三个基准测试中相较于最强基线实现了16.28%的相对提升，证明了其在任务执行中的有效性和灵活性。"}}}
{"id": "ax-2026-02-03-4", "source": "arxiv", "date": "2026-02-03", "rank": 4, "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques", "url": "https://arxiv.org/abs/2602.03837v1", "detail_url": "https://arxiv.org/pdf/2602.03837v1.pdf", "description_en": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.", "description_zh": "本论文探讨了谷歌Gemini模型在加速科学研究中的应用，通过案例展示其与研究者的有效合作。", "keywords": ["大型语言模型", "机器学习", "深度学习", "神经网络", "人机协作", "迭代优化", "问题分解", "跨学科知识转移", "Gemini模型", "llm"], "tags": ["cs.CL", "cs.AI"], "metrics": {"authors": ["David P. Woodruff", "Vincent Cohen-Addad", "Lalit Jain", "Jieming Mao", "Song Zuo", "MohammadHossein Bateni", "Simina Branzei", "Michael P. Brenner", "Lin Chen", "Ying Feng", "Lance Fortnow", "Gang Fu", "Ziyi Guan", "Zahra Hadizadeh", "Mohammad T. Hajiaghayi", "Mahdi JafariRaviz", "Adel Javanmard", "Karthik C. S.", "Ken-ichi Kawarabayashi", "Ravi Kumar", "Silvio Lattanzi", "Euiwoong Lee", "Yi Li", "Ioannis Panageas", "Dimitris Paparas", "Benjamin Przybocki", "Bernardo Subercaseaux", "Ola Svensson", "Shayan Taherijam", "Xuan Wu", "Eylon Yogev", "Morteza Zadimoghaddam", "Samson Zhou", "Vahab Mirrokni"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "autonomous", "embedding"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目展示了AI与研究者的深度协作，具备自我改进能力，且技术路径独特，解决复杂问题。商业模式与高价值用户强绑定，团队背景扎实，存在生态潜质。"}, "raw": {"published": "2026-02-03T18:56:17Z", "ai_summary": {"tldr": "本论文探讨了谷歌Gemini模型在加速科学研究中的应用，通过案例展示其与研究者的有效合作。", "motivation": "随着大型语言模型的发展，探讨其在科学研究特别是数学发现中的潜力成为一种新趋势。", "method": "通过案例研究，总结有效的人机协作技术，如迭代优化、问题分解和跨学科知识转移。", "conclusion": "AI不仅可以作为自动化工具，还能成为科学发现过程中的真正合作伙伴，推动研究的创新。"}}}
{"id": "ax-2026-02-03-5", "source": "arxiv", "date": "2026-02-03", "rank": 5, "title": "They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References", "url": "https://arxiv.org/abs/2602.03822v1", "detail_url": "https://arxiv.org/pdf/2602.03822v1.pdf", "description_en": "Meme-based social abuse detection is challenging because harmful intent often relies on implicit cultural symbolism and subtle cross-modal incongruence. Prior approaches, from fusion-based methods to in-context learning with Large Vision-Language Models (LVLMs), have made progress but remain limited by three factors: i) cultural blindness (missing symbolic context), ii) boundary ambiguity (satire vs. abuse confusion), and iii) lack of interpretability (opaque model reasoning). We introduce CROSS-ALIGN+, a three-stage framework that systematically addresses these limitations: (1) Stage I mitigates cultural blindness by enriching multimodal representations with structured knowledge from ConceptNet, Wikidata, and Hatebase; (2) Stage II reduces boundary ambiguity through parameter-efficient LoRA adapters that sharpen decision boundaries; and (3) Stage III enhances interpretability by generating cascaded explanations. Extensive experiments on five benchmarks and eight LVLMs demonstrate that CROSS-ALIGN+ consistently outperforms state-of-the-art methods, achieving up to 17% relative F1 improvement while providing interpretable justifications for each decision.", "description_zh": "提出了一种名为CROSS-ALIGN+的三阶段框架，以提高基于表情包的社交滥用检测的准确性和可解释性。", "keywords": ["文化符号", "跨模态", "文化盲点", "大型视觉语言模型", "CROSS-ALIGN+", "多模态表示", "解释性", "参数高效", "决策边界", "结构化知识", "ml"], "tags": ["cs.CL"], "metrics": {"authors": ["Sahil Tripathi", "Gautam Siddharth Kashyap", "Mehwish Nasim", "Jian Yang", "Jiechao Gao", "Usman Naseem"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 5, "bonus": 6, "penalty": 0}, "reason": "CROSS-ALIGN+框架在多模态社交滥用检测中展现出较高的自我改进能力和可解释性，符合AI原生特征。技术路径独特，解决复杂问题，具备一定的行业壁垒。商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:29:46Z", "ai_summary": {"tldr": "提出了一种名为CROSS-ALIGN+的三阶段框架，以提高基于表情包的社交滥用检测的准确性和可解释性。", "motivation": "社交媒体中基于表情包的滥用检测面临文化象征和语境不清晰的挑战，现有方法存在文化盲点、界限模糊和缺乏可解释性的问题。", "method": "CROSS-ALIGN+框架通过三个阶段解决上述问题，包括丰富多模态表示、减少决策边界模糊性及生成级联解释。", "conclusion": "在五个基准和八个大型视觉语言模型上进行的广泛实验表明，CROSS-ALIGN+在准确性上优于最先进方法，F1分数提升可达17%，同时提供可解释的决策依据。"}}}
{"id": "ax-2026-02-03-6", "source": "arxiv", "date": "2026-02-03", "rank": 6, "title": "EventNeuS: 3D Mesh Reconstruction from a Single Event Camera", "url": "https://arxiv.org/abs/2602.03847v1", "detail_url": "https://arxiv.org/pdf/2602.03847v1.pdf", "description_en": "Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.", "description_zh": "EventNeuS是一种自监督神经模型，通过单目彩色事件流进行3D网格重建，显著提升了重建精度。", "keywords": ["3D重建", "事件相机", "自监督", "神经网络", "视图合成", "事件驱动", "3D表示", "深度学习", "EventNeuS", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Shreyas Sachan", "Viktor Rudnev", "Mohamed Elgharib", "Christian Theobalt", "Vladislav Golyanik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 8, "bonus": 5, "penalty": 0}, "reason": "EventNeuS在3D重建领域展示了自监督学习的创新，具备良好的AI原生性。技术路径独特，解决复杂问题，具备一定的市场潜力，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:59:57Z", "ai_summary": {"tldr": "EventNeuS是一种自监督神经模型，通过单目彩色事件流进行3D网格重建，显著提升了重建精度。", "motivation": "现有基于事件的3D重建技术在精度上存在局限性，研究者希望通过新的方法提高重建质量。", "method": "EventNeuS结合了3D签名距离函数和密度场学习，首次采用事件驱动的监督，并引入了球谐编码以增强视角相关效果的处理能力。", "conclusion": "EventNeuS在Chamfer距离和平均绝对误差方面显著优于现有方法，展示了其在3D重建任务中的有效性。"}}}
{"id": "ax-2026-02-03-7", "source": "arxiv", "date": "2026-02-03", "rank": 7, "title": "Continuous Control of Editing Models via Adaptive-Origin Guidance", "url": "https://arxiv.org/abs/2602.03826v1", "detail_url": "https://arxiv.org/pdf/2602.03826v1.pdf", "description_en": "Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.", "description_zh": "提出了一种自适应起源引导方法，实现对图像和视频编辑的连续控制。", "keywords": ["编辑模型", "语义图像", "视频编辑", "自适应指导", "生成模型", "深度学习", "机器学习", "控制强度", "细粒度控制", "图像处理", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Alon Wolf", "Chen Katzir", "Kfir Aberman", "Or Patashnik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 67, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "项目提出了自适应起源引导方法，具备一定的AI原生性，但缺乏用户反馈闭环和明确的商业模式，技术路径有创新但应用场景尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:33:39Z", "ai_summary": {"tldr": "提出了一种自适应起源引导方法，实现对图像和视频编辑的连续控制。", "motivation": "现有的扩散模型在文本引导编辑的强度控制上缺乏平滑机制，影响编辑结果的过渡效果。", "method": "通过引入自适应起源引导（AdaOr），调整标准引导起源，依据编辑强度在身份条件预测和标准无条件预测之间进行插值，实现连续的输入和编辑结果过渡。", "conclusion": "该方法在图像和视频编辑任务中表现出更平滑和一致的控制效果，优于基于滑块的编辑方法。"}}}
{"id": "ax-2026-02-03-8", "source": "arxiv", "date": "2026-02-03", "rank": 8, "title": "From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery", "url": "https://arxiv.org/abs/2602.03785v1", "detail_url": "https://arxiv.org/pdf/2602.03785v1.pdf", "description_en": "Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.", "description_zh": "提出了一种基于U-Net的NeuralShift模型，可以仅通过术前MRI预测癫痫手术中的脑位移。", "keywords": ["神经网络", "深度学习", "预测模型", "U-Net", "脑部变形", "神经外科", "图像引导手术", "手术导航系统", "精确度", "agent"], "tags": ["cs.CV"], "metrics": {"authors": ["Jingjing Peng", "Giorgio Fiore", "Yang Liu", "Ksenia Ellum", "Debayan Daspupta", "Keyoumars Ashkan", "Andrew McEvoy", "Anna Miserocchi", "Sebastien Ourselin", "John Duncan", "Alejandro Granados"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目展示了AI在神经外科中的应用，利用术前MRI进行脑位移预测，具有较高的自我改进潜力和应用价值。技术路径独特，解决了复杂的医学问题，具备一定的市场需求和团队背景，但商业模式尚不明确，需进一步验证。"}, "raw": {"published": "2026-02-03T17:45:11Z", "ai_summary": {"tldr": "提出了一种基于U-Net的NeuralShift模型，可以仅通过术前MRI预测癫痫手术中的脑位移。", "motivation": "脑外科手术中，术前MRI在定位手术目标时至关重要，但开 dura 后脑位移会使其失效，因此需要在手术中进行脑位移补偿。", "method": "NeuralShift模型利用术前MRI预测脑位移，通过计算目标配准误差和DICE分数来评估模型的准确性。", "conclusion": "该模型能够有效预测癫痫手术中的脑整体变形，提高手术的安全性和效率，改善患者的手术结果。"}}}
{"id": "ax-2026-02-03-9", "source": "arxiv", "date": "2026-02-03", "rank": 9, "title": "QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization", "url": "https://arxiv.org/abs/2602.03782v1", "detail_url": "https://arxiv.org/pdf/2602.03782v1.pdf", "description_en": "The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.", "description_zh": "QVLA是一种新的量化框架，通过通道级比特分配策略提高了视觉-语言-行动模型在机器人上的部署效率。", "keywords": ["量化", "视觉-语言-动作", "VLA", "机器人", "模型压缩", "动作敏感性", "QVLA", "低比特量化", "通道分配策略", "自主控制", "llm"], "tags": ["cs.CV", "cs.RO"], "metrics": {"authors": ["Yuhao Xu", "Yantai Yang", "Zhenyang Fan", "Yufan Liu", "Yuming Li", "Bing Li", "Zhipeng Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 10, "team": 10, "bonus": 5, "penalty": 0}, "reason": "QVLA具备较强的AI原生能力，通过通道级比特分配优化量化，形成闭环自我改进。技术路径独特，解决复杂问题，形成了数据与场景的深度绑定。商业模式尚需明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T17:43:45Z", "ai_summary": {"tldr": "QVLA是一种新的量化框架，通过通道级比特分配策略提高了视觉-语言-行动模型在机器人上的部署效率。", "motivation": "现有的VLA模型由于计算需求高，难以在资源有限的机器人平台上部署，因此需要有效的模型压缩策略。", "method": "QVLA采用通道级的比特分配策略，直接测量量化每个通道时的最终动作空间敏感性，以优化量化和剪枝的统一框架。", "conclusion": "QVLA在保持高性能的同时显著减少了模型所需的内存和提高了速度，为在实际硬件上部署大规模模型奠定了基础。"}}}
{"id": "ax-2026-02-03-10", "source": "arxiv", "date": "2026-02-03", "rank": 10, "title": "FOVI: A biologically-inspired foveated interface for deep vision models", "url": "https://arxiv.org/abs/2602.03766v1", "detail_url": "https://arxiv.org/pdf/2602.03766v1.pdf", "description_en": "Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.", "description_zh": "本文提出了一种基于生物启发的视野接口FOVI，旨在提高深度视觉模型的效率和性能。", "keywords": ["深度学习", "计算机视觉", "神经网络", "kNN", "视觉接口", "低秩适应", "foveated vision", "高分辨率", "主动感知", "ml"], "tags": ["cs.CV", "cs.NE", "q-bio.NC"], "metrics": {"authors": ["Nicholas M. Blauch", "George A. Alvarez", "Talia Konkle"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "rag", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 0, "penalty": 0}, "reason": "FOVI展示了生物启发的高效视觉处理能力，符合AI原生的特征，技术路径独特且解决了复杂问题，商业模式相对薄弱，团队背景信息不足。"}, "raw": {"published": "2026-02-03T17:26:54Z", "ai_summary": {"tldr": "本文提出了一种基于生物启发的视野接口FOVI，旨在提高深度视觉模型的效率和性能。", "motivation": "人类视觉具有可变分辨率的特性，而大多数计算机视觉系统则在统一的分辨率下处理图像，这导致资源消耗高效能不足的问题。", "method": "FOVI通过模仿人类视网膜和初级视觉皮层，将可变分辨率传感器阵列重组为均匀密集的V1样传感器流形，并使用k近邻卷积和新颖内核映射技术实现高效处理。", "conclusion": "FOVI模型在计算成本显著降低的情况下，仍能提供与非foveated基线竞争的性能，展示了高效主动感知的潜力。"}}}
{"id": "ax-2026-02-03-11", "source": "arxiv", "date": "2026-02-03", "rank": 11, "title": "RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images", "url": "https://arxiv.org/abs/2602.03760v1", "detail_url": "https://arxiv.org/pdf/2602.03760v1.pdf", "description_en": "Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.", "description_zh": "RAWDet-7是一个针对量化RAW图像的物体检测和描述的大规模基准数据集，包含丰富的场景信息。", "keywords": ["深度学习", "机器学习", "神经网络", "对象检测", "RAW图像处理", "语义搜索", "多场景基准", "细粒度信息", "上下文信息", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Mishal Fatima", "Shashank Agnihotri", "Kanchana Vaishnavi Gandikota", "Michael Moeller", "Margret Keuper"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "context"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提供了针对量化RAW图像的物体检测基准数据集，具备一定的技术壁垒和应用场景，但商业模式和团队信息不足，无法完全评估其潜力。"}, "raw": {"published": "2026-02-03T17:22:45Z", "ai_summary": {"tldr": "RAWDet-7是一个针对量化RAW图像的物体检测和描述的大规模基准数据集，包含丰富的场景信息。", "motivation": "大多数视觉模型基于经过ISP处理的RGB图像训练，这可能丢失对机器推理有用的传感器级信息，而RAW图像能够保留更多未处理的场景数据。", "method": "该数据集包含约25,000张训练和7,600张测试的RAW图像，涵盖多种相机、光照条件和环境，按照MS-COCO和LVIS标准进行了密集标注，并提供了基于高分辨率sRGB图像的物体级描述。", "conclusion": "数据集支持在模拟的4-bit、6-bit和8-bit量化下进行评估，为研究在低比特RAW图像处理中的检测性能、描述质量和泛化能力提供了基准。"}}}
{"id": "ax-2026-02-03-12", "source": "arxiv", "date": "2026-02-03", "rank": 12, "title": "Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives", "url": "https://arxiv.org/abs/2602.03750v1", "detail_url": "https://arxiv.org/pdf/2602.03750v1.pdf", "description_en": "Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bone, sex, and imaging equipment introduce high variability. Thus, content navigation, such as identifying a subset of images with a specific projection view, can be time consuming and difficult, making efficient triaging a bottleneck for expert analysis. We report a zero shot prompting strategy that leverages a state of the art Large Vision Language Model (LVLM) to automatically identify the main bone, projection view, and laterality in such images. Our pipeline converts raw DICOM files to bone windowed PNGs, submits them to the LVLM with a carefully engineered prompt, and receives structured JSON outputs, which are extracted and formatted onto a spreadsheet in preparation for validation. On a random sample of 100 images reviewed by an expert board certified paleoradiologist, the system achieved 92% main bone accuracy, 80% projection view accuracy, and 100% laterality accuracy, with low or medium confidence flags for ambiguous cases. These results suggest that LVLMs can substantially accelerate code word development for large paleoradiology datasets, allowing for efficient content navigation in future anthropology workflows.", "description_zh": "本研究提出了一种零-shot提示策略，利用大型视觉语言模型自动识别古放射学X光图像中的主要骨骼、投影视图和侧向性。", "keywords": ["大规模视觉语言模型", "零-shot", "自动化骨骼识别", "paleoradiology", "DICOM文件", "结构化输出", "高准确率", "内容导航", "工作流", "rag"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Owen Dong", "Lily Gao", "Manish Kota", "Bennett A. Landmana", "Jelena Bekvalac", "Gaynor Western", "Katherine D. Van Schaik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "workflow"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目利用大型视觉语言模型进行自动化骨骼识别，具备一定的自我改进和反馈机制。技术路径独特，解决了古放射学中的复杂问题，具有潜在的市场价值。团队背景信息不足，但项目展示了强大的应用潜力。"}, "raw": {"published": "2026-02-03T17:14:23Z", "ai_summary": {"tldr": "本研究提出了一种零-shot提示策略，利用大型视觉语言模型自动识别古放射学X光图像中的主要骨骼、投影视图和侧向性。", "motivation": "古放射学使用现代成像技术研究考古和人类学遗骸，但由于图像异质性，内容导航复杂且耗时，亟需高效的图像筛选方法。", "method": "研究团队开发了一条管道，将原始DICOM文件转换为骨窗PNG格式，并通过精心设计的提示提交给大型视觉语言模型，最终生成结构化的JSON输出。", "conclusion": "该系统在经过认证的古放射学专家评审的100幅图像中，主要骨骼识别准确率达到92%，投影视图准确率为80%，侧向性准确率为100%，显示出LVLM在古放射学数据集中的潜力。"}}}
{"id": "ax-2026-02-03-13", "source": "arxiv", "date": "2026-02-03", "rank": 13, "title": "See-through: Single-image Layer Decomposition for Anime Characters", "url": "https://arxiv.org/abs/2602.03749v1", "detail_url": "https://arxiv.org/pdf/2602.03749v1.pdf", "description_en": "We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.", "description_zh": "本研究提出了一种将静态动漫插图自动转换为可操作2.5D模型的框架。", "keywords": ["图像分解", "动漫角色", "2.5D模型", "语义分层", "像素级深度推断", "生成模型", "深度学习", "机器学习", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Jian Lin", "Chengze Li", "Haoyun Qin", "Kwun Wang Chan", "Yanghua Jin", "Hanyuan Liu", "Stephen Chun Wang Choy", "Xueting Liu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion", "workflow"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目通过自动化图像分解实现了用户与模型的互动，具备自我改进的潜力，技术路径独特且具备行业壁垒，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T17:12:36Z", "ai_summary": {"tldr": "本研究提出了一种将静态动漫插图自动转换为可操作2.5D模型的框架。", "motivation": "当前专业工作流程需要繁琐的手动分割和艺术性重建，以便实现动画效果，亟需一种自动化的方法来简化这一过程。", "method": "该方法通过将单幅图像分解为完全修复、语义上独立的层，并结合基于扩散的身体部位一致性模块和像素级伪深度推断机制，来实现高质量的层重建。", "conclusion": "该方法生成的高保真、可操作模型适用于专业实时动画应用，显著提高了动漫角色的动态表现能力。"}}}
{"id": "ax-2026-02-03-14", "source": "arxiv", "date": "2026-02-03", "rank": 14, "title": "LIVE: Long-horizon Interactive Video World Modeling", "url": "https://arxiv.org/abs/2602.03747v1", "detail_url": "https://arxiv.org/pdf/2602.03747v1.pdf", "description_en": "Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.", "description_zh": "LIVE是一种新型的长时间交互视频世界建模方法，通过循环一致性目标减少错误积累，从而在长时间生成中获得优异表现。", "keywords": ["长视角", "交互式视频", "世界建模", "自回归模型", "错误累积", "循环一致性", "扩散损失", "训练课程", "稳定训练", "生成模型", "diffusion"], "tags": ["cs.CV"], "metrics": {"authors": ["Junchao Huang", "Ziyang Ye", "Xinting Hu", "Tianyu He", "Guiyu Zhang", "Shaoshuai Shi", "Jiang Bian", "Li Jiang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 4, "penalty": 0}, "reason": "LIVE在长时间生成中通过循环一致性目标有效减少错误积累，具备自我改进能力；技术路径独特，解决复杂问题，具备良好的行业应用潜力，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T17:10:03Z", "ai_summary": {"tldr": "LIVE是一种新型的长时间交互视频世界建模方法，通过循环一致性目标减少错误积累，从而在长时间生成中获得优异表现。", "motivation": "现有的自回归视频世界模型在长时间生成中面临预测误差累积的问题，传统方法无法有效解决这一挑战。", "method": "LIVE通过前向滚动和反向生成过程结合新的循环一致性目标来限制错误积累，避免了教师模型的使用，并引入了渐进训练课程以稳定训练过程。", "conclusion": "实验表明，LIVE在长时间基准测试中表现卓越，生成的高质量视频超出了训练滚动长度的限制。"}}}
{"id": "ax-2026-02-03-15", "source": "arxiv", "date": "2026-02-03", "rank": 15, "title": "Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment", "url": "https://arxiv.org/abs/2602.03742v1", "detail_url": "https://arxiv.org/pdf/2602.03742v1.pdf", "description_en": "Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.", "description_zh": "本文提出了一种边缘优化的视觉-语言模型，用于地下基础设施的自动化检测和总结。", "keywords": ["边缘优化", "视觉语言模型", "自主检测", "资源受限", "轻量级模型", "defect segmentation", "VLM", "实时性能", "硬件优化", "移动机器人", "autonomous"], "tags": ["cs.CV"], "metrics": {"authors": ["Johny J. Lopez", "Md Meftahul Ferdaus", "Mahdi Abdelguerfi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了边缘优化的视觉-语言模型，具备良好的用户反馈机制和在线学习潜力，解决了复杂的基础设施检测问题，且具备商业化潜力和高价值用户基础。"}, "raw": {"published": "2026-02-03T17:03:46Z", "ai_summary": {"tldr": "本文提出了一种边缘优化的视觉-语言模型，用于地下基础设施的自动化检测和总结。", "motivation": "自动化检查地下基础设施对公共安全和城市可持续性至关重要，但在资源受限的边缘设备上生成可读总结仍然是一个挑战。", "method": "研究提出了一个两阶段的管道，结合轻量级的RAPID-SCAN分割模型与在边缘计算平台上部署的微调视觉-语言模型，实现高效的缺陷分割和自然语言总结。", "conclusion": "实验结果表明，边缘可部署的集成AI系统能够有效地将自动缺陷检测与基础设施维护的可操作见解结合起来，为更具可扩展性和自主性的检查解决方案铺平了道路。"}}}
{"id": "ax-2026-02-03-16", "source": "arxiv", "date": "2026-02-03", "rank": 16, "title": "RegionReasoner: Region-Grounded Multi-Round Visual Reasoning", "url": "https://arxiv.org/abs/2602.03733v1", "detail_url": "https://arxiv.org/pdf/2602.03733v1.pdf", "description_en": "Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.", "description_zh": "RegionReasoner是一个新提出的多轮视觉推理框架，通过强化学习和区域引用来改善视觉推理的准确性和一致性。", "keywords": ["视觉推理", "多轮推理", "视觉语言模型", "强化学习", "语义一致性", "RegionReasoner", "目标检测", "语义分割", "迭代推理", "context"], "tags": ["cs.CV"], "metrics": {"authors": ["Wenfang Sun", "Hao Chen", "Yingjun Du", "Yefeng Zheng", "Cees G. M. Snoek"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "RegionReasoner展示了多轮推理的自我改进能力，强化学习框架提升了推理一致性，具备较强的技术壁垒和行业应用潜力。团队背景信息不足，商业模式尚需明确。"}, "raw": {"published": "2026-02-03T16:52:16Z", "ai_summary": {"tldr": "RegionReasoner是一个新提出的多轮视觉推理框架，通过强化学习和区域引用来改善视觉推理的准确性和一致性。", "motivation": "现有的视觉语言模型在多轮推理中表现有限，无法有效在多个视觉上下文中迭代性地提升理解能力，因此需要一个新的评估基准和框架。", "method": "RegionReasoner通过要求每个推理过程明确引用相应的边界框，并结合全局-局部一致性的奖励机制，确保推理步骤之间的语义一致性。", "conclusion": "实验结果表明，RegionReasoner显著提高了多轮推理的准确性、空间定位精度和全局-局部一致性，为这一新兴研究方向奠定了坚实的基线。"}}}
{"id": "ax-2026-02-03-17", "source": "arxiv", "date": "2026-02-03", "rank": 17, "title": "Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL", "url": "https://arxiv.org/abs/2602.03839v1", "detail_url": "https://arxiv.org/pdf/2602.03839v1.pdf", "description_en": "Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically relevant settings. Leveraging this structure, we propose PULSE (Patch Updates via Lossless Sparse Encoding), a simple yet highly efficient lossless weight synchronization method that transmits only the indices and values of modified parameters. PULSE is robust to transmission errors and avoids floating-point drift inherent in additive delta schemes. In bandwidth-constrained decentralized environments, our approach achieves over 100x (14 GB to ~108 MB) communication reduction while maintaining bit-identical training dynamics and performance compared to full weight synchronization. By exploiting this structure, PULSE enables decentralized RL training to approach centralized throughput, reducing the bandwidth required for weight synchronization from 20 Gbit/s to 0.2 Gbit/s to maintain high GPU utilization.", "description_zh": "本研究提出了一种名为PULSE的高效权重同步方法，通过利用权重更新的稀疏性显著减少了通信带宽需求。", "keywords": ["强化学习", "分布式", "权重更新", "稀疏编码", "PULSE", "通信效率", "模型训练", "深度学习", "低带宽", "llm"], "tags": ["cs.LG"], "metrics": {"authors": ["Erfan Miahi", "Eugene Belilovsky"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 20, "business": 12, "team": 8, "bonus": 6, "penalty": 0}, "reason": "PULSE方法利用权重更新的稀疏性，显著提升了分布式强化学习的通信效率，具备较强的AI原生性。技术路径前沿且复杂，具备一定的壁垒。商业模式与高价值用户绑定较弱，团队信息不足，但具备一定的进化能力。"}, "raw": {"published": "2026-02-03T18:56:48Z", "ai_summary": {"tldr": "本研究提出了一种名为PULSE的高效权重同步方法，通过利用权重更新的稀疏性显著减少了通信带宽需求。", "motivation": "在带宽受限的分布式强化学习中，策略权重的同步是可扩展性的瓶颈，因此需要高效的权重同步方案。", "method": "PULSE方法通过仅传输修改参数的索引和值，实现无损稀疏编码，避免了浮点漂移和传输错误。", "conclusion": "PULSE在带宽受限的环境中实现了超过100倍的通信减少，同时保持了与全权重同步相同的训练动态和性能。"}}}
{"id": "ax-2026-02-03-18", "source": "arxiv", "date": "2026-02-03", "rank": 18, "title": "Robust Intervention Learning from Emergency Stop Interventions", "url": "https://arxiv.org/abs/2602.03825v1", "detail_url": "https://arxiv.org/pdf/2602.03825v1.pdf", "description_en": "Human interventions are a common source of data in autonomous systems during testing. These interventions provide an important signal about where the current policy needs improvement, but are often noisy and incomplete. We define Robust Intervention Learning (RIL) as the problem of learning from intervention data while remaining robust to the quality and informativeness of the intervention signal. In the best case, interventions are precise and avoiding them is sufficient to solve the task, but in many realistic settings avoiding interventions is necessary but not sufficient for achieving good performance. We study robust intervention learning in the context of emergency stop interventions and propose Residual Intervention Fine-Tuning (RIFT), a residual fine-tuning algorithm that treats intervention feedback as an incomplete learning signal and explicitly combines it with a prior policy. By framing intervention learning as a fine-tuning problem, our approach leverages structure encoded in the prior policy to resolve ambiguity when intervention signals under-specify the task. We provide theoretical analysis characterizing conditions under which this formulation yields principled policy improvement, and identify regimes where intervention learning is expected to fail. Our experiments reveal that residual fine-tuning enables robust and consistent policy improvement across a range of intervention strategies and prior policy qualities, and highlight robust intervention learning as a promising direction for future work.", "description_zh": "本研究提出了一种鲁棒干预学习方法，旨在从噪声和不完整的干预信号中学习，以提高自主系统的政策性能。", "keywords": ["干预学习", "强健学习", "机器学习", "深度学习", "神经网络", "自主系统", "反馈机制", "Residual Intervention Fine-Tuning", "应急停止干预", "策略改进", "autonomous"], "tags": ["cs.LG"], "metrics": {"authors": ["Ethan Pronovost", "Khimya Khetarpal", "Siddhartha Srinivasa"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous", "rag", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出了鲁棒干预学习方法，具备一定的自我改进能力，但缺乏明确的商业模式和团队信息，技术路径较为常规，未显著体现非共识判断力。"}, "raw": {"published": "2026-02-03T18:33:21Z", "ai_summary": {"tldr": "本研究提出了一种鲁棒干预学习方法，旨在从噪声和不完整的干预信号中学习，以提高自主系统的政策性能。", "motivation": "自主系统在测试过程中常常依赖人类干预数据，但这些数据常常不够精确且不完整，因此需要开发新的学习方法来有效利用这些干预信号。", "method": "提出了一种残差干预微调算法（RIFT），将干预反馈视为不完整的学习信号，并与先前的策略显式结合，以提升政策的鲁棒性。", "conclusion": "实验结果表明，残差微调能够在多种干预策略和先前政策质量下实现政策的稳健和一致性改进，展示了鲁棒干预学习的未来研究潜力。"}}}
{"id": "ax-2026-02-03-19", "source": "arxiv", "date": "2026-02-03", "rank": 19, "title": "SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving", "url": "https://arxiv.org/abs/2602.03816v1", "detail_url": "https://arxiv.org/pdf/2602.03816v1.pdf", "description_en": "We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.", "description_zh": "SymPlex是一个用于发现偏微分方程解析解的强化学习框架，通过树结构决策优化候选解。", "keywords": ["符号PDE", "强化学习", "结构感知", "Transformer", "树结构决策", "语法约束", "深度学习", "解析解", "符号表达", "人类可读"], "tags": ["cs.LG"], "metrics": {"authors": ["Yesom Park", "Annie C. Lu", "Shao-Ching Huang", "Qiyang Hu", "Y. Sungtaek Ju", "Stanley Osher"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "transformer"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 8, "bonus": 4, "penalty": 0}, "reason": "SymPlex在符号PDE求解中展现出较高的AI原生程度，具备自我优化能力，且技术路径独特，解决复杂问题。商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T18:18:30Z", "ai_summary": {"tldr": "SymPlex是一个用于发现偏微分方程解析解的强化学习框架，通过树结构决策优化候选解。", "motivation": "研究旨在解决偏微分方程的解析解问题，特别是在没有真实表达式的情况下，提供可解释且人类可读的解。", "method": "SymPlex通过其核心组件SymFormer，利用树相对自注意力建模层次符号依赖，并通过语法约束的自回归解码确保语法有效性。", "conclusion": "实证结果表明，使用深度学习符号方法可以准确恢复非光滑和参数化的偏微分方程解。"}}}
{"id": "ax-2026-02-03-20", "source": "arxiv", "date": "2026-02-03", "rank": 20, "title": "Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network", "url": "https://arxiv.org/abs/2602.03808v1", "detail_url": "https://arxiv.org/pdf/2602.03808v1.pdf", "description_en": "Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model's step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.", "description_zh": "提出了一种名为CL3AN-GNN的模型，通过课程引导特征学习和三阶段注意力网络来改善图神经网络中的不平衡节点分类问题。", "keywords": ["节点分类", "图神经网络", "特征学习", "注意力网络", "课程学习", "生成模型", "语义搜索", "迭代消息传递", "neural network"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen", "Shaoyang Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "neural network", "embedding"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提出了课程引导特征学习和三阶段注意力网络，具备一定的自我改进能力，但缺乏明确的商业模式和团队信息，整体创新性和市场潜力有限。"}, "raw": {"published": "2026-02-03T18:10:40Z", "ai_summary": {"tldr": "提出了一种名为CL3AN-GNN的模型，通过课程引导特征学习和三阶段注意力网络来改善图神经网络中的不平衡节点分类问题。", "motivation": "不平衡节点分类导致模型对少数类标签的学习不公平，影响性能，因此需要有效的方法来解决这一问题。", "method": "CL3AN-GNN采用三阶段注意力机制，首先从简单特征入手，再逐步处理复杂连接，最后通过迭代消息传递和课程对齐损失加权整合特征。", "conclusion": "在多个开放图基准数据集上，CL3AN-GNN在准确率、F1分数和AUC等指标上均优于最新的先进方法，验证了课程学习在不平衡分类中的有效性。"}}}
{"id": "ax-2026-02-03-21", "source": "arxiv", "date": "2026-02-03", "rank": 21, "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation", "url": "https://arxiv.org/abs/2602.03806v1", "detail_url": "https://arxiv.org/pdf/2602.03806v1.pdf", "description_en": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.", "description_zh": "本论文提出了一种结合在线和离线强化学习的新方法Cobalt，用于多轮代码生成，并在性能上显著超越了现有基线。", "keywords": ["上下文学习", "强化学习", "多轮代码生成", "大语言模型", "代码生成轨迹", "迭代决策", "机器人过程", "语境提示", "在线学习", "llm"], "tags": ["cs.LG", "cs.AI", "cs.CL", "cs.SE"], "metrics": {"authors": ["Ziru Chen", "Dongdong Chen", "Ruinan Jin", "Yingbin Liang", "Yujia Xie", "Huan Sun"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "Cobalt方法结合在线和离线强化学习，具备良好的自我改进能力和数据反馈机制，体现了较高的AI原生程度。技术路径选择独特，解决复杂问题，具有一定的壁垒。商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:08:41Z", "ai_summary": {"tldr": "本论文提出了一种结合在线和离线强化学习的新方法Cobalt，用于多轮代码生成，并在性能上显著超越了现有基线。", "motivation": "传统的在线强化学习虽然表现较好，但高成本和不稳定性限制了其广泛应用，因此需要一种新方法来有效利用离线轨迹。", "method": "Cobalt通过使用参考LLM收集代码生成轨迹，并将其划分为上下文提示，在在线博弈学习中训练LLM完成每个部分轨迹的单步代码生成。", "conclusion": "实验结果表明，Cobalt在多轮代码生成任务中表现优异，并通过对抗性训练减轻了LLM的奖励劫持行为。"}}}
{"id": "ax-2026-02-03-22", "source": "arxiv", "date": "2026-02-03", "rank": 22, "title": "Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF", "url": "https://arxiv.org/abs/2602.03805v1", "detail_url": "https://arxiv.org/pdf/2602.03805v1.pdf", "description_en": "The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous work developed and deployed tube-based pure and hybrid ML models in the CTF subchannel code, however, full-scale reactor core simulations require the use of rod bundle geometries. Unlike isolated subchannels, rod bundles experience complex thermal hydraulic phenomena such as channel crossflow, spacer grid losses, and effects from unheated conductors. This study investigates the generalization of ML-based CHF prediction models in rod bundles after being trained on tube-based CHF data. A purely data-driven DNN and two hybrid bias-correction models were implemented in the CTF subchannel code and used to predict CHF location and magnitude in the Combustion Engineering 5-by-5 bundle CHF test series. The W-3 correlation, Bowring correlation, and Groeneveld LUT were used as baseline comparators. On average, all three ML-based approaches produced magnitude and location predictions more accurate than the baseline models, with the hybrid LUT model exhibiting the most favorable performance metrics.", "description_zh": "本研究利用管道基础的混合机器学习模型预测棒束中的临界热通量，显示出比传统方法更高的准确性。", "keywords": ["关键字：机器学习", "深度学习", "神经网络", "模型预测", "热流密度", "数据驱动", "组合模型", "CTF子通道代码", "预测精度", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Aidan Furlong", "Robert Salko", "Xingang Zhao", "Xu Wu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "rag"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目利用机器学习提升热通量预测精度，具备一定的自我改进能力，但缺乏在线学习闭环。技术路径独特，解决复杂问题，具备行业壁垒。商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T18:05:16Z", "ai_summary": {"tldr": "本研究利用管道基础的混合机器学习模型预测棒束中的临界热通量，显示出比传统方法更高的准确性。", "motivation": "随着机器学习在临界热通量预测中的应用日益增加，研究者希望开发出比传统经验公式和查找表更准确的模型，特别是在复杂的棒束几何形状中。", "method": "研究中使用了纯数据驱动的深度神经网络和两种混合偏差校正模型，训练后应用于燃烧工程5x5棒束的CHF测试系列。", "conclusion": "所有三种机器学习方法在预测幅度和位置上均优于基线模型，混合查找表模型表现最佳。"}}}
{"id": "ax-2026-02-03-23", "source": "arxiv", "date": "2026-02-03", "rank": 23, "title": "Manifold Random Features", "url": "https://arxiv.org/abs/2602.03797v1", "detail_url": "https://arxiv.org/pdf/2602.03797v1.pdf", "description_en": "We present a new paradigm for creating random features to approximate bi-variate functions (in particular, kernels) defined on general manifolds. This new mechanism of Manifold Random Features (MRFs) leverages discretization of the manifold and the recently introduced technique of Graph Random Features (GRFs) to learn continuous fields on manifolds. Those fields are used to find continuous approximation mechanisms that otherwise, in general scenarios, cannot be derived analytically. MRFs provide positive and bounded features, a key property for accurate, low-variance approximation. We show deep asymptotic connection between GRFs, defined on discrete graph objects, and continuous random features used for regular kernels. As a by-product of our method, we re-discover recently introduced mechanism of Gaussian kernel approximation applied in particular to improve linear-attention Transformers, considering simple random walks on graphs and by-passing original complex mathematical computations. We complement our algorithm with a rigorous theoretical analysis and verify in thorough experimental studies.", "description_zh": "本文提出了一种新的随机特征生成方法，旨在通过流形随机特征逼近在流形上定义的双变量函数。", "keywords": ["流形随机特征", "随机特征", "双变量函数", "核函数", "深度学习", "图随机特征", "连续逼近", "线性注意力", "Transformers", "理论分析"], "tags": ["cs.LG"], "metrics": {"authors": ["Ananya Parashar", "Derek Long", "Dwaipayan Saha", "Krzysztof Choromanski"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["transformer", "rag"], "hit_excludes": []}, "score": {"total": 56, "breakdown": {"ai_native": 15, "tech_niche": 18, "business": 10, "team": 5, "bonus": 0, "penalty": 0}, "reason": "项目提出了流形随机特征的新方法，具有一定的技术创新性，但缺乏用户转化和闭环自我学习的具体应用场景，商业模式不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:00:01Z", "ai_summary": {"tldr": "本文提出了一种新的随机特征生成方法，旨在通过流形随机特征逼近在流形上定义的双变量函数。", "motivation": "为了应对在流形上难以解析推导的连续近似机制，研究者寻求一种有效的随机特征生成方法。", "method": "采用流形离散化与图随机特征技术相结合，提出流形随机特征（MRFs）以学习流形上的连续场。", "conclusion": "MRFs能够提供正值和有界特征，并在实验中验证了其在近似复杂函数方面的有效性及其理论分析。"}}}
{"id": "ax-2026-02-03-24", "source": "arxiv", "date": "2026-02-03", "rank": 24, "title": "Should I use Synthetic Data for That? An Analysis of the Suitability of Synthetic Data for Data Sharing and Augmentation", "url": "https://arxiv.org/abs/2602.03791v1", "detail_url": "https://arxiv.org/pdf/2602.03791v1.pdf", "description_en": "Recent advances in generative modelling have led many to see synthetic data as the go-to solution for a range of problems around data access, scarcity, and under-representation. In this paper, we study three prominent use cases: (1) Sharing synthetic data as a proxy for proprietary datasets to enable statistical analyses while protecting privacy, (2) Augmenting machine learning training sets with synthetic data to improve model performance, and (3) Augmenting datasets with synthetic data to reduce variance in statistical estimation. For each use case, we formalise the problem setting and study, through formal analysis and case studies, under which conditions synthetic data can achieve its intended objectives. We identify fundamental and practical limits that constrain when synthetic data can serve as an effective solution for a particular problem. Our analysis reveals that due to these limits many existing or envisioned use cases of synthetic data are a poor problem fit. Our formalisations and classification of synthetic data use cases enable decision makers to assess whether synthetic data is a suitable approach for their specific data availability problem.", "description_zh": "本文研究了合成数据在数据共享和增强中的适用性，分析了其应用场景及限制。", "keywords": ["生成数据", "生成模型", "机器学习", "数据共享", "数据增强", "模型性能", "统计估计", "人工智能应用", "synthetic data", "use cases", "machine learning"], "tags": ["cs.LG", "cs.CY"], "metrics": {"authors": ["Bogdan Kulynych", "Theresa Stadler", "Jean Louis Raisaro", "Carmela Troncoso"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "generative"], "hit_excludes": []}, "score": {"total": 54, "breakdown": {"ai_native": 15, "tech_niche": 12, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目探讨合成数据的应用适用性，但缺乏明确的自我改进机制和数据反馈闭环，技术路径较为常规，商业模式不够清晰，团队背景信息不足。"}, "raw": {"published": "2026-02-03T17:52:57Z", "ai_summary": {"tldr": "本文研究了合成数据在数据共享和增强中的适用性，分析了其应用场景及限制。", "motivation": "随着生成建模的进步，合成数据被视为解决数据访问、稀缺和缺乏代表性的有效工具，因此需要评估其实际适用性。", "method": "通过形式化分析和案例研究，探讨了合成数据在三种主要用例中的应用条件和限制。", "conclusion": "研究表明，许多现有或设想的合成数据应用场景与问题不匹配，决策者需谨慎评估合成数据的适用性。"}}}
{"id": "ax-2026-02-03-25", "source": "arxiv", "date": "2026-02-03", "rank": 25, "title": "Efficient Estimation of Kernel Surrogate Models for Task Attribution", "url": "https://arxiv.org/abs/2602.03783v1", "detail_url": "https://arxiv.org/pdf/2602.03783v1.pdf", "description_en": "Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task's performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.", "description_zh": "本文提出了一种高效的核替代模型，用于分析多任务学习中各个任务对目标任务的影响，能更好地捕捉非线性交互关系。", "keywords": ["关键词：深度学习", "机器学习", "神经网络", "任务归因", "核心代理模型", "预训练模型", "多目标强化学习", "语境学习", "任务选择", "agent"], "tags": ["cs.LG", "cs.AI", "cs.CL"], "metrics": {"authors": ["Zhenshuo Zhang", "Minxuan Duan", "Hongyang R. Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "transformer", "rag", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了核替代模型，具备一定的自我改进能力和复杂任务处理能力，但缺乏直接的用户交互反馈机制。技术路径创新性较高，商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T17:43:48Z", "ai_summary": {"tldr": "本文提出了一种高效的核替代模型，用于分析多任务学习中各个任务对目标任务的影响，能更好地捕捉非线性交互关系。", "motivation": "随着大型语言模型在多种任务上同时训练，了解每个训练任务对目标任务表现的影响变得至关重要，但传统的逐一剔除方法计算成本过高。", "method": "提出了一种统一的任务加权框架，并引入核替代模型，通过基于梯度的估计程序高效学习，有效捕捉二阶任务交互。", "conclusion": "与线性替代模型相比，核替代模型在多个领域表现出更高的准确性，尤其在后续任务选择中显著提高了演示选择的效果。"}}}
{"id": "ax-2026-02-03-26", "source": "arxiv", "date": "2026-02-03", "rank": 26, "title": "Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity", "url": "https://arxiv.org/abs/2602.03778v1", "detail_url": "https://arxiv.org/pdf/2602.03778v1.pdf", "description_en": "Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.", "description_zh": "本文提出了一种基于增广状态的静态条件价值-at-risk (CVaR)目标的新公式，旨在改进风险敏感策略的学习。", "keywords": ["奖励再分配", "CVaR", "MDPs", "Bellman算子", "风险规避", "强化学习", "价值迭代", "模型无关Q学习", "状态增强"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Aneri Muni", "Vincent Taboga", "Esther Derman", "Pierre-Luc Bacon", "Erick Delage"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目提出了新的CVaR目标和算法，具备一定的技术创新和应用潜力，但缺乏商业模式的清晰性和团队背景信息。"}, "raw": {"published": "2026-02-03T17:39:45Z", "ai_summary": {"tldr": "本文提出了一种基于增广状态的静态条件价值-at-risk (CVaR)目标的新公式，旨在改进风险敏感策略的学习。", "motivation": "在安全关键应用中，静态CVaR用于防止稀有但灾难性的事件，但其不具备递归的贝尔曼分解，限制了其应用。", "method": "通过状态增广，提出了一种新的贝尔曼算子，构建了风险厌恶的值迭代和无模型Q学习算法，并提供了收敛性保证和近似误差界限。", "conclusion": "实验结果表明，所提出的算法成功学习了对CVaR敏感的策略，并在性能与安全性之间实现了有效的权衡。"}}}
{"id": "ax-2026-02-03-27", "source": "arxiv", "date": "2026-02-03", "rank": 27, "title": "Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon", "url": "https://arxiv.org/abs/2602.03767v1", "detail_url": "https://arxiv.org/pdf/2602.03767v1.pdf", "description_en": "Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders' needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.", "description_zh": "本研究提出了一种决策导向的基准框架，旨在通过人工智能天气预测模型改善印度季风的预测，为面临气候变化的农业提供支持。", "keywords": ["气象预测", "决策导向", "人工智能天气预测", "机器学习", "深度学习", "预测模型", "社会科学", "农业适应", "气候变化", "开放访问模型", "artificial intelligence"], "tags": ["cs.LG", "cs.AI", "econ.GN", "physics.ao-ph"], "metrics": {"authors": ["Rajat Masiwal", "Colin Aitken", "Adam Marchakitus", "Mayank Gupta", "Katherine Kowal", "Hamid A. Pahlavan", "Tyler Yang", "Y. Qiang Sun", "Michael Kremer", "Amir Jina", "William R. Boos", "Pedram Hassanzadeh"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "artificial intelligence"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了决策导向的基准框架，连接气象、AI与社会科学，但缺乏自我进化的闭环设计。技术路径具备一定的独特性，商业模式与高价值用户关联度较低。团队背景信息不足，难以评估进化能力。"}, "raw": {"published": "2026-02-03T17:27:22Z", "ai_summary": {"tldr": "本研究提出了一种决策导向的基准框架，旨在通过人工智能天气预测模型改善印度季风的预测，为面临气候变化的农业提供支持。", "motivation": "现有的AI天气预测模型在性能上优于传统模型，但评估方法未能考虑地方利益相关者在决策中的需求，因此需要新的框架来连接气象学、人工智能和社会科学。", "method": "研究引入了一个决策导向的基准框架，并应用于印度季风预测，评估了农业相关的降雨启动指数，并通过确定性和概率性指标进行验证。", "conclusion": "该框架为利用AI天气预测模型帮助脆弱人群适应气候变化提供了重要蓝图，并在2025年指导了向3800万印度农民发送季风预测的政府举措。"}}}
{"id": "ax-2026-02-03-28", "source": "arxiv", "date": "2026-02-03", "rank": 28, "title": "Soft Sensor for Bottom-Hole Pressure Estimation in Petroleum Wells Using Long Short-Term Memory and Transfer Learning", "url": "https://arxiv.org/abs/2602.03737v1", "detail_url": "https://arxiv.org/pdf/2602.03737v1.pdf", "description_en": "Monitoring bottom-hole variables in petroleum wells is essential for production optimization, safety, and emissions reduction. Permanent Downhole Gauges (PDGs) provide real-time pressure data but face reliability and cost issues. We propose a machine learning-based soft sensor to estimate flowing Bottom-Hole Pressure (BHP) using wellhead and topside measurements. A Long Short-Term Memory (LSTM) model is introduced and compared with Multi-Layer Perceptron (MLP) and Ridge Regression. We also pioneer Transfer Learning for adapting models across operational environments. Tested on real offshore datasets from Brazil's Pre-salt basin, the methodology achieved Mean Absolute Percentage Error (MAPE) consistently below 2\\%, outperforming benchmarks. This work offers a cost-effective, accurate alternative to physical sensors, with broad applicability across diverse reservoir and flow conditions.", "description_zh": "本文提出了一种基于长短期记忆网络和迁移学习的软传感器，用于估算石油井的底部压力，性能优于传统传感器。", "keywords": ["软传感器", "底孔压力", "机器学习", "长短期记忆", "转移学习", "多层感知机", "实时监测", "油田优化", "LSTM", "MAPE", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["M. A. Fernandes", "E. Gildin", "M. A. Sampaio"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["machine learning", "ml"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目利用LSTM和迁移学习实现了高效的底孔压力估算，具备AI原生特征。技术路径独特，解决了石油行业的复杂问题，具备良好的市场潜力。团队背景信息不足，未能明确显示进化能力。"}, "raw": {"published": "2026-02-03T16:56:21Z", "ai_summary": {"tldr": "本文提出了一种基于长短期记忆网络和迁移学习的软传感器，用于估算石油井的底部压力，性能优于传统传感器。", "motivation": "监测石油井的底部变量对生产优化、安全和减排至关重要，但现有的永久井下仪表存在可靠性和成本问题。", "method": "采用长短期记忆网络（LSTM）模型，并与多层感知器（MLP）和岭回归进行了比较，同时引入迁移学习以适应不同操作环境。", "conclusion": "在巴西预盐盆地的真实海上数据集上测试，该方法的一致平均绝对百分比误差（MAPE）低于2%，提供了一种经济、准确的替代物理传感器的方案。"}}}
{"id": "ax-2026-02-03-29", "source": "arxiv", "date": "2026-02-03", "rank": 29, "title": "Fast-MWEM: Private Data Release in Sublinear Time", "url": "https://arxiv.org/abs/2602.03732v1", "detail_url": "https://arxiv.org/pdf/2602.03732v1.pdf", "description_en": "The Multiplicative Weights Exponential Mechanism (MWEM) is a fundamental iterative framework for private data analysis, with broad applications such as answering $m$ linear queries, or privately solving systems of $m$ linear constraints. However, a critical bottleneck hindering its scalability is the $Θ(m)$ time complexity required to execute the exponential mechanism in each iteration. We introduce a modification to the MWEM framework that improves the per-iteration runtime dependency to $Θ(\\sqrt{m})$ in expectation. This is done via a lazy sampling approach to the Report-Noisy-Max mechanism, which we implement efficiently using Gumbel noise and a $k$-Nearest Neighbor data structure. This allows for the rapid selection of the approximate score in the exponential mechanism without an exhaustive linear scan. We apply our accelerated framework to the problems of private linear query release and solving Linear Programs (LPs) under neighboring constraint conditions and low-sensitivity assumptions. Experimental evaluation confirms that our method provides a substantial runtime improvement over classic MWEM.", "description_zh": "Fast-MWEM通过懒抽样方法将MWEM的每次迭代运行时间复杂度降低到Θ(√m)。", "keywords": ["私有数据发布", "多重权重指数机制", "私有数据分析", "线性查询", "近邻数据结构", "Gumbel噪声", "加速框架", "低敏感性假设", "迭代优化", "agent"], "tags": ["cs.LG"], "metrics": {"authors": ["Themistoklis Haris", "Steve Choi", "Mutiraj Laksanawisit"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 58, "breakdown": {"ai_native": 15, "tech_niche": 20, "business": 10, "team": 8, "bonus": 5, "penalty": 0}, "reason": "该项目在私有数据分析领域具有技术创新，但缺乏明显的AI原生闭环和自我学习能力。商业模式不够清晰，团队信息不足，未体现出显著的行业壁垒。"}, "raw": {"published": "2026-02-03T16:51:40Z", "ai_summary": {"tldr": "Fast-MWEM通过懒抽样方法将MWEM的每次迭代运行时间复杂度降低到Θ(√m)。", "motivation": "MWEM在隐私数据分析中的广泛应用受限于其每次迭代的Θ(m)时间复杂度，影响了可扩展性。", "method": "通过采用懒抽样策略和Gumbel噪声，实现了一种高效的Report-Noisy-Max机制，显著加快了指数机制的选择过程。", "conclusion": "实验表明，Fast-MWEM在私有线性查询释放和线性规划求解中，相较于经典MWEM显著提高了运行效率。"}}}
{"id": "ax-2026-02-03-30", "source": "arxiv", "date": "2026-02-03", "rank": 30, "title": "Efficient Training of Boltzmann Generators Using Off-Policy Log-Dispersion Regularization", "url": "https://arxiv.org/abs/2602.03729v1", "detail_url": "https://arxiv.org/pdf/2602.03729v1.pdf", "description_en": "Sampling from unnormalized probability densities is a central challenge in computational science. Boltzmann generators are generative models that enable independent sampling from the Boltzmann distribution of physical systems at a given temperature. However, their practical success depends on data-efficient training, as both simulation data and target energy evaluations are costly. To this end, we propose off-policy log-dispersion regularization (LDR), a novel regularization framework that builds on a generalization of the log-variance objective. We apply LDR in the off-policy setting in combination with standard data-based training objectives, without requiring additional on-policy samples. LDR acts as a shape regularizer of the energy landscape by leveraging additional information in the form of target energy labels. The proposed regularization framework is broadly applicable, supporting unbiased or biased simulation datasets as well as purely variational training without access to target samples. Across all benchmarks, LDR improves both final performance and data efficiency, with sample efficiency gains of up to one order of magnitude.", "description_zh": "提出了一种高效的Boltzmann生成器训练方法，通过离政策对数离散正则化提升数据效率和性能。", "keywords": ["生成模型", "采样", "训练", "能量分布", "数据效率", "Boltzmann生成器", "off-policy", "正则化", "generative"], "tags": ["cs.LG"], "metrics": {"authors": ["Henrik Schopmans", "Christopher von Klitzing", "Pascal Friederich"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "rag"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目提出了一种新颖的正则化方法，提升了Boltzmann生成器的训练效率，具备一定的技术壁垒。但缺乏明确的商业模式和团队背景信息，影响了整体评分。"}, "raw": {"published": "2026-02-03T16:49:32Z", "ai_summary": {"tldr": "提出了一种高效的Boltzmann生成器训练方法，通过离政策对数离散正则化提升数据效率和性能。", "motivation": "在计算科学中，从非标准概率密度进行采样是一大挑战，Boltzmann生成器的成功依赖于数据高效的训练。", "method": "提出的离政策对数离散正则化（LDR）作为能量景观的形状正则化器，结合标准数据驱动的训练目标，无需额外的策略样本。", "conclusion": "LDR显著提高了最终性能和数据效率，样本效率提升可达一个数量级。"}}}
{"id": "gh-2026-02-04-1", "source": "github", "date": "2026-02-04", "rank": 1, "title": "masoncl/review-prompts", "url": "https://github.com/masoncl/review-prompts", "detail_url": "https://github.com/masoncl/review-prompts", "description_en": "AI review prompts", "description_zh": "项目简介：AI Review Prompts 是一个旨在帮助用户生成高质量评审提示的工具。它主要面向需要撰写评审意见的学术研究人员、教师和学生，尤其适用于科研论文、项目报告等场景。该项目利用先进的人工智能技术，特别是自然语言处理（NLP），自动生成符合学术标准的评审建议，从而提升评审效率与质量。", "keywords": ["生成式对话", "机器学习", "深度学习", "神经网络", "LLM", "Chatbot", "语义搜索", "自主代理", "代理工作流", "上下文理解"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 39, "stars_today": 288}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 56, "breakdown": {"ai_native": 15, "tech_niche": 12, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目主要是生成评审提示，缺乏用户自我反馈和在线学习机制，技术路径较为常见，商业模式与价值绑定较弱，团队背景信息不足。"}, "raw": {}}
{"id": "gh-2026-02-04-2", "source": "github", "date": "2026-02-04", "rank": 2, "title": "karpathy/nanochat", "url": "https://github.com/karpathy/nanochat", "detail_url": "https://github.com/karpathy/nanochat", "description_en": "The best ChatGPT that $100 can buy.", "description_zh": "最佳的 ChatGPT，价格仅需 $100。该项目旨在为用户提供高效、智能的聊天体验，适用于个人用户、企业客户以及需要自动化客户支持的场景。核心技术包括先进的自然语言处理（NLP）和机器学习算法，以实现更人性化的对话和精准的信息提取。", "keywords": ["聊天机器人", "生成式", "深度学习", "自主代理", "语义搜索", "LLM", "GPT", "代理基础设施", "上下文", "在线学习"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 5442, "stars_today": 307}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["gpt"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提供了智能聊天体验，具备一定的自我学习能力，但缺乏明确的在线学习闭环和自我进化机制。技术路径较为常见，未体现明显的非共识判断力。"}, "raw": {}}
{"id": "gh-2026-02-04-3", "source": "github", "date": "2026-02-04", "rank": 3, "title": "OpenBMB/ChatDev", "url": "https://github.com/OpenBMB/ChatDev", "detail_url": "https://github.com/OpenBMB/ChatDev", "description_en": "ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration", "description_zh": "ChatDev 2.0：通过大型语言模型（LLM）驱动的多智能体协作实现全面开发。\n\n主要功能包括利用人工智能协助代码生成、调试和文档编写，提升开发效率。目标用户为软件开发人员和团队，适用于协作开发、项目管理等场景。核心技术基于先进的自然语言处理和机器学习算法，特别强调多智能体系统的协作能力。", "keywords": ["LLM", "多代理", "协作", "生成式", "语义搜索", "深度学习", "神经网络", "代理基础设施", "在线学习"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 3697, "stars_today": 226}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 16, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目强调多智能体协作和在线学习，具备一定的自我进化能力，但在确定性工作流和用户数据反馈方面仍有不足。技术路径较为前沿，具备一定的行业壁垒。商业模式与高价值用户紧密结合，团队背景较强。"}, "raw": {}}
{"id": "gh-2026-02-04-4", "source": "github", "date": "2026-02-04", "rank": 4, "title": "automazeio/ccpm", "url": "https://github.com/automazeio/ccpm", "detail_url": "https://github.com/automazeio/ccpm", "description_en": "Project management system for Claude Code using GitHub Issues and Git worktrees for parallel agent execution.", "description_zh": "Claude Code 的项目管理系统，利用 GitHub Issues 和 Git 工作树实现并行代理执行。该系统主要功能是优化项目管理流程，支持多任务并行处理，适用于开发团队和项目管理者。核心技术包括 GitHub 的版本控制、工作树管理以及人工智能驱动的任务分配与执行优化。", "keywords": ["项目管理", "Claude Code", "GitHub Issues", "并行代理执行", "任务管理", "自动化", "代理", "机器学习", "深度学习", "语义搜索"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 711, "stars_today": 384}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude", "agent"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目利用 GitHub Issues 和工作树实现并行执行，具备一定的 AI 驱动任务优化能力，但缺乏自我学习和进化机制。技术路径相对主流，具备一定的行业应用，但壁垒不够深厚。商业模式与价值绑定较强，团队背景信息不足，未显示出显著的进化能力。"}, "raw": {}}
{"id": "gh-2026-02-04-5", "source": "github", "date": "2026-02-04", "rank": 5, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "一个有效的自主技能框架和软件开发方法论。该项目旨在帮助开发者提升软件开发中的自主技能，适用于软件工程师、项目经理和团队领导等用户。核心技术包括人工智能驱动的技能评估与提升工具，旨在优化团队协作和项目管理效率。", "keywords": ["智能代理", "agentic skills", "软件开发方法论", "机器学习", "深度学习", "神经网络", "语义搜索", "自主代理", "生成模型", "多代理"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3339, "stars_today": 998}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的自主代理能力，但缺乏明确的在线学习闭环。技术路径较为独特，能解决复杂问题。商业模式与高价值用户绑定较弱，团队背景较好。"}, "raw": {}}
{"id": "gh-2026-02-04-6", "source": "github", "date": "2026-02-04", "rank": 6, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件能够自动记录您在编码过程中 Claude 所做的一切，利用 Claude 的 agent-sdk 进行 AI 压缩，并将相关上下文注入到未来的编码会话中。主要功能是提高编码效率和上下文记忆，适合开发者和程序员在长时间的项目中使用。该插件核心技术基于 AI 算法，旨在优化代码编写和知识管理过程。", "keywords": ["Claude Code", "自动化编码", "上下文注入", "AI助手", "生成模型", "深度学习", "神经网络", "语义搜索", "多智能体"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1442, "stars_today": 2618}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该插件利用 Claude 的 agent-sdk 实现上下文注入，具备一定的自我学习能力，但缺乏更强的自进化机制。技术路径具有一定的独特性，商业模式与高价值用户紧密绑定，团队背景较强。"}, "raw": {}}
{"id": "gh-2026-02-04-7", "source": "github", "date": "2026-02-04", "rank": 7, "title": "virattt/dexter", "url": "https://github.com/virattt/dexter", "detail_url": "https://github.com/virattt/dexter", "description_en": "An autonomous agent for deep financial research", "description_zh": "一个用于深度金融研究的自主智能体。\n\n主要功能包括自动化数据收集、分析金融市场趋势和生成投资建议。目标用户为金融分析师、投资者及研究机构，适用于进行深入的市场研究和决策支持。该项目运用了机器学习和自然语言处理等核心技术，以提升数据分析的效率和准确性。", "keywords": ["深度学习", "自主代理", "机器学习", "神经网络", "生成模型", "语义搜索", "代理基础设施", "多代理系统", "在线学习", "agent"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1250, "stars_today": 406}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "autonomous"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备较强的自我学习能力和数据反馈机制，能够为用户提供高质量的投资建议，技术路径独特且深度绑定金融领域，商业模式与高价值用户紧密结合，团队背景扎实，具备良好的进化能力。"}, "raw": {}}
{"id": "gh-2026-02-04-8", "source": "github", "date": "2026-02-04", "rank": 8, "title": "pedramamini/Maestro", "url": "https://github.com/pedramamini/Maestro", "detail_url": "https://github.com/pedramamini/Maestro", "description_en": "Agent Orchestration Command Center", "description_zh": "项目名称：代理编排指挥中心（Agent Orchestration Command Center）\n\n简介：该项目旨在提供一个集成的平台，用于管理和编排多个智能代理，以实现高效的任务自动化和决策支持。主要功能包括代理的动态调度、实时监控和性能分析，适用于企业自动化、客户服务和数据处理等场景。核心技术方面，项目使用了人工智能算法进行代理行为优化和数据分析，以提高系统的智能化和响应速度。", "keywords": ["智能代理", "Agent Orchestration", "任务调度", "机器学习", "深度学习", "神经网络", "自动化", "语义搜索", "生成模型", "多代理系统"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 162, "stars_today": 186}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备多代理系统的编排能力，符合AI原生特性，但缺乏用户反馈闭环。技术路径具有一定创新性，解决复杂问题，且有清晰的行业应用场景。商业模式与高价值用户绑定良好。团队背景信息不足，未能体现明显的AI原生进化能力。"}, "raw": {}}
{"id": "gh-2026-02-04-9", "source": "github", "date": "2026-02-04", "rank": 9, "title": "vm0-ai/vm0", "url": "https://github.com/vm0-ai/vm0", "detail_url": "https://github.com/vm0-ai/vm0", "description_en": "the easiest way to run natural language-described workflows automatically", "description_zh": "这个项目提供了最简单的方法来自动运行自然语言描述的工作流程。主要功能包括将用户的自然语言指令转化为可执行的工作流程，适用于需要简化任务自动化的开发者和非技术用户。核心技术使用了自然语言处理（NLP）和机器学习算法，以实现高效的指令解析和执行。", "keywords": ["自然语言处理", "工作流自动化", "机器学习", "深度学习", "生成模型", "语义搜索", "自主代理", "多代理系统", "机器人助手", "任务自动化", "workflow"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 32, "stars_today": 316}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的自动化能力，但用户转化为数据标注员的闭环不够明确，缺乏自我进化机制。技术路径有独特性，能解决复杂问题，商业模式与高价值用户绑定，但尚需进一步验证。团队背景信息不足。"}, "raw": {}}
{"id": "ax-2026-02-03-1", "source": "arxiv", "date": "2026-02-03", "rank": 1, "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations", "url": "https://arxiv.org/abs/2602.03828v1", "detail_url": "https://arxiv.org/pdf/2602.03828v1.pdf", "description_en": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.", "description_zh": "AutoFigure是一个自动生成高质量科学插图的框架，基于长文本输入，并通过FigureBench进行评估。", "keywords": ["生成", "科学插图", "自动生成", "机器学习", "深度学习", "神经网络", "代理框架", "文本到插图", "FigureBench", "论文插图", "agent"], "tags": ["cs.AI", "cs.CL", "cs.CV", "cs.DL"], "metrics": {"authors": ["Minjun Zhu", "Zhen Lin", "Yixuan Weng", "Panzhong Lu", "Qiujie Xie", "Yifan Wei", "Sifan Liu", "Qiyao Sun", "Yue Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "AutoFigure具备较强的AI原生能力，通过用户输入生成插图并不断优化，形成闭环；技术路径独特，解决复杂问题并依赖高质量数据；商业模式与高价值用户紧密结合，团队背景扎实，具备快速迭代能力。"}, "raw": {"published": "2026-02-03T18:41:43Z", "ai_summary": {"tldr": "AutoFigure是一个自动生成高质量科学插图的框架，基于长文本输入，并通过FigureBench进行评估。", "motivation": "科学插图在有效传达复杂概念方面至关重要，但手动制作过程效率低下，亟需自动化解决方案。", "method": "AutoFigure框架通过思考、重组和验证，生成结构合理且美观的科学插图，同时依托FigureBench数据集进行性能评估。", "conclusion": "实验结果表明，AutoFigure在生成符合出版标准的科学插图方面性能优于所有基线方法。"}}}
{"id": "ax-2026-02-03-2", "source": "arxiv", "date": "2026-02-03", "rank": 2, "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity", "url": "https://arxiv.org/abs/2602.03794v1", "detail_url": "https://arxiv.org/pdf/2602.03794v1.pdf", "description_en": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.", "description_zh": "异构多智能体系统在性能扩展上优于同质智能体系统，因为多样性显著提升了任务处理能力。", "keywords": ["多代理系统", "LLM", "代理", "多样性", "任务不确定性", "信息论框架", "效果通道", "协同工作", "机器学习", "深度学习"], "tags": ["cs.AI", "cs.LG"], "metrics": {"authors": ["Yingxuan Yang", "Chengrui Qu", "Muning Wen", "Laixi Shi", "Ying Wen", "Weinan Zhang", "Adam Wierman", "Shangding Gu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 16, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目展示了异构多智能体系统的优势，符合自我改进和闭环学习的特征，但缺乏明确的商业模式和团队背景信息。"}, "raw": {"published": "2026-02-03T17:58:10Z", "ai_summary": {"tldr": "异构多智能体系统在性能扩展上优于同质智能体系统，因为多样性显著提升了任务处理能力。", "motivation": "研究者希望理解在基于LLM的多智能体系统中，智能体数量增加时为何存在边际效益递减现象，以及多样性如何提升性能。", "method": "通过信息论框架，提出了有效通道数K*的概念，以量化不同配置的贡献，并分析任务不确定性对性能的限制。", "conclusion": "异构智能体配置的性能一致超越同质智能体，提供了通过多样性设计构建高效、稳健的多智能体系统的指导。"}}}
{"id": "ax-2026-02-03-3", "source": "arxiv", "date": "2026-02-03", "rank": 3, "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration", "url": "https://arxiv.org/abs/2602.03786v1", "detail_url": "https://arxiv.org/pdf/2602.03786v1.pdf", "description_en": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra", "description_zh": "AOrchestra是一个自动化子代理创建的系统，通过动态抽象模型提升多轮任务解决的适应性和效率。", "keywords": ["子代理", "任务自动化", "多轮任务解决", "代理抽象", "统一框架", "自适应能力", "AOrchestra", "任务执行器", "代理系统", "绩效成本权衡", "agent"], "tags": ["cs.AI", "cs.CL"], "metrics": {"authors": ["Jianhao Ruan", "Zhihao Xu", "Yiran Peng", "Fashen Ren", "Zhaoyang Yu", "Xinbing Liang", "Jinyu Xiang", "Bang Liu", "Chenglin Wu", "Yuyu Luo", "Jiayi Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "AOrchestra通过动态抽象模型提升了多轮任务的适应性，展现出强大的自我改进能力，符合Agent原生特征。技术路径具备独特性，解决复杂任务。商业模式与高价值用户紧密结合，团队背景强大。"}, "raw": {"published": "2026-02-03T17:46:16Z", "ai_summary": {"tldr": "AOrchestra是一个自动化子代理创建的系统，通过动态抽象模型提升多轮任务解决的适应性和效率。", "motivation": "现有的子代理设计缺乏动态抽象视图，限制了其适应性，迫切需要一种能够自动创建和管理子代理的系统。", "method": "AOrchestra采用统一的代理抽象模型，将代理表示为指令、上下文、工具和模型的元组，以便动态生成专用执行器。", "conclusion": "在GAIA、SWE-Bench和Terminal-Bench等三个基准测试中，AOrchestra相较于最强基准实现了16.28%的相对提升，展示了其在任务执行中的有效性。"}}}
{"id": "ax-2026-02-03-4", "source": "arxiv", "date": "2026-02-03", "rank": 4, "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques", "url": "https://arxiv.org/abs/2602.03837v1", "detail_url": "https://arxiv.org/pdf/2602.03837v1.pdf", "description_en": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.", "description_zh": "本论文展示了如何利用Gemini模型加速科学研究，并提炼出有效的人机协作技术。", "keywords": ["机器学习", "深度学习", "神经网络", "大语言模型", "人机协作", "迭代优化", "跨学科知识转移", "生成模型", "自主代码执行", "llm"], "tags": ["cs.CL", "cs.AI"], "metrics": {"authors": ["David P. Woodruff", "Vincent Cohen-Addad", "Lalit Jain", "Jieming Mao", "Song Zuo", "MohammadHossein Bateni", "Simina Branzei", "Michael P. Brenner", "Lin Chen", "Ying Feng", "Lance Fortnow", "Gang Fu", "Ziyi Guan", "Zahra Hadizadeh", "Mohammad T. Hajiaghayi", "Mahdi JafariRaviz", "Adel Javanmard", "Karthik C. S.", "Ken-ichi Kawarabayashi", "Ravi Kumar", "Silvio Lattanzi", "Euiwoong Lee", "Yi Li", "Ioannis Panageas", "Dimitris Paparas", "Benjamin Przybocki", "Bernardo Subercaseaux", "Ola Svensson", "Shayan Taherijam", "Xuan Wu", "Eylon Yogev", "Morteza Zadimoghaddam", "Samson Zhou", "Vahab Mirrokni"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "autonomous", "embedding"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目展示了AI在科学研究中的深度应用，具备在线学习和自我改进的潜力，技术路径独特且复杂，商业模式与高价值用户紧密结合，团队背景强大。"}, "raw": {"published": "2026-02-03T18:56:17Z", "ai_summary": {"tldr": "本论文展示了如何利用Gemini模型加速科学研究，并提炼出有效的人机协作技术。", "motivation": "随着大语言模型的发展，探索其在高水平数学发现中的应用潜力成为研究的动机。", "method": "通过案例研究，展示了Gemini模型在解决开放问题和生成新证明中的应用，并总结了迭代优化、问题分解等协作技术。", "conclusion": "AI不仅可以作为自动化工具，还能作为科学发现过程中的创新合作伙伴，推动研究进展。"}}}
{"id": "ax-2026-02-03-5", "source": "arxiv", "date": "2026-02-03", "rank": 5, "title": "They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References", "url": "https://arxiv.org/abs/2602.03822v1", "detail_url": "https://arxiv.org/pdf/2602.03822v1.pdf", "description_en": "Meme-based social abuse detection is challenging because harmful intent often relies on implicit cultural symbolism and subtle cross-modal incongruence. Prior approaches, from fusion-based methods to in-context learning with Large Vision-Language Models (LVLMs), have made progress but remain limited by three factors: i) cultural blindness (missing symbolic context), ii) boundary ambiguity (satire vs. abuse confusion), and iii) lack of interpretability (opaque model reasoning). We introduce CROSS-ALIGN+, a three-stage framework that systematically addresses these limitations: (1) Stage I mitigates cultural blindness by enriching multimodal representations with structured knowledge from ConceptNet, Wikidata, and Hatebase; (2) Stage II reduces boundary ambiguity through parameter-efficient LoRA adapters that sharpen decision boundaries; and (3) Stage III enhances interpretability by generating cascaded explanations. Extensive experiments on five benchmarks and eight LVLMs demonstrate that CROSS-ALIGN+ consistently outperforms state-of-the-art methods, achieving up to 17% relative F1 improvement while providing interpretable justifications for each decision.", "description_zh": "CROSS-ALIGN+是一个三阶段框架，旨在提高基于表情包的社会虐待检测的效果，克服文化盲点、边界模糊和缺乏可解释性的问题。", "keywords": ["关键词：深度学习", "大规模视觉语言模型", "文化符号", "多模态表示", "解释性", "CROSS-ALIGN+", "参数高效", "决策边界", "语义搜索", "ml"], "tags": ["cs.CL"], "metrics": {"authors": ["Sahil Tripathi", "Gautam Siddharth Kashyap", "Mehwish Nasim", "Jian Yang", "Jiechao Gao", "Usman Naseem"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "context"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 5, "penalty": 0}, "reason": "CROSS-ALIGN+框架在文化符号和多模态表示方面表现出色，具备一定的自我改进能力。技术路径独特且解决复杂问题，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:29:46Z", "ai_summary": {"tldr": "CROSS-ALIGN+是一个三阶段框架，旨在提高基于表情包的社会虐待检测的效果，克服文化盲点、边界模糊和缺乏可解释性的问题。", "motivation": "表情包中的社会虐待检测面临挑战，因为有害意图常常依赖于隐含的文化符号和微妙的跨模态不一致性。", "method": "CROSS-ALIGN+通过三个阶段依次解决文化盲点、边界模糊和可解释性问题，利用知识库丰富多模态表示，优化决策边界，并生成级联解释。", "conclusion": "实验结果表明，CROSS-ALIGN+在五个基准和八个大型视觉语言模型上均优于现有方法，最高可实现17%的相对F1提升，并提供可解释的决策依据。"}}}
{"id": "ax-2026-02-03-6", "source": "arxiv", "date": "2026-02-03", "rank": 6, "title": "EventNeuS: 3D Mesh Reconstruction from a Single Event Camera", "url": "https://arxiv.org/abs/2602.03847v1", "detail_url": "https://arxiv.org/pdf/2602.03847v1.pdf", "description_en": "Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.", "description_zh": "EventNeuS是一种自监督神经模型，通过单一事件相机的彩色事件流学习3D表示，显著提高了3D网格重建的准确性。", "keywords": ["3D重建", "事件相机", "自监督", "神经网络", "视图依赖效果", "事件驱动", "生成模型", "模型优化", "语义搜索", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Shreyas Sachan", "Viktor Rudnev", "Mohamed Elgharib", "Christian Theobalt", "Vladislav Golyanik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 71, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "EventNeuS在3D重建领域展现出强大的自监督学习能力，具备较高的AI原生程度。技术路径独特，解决了复杂的3D重建问题，具备一定的市场潜力，但商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T18:59:57Z", "ai_summary": {"tldr": "EventNeuS是一种自监督神经模型，通过单一事件相机的彩色事件流学习3D表示，显著提高了3D网格重建的准确性。", "motivation": "尽管近期在基于事件的视图合成方面取得了一定进展，但密集的3D网格重建仍然缺乏深入研究，现有技术在3D重建精度上存在严重局限。", "method": "EventNeuS首次结合了3D符号距离函数和密度场学习，并引入球谐编码以增强对视角依赖效应的处理能力。", "conclusion": "EventNeuS在性能上显著优于现有方法，平均实现了34%的Chamfer距离降低和31%的平均绝对误差降低。"}}}
{"id": "ax-2026-02-03-7", "source": "arxiv", "date": "2026-02-03", "rank": 7, "title": "Continuous Control of Editing Models via Adaptive-Origin Guidance", "url": "https://arxiv.org/abs/2602.03826v1", "detail_url": "https://arxiv.org/pdf/2602.03826v1.pdf", "description_en": "Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.", "description_zh": "本论文提出了一种自适应引导方法AdaOr，旨在实现对编辑模型的平滑控制，从而改善文本引导编辑的强度调节。", "keywords": ["扩散模型", "编辑模型", "语义图像", "视频操控", "自适应引导", "生成模型", "控制强度", "细粒度控制", "机器学习", "深度学习", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Alon Wolf", "Chen Katzir", "Kfir Aberman", "Or Patashnik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出的AdaOr方法在编辑模型中实现了平滑控制，具备一定的AI原生特性，但缺乏自我进化和闭环学习机制。技术路径较为创新，解决了复杂问题，商业模式尚需明确。团队信息不足，无法评估其背景。"}, "raw": {"published": "2026-02-03T18:33:39Z", "ai_summary": {"tldr": "本论文提出了一种自适应引导方法AdaOr，旨在实现对编辑模型的平滑控制，从而改善文本引导编辑的强度调节。", "motivation": "现有的扩散编辑模型在文本引导编辑的强度控制上存在不足，难以实现输入与编辑结果之间的平滑过渡。", "method": "提出的AdaOr方法通过将标准无条件预测与身份条件自适应预测进行插值，根据编辑强度调整引导原点，实现连续控制。", "conclusion": "与现有基于滑块的编辑方法相比，AdaOr在图像和视频编辑任务中提供了更平滑、更一致的控制，且无需依赖特定数据集或逐个编辑过程。"}}}
{"id": "ax-2026-02-03-8", "source": "arxiv", "date": "2026-02-03", "rank": 8, "title": "From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery", "url": "https://arxiv.org/abs/2602.03785v1", "detail_url": "https://arxiv.org/pdf/2602.03785v1.pdf", "description_en": "Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.", "description_zh": "本文提出了一种基于U-Net的模型NeuralShift，能够仅通过术前MRI预测癫痫手术中的脑位移。", "keywords": ["神经网络", "深度学习", "预测模型", "U-Net", "神经外科", "脑移位", "图像引导", "手术导航", "DICE评分", "目标注册误差", "agent"], "tags": ["cs.CV"], "metrics": {"authors": ["Jingjing Peng", "Giorgio Fiore", "Yang Liu", "Ksenia Ellum", "Debayan Daspupta", "Keyoumars Ashkan", "Andrew McEvoy", "Anna Miserocchi", "Sebastien Ourselin", "John Duncan", "Alejandro Granados"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出了基于U-Net的模型，能够有效预测脑位移，具备一定的AI原生能力。技术路径具有复杂性和专业性，数据与特定医疗场景深度绑定。商业模式尚需明确，团队背景信息不足，未能展现明显的进化能力。"}, "raw": {"published": "2026-02-03T17:45:11Z", "ai_summary": {"tldr": "本文提出了一种基于U-Net的模型NeuralShift，能够仅通过术前MRI预测癫痫手术中的脑位移。", "motivation": "在神经外科中，术前MRI受到脑位移的影响，导致定位不准确，因此需要更新的术中MRI来补偿脑位移。", "method": "我们提出的NeuralShift模型利用术前MRI数据，预测癫痫手术中脑的全球变形，并通过目标注册误差和DICE分数评估模型性能。", "conclusion": "该模型能够有效预测脑位移，从而提高神经外科手术的安全性和效率，改善患者的手术结果。"}}}
{"id": "ax-2026-02-03-9", "source": "arxiv", "date": "2026-02-03", "rank": 9, "title": "QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization", "url": "https://arxiv.org/abs/2602.03782v1", "detail_url": "https://arxiv.org/pdf/2602.03782v1.pdf", "description_en": "The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.", "description_zh": "QVLA是一种针对视觉-语言-动作模型量化的新框架，采用通道级比特分配策略，显著提升了模型压缩效果和性能。", "keywords": ["量子化", "视觉-语言-动作", "embodied intelligence", "低比特量子化", "模型压缩", "QVLA", "机器人控制", "action-centric quantization", "channel-wise bit allocation", "性能提升", "llm"], "tags": ["cs.CV", "cs.RO"], "metrics": {"authors": ["Yuhao Xu", "Yantai Yang", "Zhenyang Fan", "Yufan Liu", "Yuming Li", "Bing Li", "Zhipeng Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 8, "bonus": 6, "penalty": 0}, "reason": "QVLA框架创新性强，具有较高的自我改进能力和明确的应用场景，但商业模式和团队信息不足，导致评分相对较低。"}, "raw": {"published": "2026-02-03T17:43:45Z", "ai_summary": {"tldr": "QVLA是一种针对视觉-语言-动作模型量化的新框架，采用通道级比特分配策略，显著提升了模型压缩效果和性能。", "motivation": "现有的统一比特量化方法在机器人领域的应用存在缺陷，无法有效处理动作偏差对任务失败的影响，因此需要一个更为精细的量化策略。", "method": "QVLA框架通过直接测量每个通道在不同比特宽度下的最终动作空间敏感性，提供了通道重要性度量，并将量化与剪枝统一为一个优化框架。", "conclusion": "QVLA在LIBERO数据集上的实验表明，其量化版本仅需29.2%的原始模型显存，同时保持98.9%的原始性能，实现了1.49倍的加速，显著优于传统方法。"}}}
{"id": "ax-2026-02-03-10", "source": "arxiv", "date": "2026-02-03", "rank": 10, "title": "FOVI: A biologically-inspired foveated interface for deep vision models", "url": "https://arxiv.org/abs/2602.03766v1", "detail_url": "https://arxiv.org/pdf/2602.03766v1.pdf", "description_en": "Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.", "description_zh": "FOVI是一种受生物启发的凹视界面，通过模拟人类视网膜提高深度视觉模型的效率和性能。", "keywords": ["生物启发", "foveated interface", "深度视觉模型", "视觉处理", "kNN卷积", "DINOv3", "低秩适应", "主动感知", "计算效率", "ml"], "tags": ["cs.CV", "cs.NE", "q-bio.NC"], "metrics": {"authors": ["Nicholas M. Blauch", "George A. Alvarez", "Talia Konkle"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "rag", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "FOVI具有较强的AI原生程度，利用生物启发的设计实现高效的视觉处理。技术路径独特，解决了复杂的计算效率问题，具备一定的市场潜力，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T17:26:54Z", "ai_summary": {"tldr": "FOVI是一种受生物启发的凹视界面，通过模拟人类视网膜提高深度视觉模型的效率和性能。", "motivation": "人类的视力具有可变分辨率的特性，而大多数计算机视觉系统却使用均匀分辨率，这导致处理高分辨率图像时的效率问题。", "method": "FOVI通过将可变分辨率的传感器阵列重塑为均匀密集的传感器流形，并定义接收场为k近邻，利用新颖的核映射技术实现kNN卷积。", "conclusion": "FOVI在计算成本上显著优于非凹视模型，展示了高效、可扩展的主动感知在高分辨率自我中心视觉中的应用潜力。"}}}
{"id": "ax-2026-02-03-11", "source": "arxiv", "date": "2026-02-03", "rank": 11, "title": "RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images", "url": "https://arxiv.org/abs/2602.03760v1", "detail_url": "https://arxiv.org/pdf/2602.03760v1.pdf", "description_en": "Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.", "description_zh": "RAWDet-7是一个用于量化RAW图像下物体检测和描述的大型数据集，包含25k训练和7.6k测试图像。", "keywords": ["目标检测", "RAW图像", "机器学习", "深度学习", "数据集", "计算机视觉", "语义搜索", "多场景基准", "低位量化", "物体描述", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Mishal Fatima", "Shashank Agnihotri", "Kanchana Vaishnavi Gandikota", "Michael Moeller", "Margret Keuper"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目关注量化RAW图像处理，具有较强的技术壁垒和行业特定需求，但缺乏明确的商业模式和团队背景信息，AI原生程度较高但未形成闭环自我改进。"}, "raw": {"published": "2026-02-03T17:22:45Z", "ai_summary": {"tldr": "RAWDet-7是一个用于量化RAW图像下物体检测和描述的大型数据集，包含25k训练和7.6k测试图像。", "motivation": "现有视觉模型多基于RGB图像，忽视了RAW图像中保留的传感器级信息，这些信息对机器推理有重要价值。", "method": "构建了一个包含多种相机和环境的RAW图像数据集，并提供了多种量化模拟以评估物体检测和描述性能。", "conclusion": "RAWDet-7为研究量化RAW图像处理下的物体检测和描述提供了基准，显示了在低位数情况下的信息保留能力。"}}}
{"id": "ax-2026-02-03-12", "source": "arxiv", "date": "2026-02-03", "rank": 12, "title": "Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives", "url": "https://arxiv.org/abs/2602.03750v1", "detail_url": "https://arxiv.org/pdf/2602.03750v1.pdf", "description_en": "Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bone, sex, and imaging equipment introduce high variability. Thus, content navigation, such as identifying a subset of images with a specific projection view, can be time consuming and difficult, making efficient triaging a bottleneck for expert analysis. We report a zero shot prompting strategy that leverages a state of the art Large Vision Language Model (LVLM) to automatically identify the main bone, projection view, and laterality in such images. Our pipeline converts raw DICOM files to bone windowed PNGs, submits them to the LVLM with a carefully engineered prompt, and receives structured JSON outputs, which are extracted and formatted onto a spreadsheet in preparation for validation. On a random sample of 100 images reviewed by an expert board certified paleoradiologist, the system achieved 92% main bone accuracy, 80% projection view accuracy, and 100% laterality accuracy, with low or medium confidence flags for ambiguous cases. These results suggest that LVLMs can substantially accelerate code word development for large paleoradiology datasets, allowing for efficient content navigation in future anthropology workflows.", "description_zh": "该研究提出了一种零-shot提示策略，利用大型视觉语言模型自动识别古人类放射学X光图像中的主要骨骼、投影视图和侧向性。", "keywords": ["大模型", "视觉语言模型", "自动化识别", "骨骼识别", "影像分析", "DICOM处理", "人机协作", "专家验证", "内容导航", "rag"], "tags": ["cs.CV", "cs.AI"], "metrics": {"authors": ["Owen Dong", "Lily Gao", "Manish Kota", "Bennett A. Landmana", "Jelena Bekvalac", "Gaynor Western", "Katherine D. Van Schaik"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "workflow"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目展示了强大的AI原生能力，通过零-shot策略实现了自动化骨骼识别，具备持续学习潜力。技术路径独特，解决了古人类放射学中的复杂问题，且具备明确的市场需求。团队背景信息不足，无法确认其进化能力。"}, "raw": {"published": "2026-02-03T17:14:23Z", "ai_summary": {"tldr": "该研究提出了一种零-shot提示策略，利用大型视觉语言模型自动识别古人类放射学X光图像中的主要骨骼、投影视图和侧向性。", "motivation": "古人类放射学中的X光图像数据异质性使得专家分析效率低下，因此需要一种自动化的方法来加速图像内容的导航和分类。", "method": "研究中使用了先进的大型视觉语言模型，通过精心设计的提示将原始DICOM文件转换为骨窗PNG格式，并输出结构化的JSON数据。", "conclusion": "实验结果表明，该系统在骨骼识别、投影视图和侧向性识别上取得了高准确率，显示了大型视觉语言模型在古人类放射学数据集中的潜在应用价值。"}}}
{"id": "ax-2026-02-03-13", "source": "arxiv", "date": "2026-02-03", "rank": 13, "title": "See-through: Single-image Layer Decomposition for Anime Characters", "url": "https://arxiv.org/abs/2602.03749v1", "detail_url": "https://arxiv.org/pdf/2602.03749v1.pdf", "description_en": "We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.", "description_zh": "本研究提出了一种框架，将静态动漫插图自动转换为可操作的2.5D模型，通过单图层分解实现高质量动画效果。", "keywords": ["单幅图像", "层分解", "动漫角色", "2.5D模型", "语义分层", "像素级推断", "生成模型", "深度学习", "语义一致性", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Jian Lin", "Chengze Li", "Haoyun Qin", "Kwun Wang Chan", "Yanghua Jin", "Hanyuan Liu", "Stephen Chun Wang Choy", "Xueting Liu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion", "workflow"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在动漫角色动态表现上实现了自动化，具备较强的AI原生能力，但商业模式尚需明确，团队背景信息不足。"}, "raw": {"published": "2026-02-03T17:12:36Z", "ai_summary": {"tldr": "本研究提出了一种框架，将静态动漫插图自动转换为可操作的2.5D模型，通过单图层分解实现高质量动画效果。", "motivation": "当前专业工作流程需要繁琐的手动分割和艺术性补全，限制了动漫角色的动态表现能力，因此需要一种自动化的方法来提升效率。", "method": "本方法通过将单幅图像分解为语义明确的层，并使用基于扩散的身体部位一致性模块和伪深度推断机制，实现了动漫角色的动态层重构。", "conclusion": "实验表明，该方法能够生成高保真、可操作的模型，适用于专业实时动画应用。"}}}
{"id": "ax-2026-02-03-14", "source": "arxiv", "date": "2026-02-03", "rank": 14, "title": "LIVE: Long-horizon Interactive Video World Modeling", "url": "https://arxiv.org/abs/2602.03747v1", "detail_url": "https://arxiv.org/pdf/2602.03747v1.pdf", "description_en": "Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.", "description_zh": "本文提出了一种新的视频世界建模方法LIVE，能够在长时间范围内有效预测视频，减少预测误差的累积。", "keywords": ["长视距", "交互式视频", "世界建模", "自回归模型", "循环一致性", "生成模型", "训练课程", "稳定性", "预测错误", "视觉观察", "diffusion"], "tags": ["cs.CV"], "metrics": {"authors": ["Junchao Huang", "Ziyang Ye", "Xinting Hu", "Tianyu He", "Guiyu Zhang", "Shaoshuai Shi", "Jiang Bian", "Li Jiang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目提出了新的长视距视频建模方法，具有一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，整体技术路径和市场壁垒较强。"}, "raw": {"published": "2026-02-03T17:10:03Z", "ai_summary": {"tldr": "本文提出了一种新的视频世界建模方法LIVE，能够在长时间范围内有效预测视频，减少预测误差的累积。", "motivation": "传统的自回归视频模型在长时间预测中表现不佳，导致误差累积和生成质量下降，因此需要一种新的方法来改善这一问题。", "method": "LIVE通过引入循环一致性目标来限制误差累积，采用前向生成和反向重建的过程来提高长时间预测的稳定性与质量。", "conclusion": "实验表明，LIVE在长时间基准测试中表现优异，生成的视频质量高且稳定，超出训练范围的生成能力显著提升。"}}}
{"id": "ax-2026-02-03-15", "source": "arxiv", "date": "2026-02-03", "rank": 15, "title": "Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment", "url": "https://arxiv.org/abs/2602.03742v1", "detail_url": "https://arxiv.org/pdf/2602.03742v1.pdf", "description_en": "Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.", "description_zh": "本研究提出了一种边缘优化的视觉语言模型，用于地下基础设施的自动检测和总结，提升了检测效率和实时性。", "keywords": ["视觉语言模型", "深度学习", "机器人平台", "自动化检测", "边缘计算", "资源感知", "缺陷分割", "实时性能", "模型优化", "自主检查", "autonomous"], "tags": ["cs.CV"], "metrics": {"authors": ["Johny J. Lopez", "Md Meftahul Ferdaus", "Mahdi Abdelguerfi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目在边缘计算和视觉语言模型的结合上具有创新性，且能有效解决地下基础设施的检测问题。商业模式与高价值用户需求结合较弱，团队信息不足。"}, "raw": {"published": "2026-02-03T17:03:46Z", "ai_summary": {"tldr": "本研究提出了一种边缘优化的视觉语言模型，用于地下基础设施的自动检测和总结，提升了检测效率和实时性。", "motivation": "地下基础设施的自动检测对公共安全和城市可持续发展至关重要，但在资源受限的边缘设备上生成可读的检测摘要仍然是一个挑战。", "method": "本文提出了一个两阶段的管道，结合了轻量级的RAPID-SCAN分割模型和精调的视觉语言模型，在边缘计算平台上实现了高效的缺陷分割和摘要生成。", "conclusion": "该系统在移动机器人平台上进行了评估，展示了边缘可部署的集成AI系统在自动缺陷检测与基础设施维护洞察之间的桥梁作用，为更可扩展的自动检测解决方案铺平了道路。"}}}
{"id": "ax-2026-02-03-16", "source": "arxiv", "date": "2026-02-03", "rank": 16, "title": "RegionReasoner: Region-Grounded Multi-Round Visual Reasoning", "url": "https://arxiv.org/abs/2602.03733v1", "detail_url": "https://arxiv.org/pdf/2602.03733v1.pdf", "description_en": "Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.", "description_zh": "RegionReasoner是一种通过多轮推理和强化学习框架提高视觉推理准确性的模型。", "keywords": ["视觉推理", "多轮推理", "强化学习", "语义一致性", "RegionReasoner", "视觉-语言模型", "检测与分割", "奖励模型", "迭代推理", "context"], "tags": ["cs.CV"], "metrics": {"authors": ["Wenfang Sun", "Hao Chen", "Yingjun Du", "Yefeng Zheng", "Cees G. M. Snoek"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "RegionReasoner在多轮推理中通过强化学习实现了用户反馈的有效利用，具备自我改进能力，形成闭环。技术路径独特，解决复杂问题，且与行业前沿一致。商业模式清晰，潜在高价值用户明确。"}, "raw": {"published": "2026-02-03T16:52:16Z", "ai_summary": {"tldr": "RegionReasoner是一种通过多轮推理和强化学习框架提高视觉推理准确性的模型。", "motivation": "现有的视觉语言模型在多轮推理方面能力有限，因此需要一种新的基准和方法来提升其在检测和分割任务中的表现。", "method": "RegionReasoner通过要求每个推理过程明确引用对应的边界框，并结合全局-局部一致性奖励，优化推理的准确性和一致性。", "conclusion": "实验表明，RegionReasoner-7B显著提升了多轮推理的准确性和空间定位的精确度，为这一新兴研究方向奠定了坚实的基线。"}}}
{"id": "ax-2026-02-03-17", "source": "arxiv", "date": "2026-02-03", "rank": 17, "title": "Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL", "url": "https://arxiv.org/abs/2602.03839v1", "detail_url": "https://arxiv.org/pdf/2602.03839v1.pdf", "description_en": "Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically relevant settings. Leveraging this structure, we propose PULSE (Patch Updates via Lossless Sparse Encoding), a simple yet highly efficient lossless weight synchronization method that transmits only the indices and values of modified parameters. PULSE is robust to transmission errors and avoids floating-point drift inherent in additive delta schemes. In bandwidth-constrained decentralized environments, our approach achieves over 100x (14 GB to ~108 MB) communication reduction while maintaining bit-identical training dynamics and performance compared to full weight synchronization. By exploiting this structure, PULSE enables decentralized RL training to approach centralized throughput, reducing the bandwidth required for weight synchronization from 20 Gbit/s to 0.2 Gbit/s to maintain high GPU utilization.", "description_zh": "本文提出了一种名为PULSE的高效稀疏权重同步方法，显著减少了带宽需求，同时保持训练性能。", "keywords": ["权重更新稀疏性", "强化学习", "分布式RL", "大语言模型", "PULSE", "通信效率", "参数同步", "训练动态", "带宽约束", "llm"], "tags": ["cs.LG"], "metrics": {"authors": ["Erfan Miahi", "Eugene Belilovsky"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提出了PULSE方法，展现出强大的自我改进能力和数据反馈机制，符合AI原生标准。技术路径解决了带宽瓶颈问题，具备可持续的行业壁垒。商业模式与高价值用户紧密结合，团队背景信息不足，未能加分。"}, "raw": {"published": "2026-02-03T18:56:48Z", "ai_summary": {"tldr": "本文提出了一种名为PULSE的高效稀疏权重同步方法，显著减少了带宽需求，同时保持训练性能。", "motivation": "在带宽受限的分布式强化学习中，策略权重的同步常成为扩展性的瓶颈，尤其是在商品网络或去中心化环境中。", "method": "PULSE方法通过传输修改参数的索引和值，利用权重更新的稀疏性，避免了浮点数漂移和传输错误。", "conclusion": "PULSE在带宽限制的去中心化环境中实现了超过100倍的通信减少，保持了与全权重同步相同的训练动态和性能。"}}}
{"id": "ax-2026-02-03-18", "source": "arxiv", "date": "2026-02-03", "rank": 18, "title": "Robust Intervention Learning from Emergency Stop Interventions", "url": "https://arxiv.org/abs/2602.03825v1", "detail_url": "https://arxiv.org/pdf/2602.03825v1.pdf", "description_en": "Human interventions are a common source of data in autonomous systems during testing. These interventions provide an important signal about where the current policy needs improvement, but are often noisy and incomplete. We define Robust Intervention Learning (RIL) as the problem of learning from intervention data while remaining robust to the quality and informativeness of the intervention signal. In the best case, interventions are precise and avoiding them is sufficient to solve the task, but in many realistic settings avoiding interventions is necessary but not sufficient for achieving good performance. We study robust intervention learning in the context of emergency stop interventions and propose Residual Intervention Fine-Tuning (RIFT), a residual fine-tuning algorithm that treats intervention feedback as an incomplete learning signal and explicitly combines it with a prior policy. By framing intervention learning as a fine-tuning problem, our approach leverages structure encoded in the prior policy to resolve ambiguity when intervention signals under-specify the task. We provide theoretical analysis characterizing conditions under which this formulation yields principled policy improvement, and identify regimes where intervention learning is expected to fail. Our experiments reveal that residual fine-tuning enables robust and consistent policy improvement across a range of intervention strategies and prior policy qualities, and highlight robust intervention learning as a promising direction for future work.", "description_zh": "提出了一种稳健干预学习的方法，旨在从噪声和不完整的干预数据中学习，以改进自主系统的策略。", "keywords": ["干预学习", "强健学习", "机器学习", "深度学习", "神经网络", "紧急停止干预", "残差微调", "反馈信号", "策略改进", "autonomous"], "tags": ["cs.LG"], "metrics": {"authors": ["Ethan Pronovost", "Khimya Khetarpal", "Siddhartha Srinivasa"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "autonomous", "rag", "context"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了稳健干预学习的方法，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，整体技术路径较为前沿，具有一定的行业壁垒。"}, "raw": {"published": "2026-02-03T18:33:21Z", "ai_summary": {"tldr": "提出了一种稳健干预学习的方法，旨在从噪声和不完整的干预数据中学习，以改进自主系统的策略。", "motivation": "人类干预在自主系统测试中提供了重要信号，但往往噪声大且不完整，因此需要一种方法来有效利用这些干预数据。", "method": "提出了残差干预微调(RIFT)算法，将干预反馈视为不完整的学习信号，并与先验策略显式结合，以提高策略的鲁棒性。", "conclusion": "实验结果表明，残差微调能够在多种干预策略和先验策略质量下实现稳健且一致的策略改进，展示了稳健干预学习的未来应用潜力。"}}}
{"id": "ax-2026-02-03-19", "source": "arxiv", "date": "2026-02-03", "rank": 19, "title": "SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving", "url": "https://arxiv.org/abs/2602.03816v1", "detail_url": "https://arxiv.org/pdf/2602.03816v1.pdf", "description_en": "We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.", "description_zh": "SymPlex是一个用于符号偏微分方程求解的强化学习框架，能够在没有真实表达式的情况下发现解析符号解。", "keywords": ["结构感知", "Transformer", "强化学习", "符号解法", "部分微分方程", "解析解", "树结构决策", "语法约束", "自回归解码", "深度学习"], "tags": ["cs.LG"], "metrics": {"authors": ["Yesom Park", "Annie C. Lu", "Shao-Ching Huang", "Qiyang Hu", "Y. Sungtaek Ju", "Stanley Osher"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "transformer"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 0, "penalty": 0}, "reason": "SymPlex在符号PDE求解中展现出较高的AI原生程度，采用强化学习和结构感知Transformer，具备在线学习潜力。技术路径独特，解决复杂问题，具备一定的行业壁垒。商业模式尚不明确，团队信息不足，未能加分。"}, "raw": {"published": "2026-02-03T18:18:30Z", "ai_summary": {"tldr": "SymPlex是一个用于符号偏微分方程求解的强化学习框架，能够在没有真实表达式的情况下发现解析符号解。", "motivation": "现有的数值和神经方法通常在离散或隐式函数空间中近似求解，而SymPlex希望直接在符号表达空间中找到可解释的符号解。", "method": "SymPlex将符号PDE求解形式化为树结构决策过程，使用结构感知的Transformer（SymFormer）通过树相对自注意力建模层次符号依赖关系，并通过语法约束的自回归解码确保语法有效性。", "conclusion": "实验证明，SymPlex能够准确恢复非光滑和参数化的PDE解，展示了深度学习基础的符号方法的有效性。"}}}
{"id": "ax-2026-02-03-20", "source": "arxiv", "date": "2026-02-03", "rank": 20, "title": "Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network", "url": "https://arxiv.org/abs/2602.03808v1", "detail_url": "https://arxiv.org/pdf/2602.03808v1.pdf", "description_en": "Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model's step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.", "description_zh": "提出了一种名为CL3AN-GNN的三阶段注意力网络，以解决图神经网络中的不平衡节点分类问题。", "keywords": ["节点分类", "图神经网络", "特征学习", "注意力机制", "课程学习", "不平衡数据", "监督学习", "GNN", "attention network", "feature learning", "neural network"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen", "Shaoyang Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "neural network", "embedding"], "hit_excludes": []}, "score": {"total": 64, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了新颖的三阶段注意力机制，能够在不平衡节点分类中有效提升模型表现，具备一定的技术壁垒和应用潜力。但商业模式不明确，团队信息不足，未能体现出显著的行业经验。"}, "raw": {"published": "2026-02-03T18:10:40Z", "ai_summary": {"tldr": "提出了一种名为CL3AN-GNN的三阶段注意力网络，以解决图神经网络中的不平衡节点分类问题。", "motivation": "不平衡的节点分类使得模型在少数类上的表现不佳，因此需要一种新的学习策略来提升模型的公平性和准确性。", "method": "CL3AN-GNN通过三个阶段的注意力机制（Engage, Enact, Embed）逐步学习不同复杂度的特征，支持在标签不平衡情况下的稳定学习。", "conclusion": "实验结果表明，CL3AN-GNN在多个数据集上均优于现有方法，具备更快的收敛速度和良好的可解释性，对不平衡问题具有有效的解决方案。"}}}
{"id": "ax-2026-02-03-21", "source": "arxiv", "date": "2026-02-03", "rank": 21, "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation", "url": "https://arxiv.org/abs/2602.03806v1", "detail_url": "https://arxiv.org/pdf/2602.03806v1.pdf", "description_en": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.", "description_zh": "Cobalt是一种结合在线和离线强化学习的新方法，旨在提高多轮代码生成的性能。", "keywords": ["关键词：深度学习", "机器学习", "强化学习", "多轮代码生成", "上下文赌博学习", "LLM", "Markov决策过程", "迭代决策任务", "代码生成轨迹"], "tags": ["cs.LG", "cs.AI", "cs.CL", "cs.SE"], "metrics": {"authors": ["Ziru Chen", "Dongdong Chen", "Ruinan Jin", "Yingbin Liang", "Yujia Xie", "Huan Sun"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Cobalt方法结合在线与离线强化学习，具备自我改进能力，且在多轮代码生成任务中表现优越，形成了独特的技术壁垒。团队背景强大，具备AI与领域知识，但商业模式尚需进一步明确。"}, "raw": {"published": "2026-02-03T18:08:41Z", "ai_summary": {"tldr": "Cobalt是一种结合在线和离线强化学习的新方法，旨在提高多轮代码生成的性能。", "motivation": "随着大语言模型在实际任务中的应用增多，在线强化学习的高成本和不稳定性限制了其广泛采用。", "method": "Cobalt通过使用参考LLM收集代码生成轨迹，并将其分割为上下文提示，在在线赌博学习中训练LLM完成每个部分轨迹的单步代码生成。", "conclusion": "Cobalt在多轮代码生成任务中表现优越，且通过对抗性轨迹增强训练，缓解了LLM的奖励黑客行为。"}}}
{"id": "ax-2026-02-03-22", "source": "arxiv", "date": "2026-02-03", "rank": 22, "title": "Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF", "url": "https://arxiv.org/abs/2602.03805v1", "detail_url": "https://arxiv.org/pdf/2602.03805v1.pdf", "description_en": "The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous work developed and deployed tube-based pure and hybrid ML models in the CTF subchannel code, however, full-scale reactor core simulations require the use of rod bundle geometries. Unlike isolated subchannels, rod bundles experience complex thermal hydraulic phenomena such as channel crossflow, spacer grid losses, and effects from unheated conductors. This study investigates the generalization of ML-based CHF prediction models in rod bundles after being trained on tube-based CHF data. A purely data-driven DNN and two hybrid bias-correction models were implemented in the CTF subchannel code and used to predict CHF location and magnitude in the Combustion Engineering 5-by-5 bundle CHF test series. The W-3 correlation, Bowring correlation, and Groeneveld LUT were used as baseline comparators. On average, all three ML-based approaches produced magnitude and location predictions more accurate than the baseline models, with the hybrid LUT model exhibiting the most favorable performance metrics.", "description_zh": "本研究利用基于管道的混合机器学习模型预测棒束中的临界热流密度，表现优于传统模型。", "keywords": ["机器学习", "深度学习", "神经网络", "预测模型", "数据驱动", "复合模型", "热流密度", "rod bundle", "CTF", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Aidan Furlong", "Robert Salko", "Xingang Zhao", "Xu Wu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "rag"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目利用机器学习模型进行复杂热流密度预测，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，导致整体分数受限。"}, "raw": {"published": "2026-02-03T18:05:16Z", "ai_summary": {"tldr": "本研究利用基于管道的混合机器学习模型预测棒束中的临界热流密度，表现优于传统模型。", "motivation": "随着机器学习在临界热流密度预测中的应用日益增加，研究者希望建立比传统经验模型更准确的预测模型。", "method": "研究中实现了纯数据驱动的深度神经网络和两种混合偏差校正模型，并在CTF子通道代码中进行训练和预测。", "conclusion": "所有三种基于机器学习的方法在预测热流密度的大小和位置上均优于基准模型，其中混合LUT模型表现最佳。"}}}
{"id": "ax-2026-02-03-23", "source": "arxiv", "date": "2026-02-03", "rank": 23, "title": "Manifold Random Features", "url": "https://arxiv.org/abs/2602.03797v1", "detail_url": "https://arxiv.org/pdf/2602.03797v1.pdf", "description_en": "We present a new paradigm for creating random features to approximate bi-variate functions (in particular, kernels) defined on general manifolds. This new mechanism of Manifold Random Features (MRFs) leverages discretization of the manifold and the recently introduced technique of Graph Random Features (GRFs) to learn continuous fields on manifolds. Those fields are used to find continuous approximation mechanisms that otherwise, in general scenarios, cannot be derived analytically. MRFs provide positive and bounded features, a key property for accurate, low-variance approximation. We show deep asymptotic connection between GRFs, defined on discrete graph objects, and continuous random features used for regular kernels. As a by-product of our method, we re-discover recently introduced mechanism of Gaussian kernel approximation applied in particular to improve linear-attention Transformers, considering simple random walks on graphs and by-passing original complex mathematical computations. We complement our algorithm with a rigorous theoretical analysis and verify in thorough experimental studies.", "description_zh": "提出了一种新的随机特征方法，用于在一般流形上近似双变量函数，特别是核函数。", "keywords": ["随机特征", "双变量函数", "流形", "深度学习", "图随机特征", "线性注意力", "变换器", "连续近似", "低方差", "特征学习", "transformer"], "tags": ["cs.LG"], "metrics": {"authors": ["Ananya Parashar", "Derek Long", "Dwaipayan Saha", "Krzysztof Choromanski"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["transformer", "rag"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "该项目提出了新方法，但缺乏用户交互和应用场景的具体信息，AI原生程度较低。技术路径有独特性，解决复杂问题，商业模式不明确，团队信息不足。"}, "raw": {"published": "2026-02-03T18:00:01Z", "ai_summary": {"tldr": "提出了一种新的随机特征方法，用于在一般流形上近似双变量函数，特别是核函数。", "motivation": "研究如何在复杂流形上有效地近似函数，以解决无法解析推导的连续近似机制问题。", "method": "引入流形随机特征（MRFs），结合流形的离散化和图随机特征（GRFs）技术，学习流形上的连续场，从而实现准确且低方差的函数近似。", "conclusion": "通过理论分析和实验验证，MRFs能够有效改善线性注意力Transformer的性能，并简化高复杂度的数学计算。"}}}
{"id": "ax-2026-02-03-24", "source": "arxiv", "date": "2026-02-03", "rank": 24, "title": "Should I use Synthetic Data for That? An Analysis of the Suitability of Synthetic Data for Data Sharing and Augmentation", "url": "https://arxiv.org/abs/2602.03791v1", "detail_url": "https://arxiv.org/pdf/2602.03791v1.pdf", "description_en": "Recent advances in generative modelling have led many to see synthetic data as the go-to solution for a range of problems around data access, scarcity, and under-representation. In this paper, we study three prominent use cases: (1) Sharing synthetic data as a proxy for proprietary datasets to enable statistical analyses while protecting privacy, (2) Augmenting machine learning training sets with synthetic data to improve model performance, and (3) Augmenting datasets with synthetic data to reduce variance in statistical estimation. For each use case, we formalise the problem setting and study, through formal analysis and case studies, under which conditions synthetic data can achieve its intended objectives. We identify fundamental and practical limits that constrain when synthetic data can serve as an effective solution for a particular problem. Our analysis reveals that due to these limits many existing or envisioned use cases of synthetic data are a poor problem fit. Our formalisations and classification of synthetic data use cases enable decision makers to assess whether synthetic data is a suitable approach for their specific data availability problem.", "description_zh": "本论文分析了合成数据在数据共享和增强中的适用性，提出了其在特定条件下的局限性。", "keywords": ["生成数据", "生成模型", "机器学习", "数据共享", "数据增强", "统计分析", "模型性能", "变异性降低", "synthetic data", "数据隐私", "machine learning"], "tags": ["cs.LG", "cs.CY"], "metrics": {"authors": ["Bogdan Kulynych", "Theresa Stadler", "Jean Louis Raisaro", "Carmela Troncoso"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "generative"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 15, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目分析合成数据的适用性，具备一定的技术深度和行业应用潜力，但缺乏明确的自我进化和闭环能力，团队信息不足，无法确认其AI原生程度。"}, "raw": {"published": "2026-02-03T17:52:57Z", "ai_summary": {"tldr": "本论文分析了合成数据在数据共享和增强中的适用性，提出了其在特定条件下的局限性。", "motivation": "随着生成建模的进步，合成数据被视为解决数据访问和稀缺问题的一种理想方案，本文旨在评估其实际应用潜力。", "method": "通过形式化分析和案例研究，识别合成数据在三种主要使用场景下的适用条件及其局限性。", "conclusion": "研究表明，许多现有或设想的合成数据应用场景并不适合，这为决策者提供了评估合成数据适用性的框架。"}}}
{"id": "ax-2026-02-03-25", "source": "arxiv", "date": "2026-02-03", "rank": 25, "title": "Efficient Estimation of Kernel Surrogate Models for Task Attribution", "url": "https://arxiv.org/abs/2602.03783v1", "detail_url": "https://arxiv.org/pdf/2602.03783v1.pdf", "description_en": "Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task's performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.", "description_zh": "本文提出了一种高效的核代理模型，用于分析任务归属，克服了线性代理模型在捕捉非线性交互方面的局限。", "keywords": ["任务归因", "核心代理模型", "机器学习", "深度学习", "代理", "预训练模型", "任务加权框架", "多目标强化学习", "上下文学习", "性能预测", "agent"], "tags": ["cs.LG", "cs.AI", "cs.CL"], "metrics": {"authors": ["Zhenshuo Zhang", "Minxuan Duan", "Hongyang R. Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "transformer", "rag", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出了核代理模型，提升了任务归因的效率，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息。"}, "raw": {"published": "2026-02-03T17:43:48Z", "ai_summary": {"tldr": "本文提出了一种高效的核代理模型，用于分析任务归属，克服了线性代理模型在捕捉非线性交互方面的局限。", "motivation": "现代AI代理同时在多种任务上进行训练，理解每个训练任务对目标任务性能的影响是至关重要的，但传统的方法在大规模上计算不可行。", "method": "文章提出了基于梯度的核代理模型估计程序，能够有效地表示任务间的二阶交互，同时通过一阶近似加速学习过程。", "conclusion": "实验结果表明，核代理模型在多种领域中的性能评估上比线性代理更为准确，且在下游任务选择中显著提高了表现。"}}}
{"id": "ax-2026-02-03-26", "source": "arxiv", "date": "2026-02-03", "rank": 26, "title": "Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity", "url": "https://arxiv.org/abs/2602.03778v1", "detail_url": "https://arxiv.org/pdf/2602.03778v1.pdf", "description_en": "Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.", "description_zh": "本研究提出了一种基于增强的静态条件价值-at-risk (CVaR)目标的新公式，通过贝尔曼算子实现风险厌恶的价值迭代和无模型Q学习算法。", "keywords": ["奖励再分配", "CVaR", "马尔可夫决策过程", "风险规避", "值迭代", "强化学习", "Bellman算子", "稠密奖励", "近似误差界限"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Aneri Muni", "Vincent Taboga", "Esther Derman", "Pierre-Luc Bacon", "Erick Delage"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 54, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 8, "team": 6, "bonus": 0, "penalty": 0}, "reason": "项目的技术路径具有一定的创新性，但缺乏明确的商业模式和团队背景信息，AI原生程度和商业潜力较低。"}, "raw": {"published": "2026-02-03T17:39:45Z", "ai_summary": {"tldr": "本研究提出了一种基于增强的静态条件价值-at-risk (CVaR)目标的新公式，通过贝尔曼算子实现风险厌恶的价值迭代和无模型Q学习算法。", "motivation": "在安全关键应用中，传统的风险中性目标无法有效处理尾部风险，因此需要新的方法来更好地管理稀有但灾难性的事件。", "method": "通过状态增强的方法提出静态CVaR目标的新公式，从而获得稠密的每步奖励和收敛性质，并开发相应的算法。", "conclusion": "实验结果表明，所提出的算法能够成功学习对CVaR敏感的策略，并实现有效的性能与安全权衡。"}}}
{"id": "ax-2026-02-03-27", "source": "arxiv", "date": "2026-02-03", "rank": 27, "title": "Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon", "url": "https://arxiv.org/abs/2602.03767v1", "detail_url": "https://arxiv.org/pdf/2602.03767v1.pdf", "description_en": "Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders' needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.", "description_zh": "该研究提出了一种决策导向的基准评估框架，以提升AI天气预报在印度季风预测中的应用，帮助农民应对气候变化带来的影响。", "keywords": ["气象预测", "机器学习", "深度学习", "神经网络", "决策导向", "农业适应", "AI天气预测", "预测模型", "气候变化", "农民助手"], "tags": ["cs.LG", "cs.AI", "econ.GN", "physics.ao-ph"], "metrics": {"authors": ["Rajat Masiwal", "Colin Aitken", "Adam Marchakitus", "Mayank Gupta", "Katherine Kowal", "Hamid A. Pahlavan", "Tyler Yang", "Y. Qiang Sun", "Michael Kremer", "Amir Jina", "William R. Boos", "Pedram Hassanzadeh"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "artificial intelligence"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目结合气象、AI和社会科学，提供决策导向的评估框架，具备较强的AI原生度和技术壁垒，但缺乏商业模式的清晰性和团队信息。"}, "raw": {"published": "2026-02-03T17:27:22Z", "ai_summary": {"tldr": "该研究提出了一种决策导向的基准评估框架，以提升AI天气预报在印度季风预测中的应用，帮助农民应对气候变化带来的影响。", "motivation": "当前的AI天气预报模型在性能上优于传统模型，但评估方法未能满足当地利益相关者的决策需求，因此需要一种新的评估框架。", "method": "研究引入了一个结合气象学、人工智能和社会科学的决策导向框架，并应用于印度季风的预测，特别关注对雨养农业的影响。", "conclusion": "该框架为利用AI天气预报模型帮助脆弱人群适应气候变化提供了重要的参考，成功地为3800万农民提供了季风预测信息。"}}}
{"id": "ax-2026-02-03-28", "source": "arxiv", "date": "2026-02-03", "rank": 28, "title": "Soft Sensor for Bottom-Hole Pressure Estimation in Petroleum Wells Using Long Short-Term Memory and Transfer Learning", "url": "https://arxiv.org/abs/2602.03737v1", "detail_url": "https://arxiv.org/pdf/2602.03737v1.pdf", "description_en": "Monitoring bottom-hole variables in petroleum wells is essential for production optimization, safety, and emissions reduction. Permanent Downhole Gauges (PDGs) provide real-time pressure data but face reliability and cost issues. We propose a machine learning-based soft sensor to estimate flowing Bottom-Hole Pressure (BHP) using wellhead and topside measurements. A Long Short-Term Memory (LSTM) model is introduced and compared with Multi-Layer Perceptron (MLP) and Ridge Regression. We also pioneer Transfer Learning for adapting models across operational environments. Tested on real offshore datasets from Brazil's Pre-salt basin, the methodology achieved Mean Absolute Percentage Error (MAPE) consistently below 2\\%, outperforming benchmarks. This work offers a cost-effective, accurate alternative to physical sensors, with broad applicability across diverse reservoir and flow conditions.", "description_zh": "本研究提出了一种基于LSTM和迁移学习的软传感器，用于准确估计石油井的底部压力，且在实际数据测试中表现优异。", "keywords": ["底部压力", "软传感器", "机器学习", "LSTM", "转移学习", "多层感知器", "准确性", "实时监测", "数据适应", "machine learning"], "tags": ["cs.LG"], "metrics": {"authors": ["M. A. Fernandes", "E. Gildin", "M. A. Sampaio"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["machine learning", "ml"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目利用LSTM和迁移学习进行底部压力估计，具备一定的AI原生特征，但缺乏用户反馈闭环和自我改进机制。技术路径选择较为独特，解决了石油行业的复杂问题，具备一定的行业壁垒。商业模式与真实价值绑定较弱，团队信息不足，无法确认其进化能力。"}, "raw": {"published": "2026-02-03T16:56:21Z", "ai_summary": {"tldr": "本研究提出了一种基于LSTM和迁移学习的软传感器，用于准确估计石油井的底部压力，且在实际数据测试中表现优异。", "motivation": "监测石油井底部变量对于优化生产、安全和减少排放至关重要，但现有的永久井下传感器存在可靠性和成本问题。", "method": "引入长短期记忆（LSTM）模型，并与多层感知器（MLP）和岭回归进行比较，同时应用迁移学习以适应不同的操作环境。", "conclusion": "该方法在巴西预盐盆地的实际数据集上测试，平均绝对百分比误差（MAPE）始终低于2%，为物理传感器提供了一种成本效益高且准确的替代方案。"}}}
{"id": "ax-2026-02-03-29", "source": "arxiv", "date": "2026-02-03", "rank": 29, "title": "Fast-MWEM: Private Data Release in Sublinear Time", "url": "https://arxiv.org/abs/2602.03732v1", "detail_url": "https://arxiv.org/pdf/2602.03732v1.pdf", "description_en": "The Multiplicative Weights Exponential Mechanism (MWEM) is a fundamental iterative framework for private data analysis, with broad applications such as answering $m$ linear queries, or privately solving systems of $m$ linear constraints. However, a critical bottleneck hindering its scalability is the $Θ(m)$ time complexity required to execute the exponential mechanism in each iteration. We introduce a modification to the MWEM framework that improves the per-iteration runtime dependency to $Θ(\\sqrt{m})$ in expectation. This is done via a lazy sampling approach to the Report-Noisy-Max mechanism, which we implement efficiently using Gumbel noise and a $k$-Nearest Neighbor data structure. This allows for the rapid selection of the approximate score in the exponential mechanism without an exhaustive linear scan. We apply our accelerated framework to the problems of private linear query release and solving Linear Programs (LPs) under neighboring constraint conditions and low-sensitivity assumptions. Experimental evaluation confirms that our method provides a substantial runtime improvement over classic MWEM.", "description_zh": "Fast-MWEM通过懒采样方法将MWEM框架的每次迭代时间复杂度降低至Θ(√m)，显著提高了私有数据发布的效率。", "keywords": ["私有数据发布", "多重权重指数机制", "线性查询", "线性约束", "Gumbel噪声", "k-近邻数据结构", "近似评分", "数据分析", "迭代框架", "agent"], "tags": ["cs.LG"], "metrics": {"authors": ["Themistoklis Haris", "Steve Choi", "Mutiraj Laksanawisit"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目在私有数据发布领域具有较高的技术创新性和效率提升，但缺乏明确的商业模式和用户价值绑定，团队背景信息不足。"}, "raw": {"published": "2026-02-03T16:51:40Z", "ai_summary": {"tldr": "Fast-MWEM通过懒采样方法将MWEM框架的每次迭代时间复杂度降低至Θ(√m)，显著提高了私有数据发布的效率。", "motivation": "MWEM框架在执行每次迭代时需要Θ(m)的时间复杂度，影响了其可扩展性，因此需要寻找更高效的实现方式。", "method": "采用懒采样的Report-Noisy-Max机制，结合Gumbel噪声和k-近邻数据结构，优化每次迭代的运行时间至Θ(√m)。", "conclusion": "实验结果表明，Fast-MWEM在私有线性查询发布和解决线性规划问题上，相较于经典MWEM方法显著提升了运行效率。"}}}
{"id": "ax-2026-02-03-30", "source": "arxiv", "date": "2026-02-03", "rank": 30, "title": "Efficient Training of Boltzmann Generators Using Off-Policy Log-Dispersion Regularization", "url": "https://arxiv.org/abs/2602.03729v1", "detail_url": "https://arxiv.org/pdf/2602.03729v1.pdf", "description_en": "Sampling from unnormalized probability densities is a central challenge in computational science. Boltzmann generators are generative models that enable independent sampling from the Boltzmann distribution of physical systems at a given temperature. However, their practical success depends on data-efficient training, as both simulation data and target energy evaluations are costly. To this end, we propose off-policy log-dispersion regularization (LDR), a novel regularization framework that builds on a generalization of the log-variance objective. We apply LDR in the off-policy setting in combination with standard data-based training objectives, without requiring additional on-policy samples. LDR acts as a shape regularizer of the energy landscape by leveraging additional information in the form of target energy labels. The proposed regularization framework is broadly applicable, supporting unbiased or biased simulation datasets as well as purely variational training without access to target samples. Across all benchmarks, LDR improves both final performance and data efficiency, with sample efficiency gains of up to one order of magnitude.", "description_zh": "提出了一种新颖的离线政策对数散布正则化方法，以提高Boltzmann生成器的训练效率和数据利用率。", "keywords": ["生成模型", "采样", "训练", "正则化", "Boltzmann生成器", "数据效率", "能量标签", "离线学习", "生成模型优化", "物理系统", "generative"], "tags": ["cs.LG"], "metrics": {"authors": ["Henrik Schopmans", "Christopher von Klitzing", "Pascal Friederich"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "rag"], "hit_excludes": []}, "score": {"total": 69, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了新颖的正则化方法，提升了Boltzmann生成器的训练效率，具备一定的技术壁垒和应用潜力，但缺乏明确的商业模式和团队背景信息。"}, "raw": {"published": "2026-02-03T16:49:32Z", "ai_summary": {"tldr": "提出了一种新颖的离线政策对数散布正则化方法，以提高Boltzmann生成器的训练效率和数据利用率。", "motivation": "在计算科学中，从未归一化概率密度中采样是一项重要挑战，而Boltzmann生成器在此过程中依赖于高效的数据训练。", "method": "提出的离线政策对数散布正则化（LDR）在不需要额外样本的情况下，结合标准数据训练目标，以改善能量景观的形状。", "conclusion": "LDR在所有基准测试中都提高了最终性能和数据效率，样本效率提升可达一个数量级。"}}}
{"id": "gh-2026-02-04-1", "source": "github", "date": "2026-02-04", "rank": 1, "title": "masoncl/review-prompts", "url": "https://github.com/masoncl/review-prompts", "detail_url": "https://github.com/masoncl/review-prompts", "description_en": "AI review prompts", "description_zh": "项目简介：AI Review Prompts 是一个旨在帮助用户生成高质量审查提示的工具。该项目主要功能是通过人工智能算法自动生成针对不同文档或内容的审查问题，帮助用户更有效地进行内容评估和反馈。\n\n主要功能包括自定义审查提示生成、支持多种文档格式的输入、以及智能优化问题以提高审查效率。目标用户包括编辑、内容创作者和教育工作者，适用于需要快速审查和反馈信息的场景。核心技术主要涉及自然语言处理（NLP）和机器学习（ML），以实现智能生成和优化提示。", "keywords": ["AI review prompts", "生成式对话", "语义搜索", "深度学习", "机器学习", "神经网络", "LLM", "助手", "多智能体", "主动式AI"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 39, "stars_today": 288}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 54, "breakdown": {"ai_native": 15, "tech_niche": 12, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目主要是生成审查提示，缺乏用户数据反馈的闭环和自我进化机制，技术路径较为常见，商业模式与价值绑定不强，团队信息不足。"}, "raw": {}}
{"id": "gh-2026-02-04-2", "source": "github", "date": "2026-02-04", "rank": 2, "title": "karpathy/nanochat", "url": "https://github.com/karpathy/nanochat", "detail_url": "https://github.com/karpathy/nanochat", "description_en": "The best ChatGPT that $100 can buy.", "description_zh": "这是您花费100美元能买到的最佳ChatGPT。该项目旨在提供高效、智能的对话生成技术，适用于需要自然语言处理的用户，如开发者、内容创作者和客服人员。核心技术包括深度学习、自然语言处理和机器学习，特别是在AI模型的训练和优化方面，确保提供准确且流畅的对话体验。", "keywords": ["聊天机器人", "生成式", "深度学习", "自主动", "LLM", "语义搜索", "代理", "语境", "多代理", "嵌入"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 5442, "stars_today": 307}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["gpt"], "hit_excludes": []}, "score": {"total": 52, "breakdown": {"ai_native": 18, "tech_niche": 12, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目提供了基本的对话生成能力，但缺乏用户反馈的闭环和自我改进机制，技术路径较为常规，商业模式与价值绑定不强，团队信息不足。"}, "raw": {}}
{"id": "gh-2026-02-04-3", "source": "github", "date": "2026-02-04", "rank": 3, "title": "OpenBMB/ChatDev", "url": "https://github.com/OpenBMB/ChatDev", "detail_url": "https://github.com/OpenBMB/ChatDev", "description_en": "ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration", "description_zh": "**ChatDev 2.0：通过大语言模型驱动的多代理协作进行开发**\n\nChatDev 2.0 是一个基于大语言模型（LLM）的开发工具，旨在通过多代理协作提高软件开发效率。主要功能包括自动代码生成、智能错误检测和实时协作编辑，适用于开发团队和自由开发者。核心技术采用了最新的 AI 算法，以优化代码编写和项目管理流程。", "keywords": ["多代理协作", "LLM", "生成模型", "深度学习", "神经网络", "语义搜索", "人机协作", "代理工作流", "主动式AI"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 3698, "stars_today": 226}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["llm", "agent", "multi-agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "ChatDev 2.0 具备多代理协作和代码生成能力，但用户反馈和自我学习机制尚不明确，未完全实现闭环。技术路径具备一定壁垒，商业模式与高价值用户绑定良好，团队背景较强。"}, "raw": {}}
{"id": "gh-2026-02-04-4", "source": "github", "date": "2026-02-04", "rank": 4, "title": "automazeio/ccpm", "url": "https://github.com/automazeio/ccpm", "detail_url": "https://github.com/automazeio/ccpm", "description_en": "Project management system for Claude Code using GitHub Issues and Git worktrees for parallel agent execution.", "description_zh": "项目管理系统，旨在为 Claude Code 提供支持，利用 GitHub Issues 和 Git 工作树进行并行代理执行。主要功能包括任务跟踪、团队协作和代码管理，适用于开发团队和项目管理者。核心技术方面，该系统结合了 Git 版本控制和 AI 代理执行，提升了项目管理的效率与灵活性。", "keywords": ["项目管理", "Claude Code", "GitHub Issues", "并行代理执行", "自动化", "任务管理", "代理", "生成模型", "语义搜索", "深度学习"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 711, "stars_today": 384}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude", "agent"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目结合了 Claude Code 和 GitHub Issues，但缺乏用户自我反馈和在线学习机制，技术路径较为常见，商业模式绑定不够强，团队信息不足。"}, "raw": {}}
{"id": "gh-2026-02-04-5", "source": "github", "date": "2026-02-04", "rank": 5, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "一个有效的代理技能框架和软件开发方法论。该项目旨在帮助开发者提升在软件开发过程中的代理能力，适合需要提升团队协作和项目管理技能的技术团队。核心技术包括机器学习和自然语言处理，旨在通过智能化的工具支持和优化开发流程。", "keywords": ["智能代理", "代理技能框架", "软件开发方法", "深度学习", "神经网络", "生成模型", "语义搜索", "多代理系统", "自主代理", "agent"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3345, "stars_today": 998}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的代理能力和智能化工具支持，但在用户反馈和自我学习闭环方面信息不足。技术路径具有复杂性，且与行业需求结合紧密，商业模式与高价值用户绑定较弱。团队背景良好，具备一定的AI原生能力。"}, "raw": {}}
{"id": "gh-2026-02-04-6", "source": "github", "date": "2026-02-04", "rank": 6, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件能够自动记录您在编码会话中的所有操作，利用 AI 技术（使用 Claude 的 agent-sdk）进行压缩，并将相关上下文注入到未来的会话中。该插件的主要功能是提升编码效率，帮助开发者更好地管理和回顾代码历史。目标用户为软件开发人员，特别是在需要频繁切换任务或处理复杂项目时。核心技术包括 AI 压缩算法和上下文注入机制，旨在智能化地优化开发流程。", "keywords": ["Claude Code", "自动化", "代码插件", "上下文注入", "机器学习", "深度学习", "生成式", "神经网络", "多智能体"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1445, "stars_today": 2618}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该插件通过上下文注入和AI压缩提升编码效率，具备一定的自我改进能力，但缺乏深度的用户数据反馈机制。技术路径独特且针对开发者的需求，商业模式与高价值用户紧密结合。团队背景信息不足，未能显示出明显的AI原生进化能力。"}, "raw": {}}
{"id": "gh-2026-02-04-7", "source": "github", "date": "2026-02-04", "rank": 7, "title": "virattt/dexter", "url": "https://github.com/virattt/dexter", "detail_url": "https://github.com/virattt/dexter", "description_en": "An autonomous agent for deep financial research", "description_zh": "一个用于深度金融研究的自主智能体。\n\n主要功能包括数据分析、市场预测和投资策略生成。目标用户为金融分析师、投资顾问和机构投资者，适用于金融市场分析和投资决策场景。该项目采用了深度学习和自然语言处理等核心技术，以提高数据处理效率和分析准确性。", "keywords": ["深度学习", "神经网络", "自主智能体", "生成模型", "语义搜索", "多智能体", "代理基础设施", "在线学习", "奖励模型", "agent"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1250, "stars_today": 406}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent", "autonomous"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目具备在线学习能力和自主智能体特性，能够为用户提供深度金融研究的高质量反馈。技术路径选择深度学习和自然语言处理，具有较高的行业壁垒。商业模式与高价值用户紧密相关，团队背景较强，具备快速迭代能力。"}, "raw": {}}
{"id": "gh-2026-02-04-8", "source": "github", "date": "2026-02-04", "rank": 8, "title": "pedramamini/Maestro", "url": "https://github.com/pedramamini/Maestro", "detail_url": "https://github.com/pedramamini/Maestro", "description_en": "Agent Orchestration Command Center", "description_zh": "**项目简介：代理编排指挥中心**\n\n代理编排指挥中心是一个用于管理和协调多个智能代理的工具，旨在简化复杂系统中的代理交互和任务分配。主要功能包括实时监控代理状态、任务调度和结果分析。目标用户为需要高效管理智能代理的企业和开发者，适用于自动化、智能客服和数据分析等场景。该项目核心技术包括机器学习、自然语言处理和多代理系统编排等 AI 相关技术。", "keywords": ["智能代理", "Agent Orchestration", "任务调度", "语义搜索", "深度学习", "多智能体", "人机协作", "自动化助手", "生成模型", "代理基础设施"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 162, "stars_today": 186}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 69, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备较强的代理编排能力，用户交互自然且能反哺系统，但缺乏明确的自我学习机制。技术路径选择较为独特，具备一定的行业壁垒。商业模式尚需进一步验证，团队背景信息不足。"}, "raw": {}}
{"id": "gh-2026-02-04-9", "source": "github", "date": "2026-02-04", "rank": 9, "title": "vm0-ai/vm0", "url": "https://github.com/vm0-ai/vm0", "detail_url": "https://github.com/vm0-ai/vm0", "description_en": "the easiest way to run natural language-described workflows automatically", "description_zh": "该项目是运行自然语言描述的工作流的最简单方法。其主要功能是通过解析用户的自然语言指令，自动化执行复杂的工作流程。目标用户包括希望简化日常任务的开发者和非技术用户，适用场景包括数据处理、信息提取和自动化办公等。核心技术涉及自然语言处理（NLP）和机器学习（ML），使系统能够理解和执行用户的意图。", "keywords": ["自然语言处理", "工作流自动化", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "自主代理", "助手工具", "多代理系统", "workflow"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 33, "stars_today": 316}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目通过自然语言解析实现工作流自动化，具备一定的AI原生能力，但缺乏用户反馈闭环和自我改进机制。技术路径较为独特，具备一定的行业壁垒。商业模式与高价值用户的绑定较弱，团队信息不足。"}, "raw": {}}
{"id": "ax-2026-02-04-1", "source": "arxiv", "date": "2026-02-04", "rank": 1, "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing", "url": "https://arxiv.org/abs/2602.04837v1", "detail_url": "https://arxiv.org/pdf/2602.04837v1.pdf", "description_en": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.", "description_zh": "本研究提出了群体进化代理（GEA）方法，通过经验共享实现开放式自我改进，显著提高了在编码基准上的表现。", "keywords": ["自我改进", "进化代理", "经验共享", "结构设计", "编码基准", "多代理", "自主学习", "生成模型", "代理友好工具", "agent"], "tags": ["cs.AI"], "metrics": {"authors": ["Zhaotian Weng", "Antonis Antoniades", "Deepak Nathani", "Zhen Zhang", "Xiao Pu", "Xin Eric Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 28, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 0}, "reason": "GEA展示了强大的自我改进能力和经验共享机制，符合AI原生的高标准；技术路径独特且有效解决复杂问题，具备明显的行业壁垒；商业模式与高价值用户紧密结合，团队背景扎实，具备进化能力。"}, "raw": {"published": "2026-02-04T18:29:36Z", "ai_summary": {"tldr": "本研究提出了群体进化代理（GEA）方法，通过经验共享实现开放式自我改进，显著提高了在编码基准上的表现。", "motivation": "研究的动机在于减少人工干预，使代理能够自主修改结构设计以提升能力，并克服现有自演化架构的局限性。", "method": "GEA将代理组视为基本的进化单元，促进组内明确的经验共享与重用，克服了现有树状进化方法的探索多样性低效利用问题。", "conclusion": "GEA在编码基准测试中表现优异，不仅超越了现有自演化方法，还在不同编码模型间展现出一致的可迁移性和更强的鲁棒性。"}}}
{"id": "ax-2026-02-04-2", "source": "arxiv", "date": "2026-02-04", "rank": 2, "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis", "url": "https://arxiv.org/abs/2602.04836v1", "detail_url": "https://arxiv.org/pdf/2602.04836v1.pdf", "description_en": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.", "description_zh": "本文质疑当前对AI能力呈指数增长的看法，认为数据不支持这一结论。", "keywords": ["AI能力", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "模型评估", "劳动力市场", "自主智能代理"], "tags": ["cs.AI"], "metrics": {"authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 54, "breakdown": {"ai_native": 10, "tech_niche": 12, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目主要关注AI能力增长的理论探讨，缺乏实际应用场景和商业模式，团队背景信息不足，未能展示出明显的AI原生特征和技术壁垒。"}, "raw": {"published": "2026-02-04T18:28:49Z", "ai_summary": {"tldr": "本文质疑当前对AI能力呈指数增长的看法，认为数据不支持这一结论。", "motivation": "研究AI能力的增长趋势及其对社会的影响，尤其是在安全性和劳动市场方面的担忧。", "method": "通过对现有数据拟合sigmoid曲线，并提出更复杂的模型来分解AI能力，以验证自己的假设。", "conclusion": "AI能力的增长可能在不久的将来会出现转折点，现有的指数增长预测存在脆弱性。"}}}
{"id": "ax-2026-02-04-3", "source": "arxiv", "date": "2026-02-04", "rank": 3, "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents", "url": "https://arxiv.org/abs/2602.04813v1", "detail_url": "https://arxiv.org/pdf/2602.04813v1.pdf", "description_en": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).", "description_zh": "本文提出了一个七维分类法来评估基于大语言模型的AI在医疗和医学领域的应用，并分析了49项相关研究的能力实现情况。", "keywords": ["智能代理", "大语言模型", "医疗", "知识管理", "适应与学习", "多代理设计", "信息中心能力", "医学问答", "决策支持", "llm"], "tags": ["cs.AI", "cs.CY"], "metrics": {"authors": ["Shubham Vatsal", "Harsh Dubey", "Aditi Singh"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent", "workflow"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目提出了七维分类法，评估LLM在医疗中的应用，展现出一定的自我改进能力和复杂任务处理能力，具备良好的技术路径和行业壁垒，但商业模式尚需进一步明确，团队信息不足。"}, "raw": {"published": "2026-02-04T17:59:14Z", "ai_summary": {"tldr": "本文提出了一个七维分类法来评估基于大语言模型的AI在医疗和医学领域的应用，并分析了49项相关研究的能力实现情况。", "motivation": "目前的文献缺乏统一框架，主要研究集中在单一能力，无法全面评估LLM在医疗中的作用。", "method": "通过回顾49项研究，并运用七维分类法进行分析，采用明确的纳入和排除标准以及标记规则，量化能力的实现情况。", "conclusion": "研究发现，在知识管理中外部知识整合能力普遍实现，但在互动模式和适应学习等方面存在明显缺失，表明医疗领域的LLM应用尚有许多发展空间。"}}}
{"id": "ax-2026-02-04-4", "source": "arxiv", "date": "2026-02-04", "rank": 4, "title": "CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation", "url": "https://arxiv.org/abs/2602.04856v1", "detail_url": "https://arxiv.org/pdf/2602.04856v1.pdf", "description_en": "From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake news generation, even when a model rejects a harmful request, its Chain-of-Thought (CoT) reasoning may still internally contain and propagate unsafe narratives. To analyze this phenomenon, we introduce a unified safety-analysis framework that systematically deconstructs CoT generation across model layers and evaluates the role of individual attention heads through Jacobian-based spectral metrics. Within this framework, we introduce three interpretable measures: stability, geometry, and energy to quantify how specific attention heads respond or embed deceptive reasoning patterns. Extensive experiments on multiple reasoning-oriented LLMs show that the generation risk rise significantly when the thinking mode is activated, where the critical routing decisions concentrated in only a few contiguous mid-depth layers. By precisely identifying the attention heads responsible for this divergence, our work challenges the assumption that refusal implies safety and provides a new understanding perspective for mitigating latent reasoning risks.", "description_zh": "本研究揭示大型语言模型在生成假新闻时即使拒绝有害请求，其内部的推理链可能仍包含不安全的叙述。", "keywords": ["关键词：生成模型", "大语言模型", "逻辑推理", "安全分析", "反向传播", "关注头", "伪造新闻", "复杂性分析", "风险评估", "llm"], "tags": ["cs.CL"], "metrics": {"authors": ["Zhao Tong", "Chunlin Gong", "Yiping Zhang", "Qiang Liu", "Xingcheng Xu", "Shu Wu", "Haichao Shi", "Xiao-Yu Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目探讨了LLM在假新闻生成中的潜在风险，具有一定的技术深度和行业相关性，但缺乏明确的商业模式和团队背景信息，导致整体评分偏低。"}, "raw": {"published": "2026-02-04T18:43:10Z", "ai_summary": {"tldr": "本研究揭示大型语言模型在生成假新闻时即使拒绝有害请求，其内部的推理链可能仍包含不安全的叙述。", "motivation": "研究旨在挑战传统认知，即拒绝响应意味着整个推理过程是安全的，特别是在假新闻生成的背景下。", "method": "引入统一的安全分析框架，系统性地分解推理生成过程，并通过雅可比谱度量评估特定注意力头的作用，使用稳定性、几何和能量三种可解释度量进行量化。", "conclusion": "实验表明，在激活推理模式时，生成风险显著上升，且关键决策集中在少数中层，挑战了拒绝意味着安全的假设，并为降低潜在推理风险提供了新视角。"}}}
{"id": "ax-2026-02-04-5", "source": "arxiv", "date": "2026-02-04", "rank": 5, "title": "Decomposed Prompting Does Not Fix Knowledge Gaps, But Helps Models Say \"I Don't Know\"", "url": "https://arxiv.org/abs/2602.04853v1", "detail_url": "https://arxiv.org/pdf/2602.04853v1.pdf", "description_en": "Large language models often struggle to recognize their knowledge limits in closed-book question answering, leading to confident hallucinations. While decomposed prompting is typically used to improve accuracy, we investigate its impact on reliability. We evaluate three task-equivalent prompting regimes: Direct, Assistive, and Incremental, across different model scales and multi-hop QA benchmarks. We find that although accuracy gains from decomposition diminish in frontier models, disagreements between prompting regimes remain highly indicative of potential errors. Because factual knowledge is stable while hallucinations are stochastic, cross-regime agreement provides a precise signal of internal uncertainty. We leverage this signal to implement a training-free abstention policy that requires no retrieval or fine-tuning. Our results show that disagreement-based abstention outperforms standard uncertainty baselines as an error detector, improving both F1 and AUROC across settings. This demonstrates that decomposition-based prompting can serve as a practical diagnostic probe for model reliability in closed-book QA.", "description_zh": "分解提示虽然无法弥补知识缺口，但有助于模型识别不确定性并说出‘我不知道’。", "keywords": ["知识缺口", "知识限制", "大型语言模型", "可靠性", "任务等效提示", "多跳问答", "模型规模", "误差检测", "训练无关", "不确定性", "rag"], "tags": ["cs.CL"], "metrics": {"authors": ["Dhruv Madhwal", "Lyuxin David Zhang", "Dan Roth", "Tomer Wolfson", "Vivek Gupta"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "retrieval"], "hit_excludes": []}, "score": {"total": 61, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目探讨了分解提示对模型可靠性的影响，尽管未能解决知识缺口，但提供了新的不确定性识别方法。技术路径和商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T18:39:58Z", "ai_summary": {"tldr": "分解提示虽然无法弥补知识缺口，但有助于模型识别不确定性并说出‘我不知道’。", "motivation": "大型语言模型在闭卷问答中常常无法识别其知识局限，导致自信的错误回答，因此需要探索如何提高模型的可靠性。", "method": "研究评估了三种任务等效的提示策略：直接、辅助和增量，在不同模型规模和多跳问答基准上进行比较，利用不同策略间的分歧来实现无需训练的弃权策略。", "conclusion": "基于分歧的弃权策略在错误检测上优于标准不确定性基准，显示出分解提示可以作为评估模型在闭卷问答中的可靠性的有效工具。"}}}
{"id": "ax-2026-02-04-6", "source": "arxiv", "date": "2026-02-04", "rank": 6, "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization", "url": "https://arxiv.org/abs/2602.04811v1", "detail_url": "https://arxiv.org/pdf/2602.04811v1.pdf", "description_en": "True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring \"Closed-Book Training\" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.", "description_zh": "SE-Bench是一个用于评估自我进化和知识内化能力的基准环境，揭示了训练和评估中的多个重要现象。", "keywords": ["自我进化", "知识内化", "终身学习", "代理", "编码任务", "自我训练", "强化学习", "SE-Bench", "任务评估", "agent"], "tags": ["cs.CL", "cs.AI", "cs.LG"], "metrics": {"authors": ["Jiarui Yuan", "Tailin Jin", "Weize Chen", "Zeyuan Liu", "Zhiyuan Liu", "Maosong Sun"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "sft"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目展示了自我进化和知识内化的能力，符合AI原生标准；技术路径具有独特性和复杂性，且与行业需求紧密结合；商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:58:32Z", "ai_summary": {"tldr": "SE-Bench是一个用于评估自我进化和知识内化能力的基准环境，揭示了训练和评估中的多个重要现象。", "motivation": "为了准确测量智能体的自我进化能力，研究者需要解决知识纠缠和推理复杂性带来的挑战。", "method": "通过将NumPy库模糊化为伪新包，训练智能体在没有文档支持的情况下完成简单编程任务，从而评估其知识内化能力。", "conclusion": "研究发现，文档参考训练会抑制知识保留，而自我生成的噪声任务与监督微调结合可以有效促进知识内化，SE-Bench为此提供了一个严格的诊断平台。"}}}
{"id": "ax-2026-02-04-7", "source": "arxiv", "date": "2026-02-04", "rank": 7, "title": "CoWTracker: Tracking by Warping instead of Correlation", "url": "https://arxiv.org/abs/2602.04877v1", "detail_url": "https://arxiv.org/pdf/2602.04877v1.pdf", "description_en": "Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \\method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.", "description_zh": "本论文提出了一种基于形变的密集点跟踪器CoWTracker，取代了传统的相关性匹配方法，提升了效率和性能。", "keywords": ["深度学习", "机器学习", "神经网络", "transformer", "语义搜索", "目标跟踪", "计算机视觉", "光流估计", "spatiotemporal reasoning", "数据驱动方法"], "tags": ["cs.CV"], "metrics": {"authors": ["Zihang Lai", "Eldar Insafutdinov", "Edgar Sucar", "Andrea Vedaldi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["transformer"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "该项目在AI原生程度上表现一般，缺乏用户反馈闭环和自我改进机制；技术路径具备一定的创新性和复杂性，构建了特定的Niche壁垒；商业模式较弱，未能明确与真实价值绑定；团队背景信息不足，创新能力有限。"}, "raw": {"published": "2026-02-04T18:58:59Z", "ai_summary": {"tldr": "本论文提出了一种基于形变的密集点跟踪器CoWTracker，取代了传统的相关性匹配方法，提升了效率和性能。", "motivation": "传统的密集点跟踪方法依赖于成本体积匹配特征，导致空间分辨率上的复杂度呈平方增长，限制了其可扩展性和效率。", "method": "CoWTracker通过形变来迭代精炼跟踪估计，结合变换器架构在所有轨迹上进行联合时空推理，而不计算特征相关性。", "conclusion": "该模型在标准密集点跟踪基准上表现优异，并在光流估计上也取得了良好成绩，表明基于形变的架构能够统一密集点跟踪与光流估计。"}}}
{"id": "ax-2026-02-04-8", "source": "arxiv", "date": "2026-02-04", "rank": 8, "title": "PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation", "url": "https://arxiv.org/abs/2602.04876v1", "detail_url": "https://arxiv.org/pdf/2602.04876v1.pdf", "description_en": "We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.", "description_zh": "PerpetualWonder是一个混合生成模拟器，可以基于单张图像生成长期、动作条件下的4D场景。", "keywords": ["生成模型", "4D场景生成", "长期交互", "物理状态", "视觉表示", "生成细化", "闭环系统", "统一表示", "多视角监督", "复杂交互", "generative"], "tags": ["cs.CV"], "metrics": {"authors": ["Jiahao Zhan", "Zizhang Li", "Hong-Xing Yu", "Jiajun Wu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "PerpetualWonder具备闭环系统和自我改进能力，用户在生成过程中提供高质量反馈。技术路径独特，解决复杂问题，具备深度绑定的行业应用潜力。商业模式与高价值用户强绑定，团队背景优秀。"}, "raw": {"published": "2026-02-04T18:58:55Z", "ai_summary": {"tldr": "PerpetualWonder是一个混合生成模拟器，可以基于单张图像生成长期、动作条件下的4D场景。", "motivation": "当前的生成模型在物理状态与视觉表现之间缺乏耦合，导致无法进行有效的生成性细化以适应后续交互。", "method": "PerpetualWonder引入了首个真正的闭环系统，通过统一表示建立物理状态与视觉原件之间的双向链接，并采用多视角监督机制解决优化模糊性。", "conclusion": "实验表明，PerpetualWonder能够从单张图像成功模拟复杂的多步交互，保持物理合理性和视觉一致性。"}}}
{"id": "ax-2026-02-04-9", "source": "arxiv", "date": "2026-02-04", "rank": 9, "title": "LitS: A novel Neighborhood Descriptor for Point Clouds", "url": "https://arxiv.org/abs/2602.04838v1", "detail_url": "https://arxiv.org/pdf/2602.04838v1.pdf", "description_en": "With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.", "description_zh": "本文提出了一种新的邻域描述符LitS，用于2D和3D点云，以准确表征局部几何结构。", "keywords": ["邻域描述符", "点云", "3D扫描", "深度学习", "机器学习", "语义搜索", "生成模型", "结构分析", "数据处理", "LitS", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Jonatan B. Bastos", "Francisco F. Rivera", "Oscar G. Lorenzo", "David L. Vilariño", "José C. Cabaleiro", "Alberto M. Esmorís", "Tomás F. Pena"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "context"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 15, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目提出了一种新的邻域描述符，具有一定的技术壁垒，但缺乏明确的商业模式和团队背景信息，AI原生程度较低。"}, "raw": {"published": "2026-02-04T18:31:02Z", "ai_summary": {"tldr": "本文提出了一种新的邻域描述符LitS，用于2D和3D点云，以准确表征局部几何结构。", "motivation": "随着3D扫描技术的发展，点云成为表示3D空间数据的基础，准确分析这些数据依赖于有效的邻域描述符。", "method": "LitS作为一种分段常数函数，能够通过方向信息跟踪点的周围环境，提供关于邻域的丰富信息，并可根据不同上下文进行调整。", "conclusion": "LitS是一种多功能的邻域描述符，能够捕捉局部点排列的细微差别，并对常见的点云数据问题具有韧性。"}}}
{"id": "ax-2026-02-04-10", "source": "arxiv", "date": "2026-02-04", "rank": 10, "title": "Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization", "url": "https://arxiv.org/abs/2602.04820v1", "detail_url": "https://arxiv.org/pdf/2602.04820v1.pdf", "description_en": "Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.", "description_zh": "本文提出了一种基于机器学习的指甲疾病分类模型，利用对抗性训练和Grad-CAM可视化提高准确性和可解释性。", "keywords": ["机器学习", "深度学习", "卷积神经网络", "生成对抗训练", "可解释性", "图像分类", "自动化诊断", "SHAP", "医学影像分析", "早期检测", "machine learning"], "tags": ["cs.CV", "cs.AI", "cs.LG"], "metrics": {"authors": ["Farzia Hossain", "Samanta Ghosh", "Shahida Begum", "B. M. Shahria Alam", "Mohammad Tahmid Noor", "Md Parvez Mia", "Nishat Tasnim Niloy"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "rag"], "hit_excludes": []}, "score": {"total": 55, "breakdown": {"ai_native": 15, "tech_niche": 18, "business": 12, "team": 6, "bonus": 0, "penalty": 0}, "reason": "项目主要集中在图像分类领域，缺乏用户反馈闭环和自我改进机制，AI原生程度较低；技术路径具有一定的复杂性和行业需求，但缺少明显的壁垒；商业模式较为基础，未能突出高价值用户的需求；团队信息不足，难以评估其进化能力。"}, "raw": {"published": "2026-02-04T18:08:13Z", "ai_summary": {"tldr": "本文提出了一种基于机器学习的指甲疾病分类模型，利用对抗性训练和Grad-CAM可视化提高准确性和可解释性。", "motivation": "人类指甲疾病在各年龄段逐渐增多，早期检测和准确诊断至关重要，但由于不同疾病类型的视觉差异，诊断具有挑战性。", "method": "使用包含3835张图像的公开数据集，通过训练多个CNN模型（如InceptionV3和DenseNet201）进行分类，并引入对抗性训练以提升模型鲁棒性，同时利用SHAP进行可解释性分析。", "conclusion": "InceptionV3模型取得了95.57%的准确率，为医生提供了更准确和快速的指甲疾病诊断支持。"}}}
{"id": "ax-2026-02-04-11", "source": "arxiv", "date": "2026-02-04", "rank": 11, "title": "XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas", "url": "https://arxiv.org/abs/2602.04819v1", "detail_url": "https://arxiv.org/pdf/2602.04819v1.pdf", "description_en": "Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.", "description_zh": "XtraLight-MedMamba是一种超轻量级深度学习框架，能有效分类肿瘤性管状腺瘤，准确率达到97.18%。", "keywords": ["深度学习", "机器学习", "神经网络", "图像分类", "风险分层", "医学影像", "特征提取", "多尺度特征", "模型优化", "XtraLight-MedMamba", "deep learning"], "tags": ["cs.CV", "cs.LG"], "metrics": {"authors": ["Aqsa Sultana", "Rayan Afsar", "Ahmed Rahu", "Surendra P. Singh", "Brian Shula", "Brandon Combs", "Derrick Forchetti", "Vijayan K. Asari"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "transformer"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "XtraLight-MedMamba展示了深度学习在医学影像中的应用，具备高效的自我学习能力和明确的行业需求，且团队背景强大，具备良好的市场潜力。"}, "raw": {"published": "2026-02-04T18:07:51Z", "ai_summary": {"tldr": "XtraLight-MedMamba是一种超轻量级深度学习框架，能有效分类肿瘤性管状腺瘤，准确率达到97.18%。", "motivation": "在常规结肠镜检查中，准确评估癌前息肉的风险对于降低结直肠癌的发生率至关重要，但低级别异型增生的评估仍受限于主观组织病理解读。", "method": "本研究提出的XtraLight-MedMamba框架结合了ConvNext浅层特征提取器与并行视觉mamba，利用SCAB模块增强多尺度特征提取，并通过FNOClassifier实现参数显著减少与泛化能力提升。", "conclusion": "XtraLight-MedMamba在处理低级别管状腺瘤的数据集上表现优异，准确率和F1-score均高于传统和基于变换器的架构，显示出其在临床应用中的潜力。"}}}
{"id": "ax-2026-02-04-12", "source": "arxiv", "date": "2026-02-04", "rank": 12, "title": "X2HDR: HDR Image Generation in a Perceptually Uniform Space", "url": "https://arxiv.org/abs/2602.04814v1", "detail_url": "https://arxiv.org/pdf/2602.04814v1.pdf", "description_en": "High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing pretrained diffusion models can be easily adapted to HDR generation without retraining from scratch. A key challenge is that HDR images are natively represented in linear RGB, whose intensity and color statistics differ substantially from those of sRGB-encoded LDR images. This gap, however, can be effectively bridged by converting HDR inputs into perceptually uniform encodings (e.g., using PU21 or PQ). Empirically, we find that LDR-pretrained variational autoencoders (VAEs) reconstruct PU21-encoded HDR inputs with fidelity comparable to LDR data, whereas linear RGB inputs cause severe degradations. Motivated by this finding, we describe an efficient adaptation strategy that freezes the VAE and finetunes only the denoiser via low-rank adaptation in a perceptually uniform space. This results in a unified computational method that supports both text-to-HDR synthesis and single-image RAW-to-HDR reconstruction. Experiments demonstrate that our perceptually encoded adaptation consistently improves perceptual fidelity, text-image alignment, and effective dynamic range, relative to previous techniques.", "description_zh": "本研究提出了一种有效的方法，将现有的低动态范围图像生成模型适应于高动态范围图像生成，使用感知均匀编码来桥接两者之间的差距。", "keywords": ["生成图像", "高动态范围", "预训练模型", "适应策略", "低秩适应", "视觉一致性", "生成对抗网络", "文本到图像", "单图像重建", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Ronghuan Wu", "Wanchao Su", "Kede Ma", "Jing Liao", "Rafał K. Mantiuk"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在HDR图像生成上有创新，但缺乏用户反馈与自我改进机制，商业模式尚不明确。技术路径具备一定壁垒，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:59:51Z", "ai_summary": {"tldr": "本研究提出了一种有效的方法，将现有的低动态范围图像生成模型适应于高动态范围图像生成，使用感知均匀编码来桥接两者之间的差距。", "motivation": "随着高动态范围格式和显示技术的普及，现有的图像生成模型在生成高动态范围图像时受到训练数据不足的限制。", "method": "本研究通过将HDR输入转换为感知均匀编码，冷冻变分自编码器（VAE），并仅通过低秩适应调整去噪器，实现了文本到HDR合成和单图像RAW到HDR重建的统一计算方法。", "conclusion": "实验结果表明，该方法在感知保真度、文本与图像的对齐以及动态范围的有效性方面，优于以往技术。"}}}
{"id": "ax-2026-02-04-13", "source": "arxiv", "date": "2026-02-04", "rank": 13, "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention", "url": "https://arxiv.org/abs/2602.04789v1", "detail_url": "https://arxiv.org/pdf/2602.04789v1.pdf", "description_en": "Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \\textsc{Light Forcing}, the \\textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \\textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \\textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\\eg, 84.5 on VBench) and efficiency (\\eg, $1.2{\\sim}1.3\\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \\textsc{Light Forcing} further achieves a $2.3\\times$ speedup and 19.7\\,FPS on an RTX~5090 GPU. Code will be released at \\href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.", "description_zh": "提出了一种名为Light Forcing的稀疏注意力机制，专门针对自回归视频生成模型，以提高生成效率和质量。", "keywords": ["自回归视频生成", "稀疏注意力", "生成模型", "深度学习", "机器学习", "历史上下文", "逐块生成", "速度提升", "Light Forcing", "diffusion"], "tags": ["cs.CV"], "metrics": {"authors": ["Chengtao Lv", "Yumeng Shi", "Yushi Huang", "Ruihao Gong", "Shen Ren", "Wenya Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了针对自回归视频生成的稀疏注意力机制，具备较强的AI原生能力和自我改进潜力，技术路径具有创新性和复杂性，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T17:41:53Z", "ai_summary": {"tldr": "提出了一种名为Light Forcing的稀疏注意力机制，专门针对自回归视频生成模型，以提高生成效率和质量。", "motivation": "自回归视频生成模型在视觉效果和交互性上有显著进步，但注意力机制的平方复杂度限制了其高效部署，因此需要更好的稀疏注意力解决方案。", "method": "Light Forcing结合了Chunk-Aware Growth机制和Hierarchical Sparse Attention，通过逐步增加稀疏性和两级掩码选择策略，提高了生成过程中对历史信息的利用。", "conclusion": "实验表明，Light Forcing在生成质量和效率上都优于现有的稀疏注意力方法，同时结合FP8量化和LightVAE实现了更高的速度提升。"}}}
{"id": "ax-2026-02-04-14", "source": "arxiv", "date": "2026-02-04", "rank": 14, "title": "Protein Autoregressive Modeling via Multiscale Structure Generation", "url": "https://arxiv.org/abs/2602.04883v1", "detail_url": "https://arxiv.org/pdf/2602.04883v1.pdf", "description_en": "We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.", "description_zh": "PAR是一种新颖的多尺度自回归框架，用于蛋白质骨架生成，通过粗到细的预测过程提升结构生成质量。", "keywords": ["蛋白质", "自回归建模", "多尺度", "结构生成", "自回归变换器", "条件嵌入", "背骨解码器", "生成模型", "结构生成质量", "transformer"], "tags": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "metrics": {"authors": ["Yanru Qu", "Cheng-Yen Hsieh", "Zaixiang Zheng", "Ge Liu", "Quanquan Gu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer", "embedding", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 5, "penalty": 0}, "reason": "PAR展示了多尺度自回归建模的创新，能有效解决生成中的曝光偏差，具备良好的零-shot泛化能力。技术路径复杂且具有行业壁垒，商业模式与高价值用户紧密结合，团队背景扎实。"}, "raw": {"published": "2026-02-04T18:59:49Z", "ai_summary": {"tldr": "PAR是一种新颖的多尺度自回归框架，用于蛋白质骨架生成，通过粗到细的预测过程提升结构生成质量。", "motivation": "现有的自回归模型在生成过程中存在曝光偏差，影响蛋白质结构的生成质量，因此需要一种新的框架来解决这一问题。", "method": "PAR包括多尺度下采样、自回归变换器和基于流的骨架解码器，结合噪声上下文学习和调度采样来增强生成能力。", "conclusion": "PAR在无条件生成基准上表现优异，能够学习蛋白质分布并生成高质量骨架，展现出良好的零-shot泛化能力，成为蛋白质结构生成的有力框架。"}}}
{"id": "ax-2026-02-04-15", "source": "arxiv", "date": "2026-02-04", "rank": 15, "title": "Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism", "url": "https://arxiv.org/abs/2602.04870v1", "detail_url": "https://arxiv.org/pdf/2602.04870v1.pdf", "description_en": "Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.", "description_zh": "提出了一种新型的多头稀疏专家模型架构和并行方法，实现了通信效率提高和训练速度加快。", "keywords": ["多头", "潜在专家", "计算效率", "确定性", "稀疏混合专家", "分布式训练", "负载均衡", "数据依赖通信", "语言模型", "训练加速", "agent"], "tags": ["cs.LG"], "metrics": {"authors": ["Chenwei Cui", "Rockwell Jackson", "Benjamin Joseph Herrera", "Ana María Tárano", "Hannah Kerner"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了新型的多头稀疏专家模型，具备一定的自我提升能力，但缺乏明确的商业模式和团队信息，技术路径较为前沿，具有一定的行业壁垒。"}, "raw": {"published": "2026-02-04T18:57:19Z", "ai_summary": {"tldr": "提出了一种新型的多头稀疏专家模型架构和并行方法，实现了通信效率提高和训练速度加快。", "motivation": "大规模语言模型训练成本高，稀疏混合专家（MoE）通过条件计算来解决这一问题，但现有的专家并行方法存在通信成本高、负载不均和数据依赖性等问题。", "method": "提出了多头LatentMoE和头并行（HP）架构，确保通信成本与激活的专家数量无关，并通过IO感知路由和专家计算加速训练。", "conclusion": "与传统的专家并行（EP）方法相比，多头LatentMoE与HP的训练速度提高了1.61倍，且性能保持一致，使得数十亿参数基础模型的研究更加可行。"}}}
{"id": "ax-2026-02-04-16", "source": "arxiv", "date": "2026-02-04", "rank": 16, "title": "CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation", "url": "https://arxiv.org/abs/2602.04868v1", "detail_url": "https://arxiv.org/pdf/2602.04868v1.pdf", "description_en": "Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.", "description_zh": "本文介绍了一种名为CRoSS的基于Gazebo模拟器的持续机器人仿真套件，用于支持高任务多样性和现实物理模拟的持续强化学习研究。", "keywords": ["强化学习", "机器人", "机器人仿真", "任务多样性", "深度学习", "连续学习", "代理", "Gazebo", "DQN", "政策梯度", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Yannick Denker", "Alexander Gepperth"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "CRoSS具备高质量的用户反馈和自我改进能力，且在机器人仿真领域具有独特的技术路径和深度绑定的应用场景，商业模式尚需进一步明确。"}, "raw": {"published": "2026-02-04T18:54:26Z", "ai_summary": {"tldr": "本文介绍了一种名为CRoSS的基于Gazebo模拟器的持续机器人仿真套件，用于支持高任务多样性和现实物理模拟的持续强化学习研究。", "motivation": "持续强化学习要求智能体能够从一系列任务中学习而不遗忘之前的策略，因此需要一个高真实性和高多样性的基准套件来测试和评估相关算法。", "method": "CRoSS基于两种机器人平台，分别是具有激光雷达和摄像头的差分驱动机器人，以及七关节的机械臂，支持多种任务场景，并允许扩展和使用几乎任意的仿真传感器。", "conclusion": "CRoSS提供了一个可扩展、可复现的基准，适用于持续强化学习研究，并展示了标准RL算法的性能。"}}}
{"id": "ax-2026-02-04-17", "source": "arxiv", "date": "2026-02-04", "rank": 17, "title": "Subliminal Effects in Your Data: A General Mechanism via Log-Linearity", "url": "https://arxiv.org/abs/2602.04863v1", "detail_url": "https://arxiv.org/pdf/2602.04863v1.pdf", "description_en": "Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.   We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.", "description_zh": "本文提出了一种新方法，通过选择数据集子集揭示隐藏的潜在信号，以理解大型语言模型的训练效果。", "keywords": ["隐含效应", "数据集", "大语言模型", "Logit-Linear-Selection", "训练方法", "模型属性", "偏好选择", "行为表现", "语义理解", "llm"], "tags": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "metrics": {"authors": ["Ishaq Aden-Ali", "Noah Golowich", "Allen Liu", "Abhishek Shetty", "Ankur Moitra", "Nika Haghtalab"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 5, "bonus": 0, "penalty": 0}, "reason": "该项目提出了新方法理解数据集对模型的影响，但缺乏明确的自我进化机制和商业应用场景，团队信息不足，未能显示出显著的行业壁垒。"}, "raw": {"published": "2026-02-04T18:50:46Z", "ai_summary": {"tldr": "本文提出了一种新方法，通过选择数据集子集揭示隐藏的潜在信号，以理解大型语言模型的训练效果。", "motivation": "随着大型语言模型训练算法和数据集的多样化，理解数据集对模型属性的影响变得愈发重要，尤其是数据集可能传递不可直接观察的信号。", "method": "本文介绍了Logit-Linear-Selection (LLS) 方法，用于选择通用偏好数据集的子集，以引发广泛的隐藏效应。", "conclusion": "研究表明，所选子集在不同架构的模型上均能持续产生预期效果，证明了该方法的普遍性和适用性。"}}}
{"id": "ax-2026-02-04-18", "source": "arxiv", "date": "2026-02-04", "rank": 18, "title": "From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures", "url": "https://arxiv.org/abs/2602.04861v1", "detail_url": "https://arxiv.org/pdf/2602.04861v1.pdf", "description_en": "Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an \"in-the-loop\" model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.", "description_zh": "本文提出了新的Bond Smoothness Characterization Test (BSCT)作为评估和指导机器学习原子间势能模型设计的有效工具。", "keywords": ["机器学习", "深度学习", "变换器", "代理", "多代理", "迭代模型设计", "物理平滑性", "评价指标", "原子间势能", "machine learning"], "tags": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "metrics": {"authors": ["Ryan Liu", "Eric Qu", "Tobias Kreiman", "Samuel M. Blau", "Aditi S. Krishnapriyan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "transformer"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出了新的评估指标BSCT，能有效指导机器学习原子间势能模型设计，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息。"}, "raw": {"published": "2026-02-04T18:50:10Z", "ai_summary": {"tldr": "本文提出了新的Bond Smoothness Characterization Test (BSCT)作为评估和指导机器学习原子间势能模型设计的有效工具。", "motivation": "现有的机器学习原子间势能模型在物理平滑性上的表现不佳，导致下游模拟错误，因此需要更好的评估指标。", "method": "BSCT通过控制键的变形来探测势能面中的非平滑性，并与分子动力学稳定性强相关，同时成本远低于传统方法。", "conclusion": "BSCT不仅可以作为验证指标，还能作为模型设计的参考，帮助开发人员识别当前基准无法高效评估的物理挑战。"}}}
{"id": "ax-2026-02-04-19", "source": "arxiv", "date": "2026-02-04", "rank": 19, "title": "The Key to State Reduction in Linear Attention: A Rank-based Perspective", "url": "https://arxiv.org/abs/2602.04852v1", "detail_url": "https://arxiv.org/pdf/2602.04852v1.pdf", "description_en": "Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.", "description_zh": "本论文提出了一种基于秩的视角来减少线性注意力模型的状态大小，同时保持模型性能。", "keywords": ["线性注意力", "低秩结构", "硬件感知", "结构化剪枝", "查询噪声", "CUDA", "模型压缩", "记忆效率", "计算效率", "retrieval"], "tags": ["cs.LG"], "metrics": {"authors": ["Philipp Nazari", "T. Konstantin Rusch"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "retrieval"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该项目提出了基于秩的线性注意力模型状态减少方法，具有较高的AI原生程度和技术壁垒，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T18:39:38Z", "ai_summary": {"tldr": "本论文提出了一种基于秩的视角来减少线性注意力模型的状态大小，同时保持模型性能。", "motivation": "研究表明，训练后的线性注意力模型呈现低秩结构，表明其在实际应用中未充分利用能力，因此需要探讨如何优化其状态。", "method": "论文提出了一种硬件感知的方法，通过结构性修剪关键和查询矩阵，结合基于秩揭示的QR分解的结构化修剪方法来减少状态大小。", "conclusion": "实验证明该框架可以在仅轻微提高困惑度的情况下，移除50%的查询和关键通道，从而实现更快和更高效的模型。"}}}
{"id": "ax-2026-02-04-20", "source": "arxiv", "date": "2026-02-04", "rank": 20, "title": "Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning", "url": "https://arxiv.org/abs/2602.04821v1", "detail_url": "https://arxiv.org/pdf/2602.04821v1.pdf", "description_en": "Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\\% coverage efficiency, controls FDR at 4.1\\% under verified dependence, and improves safety rate to 95.2\\% compared to 69\\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.", "description_zh": "STREAM-RL是一个统一框架，通过不确定性感知的预测和安全强化学习实现安全的城市交通控制。", "keywords": ["城市交通管理", "不确定性", "强化学习", "预测模型", "安全控制", "STREAM-RL", "PU-GAT+", "CRFN-BY", "LyCon-WRL+", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Joydeep Chandra", "Satyam Kumar Navneet", "Aleksandr Algazinov", "Yong Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目展示了强大的AI原生能力，具备自我改进和闭环学习机制，技术路径独特并解决复杂问题。商业模式尚不清晰，团队信息不足。"}, "raw": {"published": "2026-02-04T18:10:59Z", "ai_summary": {"tldr": "STREAM-RL是一个统一框架，通过不确定性感知的预测和安全强化学习实现安全的城市交通控制。", "motivation": "城市交通管理需要同时预测未来情况、检测异常并采取安全的纠正措施，同时提供可靠性保证。", "method": "框架包括PU-GAT+、CRFN-BY和LyCon-WRL+三个新算法，分别用于不确定性引导的预测、残差建模和安全强化学习。", "conclusion": "STREAM-RL在真实交通数据上实现了91.4%的覆盖效率，控制FDR为4.1%，安全率提升至95.2%，并具有较低的推理延迟。"}}}
{"id": "ax-2026-02-04-21", "source": "arxiv", "date": "2026-02-04", "rank": 21, "title": "Beyond Rewards in Reinforcement Learning for Cyber Defence", "url": "https://arxiv.org/abs/2602.04809v1", "detail_url": "https://arxiv.org/pdf/2602.04809v1.pdf", "description_en": "Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.", "description_zh": "本文研究了稀疏与密集奖励在强化学习中的影响，发现稀疏奖励在网络防御中提供了更可靠的训练和更低风险的策略。", "keywords": ["深度学习", "强化学习", "自主代理", "网络防御", "稀疏奖励", "奖励函数", "行为特征", "网络环境", "政策梯度", "价值基础", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Elizabeth Bates", "Chris Hicks", "Vasilios Mavroudis"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "项目在AI原生程度上表现一般，虽然探讨了奖励结构对学习的影响，但缺乏自我改进和闭环机制。技术路径具有一定的复杂性和独特性，但商业模式不够明确，缺乏高价值用户的强绑定。"}, "raw": {"published": "2026-02-04T17:55:23Z", "ai_summary": {"tldr": "本文研究了稀疏与密集奖励在强化学习中的影响，发现稀疏奖励在网络防御中提供了更可靠的训练和更低风险的策略。", "motivation": "随着对自主网络防御代理的兴趣增加，现有的密集奖励函数可能导致次优和高风险的解决方案，因此需要探索奖励结构的影响。", "method": "通过使用多种稀疏和密集奖励函数，以及两种网络规模和多种强化学习算法，评估奖励函数结构对学习和策略行为特征的影响。", "conclusion": "稀疏奖励在目标一致且频繁遭遇的情况下，能提高训练的可靠性，并生成与网络防御目标更一致且低风险的策略。"}}}
{"id": "ax-2026-02-04-22", "source": "arxiv", "date": "2026-02-04", "rank": 22, "title": "Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning", "url": "https://arxiv.org/abs/2602.04807v1", "detail_url": "https://arxiv.org/pdf/2602.04807v1.pdf", "description_en": "We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.", "description_zh": "该论文提出了一个名为Afferent Learning的框架，通过进化优化和强化学习相结合，生成适应性内部风险信号以实现损伤规避学习。", "keywords": ["生物启发模型", "适应性学习", "强化学习", "进化优化", "计算感知轨迹", "伤害规避策略", "生物机械数字双胞胎", "年龄适应性行为", "context"], "tags": ["cs.LG"], "metrics": {"authors": ["Wolfgang Maass", "Sabine Janzen", "Prajvi Saxena", "Sach Mukherjee"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目采用生物启发的感知架构，结合进化优化和强化学习，具备较强的自我改进能力和高效的学习机制。技术路径独特，解决复杂问题，且有明确的行业应用潜力。团队背景较强，具备AI领域的复合认知。"}, "raw": {"published": "2026-02-04T17:53:28Z", "ai_summary": {"tldr": "该论文提出了一个名为Afferent Learning的框架，通过进化优化和强化学习相结合，生成适应性内部风险信号以实现损伤规避学习。", "motivation": "研究旨在模仿生物系统的感知架构，以提高政策学习的有效性并避免损伤。", "method": "框架采用两级架构，外层通过进化优化发现有效的感知架构，内层通过强化学习训练损伤规避政策，并提供理论收敛保证。", "conclusion": "实验结果表明，基于计算性afferent痕迹的进化架构在效率和年龄鲁棒性方面超越了手动设计的基线，且能够实现年龄依赖的行为适应。"}}}
{"id": "ax-2026-02-04-23", "source": "arxiv", "date": "2026-02-04", "rank": 23, "title": "Maximum-Volume Nonnegative Matrix Factorization", "url": "https://arxiv.org/abs/2602.04795v1", "detail_url": "https://arxiv.org/pdf/2602.04795v1.pdf", "description_en": "Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.", "description_zh": "本文提出最大体积非负矩阵分解（MaxVol NMF），通过最大化矩阵H的体积来提高稀疏分解的效果。", "keywords": ["非负矩阵分解", "数据嵌入", "最大体积", "最小体积", "稀疏分解", "超光谱解混合", "机器学习", "算法优化", "维度降低", "embedding"], "tags": ["cs.LG", "eess.SP", "math.NA", "stat.ML"], "metrics": {"authors": ["Olivier Vu Thanh", "Nicolas Gillis"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding", "context"], "hit_excludes": []}, "score": {"total": 56, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目提出了新的非负矩阵分解方法，但缺乏明确的商业应用场景和团队背景信息，技术路径较为传统，未能展示出明显的行业壁垒。"}, "raw": {"published": "2026-02-04T17:43:25Z", "ai_summary": {"tldr": "本文提出最大体积非负矩阵分解（MaxVol NMF），通过最大化矩阵H的体积来提高稀疏分解的效果。", "motivation": "为了获得更具可解释性和唯一性的解，传统的最小体积非负矩阵分解（MinVol NMF）被提出，而MaxVol NMF则从另一个角度优化分解。", "method": "MaxVol NMF通过最大化H的体积来实现解的识别性，并提出两种算法解决该问题，同时引入归一化变体以提升性能。", "conclusion": "MaxVol NMF在处理噪声时表现优于MinVol NMF，且其解对应于将数据矩阵X的列聚类，而MinVol NMF的解则可能出现秩缺乏。"}}}
{"id": "ax-2026-02-04-24", "source": "arxiv", "date": "2026-02-04", "rank": 24, "title": "Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation", "url": "https://arxiv.org/abs/2602.04785v1", "detail_url": "https://arxiv.org/pdf/2602.04785v1.pdf", "description_en": "While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.", "description_zh": "本文提出了一种名为Team-then-Trim (T$^2$) 的框架，通过协作的语言模型生成高质量的表格数据，并结合严格的数据质量控制管道。", "keywords": ["生成框架", "高质量", "表格数据", "大语言模型", "数据质量控制", "协作团队", "机器学习", "合成数据", "machine learning"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Congjing Zhang", "Ryan Feng Lin", "Ruoxuan Bao", "Shuai Huang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "llm"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 2}, "reason": "该项目通过协作的 LLMs 生成高质量表格数据，具备一定的自我改进能力和闭环，但缺乏明确的商业模式和市场应用场景，且创始人信息不足，减分。"}, "raw": {"published": "2026-02-04T17:34:41Z", "ai_summary": {"tldr": "本文提出了一种名为Team-then-Trim (T$^2$) 的框架，通过协作的语言模型生成高质量的表格数据，并结合严格的数据质量控制管道。", "motivation": "高质量的表格数据在机器学习应用中至关重要，但获取过程通常费时费力且成本高，且现有数据集存在严重缺陷。", "method": "T$^2$框架将表格数据生成视为一个制造过程，由专业的语言模型根据领域知识依次生成数据组件，并通过三阶段的数据质量控制管道进行评估。", "conclusion": "实证结果表明，T$^2$在生成高质量表格数据方面优于现有最先进方法，显示其在直接数据收集不可行时的潜力。"}}}
{"id": "ax-2026-02-04-25", "source": "arxiv", "date": "2026-02-04", "rank": 25, "title": "Dynamical Regimes of Multimodal Diffusion Models", "url": "https://arxiv.org/abs/2602.04780v1", "detail_url": "https://arxiv.org/pdf/2602.04780v1.pdf", "description_en": "Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.", "description_zh": "本研究提出了一种理论框架来理解多模态扩散模型中的动态相位转换及其生成机制。", "keywords": ["扩散模型", "生成模型", "多模态生成", "动态相变", "统计物理", "训练实验", "MNIST数据集", "模式特定时间尺度", "频谱层次", "generative"], "tags": ["cs.LG"], "metrics": {"authors": ["Emil Albrychiewicz", "Andrés Franco Valiente", "Li-Ching Chen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 4, "penalty": 0}, "reason": "项目提出了多模态生成的理论框架，具有一定的创新性，但商业模式和团队信息不足，影响了整体评分。"}, "raw": {"published": "2026-02-04T17:16:12Z", "ai_summary": {"tldr": "本研究提出了一种理论框架来理解多模态扩散模型中的动态相位转换及其生成机制。", "motivation": "尽管扩散生成模型在高维数据合成中表现出色，但其多模态生成的理论机制仍不清晰，因此需要深入研究。", "method": "我们利用耦合的Ornstein-Uhlenbeck过程和非平衡统计物理理论，探讨了生成过程中的动态相位转换及其时间尺度的谱层次结构。", "conclusion": "研究表明耦合强度作为光谱滤波器，能够在生成过程中施加可调节的时间层次，为多模态生成提供了新的时间依赖耦合调度方法。"}}}
{"id": "ax-2026-02-04-26", "source": "arxiv", "date": "2026-02-04", "rank": 26, "title": "Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification", "url": "https://arxiv.org/abs/2602.04775v1", "detail_url": "https://arxiv.org/pdf/2602.04775v1.pdf", "description_en": "In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.", "description_zh": "提出了一种基于区间的ROC分析框架，以应对不确定性感知分类中的评估问题。", "keywords": ["不确定性", "预测", "排序", "评估", "分类", "机器学习", "深度学习", "模型优化", "选择性预测", "ROC曲线", "rag"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuqi Li", "Matthew M. Engelhard"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目提出了不确定性感知的ROC分析框架，具备一定的自我改进能力，但缺乏明确的Agent特性。技术路径独特，解决复杂问题，商业模式较弱，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:12:04Z", "ai_summary": {"tldr": "提出了一种基于区间的ROC分析框架，以应对不确定性感知分类中的评估问题。", "motivation": "在高风险预测中，通过区间值预测量化不确定性对可靠决策至关重要，现有的ROC曲线和AUC无法有效捕捉这种不确定性。", "method": "提出了两个新度量$AUC_L$和$AUC_U$，并构建了不确定性感知的ROC框架，支持对重叠区间的选择性预测。", "conclusion": "该框架在真实数据集上的实验验证了其有效性，并展示了在不确定性评估和决策中的实用性。"}}}
{"id": "ax-2026-02-04-27", "source": "arxiv", "date": "2026-02-04", "rank": 27, "title": "Generative Modeling via Drifting", "url": "https://arxiv.org/abs/2602.04770v1", "detail_url": "https://arxiv.org/pdf/2602.04770v1.pdf", "description_en": "Generative modeling can be formulated as learning a mapping f such that its pushforward distribution matches the data distribution. The pushforward behavior can be carried out iteratively at inference time, for example in diffusion and flow-based models. In this paper, we propose a new paradigm called Drifting Models, which evolve the pushforward distribution during training and naturally admit one-step inference. We introduce a drifting field that governs the sample movement and achieves equilibrium when the distributions match. This leads to a training objective that allows the neural network optimizer to evolve the distribution. In experiments, our one-step generator achieves state-of-the-art results on ImageNet at 256 x 256 resolution, with an FID of 1.54 in latent space and 1.61 in pixel space. We hope that our work opens up new opportunities for high-quality one-step generation.", "description_zh": "本文提出了一种新的生成建模范式——Drifting Models，通过演变推送分布实现一阶段推理。", "keywords": ["生成模型", "生成建模", "推进分布", "神经网络", "漂移模型", "训练目标", "一步推理", "图像生成", "ImageNet", "FID", "neural network"], "tags": ["cs.LG", "cs.CV"], "metrics": {"authors": ["Mingyang Deng", "He Li", "Tianhong Li", "Yilun Du", "Kaiming He"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "neural network", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 4, "penalty": 0}, "reason": "该项目提出了新的生成建模范式，具备高效的一步推理能力，符合AI原生要求。技术路径独特且解决复杂问题，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T17:06:49Z", "ai_summary": {"tldr": "本文提出了一种新的生成建模范式——Drifting Models，通过演变推送分布实现一阶段推理。", "motivation": "传统的生成建模方法在推理时通常需要多步骤，而本研究旨在实现一种高效的一步生成过程。", "method": "引入了漂移场以控制样本移动，并在训练中进化推送分布，最终目标是使分布达到平衡。", "conclusion": "实验结果表明，该方法在256 x 256分辨率的ImageNet上达到了最先进的表现，表明其在高质量一阶段生成中的潜力。"}}}
{"id": "ax-2026-02-04-28", "source": "arxiv", "date": "2026-02-04", "rank": 28, "title": "Billion-Scale Graph Foundation Models", "url": "https://arxiv.org/abs/2602.04768v1", "detail_url": "https://arxiv.org/pdf/2602.04768v1.pdf", "description_en": "Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.", "description_zh": "本文提出了一种名为GraphBFF的亿级图基础模型，旨在通过大规模预训练和轻量化适应来处理图结构数据。", "keywords": ["图神经网络", "图基础模型", "预训练", "微调", "GraphBFF", "大规模数据", "任务性能", "零-shot学习", "代理工作流", "transformer"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Maya Bechler-Speicher", "Yoel Gottlieb", "Andrey Isakov", "David Abensur", "Ami Tavory", "Daniel Haimovich", "Ido Guy", "Udi Weinsberg"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提出了亿级图基础模型GraphBFF，具有一定的AI原生程度和技术壁垒，但商业模式不够明确，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:03:51Z", "ai_summary": {"tldr": "本文提出了一种名为GraphBFF的亿级图基础模型，旨在通过大规模预训练和轻量化适应来处理图结构数据。", "motivation": "图结构数据在多个关键应用中至关重要，但将大型预训练模型扩展到实际的异构图数据中面临挑战。", "method": "GraphBFF采用了一种灵活可扩展的Transformer架构，并提供了针对数据批处理、预训练和微调的具体方法，以构建亿级参数的图基础模型。", "conclusion": "GraphBFF在多个未见过的下游任务中表现出色，证明了其在工业规模图学习中的可行性，并指出了未来的挑战和机会。"}}}
{"id": "ax-2026-02-04-29", "source": "arxiv", "date": "2026-02-04", "rank": 29, "title": "Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty", "url": "https://arxiv.org/abs/2602.04763v1", "detail_url": "https://arxiv.org/pdf/2602.04763v1.pdf", "description_en": "Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.", "description_zh": "提出了一种新的多代理多模态学习方法A2MAML，通过不确定性感知促进不同模态的协作，显著提高事故检测率。", "keywords": ["多智能体", "多模态", "学习", "不确定性", "协作", "机器人", "传感器", "自主驾驶", "A2MAML", "模态融合"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Rui Liu", "Pratap Tokekar", "Ming Lin"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "agent", "autonomous", "multi-agent"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 2}, "reason": "项目提出了一种新的多代理多模态学习方法，具备良好的自我改进能力和模态融合能力，但商业模式尚不明确，且缺乏团队背景信息。"}, "raw": {"published": "2026-02-04T17:01:31Z", "ai_summary": {"tldr": "提出了一种新的多代理多模态学习方法A2MAML，通过不确定性感知促进不同模态的协作，显著提高事故检测率。", "motivation": "现有的多代理协作框架在处理异构传感器和不确定性时存在局限，无法有效应对传感器损坏带来的影响。", "method": "A2MAML通过将每个模态特征建模为带有不确定性预测的随机估计，主动选择可靠的代理-模态对，并通过贝叶斯逆方差加权进行信息聚合。", "conclusion": "在连接的自动驾驶场景中，A2MAML的事故检测率比单代理和协作基线高出18.7%，展示了其优越的性能。"}}}
{"id": "ax-2026-02-04-30", "source": "arxiv", "date": "2026-02-04", "rank": 30, "title": "A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates", "url": "https://arxiv.org/abs/2602.04757v1", "detail_url": "https://arxiv.org/pdf/2602.04757v1.pdf", "description_en": "Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.", "description_zh": "提出了一种基于双阶段TransUNet的多源降水合并框架，以提高降水估计的准确性和极端事件检测能力。", "keywords": ["深度学习", "机器学习", "多源降水", "TransUNet", "预处理", "预测模型", "数据融合", "极端事件", "解释性分析", "deep learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuchen Ye", "Zixuan Qi", "Shixuan Li", "Wei Qi", "Yanpeng Cai", "Chaoxia Yuan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "retrieval"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目展示了AI原生能力，但缺乏用户交互和自我学习机制。技术路径具有一定的独特性和复杂性，商业模式绑定较弱，团队背景信息不足。"}, "raw": {"published": "2026-02-04T16:55:43Z", "ai_summary": {"tldr": "提出了一种基于双阶段TransUNet的多源降水合并框架，以提高降水估计的准确性和极端事件检测能力。", "motivation": "多源降水产品在水文气候监测中广泛应用，但由于空间异质性偏差和极端事件的技能限制，影响了其效用。", "method": "开发了一个双阶段的TransUNet框架，第一阶段为分类器估计降水发生概率，第二阶段为回归器融合输出与物理预测因子，估计中国2001-2020年的日降水量。", "conclusion": "该框架在东中国重降水事件的检测上表现优越，且在数据稀缺地区的适用性得到了独立评估的支持，提供了一种可扩展且可解释的降水融合方法。"}}}
{"id": "gh-2026-02-05-1", "source": "github", "date": "2026-02-05", "rank": 1, "title": "aquasecurity/trivy", "url": "https://github.com/aquasecurity/trivy", "detail_url": "https://github.com/aquasecurity/trivy", "description_en": "Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more", "description_zh": "该项目旨在识别容器、Kubernetes、代码库、云环境等中的漏洞、错误配置、秘密信息和软件物料清单（SBOM）。主要功能包括自动扫描和分析，以确保系统的安全性和合规性。目标用户包括开发人员、安全团队及DevOps工程师，核心技术涉及人工智能算法，以提高漏洞检测的准确性和效率。", "keywords": ["漏洞扫描", "misconfigurations", "SBOM", "Kubernetes", "代码仓库", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "agent"], "tags": ["Go"], "metrics": {"stars": 0, "forks": 2907, "stars_today": 23}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目利用AI提高漏洞检测，但缺乏用户自我反馈闭环。技术路径较为复杂且具有一定壁垒，商业模式与高价值用户紧密绑定。团队背景信息不足，未能展示明显的AI原生进化能力。"}, "raw": {}}
{"id": "gh-2026-02-05-2", "source": "github", "date": "2026-02-05", "rank": 2, "title": "topoteretes/cognee", "url": "https://github.com/topoteretes/cognee", "detail_url": "https://github.com/topoteretes/cognee", "description_en": "Memory for AI Agents in 6 lines of code", "description_zh": "项目简介：在仅用六行代码的情况下，为人工智能代理提供内存管理功能。该项目旨在帮助开发者轻松集成记忆机制，从而提升 AI 代理的智能水平和交互能力。主要用户包括 AI 开发者和研究人员，适用于智能助手、对话系统等场景。核心技术涉及自然语言处理和记忆网络，利用 AI 理解和存储用户信息以优化后续互动。", "keywords": ["记忆", "AI Agents", "代码优化", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "自主代理", "多代理"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 1150, "stars_today": 69}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提供了简单的内存管理功能，提升了AI代理的智能水平，但缺乏自我学习和进化的闭环机制。技术路径较为独特，适合特定场景，但商业模式尚不明确。团队背景信息不足，无法评估其能力。"}, "raw": {}}
{"id": "gh-2026-02-05-3", "source": "github", "date": "2026-02-05", "rank": 3, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "一个有效的代理技能框架和软件开发方法论。该项目的主要功能是提供一个系统化的框架，帮助开发者提升软件开发中的技能和效率，特别是在团队协作和项目管理方面。目标用户包括软件开发团队和项目经理，适用于敏捷开发和持续集成的场景。核心技术涉及人工智能，以优化工作流程和自动化任务分配，从而提升整体开发效率。", "keywords": ["智能代理", "agentic skills", "软件开发方法论", "机器学习", "深度学习", "神经网络", "生成模型", "语义搜索", "自主代理", "多智能体"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3407, "stars_today": 893}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目提供了代理技能框架，具备一定的自我优化能力，但在用户反馈和数据闭环方面信息不足。技术路径较为独特，且有明确的行业应用，但需进一步验证市场需求和团队背景。"}, "raw": {}}
{"id": "gh-2026-02-05-4", "source": "github", "date": "2026-02-05", "rank": 4, "title": "bytedance/UI-TARS-desktop", "url": "https://github.com/bytedance/UI-TARS-desktop", "detail_url": "https://github.com/bytedance/UI-TARS-desktop", "description_en": "The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra", "description_zh": "开源多模态人工智能代理架构：连接前沿人工智能模型与代理基础设施。\n\n该项目主要功能是整合多种人工智能模型，支持文本、图像等多种数据形式的处理，旨在为开发者和研究人员提供一个高效的多模态 AI 代理平台。目标用户包括需要构建智能应用的开发者和希望探索 AI 代理技术的学术研究者。核心技术涉及自然语言处理、计算机视觉及深度学习等，特别强调了在多模态信息处理中的应用。", "keywords": ["多模态", "AI Agent", "连接", "模型", "开源", "代理基础设施", "深度学习", "神经网络", "语义搜索", "自主代理"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 2582, "stars_today": 862}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "agent infra"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目整合多模态AI模型，具备一定的自我改进能力，但缺乏明确的用户反馈闭环。技术路径具有非共识判断力，且深度绑定特定场景。商业模式与真实价值绑定较弱，团队背景较为一般。"}, "raw": {}}
{"id": "gh-2026-02-05-5", "source": "github", "date": "2026-02-05", "rank": 5, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件可以自动记录您在编码会话中 Claude 所做的一切，利用 AI（通过 Claude 的 agent-sdk）进行压缩，并将相关上下文注入未来的会话中。该插件的主要功能是提升编码效率和上下文管理，特别适合开发者和程序员在进行复杂项目时使用。核心技术包括 AI 压缩算法和上下文重构能力，旨在优化编程体验和知识传递。", "keywords": ["claude", "agent-sdk", "自动化", "代码插件", "上下文注入", "机器学习", "深度学习", "神经网络", "生成式", "自主代理"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1535, "stars_today": 1899}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 4, "penalty": 0}, "reason": "该项目利用 Claude Code 插件实现上下文注入，具备一定的自我学习能力，提升编码效率。技术路径较为独特，解决了复杂项目中的上下文管理问题。商业模式与高价值用户绑定，但仍需进一步验证。团队背景信息不足。"}, "raw": {}}
{"id": "ph-2026-02-05-1", "source": "producthunt", "date": "2026-02-05", "rank": 1, "title": "CreateOS", "url": "https://www.producthunt.com/products/createos?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/2J6ZEMSMJLCGOA?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "CreateOS is a unified workspace to build, deploy, and scale apps—no DevOps, no tool sprawl. Eliminate complexity and ship faster with an all-in-one workflow built for speed, focus, and product momentum.", "description_zh": "CreateOS 是一个统一的工作空间，旨在构建、部署和扩展应用程序——无需 DevOps 和各种工具的繁杂。它消除了复杂性，让你可以更快地完成任务，提供了一个集成的工作流程，专注于速度、专注力和产品发展。", "keywords": ["机器学习", "深度学习", "神经网络", "生成式", "助手", "嵌入", "语义搜索", "CreateOS", "应用开发", "一体化工作区", "workflow"], "tags": ["Product Hunt"], "metrics": {"votes": 480, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/a1feb16b-580a-4edd-8fd4-2dfc679dd63a.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "workflow"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "CreateOS 提供了一体化的应用开发环境，但缺乏用户数据反馈的闭环，AI 原生程度较低。技术路径较为常见，未能体现明显的非共识判断力。商业模式与高价值用户绑定较强，团队背景较为扎实。"}, "raw": {"tagline": "Build and deploy apps from any AI coding tool, in one place", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-2", "source": "producthunt", "date": "2026-02-05", "rank": 2, "title": "Genstore.ai", "url": "https://www.producthunt.com/products/genstore-ai-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/FZSOVHXQRCUHJY?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Genstore turns a simple prompt into a ready-to-sell store in minutes. AI agents handle product curation, design, and supplier setup so you can test your idea fast. Iterate with built-in AI editors, then let your agents scale operations as you grow. No product. No inventory. No limits.", "description_zh": "Genstore可以将一个简单的提示在几分钟内转化为一个可直接销售的商店。人工智能代理负责产品筛选、设计和供应商设置，让你能够快速测试自己的创意。你可以利用内置的AI编辑工具进行多次迭代，然后让你的代理在你业务增长时扩展操作。无需产品，无需库存，无需限制。", "keywords": ["智能助手", "自主代理", "生成式设计", "深度学习", "产品自迭代", "多代理", "语义搜索", "代理友好工具", "快速迭代", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 376, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e90e620d-8643-4a15-8d63-01046177a7a6.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 22, "tech_niche": 16, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品通过 AI 代理实现快速迭代，具备一定的自我学习能力，但在技术路径和市场壁垒上尚需加强。商业模式与高价值用户绑定较好，团队背景较为扎实。"}, "raw": {"tagline": "Test, iterate, and launch an agentic storefront in minutes", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-3", "source": "producthunt", "date": "2026-02-05", "rank": 3, "title": "Xcode 26.3", "url": "https://www.producthunt.com/products/xcode?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/V3UPPKCPGGKR2D?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Xcode 26.3 introduces support for agentic coding, a new way in Xcode for developers to build apps using coding agents such as Anthropic’s Claude Agent and OpenAI’s Codex. With agentic coding, Xcode can work with greater autonomy toward a developer’s goals — from breaking down tasks to making decisions based on the project architecture and using built-in tools.", "description_zh": "Xcode 26.3引入了“智能编程”的支持，这是一种开发者在Xcode中使用编码助手（如Anthropic的Claude Agent和OpenAI的Codex）来构建应用的新方式。通过智能编程，Xcode可以更自主地朝着开发者的目标前进——从任务分解到根据项目架构做出决策，并利用内置工具进行操作。", "keywords": ["agentic coding", "编程助手", "Claude Agent", "OpenAI Codex", "自主任务处理", "语义搜索", "深度学习", "神经网络"], "tags": ["Product Hunt"], "metrics": {"votes": 319, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/a67460b4-029a-4ad3-af8d-714578eb91bf.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目利用编码代理实现自主任务处理，具备一定的AI原生能力，但缺乏显著的自我进化机制和数据反馈闭环。技术路径较为主流，商业模式与价值绑定较弱，团队背景信息不足。"}, "raw": {"tagline": "Leverage coding agents to tackle complex tasks autonomously", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-4", "source": "producthunt", "date": "2026-02-05", "rank": 4, "title": "Nexuscale AI", "url": "https://www.producthunt.com/products/nexuscale-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/UL6DVNHVUJL7SB?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Stop filtering databases. Nexuscale AI is the first Autonomous Outbound OS. Just paste your website URL, and our Agents research your market, enrich the contacts, and run the entire email & LinkedIn sequence.", "description_zh": "停止过滤数据库！Nexuscale AI 是首款自主外向操作系统。只需粘贴您的网站网址，我们的智能代理会研究您的市场、丰富联系人信息，并自动执行整个电子邮件和 LinkedIn 的沟通流程。", "keywords": ["销售助手", "自动化", "潜在客户", "会议预约", "Nexuscale", "代理人", "市场研究", "联系人丰富", "邮件序列", "LinkedIn序列", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 225, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/4b876ef7-0fb2-4cd6-8df9-e0e30a6beeec.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous", "assistant"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Nexuscale AI 具备一定的 AI 原生能力，但用户反馈和自我学习机制尚不明确。技术路径较为常见，缺乏明显的 niche 壁垒。商业模式与高价值用户绑定良好。团队背景信息不足，未能体现明显的 AI 原生进化能力。"}, "raw": {"tagline": "AI sales assistant that finds leads + books meetings for you", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-5", "source": "producthunt", "date": "2026-02-05", "rank": 5, "title": "Sheetful.co", "url": "https://www.producthunt.com/products/sheetful-co?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/4NSSF4M32T672R?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Turn Google Sheets into a full REST API in seconds. Get GET, POST, PUT, and DELETE endpoints instantly to power apps and sites. No-code, free, and updates in real-time.", "description_zh": "在几秒钟内将谷歌表格变成一个完整的REST API。立即获取GET、POST、PUT和DELETE接口，为应用程序和网站提供支持。无需编码、免费，并且实时更新。", "keywords": ["REST API", "Google Sheets", "无代码", "实时更新", "生成接口", "机器学习", "代理工具", "语义搜索", "任务自动化", "深度学习", "dpo"], "tags": ["Product Hunt"], "metrics": {"votes": 148, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/5dea21c8-6ca6-4ba5-be02-24db8c718283.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["dpo"], "hit_excludes": []}, "score": {"total": 52, "breakdown": {"ai_native": 10, "tech_niche": 15, "business": 12, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目主要是将 Google Sheets 转化为 REST API，缺乏自我学习和进化能力，且没有明显的 AI 原生特征。技术路径较为常见，商业模式与价值绑定一般，团队信息不足。"}, "raw": {"tagline": "Build robust REST APIs with Google Sheets for free", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-6", "source": "producthunt", "date": "2026-02-05", "rank": 6, "title": "Scribeist V2", "url": "https://www.producthunt.com/products/scribeist?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/WJL5BOWZ4WXJHA?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Scribeist has evolved from a blog and research tool into a complete writing platform. We've added two new workspaces: Novel (with character tracking, timelines, and world-building for writers) and General (distraction-free notes). The original Blog workspace now includes enhanced SEO tools and readability metrics. All three workspaces feature project-specific organizational tools, research tools and optional AI writing assistance that is made to understand your selected workspace.", "description_zh": "Scribeist已经从一个博客和研究工具发展成为一个完整的写作平台。我们新增了两个工作区：小说工作区（包含角色跟踪、时间线和世界构建功能，专为作家设计）和通用工作区（提供无干扰的笔记功能）。原来的博客工作区现在也加入了更强大的SEO工具和可读性指标。三个工作区都配备了项目特定的组织工具、研究工具，以及可选的AI写作辅助功能，能够理解您所选择的工作区需求。", "keywords": ["机器学习", "深度学习", "生成式", "助手", "语义搜索", "写作助手", "项目管理", "SEO工具", "写作平台", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 142, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/a406b06e-5b4f-48f7-ae5e-fca16420617a.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 14, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Scribeist V2 提供多种写作工具，但缺乏用户反馈的闭环和自我改进机制，AI 原生程度较低。技术路径和市场定位尚可，但未展现出明显的壁垒。商业模式与价值绑定较好，团队背景一般。"}, "raw": {"tagline": "Write without switching tools", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-7", "source": "producthunt", "date": "2026-02-05", "rank": 7, "title": "Unblocked Code Review", "url": "https://www.producthunt.com/products/unblocked?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/BYG6DIFGTW4DMN?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "AI code review that sees your context, not just your diff. Unblocked draws on context from your whole repo, Slack, Jira, docs, PR history, and more. Every comment moves the conversation forward with cited sources. The result: high-signal comments you'll actually want to implement.", "description_zh": "AI代码审查不仅关注你的代码差异，还能理解你的上下文。Unblocked会从整个代码库、Slack、Jira、文档、PR历史记录等多个来源提取信息。每条评论都有引用来源，推动讨论向前发展。最终的结果是，你会收到高质量的评论，真正值得你去采纳。", "keywords": ["代码审查", "AI 代码评审", "语境理解", "生成评论", "语义搜索", "自动化助手"], "tags": ["Product Hunt"], "metrics": {"votes": 141, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/fed01b74-3731-4121-8573-7332cf7bce92.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在代码审查中利用上下文信息，提升了评论质量，符合AI原生标准。技术路径具有一定复杂性，但缺乏清晰的私有数据飞轮和行业壁垒。商业模式与高价值用户绑定良好，团队背景尚可。"}, "raw": {"tagline": "AI code review that knows when to chime in", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-8", "source": "producthunt", "date": "2026-02-05", "rank": 8, "title": "Postproxy", "url": "https://www.producthunt.com/products/postproxy?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/FM5QGW6HQCI5TM?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Postproxy is a unified publishing API for social networks. Built for developers who automate content at scale. One endpoint, explicit states, built-in retries. And scheduling, of course.", "description_zh": "Postproxy是一个统一的社交网络发布API，专为需要大规模自动化内容的开发者设计。它提供了一个接口，明确状态，内置重试机制，当然还有排程功能。", "keywords": ["自动化发布", "社交网络", "内容管理", "生成内容", "机器学习", "深度学习", "语义搜索", "多代理", "agent-friendly tooling", "proactive ai"], "tags": ["Product Hunt"], "metrics": {"votes": 126, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/9a58bff9-8ec4-404a-8681-982a18023a3c.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["dpo"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "项目提供统一的社交媒体发布API，但缺乏用户数据反馈的闭环和自我改进机制，AI原生程度较低。技术路径选择较为常见，壁垒较弱。商业模式与真实价值绑定一般，团队背景信息不足。"}, "raw": {"tagline": "One API to publish to Instagram, TikTok, Youtube and others", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-9", "source": "producthunt", "date": "2026-02-05", "rank": 9, "title": "Multitui", "url": "https://www.producthunt.com/products/multitui?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/HTSKVUDHRDPDC2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Multitui is a macOS app factory that generates individual terminal apps for TUI programs, with optional sandbox. Create dedicated native apps for claude code, codex, gemini, lazygit, harlequin, or any TUI.", "description_zh": "Multitui 是一款 macOS 应用工厂，它可以为 TUI 程序生成独立的终端应用，并且可以选择开启沙盒模式。你可以为 claude code、codex、gemini、lazygit、harlequin 或者其他任何 TUI 程序创建专属的本地应用。", "keywords": ["机器学习", "深度学习", "神经网络", "chatbot", "语义搜索", "生成式", "多智能体", "代理工作流", "Multitui", "macOS 应用"], "tags": ["Product Hunt"], "metrics": {"votes": 121, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/14594ec3-d02d-4984-9328-2af00d9ca7f3.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 12, "team": 10, "bonus": 7, "penalty": 0}, "reason": "产品具备一定的AI原生特征，但用户反馈和自我学习能力不足；技术路径较为常规，缺乏独特的市场壁垒；商业模式与价值绑定较弱；团队背景信息不足，无法确认其创新能力。"}, "raw": {"tagline": "Sandbox claude code, codex, or any TUI on macOS", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-10", "source": "producthunt", "date": "2026-02-05", "rank": 10, "title": "Ember Mug CLI", "url": "https://www.producthunt.com/products/ember-mug-cli?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/XMBLCPFN7C5GAD?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Ember's mobile app isn't great and I would prefer to see my coffee mug on the screens I am already looking at. Plus now I can put it right next to my Claude Code and it looks great. Submit issues on Github if you find any problems. Feel free to submit a PR too.", "description_zh": "Ember的手机应用体验不太好，我更希望能在我已经在看的屏幕上看到我的咖啡杯。而且现在我可以把它放在我的Claude Code旁边，看起来很棒。如果你发现了什么问题，可以在Github上提交问题反馈，也欢迎提交PR（合并请求）。", "keywords": ["智能助手", "自动化", "聊天机器人", "Ember Mug", "终端控制", "代码集成", "人机交互", "上手简单", "claude"], "tags": ["Product Hunt"], "metrics": {"votes": 108, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/ff1fef73-4c5a-416d-9e9c-b971481628d4.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude"], "hit_excludes": []}, "score": {"total": 54, "breakdown": {"ai_native": 15, "tech_niche": 12, "business": 10, "team": 7, "bonus": 0, "penalty": 0}, "reason": "项目主要是通过终端控制 Ember Mug，缺乏深度的 AI 原生能力和自我进化机制，技术路径较为常规，商业模式与价值绑定较弱，团队信息不足。"}, "raw": {"tagline": "Control your ember mug from the terminal", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-11", "source": "producthunt", "date": "2026-02-05", "rank": 11, "title": "Camzy", "url": "https://www.producthunt.com/products/camzy?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/DGESREUKRVDIFD?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Reviewing TeslaCam footage shouldn’t be a chore. Camzy is built for Tesla owners who need clarity and control. The built-in Tesla player works for quick checks. Camzy goes further: 🎥 6-camera synced playback with driving data 🗺️ Map-based browsing to find clips instantly ⚡ Smart jumps to Sentry and Dashcam events 📦 Batch backup and deletion 💎 Clean exports with timestamp and speed overlays From insurance claims to road trip memories, Camzy makes TeslaCam effortless.", "description_zh": "查看TeslaCam录像不应该是一件麻烦事。Camzy专为需要清晰和控制的特斯拉车主设计。内置的特斯拉播放器可以快速查看录像，而Camzy更进一步：🎥 支持六个摄像头同步回放和驾驶数据 🗺️ 基于地图的浏览方式，轻松找到录像片段 ⚡ 智能跳转到Sentry和行车记录事件 📦 批量备份和删除 💎 干净的导出，带时间戳和速度叠加 从保险索赔到公路旅行的美好回忆，Camzy让使用TeslaCam变得轻而易举。", "keywords": ["深度学习", "机器学习", "神经网络", "生成式", "助手", "语义搜索", "自动驾驶", "智能视频处理", "事件检测", "数据可视化", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 107, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/766c7984-d66f-4fb0-9640-d6c2b8bf02c7.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 64, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Camzy在视频处理和数据叠加方面具备一定的AI能力，但缺乏自我学习和进化的闭环。技术路径较为常见，未体现明显的非共识判断力。商业模式与高价值用户绑定较好，团队背景尚可。"}, "raw": {"tagline": "Export Tesla dashcam video with driving data overlaid", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-12", "source": "producthunt", "date": "2026-02-05", "rank": 12, "title": "SERA", "url": "https://www.producthunt.com/products/allen-institute-of-artificial-intelligence?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/T225RK5DU5CL52?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "SERA is a family of open coding models (8B, 14B, 32B) trained with a new efficient method. SERA learns from \"soft-verified\" data, drastically reducing training costs. Easily adaptable to private codebases. Open weights, data & recipes.", "description_zh": "SERA是一系列开放编码模型（8B、14B、32B），采用了一种全新的高效训练方法。SERA从“软验证”数据中学习，这大大降低了训练成本。此外，它还可以轻松适配私有代码库。该模型的权重、数据和训练方案都是开放的。", "keywords": ["机器学习", "深度学习", "编码助手", "自主代理", "语义搜索", "生成模型", "SERA", "开放模型", "适应性编码", "软验证数据", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 106, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/1426b3c3-9b56-47d0-93a8-ad521c5b45b0.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 22, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "SERA展示了较强的AI原生能力，能够适应不同代码库并进行自我学习。技术路径选择了开源模型，具备良好的市场壁垒。商业模式与高价值用户强绑定，团队背景扎实，具备快速迭代能力。"}, "raw": {"tagline": "Fast, accessible coding agents that adapt to any repo", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-13", "source": "producthunt", "date": "2026-02-05", "rank": 13, "title": "Chord Identifier", "url": "https://www.producthunt.com/products/chord-identifier-2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/RFMQ5T7PXTRT2D?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Chord Identifier is a visually aesthetic and musically accurate music theory companion, designed with visual learners in mind that listens to your real-time MIDI performance and uses a harmonic gravity engine to instantly identify and explain complex harmonies, within their correct musical context. At its core,as the name suggests, is a chord identification tool, you play a stack of notes, and it tells you what chord you are playing, while being context aware of what scale and key you are in.", "description_zh": "和弦识别器是一款既美观又准确的音乐理论助手，特别为视觉学习者设计。它能够实时监听你的MIDI演奏，通过一个和声重力引擎，快速识别并解释复杂的和声，并将其放在正确的音乐背景中。正如名字所示，核心功能是和弦识别工具。当你弹奏一堆音符时，它会告诉你你正在演奏的和弦，同时还会考虑到你所处的音阶和调性。", "keywords": ["和弦识别", "音乐理论", "生成模型", "深度学习", "语义搜索", "实时MIDI", "自主学习", "代理工作流", "音乐上下文", "context"], "tags": ["Product Hunt"], "metrics": {"votes": 101, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/374af7b5-5b46-412a-8ae0-0c5aec2f36e2.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Chord Identifier在和弦识别和音乐理论方面具有一定的AI原生能力，但缺乏明显的自我学习和进化机制。技术路径符合特定领域需求，具备一定的壁垒。商业模式与价值绑定良好，团队背景较强。"}, "raw": {"tagline": "Highlights in‑key notes and flags wrong notes as you play", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-14", "source": "producthunt", "date": "2026-02-05", "rank": 14, "title": "Universal-3 Pro", "url": "https://www.producthunt.com/products/assemblyai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/T5OFLP4IHN57OA?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Universal-3 Pro is a new class of speech language model built for Voice AI. Control transcription using instructions and domain context like names, terminology, and topics to get accurate output at the source. No custom models, no post-processing pipelines, no hallucinations. Includes 1,000 keyterms, audio tagging, and 6-language code-switching for $0.21/hr.", "description_zh": "Universal-3 Pro是一种新型的语音语言模型，专门为语音人工智能（Voice AI）而设计。通过使用指令和领域上下文（例如名称、术语和主题），你可以控制转录过程，从而在源头获得更准确的输出。它不需要自定义模型，也不需要后处理流程，避免了虚假信息的产生。该系统包含1000个关键词、音频标记功能，以及6种语言的切换，价格为每小时0.21美元。", "keywords": ["语音AI", "语言模型", "生成模型", "深度学习", "语义搜索", "语音转录", "指令控制", "自然语言处理", "多语言支持", "关键词提取"], "tags": ["Product Hunt"], "metrics": {"votes": 97, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/e7758fa4-1260-43ff-9fdb-5ab8f31de3f8.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 65, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "该项目在AI原生程度上表现一般，缺乏在线学习和自我改进机制。技术路径选择较为主流，未体现非共识判断力。商业模式与真实价值绑定较弱，团队背景信息不足。"}, "raw": {"tagline": "The first of its kind promptable speech language model", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-15", "source": "producthunt", "date": "2026-02-05", "rank": 15, "title": "Agentset", "url": "https://www.producthunt.com/products/agentset?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/2LRIDZBHHRSQAK?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Open-source RAG infrastructure that survives production workloads. Upload documents, query via API, get answers with sources. Hybrid search, multimodal, complex reasoning - all included. Model-agnostic. Used by 1,500+ teams in medical AI, legal tech, enterprise search.", "description_zh": "一个能够承受生产负载的开源RAG基础设施。你可以上传文档，通过API进行查询，并获取带有来源的答案。它支持混合搜索、多模态处理和复杂推理，功能全面。与模型无关，已经被1500多个团队在医疗AI、法律科技和企业搜索等领域广泛使用。", "keywords": ["生成式搜索", "多模态", "复杂推理", "代理基础设施", "语义搜索", "人工智能助手", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 96, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/7152d327-42be-4949-9ae6-8a1c5267360f.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的AI原生特性，但在自我学习和闭环能力上尚不明确。技术路径具有独特性且与行业需求紧密结合，商业模式与高价值用户强绑定。团队背景较强，整体具备较高的潜力。"}, "raw": {"tagline": "APIs for building AI chat and search", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-16", "source": "producthunt", "date": "2026-02-05", "rank": 16, "title": "Pastey Extension", "url": "https://www.producthunt.com/products/pastey-extension?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/76LSQ6ISY4VKT6?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Pastey reimagines the most used shortcut in history: ⌘+V. We believe AI shouldn't be a separate chat window; it should be woven into your flow. Your clipboard is now context-aware. ✨ Smart Paste: Hold ⌘+V to adapt copied text to the destination (email, code, docs). ✍️ Inline Rewrite: Select text and paste to transform tone instantly. 🧠 Memory: Searchable history + auto-detected 2FA codes. Private & local-first. The upgrade your keys have been waiting for.", "description_zh": "Pastey重新定义了历史上使用最频繁的快捷键：⌘+V。我们相信，人工智能不应该是一个独立的聊天窗口，而应该融入你的工作流程中。现在，你的剪贴板具备了上下文感知能力。✨ 智能粘贴：长按⌘+V，可以将复制的文本自动调整为适合目标内容（如邮件、代码、文档）的格式。✍️ 内联重写：选择文本后粘贴，即可瞬间改变语气。🧠 记忆功能：支持可搜索的历史记录和自动识别的双重身份验证（2FA）代码。私密且优先考虑本地存储。这是你一直在等待的键盘升级。", "keywords": ["智能助手", "语义搜索", "上下文感知", "记忆搜索", "文本粘贴", "自动化工作流", "inline rewrite", "剪贴板AI", "smart paste", "自适应粘贴"], "tags": ["Product Hunt"], "metrics": {"votes": 96, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/28336934-e3c7-41ae-9101-619c6da3c11b.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品在剪贴板功能上引入了AI，但缺乏明显的自我学习和进化机制。技术路径较为常见，未体现出明显的非共识判断力。商业模式与价值绑定较好，团队背景信息不足，未见明显的创新点。"}, "raw": {"tagline": "Keep a library of saved text, paste it in a keystroke", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-17", "source": "producthunt", "date": "2026-02-05", "rank": 17, "title": "Miniloop", "url": "https://www.producthunt.com/products/miniloop?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/QUZQQ4YR6HB427?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Miniloop lets you build AI agents and automations using natural language. Describe what you want to happen, and Miniloop turns it into a live, runnable system with tools, memory, and execution built in. Founders and engineers can iterate faster by skipping glue code, manual wiring, and brittle workflows. Build reliable AI systems that actually run.", "description_zh": "Miniloop 让你可以通过自然语言构建人工智能代理和自动化系统。只需描述你想要实现的功能，Miniloop 就会将其转化为一个实时可运行的系统，内置各种工具、记忆功能和执行机制。创始人和工程师们能够更快地迭代，不再需要繁琐的粘合代码、手动连接和不稳定的工作流程。借助 Miniloop，你可以构建真正可靠的人工智能系统，让它们顺利运行。", "keywords": ["智能助手", "AI代理", "自动化", "自然语言处理", "生成式", "深度学习", "语义搜索", "工作流", "迭代开发", "任务自动化"], "tags": ["Product Hunt"], "metrics": {"votes": 80, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/f47bec52-def0-4600-b627-6000649cf522.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "workflow"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Miniloop 能够通过自然语言构建 AI 代理和自动化，具备较高的 AI 原生程度和自我迭代能力。技术路径选择独特，解决复杂问题，具有较强的 niche 壁垒。商业模式与真实价值绑定，团队背景扎实，具备快速迭代能力。"}, "raw": {"tagline": "Turn natural language into AI agents and automations", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-18", "source": "producthunt", "date": "2026-02-05", "rank": 18, "title": "Beni AI", "url": "https://www.producthunt.com/products/beni-ai-video-call-ai-companion?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/ZNQE2KZWRFXL6O?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Beni AI is a real time, video call first AI companion. Instead of only texting, you can create and video call your AI Companion that responds with voice, motion, and expressions. Beni also builds long term memory adapts over time with you, so your companion stays consistent over time. We’d love feedback on: - Does the call feel natural or uncanny? - What persona do you desire from companion? - What would make you come back daily?", "description_zh": "Beni AI是一款实时视频通话的AI伴侣。与传统的文字聊天不同，你可以通过视频通话与Beni互动，它会用声音、动作和表情来回应你。Beni还具备长期记忆的功能，能够随着时间的推移不断适应你的需求，让这个伴侣保持一致性。我们非常希望听到你的反馈：  \n- 通话的感觉是自然的还是让人感到不适？  \n- 你希望伴侣呈现出怎样的人格特征？  \n- 有哪些因素会让你每天都想回来使用它？", "keywords": ["视频通话", "AI 伴侣", "语音交互", "深度学习", "记忆适应", "生成模型", "语义搜索", "自主代理", "人机交互", "实时反馈"], "tags": ["Product Hunt"], "metrics": {"votes": 74, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/a68856e9-8822-473f-a347-42e7f96a57e8.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Beni AI在用户交互中实现了视频通话和长期记忆，具备一定的自我改进能力，符合AI原生特征。技术路径独特，解决了复杂的人机交互问题，具备行业壁垒。商业模式与用户价值绑定较强，但未能突出高价值用户。团队背景信息不足，进化能力尚可。"}, "raw": {"tagline": "Face to face AI companion calls with voice, motion, memory", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-19", "source": "producthunt", "date": "2026-02-05", "rank": 19, "title": "spacecake", "url": "https://www.producthunt.com/products/spacecake?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/Y2G6GI4E7J4K5A?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Terminals are great for running agents, but terrible for editing markdown. spacecake is an open-source desktop app that supercharges Claude Code with a Notion-style markdown editor and integrated Ghostty terminal. The status bar shows your context window and usage cost ($) in real time, while the tasks panel gives you a live view of what agents are doing and what’s coming next.", "description_zh": "终端非常适合运行智能助手，但在编辑Markdown时却不太理想。Spacecake是一款开源桌面应用，旨在为Claude Code提供强大的支持，配有类似Notion的Markdown编辑器和集成的Ghostty终端。状态栏实时显示你的上下文窗口和使用费用（$），而任务面板则让你可以实时查看智能助手正在做什么，以及接下来会发生什么。", "keywords": ["机器学习", "深度学习", "神经网络", "Claude Code", "代理", "任务面板", "上下文窗口", "视觉编辑器", "主动 AI", "助手"], "tags": ["Product Hunt"], "metrics": {"votes": 72, "featured": "是"}, "media": {"image": "https://ph-files.imgix.net/fa2f2ad7-757b-4b3f-a130-be378eb9cbcd.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品提供了可视化编辑器和实时任务面板，但缺乏用户反馈的自我学习机制，AI 原生程度稍低。技术路径具有独特性，解决了复杂问题，具备一定的行业壁垒。商业模式与真实价值绑定良好，团队背景较强。"}, "raw": {"tagline": "Run Claude Code agents in terminal with a visual editor", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-20", "source": "producthunt", "date": "2026-02-05", "rank": 20, "title": "CFO Studio", "url": "https://www.producthunt.com/products/cfo-studio?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/TVMY3VPOFGZBGE?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "CFO Studio is built on our unique Semantic Model—the data unification layer that guarantees 100% accurate, hallucination-free AI financial intelligence. It's finance infrastructure done right. For Series B-D tech CFOs who dread board reporting and messy data. ✅ Deploy in 9 days. ✅ Consolidate ERP, CRM, billing data. ✅ Get real-time, board-ready insights. ✅ On-premise security. Built by actual finance pros (Big 4, 5+ yrs FPA). Stop guessing at numbers. Start leading with trusted data.", "description_zh": "CFO Studio 基于我们独特的语义模型构建，这是一层数据统一层，确保提供100%准确、无误导的人工智能财务智能。这是正确的财务基础设施，专为那些畏惧董事会报告和混乱数据的B轮至D轮科技公司的首席财务官们设计。✅ 9天内完成部署。✅ 整合企业资源规划（ERP）、客户关系管理（CRM）和账单数据。✅ 获取实时、适合董事会使用的深度洞见。✅ 具备本地安全性。由真正的财务专业人士（来自“四大”，拥有5年以上财务规划与分析经验）打造。别再对数字猜来猜去，开始用可信的数据引领财务决策吧。", "keywords": ["智能财务", "财务智能平台", "语义模型", "数据整合", "实时洞察", "机器学习", "深度学习", "自动化助手", "生成式AI", "代理工作流"], "tags": ["Product Hunt"], "metrics": {"votes": 66, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/b778ef0a-24f2-42f3-999e-4fb2bf654535.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "CFO Studio在AI原生性方面表现一般，缺乏用户数据反馈闭环和自我改进机制。技术路径独特，解决复杂财务问题，具备行业壁垒。商业模式与真实价值绑定较强，团队背景扎实，具备快速迭代能力。"}, "raw": {"tagline": "AI Financial Intelligence Platform. Board-Ready in 9 Days", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-21", "source": "producthunt", "date": "2026-02-05", "rank": 21, "title": "HiringPartner.ai", "url": "https://www.producthunt.com/products/hiringpartner-ai?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/QNIPJFJ7EZQ6SP?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "HiringPartner.ai is an agentic AI hiring platform that reduces ~1,000 candidates to your top ~10 matches in 48 hours. The platform autonomously handles resume screening, voice pre-screens, 24/7 AI interviews, and delivers ranked shortlists with video recordings, transcripts, and competency scores - so you can focus on final hiring decisions, not endless resume reviews.", "description_zh": "HiringPartner.ai 是一个智能招聘平台，可以在48小时内将大约1000名候选人筛选到你最合适的10名。这个平台自动处理简历筛选、语音初筛、全天候的AI面试，并提供带有视频录制、文字稿和能力评分的排名候选名单，让你可以集中精力做出最终的招聘决定，而不必再花时间在无休止的简历审查上。", "keywords": ["招聘助手", "AI 招聘平台", "自动化筛选", "候选人匹配", "语音面试", "职位推荐", "机器学习", "自主代理"], "tags": ["Product Hunt"], "metrics": {"votes": 45, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/86af4988-0064-4636-9916-7ab9e960a0c5.jpeg?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous"], "hit_excludes": []}, "score": {"total": 73, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 15, "team": 10, "bonus": 5, "penalty": 0}, "reason": "该平台具备较强的AI原生程度，用户在使用过程中提供高质量数据反馈，且存在在线学习闭环。技术路径选择了复杂的招聘自动化，构建了私有数据飞轮。商业模式与真实价值紧密绑定，团队具备AI和招聘领域的复合能力。"}, "raw": {"tagline": "AI Recruiter that screens, calls & interviews candidates", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-22", "source": "producthunt", "date": "2026-02-05", "rank": 22, "title": "Get Aman", "url": "https://www.producthunt.com/products/get-aman?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/Y44JQ6LG2VSQRF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Get Aman is the AI salesperson that lives on your website and instantly engages every visitor, like walking into a physical store and being warmly welcomed. It understands your business and converts visitors like a top-performing sales rep.", "description_zh": "Aman是一个智能销售助手，驻扎在您的网站上，能够即时与每位访客互动，就像走进一家实体店时，受到热情的欢迎。它了解您的业务，并能像优秀的销售代表一样，将访客转化为客户。", "keywords": ["销售助手", "网站转化", "自动化销售", "聊天机器人", "人工智能助手", "访客互动", "语义搜索", "生成式对话", "ml"], "tags": ["Product Hunt"], "metrics": {"votes": 43, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/f4fbe799-c721-4563-a1b2-169147681bd6.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品具备一定的 AI 原生特征，但缺乏明显的自我学习闭环。技术路径选择较为常见，未体现明显的非共识判断力。商业模式与价值绑定较好，团队背景信息不足。"}, "raw": {"tagline": "Let your website speak, guide, sell, and convert 10x more", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-23", "source": "producthunt", "date": "2026-02-05", "rank": 23, "title": "Familey", "url": "https://www.producthunt.com/products/familey?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/AM56V4DQWX2GN2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Your family stories deserve more than a general-purpose chat box. Familey is a private archive designed for legacy. Through a few daily questions, turn updates into a permanent shared history. A dedicated space to cultivate a sense of closeness.", "description_zh": "你的家族故事值得拥有一个专属的空间，而不仅仅是一个普通的聊天工具。Familey是一个为传承而设计的私人档案库。通过几道日常问题，让你的生活点滴变成永久的共享历史。这里是一个专注于增进亲密感的空间。", "keywords": ["家族故事", "私人档案", "机器学习", "深度学习", "聊天助手", "语义搜索", "主动智能", "生成式", "多代理", "人机协作", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 30, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/75610ce5-bd9a-433f-bbac-c4d7a3d9f992.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品通过日常问题收集家族故事，具备一定的AI反馈机制，但缺乏明确的自我学习闭环。技术路径较为独特，专注于家族故事的私密性，形成了独特的市场壁垒。商业模式与用户价值紧密相关，团队背景符合要求。"}, "raw": {"tagline": "A dedicated, private space for your family's stories", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-24", "source": "producthunt", "date": "2026-02-05", "rank": 24, "title": "It Works Now", "url": "https://www.producthunt.com/products/it-works-now?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/LEDCWR6U7ZGZPF?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "1926: a 28-page book sells 1.5M copies. The method: write what you want, read it daily. It Works Now adds the missing piece - track what actually happens. The List for what you want (things, experiences). The Money Map for income (net, spendable). Activity Rings for momentum. Intelligence for patterns and blind spots. Paper journal meets digital proof. No hustle theater. No woo. Free to use.", "description_zh": "1926年：一本28页的小书卖出了150万本。它的方法是：写下你想要的东西，每天阅读。这本书《It Works Now》增加了一个重要的环节——追踪实际发生的事情。你可以列出你想要的清单（包括物品和经历），制作一张收入图（净收入和可支配收入），还有活动环（帮助保持积极性），以及智能分析（识别模式和盲点）。纸质日记结合数字记录，不需要花里胡哨的推销，也没有神秘的成分，免费使用。", "keywords": ["智能助手", "机器学习", "深度学习", "生成式", "语义搜索", "模式识别", "活动追踪", "数据分析", "agent"], "tags": ["Product Hunt"], "metrics": {"votes": 18, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/11c57de3-91d6-4f8d-b5e5-83f695577259.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "产品结合了传统方法与数字追踪，具备一定的智能分析能力，但缺乏明显的自我学习和进化机制，技术路径和市场壁垒较弱。"}, "raw": {"tagline": "Write what you want. Track when it happens. It works.", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ph-2026-02-05-25", "source": "producthunt", "date": "2026-02-05", "rank": 25, "title": "Signal", "url": "https://www.producthunt.com/products/signal-5?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "detail_url": "https://www.producthunt.com/r/3AOIQCF6CJL3F2?utm_campaign=producthunt-api&utm_medium=api-v2&utm_source=Application%3A+Agent+%28ID%3A+266065%29", "description_en": "Signal uses multimodal AI to watch millions of sessions, tag them with english prompts, and turn them into metrics and dashboards. You can also chat with your sessions using a deep research interface to find what’s really broken. No custom event instrumentation. No analytics infra to build or maintain.", "description_zh": "Signal利用多模态人工智能监控数百万个会话，并用英文提示为它们打标签，从而转化为指标和仪表盘。你还可以通过深度研究界面与会话进行互动，深入查找真正存在的问题。无需定制事件监测，也不需要搭建或维护分析基础设施。", "keywords": ["产品分析", "多模态AI", "深度学习", "会话分析", "指标仪表盘", "人工智能助手", "生成式分析", "语义搜索", "用户研究", "数据洞察"], "tags": ["Product Hunt"], "metrics": {"votes": 18, "featured": "否"}, "media": {"image": "https://ph-files.imgix.net/2146a2fe-4716-4704-87c8-2cb98b908a00.png?auto=format"}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "Signal具备一定的AI原生能力，能通过用户行为生成数据反馈，但缺乏自我进化机制。技术路径较为独特，解决了复杂的产品分析问题，具备一定的行业壁垒。商业模式与价值绑定较强，团队背景尚可，但未突出。"}, "raw": {"tagline": "AI product analytics engineer", "created_at": "2026年02月04日 PM04:01 (北京时间)"}}
{"id": "ax-2026-02-04-1", "source": "arxiv", "date": "2026-02-04", "rank": 1, "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing", "url": "https://arxiv.org/abs/2602.04837v1", "detail_url": "https://arxiv.org/pdf/2602.04837v1.pdf", "description_en": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.", "description_zh": "提出了一种新颖的群体进化代理（GEA）框架，通过经验共享实现开放式自我改进，显著提升了性能和适应性。", "keywords": ["自我改进", "代理", "经验共享", "进化", "机器学习", "编码基准", "结构设计", "进化单元", "性能提升", "GEA", "agent"], "tags": ["cs.AI"], "metrics": {"authors": ["Zhaotian Weng", "Antonis Antoniades", "Deepak Nathani", "Zhen Zhang", "Xiao Pu", "Xin Eric Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous", "rag"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 20, "business": 15, "team": 10, "bonus": 6, "penalty": 4}, "reason": "GEA框架具备高效的自我改进能力和经验共享，体现出AI原生特征；技术路径独特且解决复杂问题，构建了强大的数据壁垒；商业模式与高价值用户强绑定，具备被大厂收购潜力；团队背景优秀；但由于存在老互联网公司推出的新产品，减分4分。"}, "raw": {"published": "2026-02-04T18:29:36Z", "ai_summary": {"tldr": "提出了一种新颖的群体进化代理（GEA）框架，通过经验共享实现开放式自我改进，显著提升了性能和适应性。", "motivation": "现有自我进化代理受限于预定义架构，无法高效利用探索多样性，因此需要一种新方法以促进自主进化和能力提升。", "method": "GEA将代理视为基本的进化单元，通过群体内的显性经验共享和重用，克服了树状进化结构的局限性。", "conclusion": "GEA在多个编码基准测试中表现优越，能够更有效地将早期探索多样性转化为长期进展，并在不同编码模型中展示出更强的转移性和鲁棒性。"}}}
{"id": "ax-2026-02-04-2", "source": "arxiv", "date": "2026-02-04", "rank": 2, "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis", "url": "https://arxiv.org/abs/2602.04836v1", "detail_url": "https://arxiv.org/pdf/2602.04836v1.pdf", "description_en": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.", "description_zh": "本文质疑AI能力是否呈指数增长，提出现有数据支持的模型与METR报告不同。", "keywords": ["AI能力", "机器学习", "深度学习", "神经网络", "模型评估", "劳动力市场", "安全性问题", "推理能力", "复杂模型", "预测模型"], "tags": ["cs.AI"], "metrics": {"authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 42, "breakdown": {"ai_native": 10, "tech_niche": 12, "business": 8, "team": 6, "bonus": 0, "penalty": 0}, "reason": "项目主要讨论AI能力增长的模型，缺乏AI原生应用和商业模式的具体体现。技术路径和团队背景信息不足，导致评分较低。"}, "raw": {"published": "2026-02-04T18:28:49Z", "ai_summary": {"tldr": "本文质疑AI能力是否呈指数增长，提出现有数据支持的模型与METR报告不同。", "motivation": "随着AI能力的快速提升，理解其增长模式对安全性和劳动力市场具有重要意义。", "method": "本文采用拟合sigmoid曲线的方法，分析AI能力的基础与推理能力，并提出更复杂的模型。", "conclusion": "研究表明AI能力的拐点已过去，未来将表现出不同的增长模式，现有的指数增长预测存在脆弱性。"}}}
{"id": "ax-2026-02-04-3", "source": "arxiv", "date": "2026-02-04", "rank": 3, "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents", "url": "https://arxiv.org/abs/2602.04813v1", "detail_url": "https://arxiv.org/pdf/2602.04813v1.pdf", "description_en": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).", "description_zh": "本文提出了一种七维分类法，用于评估基于大型语言模型的医疗保健代理的能力，揭示了当前文献中的能力不均衡现象。", "keywords": ["智能代理", "大语言模型", "医疗", "知识管理", "交互模式", "自适应学习", "多代理设计", "信息中心能力", "任务规划", "llm"], "tags": ["cs.AI", "cs.CY"], "metrics": {"authors": ["Shubham Vatsal", "Harsh Dubey", "Aditi Singh"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm", "agent", "multi-agent", "workflow"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 4, "penalty": 0}, "reason": "项目提出了七维分类法，具备一定的自我改进能力，且在医疗领域有明确应用场景。但商业模式不够清晰，团队背景信息不足，缺乏明确的市场价值绑定。"}, "raw": {"published": "2026-02-04T17:59:14Z", "ai_summary": {"tldr": "本文提出了一种七维分类法，用于评估基于大型语言模型的医疗保健代理的能力，揭示了当前文献中的能力不均衡现象。", "motivation": "尽管已有研究显示LLM代理在医疗领域的多种任务中表现出色，但缺乏一个统一的框架来系统评估其能力。", "method": "通过回顾49项研究，使用七维分类法对能力进行量化分析，并运用明确的纳入和排除标准及标签规则进行映射。", "conclusion": "分析结果显示，知识管理中的外部知识整合较为常见，而适应与学习中的漂移检测和缓解则极为稀缺，整体上信息中心能力在核心任务中占主导地位。"}}}
{"id": "ax-2026-02-04-4", "source": "arxiv", "date": "2026-02-04", "rank": 4, "title": "CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation", "url": "https://arxiv.org/abs/2602.04856v1", "detail_url": "https://arxiv.org/pdf/2602.04856v1.pdf", "description_en": "From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake news generation, even when a model rejects a harmful request, its Chain-of-Thought (CoT) reasoning may still internally contain and propagate unsafe narratives. To analyze this phenomenon, we introduce a unified safety-analysis framework that systematically deconstructs CoT generation across model layers and evaluates the role of individual attention heads through Jacobian-based spectral metrics. Within this framework, we introduce three interpretable measures: stability, geometry, and energy to quantify how specific attention heads respond or embed deceptive reasoning patterns. Extensive experiments on multiple reasoning-oriented LLMs show that the generation risk rise significantly when the thinking mode is activated, where the critical routing decisions concentrated in only a few contiguous mid-depth layers. By precisely identifying the attention heads responsible for this divergence, our work challenges the assumption that refusal implies safety and provides a new understanding perspective for mitigating latent reasoning risks.", "description_zh": "本研究揭示了大型语言模型在生成假新闻时，即使拒绝有害请求，其思维链推理仍可能传播不安全的叙事。", "keywords": ["生成模型", "大语言模型", "生成新闻", "逻辑推理", "注意力机制", "安全分析", "Chain-of-Thought", "模型层级", "反向传播", "风险评估"], "tags": ["cs.CL"], "metrics": {"authors": ["Zhao Tong", "Chunlin Gong", "Yiping Zhang", "Qiang Liu", "Xingcheng Xu", "Shu Wu", "Haichao Shi", "Xiao-Yu Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目关注大型语言模型的安全性分析，具备一定的技术壁垒和创新性，但缺乏强烈的商业模式和团队背景信息，整体表现中等。"}, "raw": {"published": "2026-02-04T18:43:10Z", "ai_summary": {"tldr": "本研究揭示了大型语言模型在生成假新闻时，即使拒绝有害请求，其思维链推理仍可能传播不安全的叙事。", "motivation": "研究者质疑传统假设，即拒绝响应可以保证整个过程的安全推理，特别是在假新闻生成的背景下。", "method": "提出一个统一的安全分析框架，系统性地解构思维链生成，并通过雅可比谱度量评估个别注意力头的作用，使用稳定性、几何和能量等可解释性度量来量化欺骗性推理模式的嵌入。", "conclusion": "研究表明，思维模式激活时生成风险显著上升，关键的路由决策集中在少数中层，挑战了拒绝即安全的假设，并为减轻潜在推理风险提供了新视角。"}}}
{"id": "ax-2026-02-04-5", "source": "arxiv", "date": "2026-02-04", "rank": 5, "title": "Decomposed Prompting Does Not Fix Knowledge Gaps, But Helps Models Say \"I Don't Know\"", "url": "https://arxiv.org/abs/2602.04853v1", "detail_url": "https://arxiv.org/pdf/2602.04853v1.pdf", "description_en": "Large language models often struggle to recognize their knowledge limits in closed-book question answering, leading to confident hallucinations. While decomposed prompting is typically used to improve accuracy, we investigate its impact on reliability. We evaluate three task-equivalent prompting regimes: Direct, Assistive, and Incremental, across different model scales and multi-hop QA benchmarks. We find that although accuracy gains from decomposition diminish in frontier models, disagreements between prompting regimes remain highly indicative of potential errors. Because factual knowledge is stable while hallucinations are stochastic, cross-regime agreement provides a precise signal of internal uncertainty. We leverage this signal to implement a training-free abstention policy that requires no retrieval or fine-tuning. Our results show that disagreement-based abstention outperforms standard uncertainty baselines as an error detector, improving both F1 and AUROC across settings. This demonstrates that decomposition-based prompting can serve as a practical diagnostic probe for model reliability in closed-book QA.", "description_zh": "分解提示并不能解决知识缺口，但能帮助模型更好地表达不确定性。", "keywords": ["大语言模型", "知识限制", "问答", "提示策略", "准确性", "可靠性", "训练-free", "不确定性", "模型评估", "multi-hop QA", "rag"], "tags": ["cs.CL"], "metrics": {"authors": ["Dhruv Madhwal", "Lyuxin David Zhang", "Dan Roth", "Tomer Wolfson", "Vivek Gupta"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "retrieval"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 14, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "项目关注模型可靠性和不确定性，具备一定的AI原生特征，但缺乏自我进化和闭环能力。技术路径较为常见，未能体现明显的非共识判断力。商业模式与价值绑定不足，团队信息有限。"}, "raw": {"published": "2026-02-04T18:39:58Z", "ai_summary": {"tldr": "分解提示并不能解决知识缺口，但能帮助模型更好地表达不确定性。", "motivation": "大语言模型在闭卷问答中常常无法识别知识的局限性，导致自信的虚构回答，因此需要提高模型的可靠性。", "method": "研究评估了直接、辅助和增量三种任务等效的提示方式，分析其对模型准确性和内部不确定性的影响。", "conclusion": "基于不一致性的拒绝策略在检测错误上优于传统的不确定性基线，证明了分解提示可以作为模型可靠性的有效诊断工具。"}}}
{"id": "ax-2026-02-04-6", "source": "arxiv", "date": "2026-02-04", "rank": 6, "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization", "url": "https://arxiv.org/abs/2602.04811v1", "detail_url": "https://arxiv.org/pdf/2602.04811v1.pdf", "description_en": "True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring \"Closed-Book Training\" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.", "description_zh": "SE-Bench是一个用于评估自我进化与知识内化能力的基准测试环境。", "keywords": ["自我进化", "知识内化", "代理", "终身学习", "训练", "评估", "编码任务", "自我生成任务", "SFT"], "tags": ["cs.CL", "cs.AI", "cs.LG"], "metrics": {"authors": ["Jiarui Yuan", "Tailin Jin", "Weize Chen", "Zeyuan Liu", "Zhiyuan Liu", "Maosong Sun"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "sft"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 7, "penalty": 0}, "reason": "项目展示了自我进化与知识内化的能力，具备良好的闭环学习机制，技术路径独特且具备深度绑定的场景应用。商业模式尚不明确，但有潜力服务高价值用户。团队背景信息不足，未能获得更高分。"}, "raw": {"published": "2026-02-04T17:58:32Z", "ai_summary": {"tldr": "SE-Bench是一个用于评估自我进化与知识内化能力的基准测试环境。", "motivation": "研究旨在解决自我进化能力评估中的知识纠缠和推理复杂性问题。", "method": "通过将NumPy库混淆为伪新包并随机化标识符，训练代理在没有文档的情况下完成编码任务。", "conclusion": "研究发现关闭书本训练更有效，标准强化学习无法完全内化新知识，而自我对弈结合SFT能够促进内化。"}}}
{"id": "ax-2026-02-04-7", "source": "arxiv", "date": "2026-02-04", "rank": 7, "title": "CoWTracker: Tracking by Warping instead of Correlation", "url": "https://arxiv.org/abs/2602.04877v1", "detail_url": "https://arxiv.org/pdf/2602.04877v1.pdf", "description_en": "Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \\method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.", "description_zh": "提出了一种新的稠密点跟踪器CoWTracker，通过变形而非相关性匹配来提高效率和性能。", "keywords": ["深度学习", "计算机视觉", "变换器", "特征匹配", "光流估计", "dense point tracking", "spatiotemporal reasoning", "optical flow", "轨迹估计", "transformer"], "tags": ["cs.CV"], "metrics": {"authors": ["Zihang Lai", "Eldar Insafutdinov", "Edgar Sucar", "Andrea Vedaldi"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["transformer"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目在稠密点跟踪领域提出了新方法，具备一定的技术壁垒，但缺乏明确的商业模式和团队背景信息。"}, "raw": {"published": "2026-02-04T18:58:59Z", "ai_summary": {"tldr": "提出了一种新的稠密点跟踪器CoWTracker，通过变形而非相关性匹配来提高效率和性能。", "motivation": "现有的稠密点跟踪方法依赖于成本体积，导致在空间分辨率下的复杂度过高，限制了其可扩展性和效率。", "method": "CoWTracker通过基于当前估计的变形来迭代精炼轨迹估计，并结合变压器架构进行联合时空推理，以建立长距离对应关系。", "conclusion": "该模型在标准稠密点跟踪基准上表现优异，同时在光流估计方面也超过了一些专门的方法，显示了变形架构在这两个领域的统一潜力。"}}}
{"id": "ax-2026-02-04-8", "source": "arxiv", "date": "2026-02-04", "rank": 8, "title": "PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation", "url": "https://arxiv.org/abs/2602.04876v1", "detail_url": "https://arxiv.org/pdf/2602.04876v1.pdf", "description_en": "We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.", "description_zh": "PerpetualWonder是一个混合生成模拟器，可以从单张图像生成长期、基于动作的4D场景。", "keywords": ["生成模型", "生成模拟器", "长期预测", "4D场景生成", "物理状态", "视觉表示", "反馈机制", "多视角监督", "人机交互", "generative"], "tags": ["cs.CV"], "metrics": {"authors": ["Jiahao Zhan", "Zizhang Li", "Hong-Xing Yu", "Jiajun Wu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "PerpetualWonder具备闭环系统和自我优化能力，用户反馈自然生成高质量数据，技术路径独特且复杂，商业模式尚需明确，团队背景信息不足。"}, "raw": {"published": "2026-02-04T18:58:55Z", "ai_summary": {"tldr": "PerpetualWonder是一个混合生成模拟器，可以从单张图像生成长期、基于动作的4D场景。", "motivation": "现有方法无法实现长期的、基于动作的场景生成，因为物理状态与视觉表现脱节，影响后续交互的生成优化。", "method": "PerpetualWonder引入了首个真正的闭环系统，采用统一表示法建立物理状态与视觉原始元素之间的双向联系，并通过多视角监督机制解决优化模糊性。", "conclusion": "实验表明，PerpetualWonder能够从单一图像成功模拟复杂的多步交互，保持物理合理性和视觉一致性。"}}}
{"id": "ax-2026-02-04-9", "source": "arxiv", "date": "2026-02-04", "rank": 9, "title": "LitS: A novel Neighborhood Descriptor for Point Clouds", "url": "https://arxiv.org/abs/2602.04838v1", "detail_url": "https://arxiv.org/pdf/2602.04838v1.pdf", "description_en": "With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.", "description_zh": "本文提出了一种新颖的邻域描述符LitS，用于准确表征点云的局部几何特征。", "keywords": ["点云", "邻域描述符", "3D扫描", "几何特征", "LitS", "机器学习", "深度学习", "语义搜索", "自适应算法", "数据分析", "rag"], "tags": ["cs.CV"], "metrics": {"authors": ["Jonatan B. Bastos", "Francisco F. Rivera", "Oscar G. Lorenzo", "David L. Vilariño", "José C. Cabaleiro", "Alberto M. Esmorís", "Tomás F. Pena"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag", "context"], "hit_excludes": []}, "score": {"total": 58, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 10, "team": 5, "bonus": 0, "penalty": 0}, "reason": "该项目提出了新颖的邻域描述符LitS，具有一定的技术创新性，但缺乏明确的商业模式和团队背景信息，影响了整体评分。"}, "raw": {"published": "2026-02-04T18:31:02Z", "ai_summary": {"tldr": "本文提出了一种新颖的邻域描述符LitS，用于准确表征点云的局部几何特征。", "motivation": "随着3D扫描技术的发展，点云在多个科学和技术领域中变得至关重要，分析这些数据需要有效的邻域描述符。", "method": "LitS是单位圆上的分段常数函数，能够记录点的周围环境，并通过评估特定方向的信息来捕捉邻域特征。", "conclusion": "LitS是一种灵活的邻域描述符，适应多种点云类型，并能有效处理常见的数据问题，如密度变化和噪声。"}}}
{"id": "ax-2026-02-04-10", "source": "arxiv", "date": "2026-02-04", "rank": 10, "title": "Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization", "url": "https://arxiv.org/abs/2602.04820v1", "detail_url": "https://arxiv.org/pdf/2602.04820v1.pdf", "description_en": "Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.", "description_zh": "本文提出了一种基于机器学习的指甲疾病分类模型，通过对抗训练和SHAP可视化提升准确性和可解释性。", "keywords": ["机器学习", "深度学习", "卷积神经网络", "视觉分类", "对抗训练", "Grad-CAM", "自动化诊断", "医学图像分析", "特征重要性", "machine learning"], "tags": ["cs.CV", "cs.AI", "cs.LG"], "metrics": {"authors": ["Farzia Hossain", "Samanta Ghosh", "Shahida Begum", "B. M. Shahria Alam", "Mohammad Tahmid Noor", "Md Parvez Mia", "Nishat Tasnim Niloy"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "rag"], "hit_excludes": []}, "score": {"total": 52, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 10, "team": 5, "bonus": 0, "penalty": 0}, "reason": "项目基于机器学习进行指甲疾病分类，具备一定的AI原生程度，使用对抗训练提升模型鲁棒性，但缺乏在线学习和自我改进的闭环；技术路径较为常见，未体现明显的非共识判断力；商业模式不够清晰，团队背景信息不足，整体发展潜力有限。"}, "raw": {"published": "2026-02-04T18:08:13Z", "ai_summary": {"tldr": "本文提出了一种基于机器学习的指甲疾病分类模型，通过对抗训练和SHAP可视化提升准确性和可解释性。", "motivation": "人类指甲疾病在各年龄段普遍存在，早期检测与准确诊断对健康至关重要，但由于疾病类型间的视觉差异，分类任务具有挑战性。", "method": "研究中使用了四种CNN模型进行训练和评估，并在此基础上采用对抗训练增强模型鲁棒性，同时利用SHAP可视化重要特征以增加模型的可解释性。", "conclusion": "InceptionV3模型在所有测试中表现最佳，准确率达到95.57%，该系统可为医生提供有效支持，提高指甲疾病的诊断效率和准确性。"}}}
{"id": "ax-2026-02-04-11", "source": "arxiv", "date": "2026-02-04", "rank": 11, "title": "XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas", "url": "https://arxiv.org/abs/2602.04819v1", "detail_url": "https://arxiv.org/pdf/2602.04819v1.pdf", "description_en": "Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.", "description_zh": "XtraLight-MedMamba是一种超轻量级深度学习框架，能高效分类肿瘤性管腺瘤，准确率达97.18%。", "keywords": ["深度学习", "机器学习", "神经网络", "图像分类", "低级别腺瘤", "风险分层", "数字病理", "特征提取", "多尺度特征", "deep learning"], "tags": ["cs.CV", "cs.LG"], "metrics": {"authors": ["Aqsa Sultana", "Rayan Afsar", "Ahmed Rahu", "Surendra P. Singh", "Brian Shula", "Brandon Combs", "Derrick Forchetti", "Vijayan K. Asari"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "transformer"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "XtraLight-MedMamba在深度学习框架中具备较高的自我学习和改进能力，且解决了复杂的医学图像分类问题，具有较强的行业壁垒。商业模式与高价值用户的需求紧密结合，但缺乏明确的退出策略。"}, "raw": {"published": "2026-02-04T18:07:51Z", "ai_summary": {"tldr": "XtraLight-MedMamba是一种超轻量级深度学习框架，能高效分类肿瘤性管腺瘤，准确率达97.18%。", "motivation": "在常规结肠镜筛查中，准确评估前癌性息肉的风险对于降低结直肠癌风险至关重要，但低级别异型增生的主观病理评估仍存在局限。", "method": "本研究提出XtraLight-MedMamba框架，结合ConvNext浅层特征提取器与并行视觉Mamba，有效建模长短距离依赖，集成空间和通道注意力模块以增强多尺度特征提取。", "conclusion": "XtraLight-MedMamba在低级别管腺瘤数据集上的表现优于变压器和传统Mamba架构，显示出更高的准确性和更少的参数使用。"}}}
{"id": "ax-2026-02-04-12", "source": "arxiv", "date": "2026-02-04", "rank": 12, "title": "X2HDR: HDR Image Generation in a Perceptually Uniform Space", "url": "https://arxiv.org/abs/2602.04814v1", "detail_url": "https://arxiv.org/pdf/2602.04814v1.pdf", "description_en": "High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing pretrained diffusion models can be easily adapted to HDR generation without retraining from scratch. A key challenge is that HDR images are natively represented in linear RGB, whose intensity and color statistics differ substantially from those of sRGB-encoded LDR images. This gap, however, can be effectively bridged by converting HDR inputs into perceptually uniform encodings (e.g., using PU21 or PQ). Empirically, we find that LDR-pretrained variational autoencoders (VAEs) reconstruct PU21-encoded HDR inputs with fidelity comparable to LDR data, whereas linear RGB inputs cause severe degradations. Motivated by this finding, we describe an efficient adaptation strategy that freezes the VAE and finetunes only the denoiser via low-rank adaptation in a perceptually uniform space. This results in a unified computational method that supports both text-to-HDR synthesis and single-image RAW-to-HDR reconstruction. Experiments demonstrate that our perceptually encoded adaptation consistently improves perceptual fidelity, text-image alignment, and effective dynamic range, relative to previous techniques.", "description_zh": "本研究提出了一种通过感知统一空间实现HDR图像生成的新方法，能有效提高HDR生成的视觉保真度。", "keywords": ["生成图像", "高动态范围", "预训练模型", "视觉感知", "低秩适应", "图像重建", "生成对抗网络", "变分自编码器", "perceptually uniform encoding", "diffusion"], "tags": ["cs.CV", "cs.GR"], "metrics": {"authors": ["Ronghuan Wu", "Wanchao Su", "Kede Ma", "Jing Liao", "Rafał K. Mantiuk"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 6, "bonus": 0, "penalty": 0}, "reason": "该项目在HDR图像生成上有创新方法，但缺乏用户交互和商业模式的明确性，技术路径虽有独特性但未形成强壁垒。"}, "raw": {"published": "2026-02-04T17:59:51Z", "ai_summary": {"tldr": "本研究提出了一种通过感知统一空间实现HDR图像生成的新方法，能有效提高HDR生成的视觉保真度。", "motivation": "随着HDR格式和显示屏的普及，现有图像生成模型在HDR生成上受到大规模训练数据的限制，因此需要一种有效的适应策略。", "method": "通过将HDR输入转换为感知统一编码（如PU21或PQ），冻结变分自编码器（VAE），并仅微调去噪器，从而实现LDR预训练模型的HDR生成适应。", "conclusion": "实验表明，所提出的方法在感知保真度、文本与图像对齐及有效动态范围方面均优于之前的技术。"}}}
{"id": "ax-2026-02-04-13", "source": "arxiv", "date": "2026-02-04", "rank": 13, "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention", "url": "https://arxiv.org/abs/2602.04789v1", "detail_url": "https://arxiv.org/pdf/2602.04789v1.pdf", "description_en": "Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \\textsc{Light Forcing}, the \\textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \\textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \\textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\\eg, 84.5 on VBench) and efficiency (\\eg, $1.2{\\sim}1.3\\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \\textsc{Light Forcing} further achieves a $2.3\\times$ speedup and 19.7\\,FPS on an RTX~5090 GPU. Code will be released at \\href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.", "description_zh": "提出了一种名为Light Forcing的稀疏注意力机制，以提升自回归视频生成模型的效率和质量。", "keywords": ["稀疏注意力", "自回归视频生成", "生成模型", "机器学习", "深度学习", "神经网络", "结构化稀疏", "逐层掩码选择", "速度提升", "FP8量化", "diffusion"], "tags": ["cs.CV"], "metrics": {"authors": ["Chengtao Lv", "Yumeng Shi", "Yushi Huang", "Ruihao Gong", "Shen Ren", "Wenya Wang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "diffusion", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出了针对自回归视频生成的新稀疏注意力机制，具备良好的自我改进能力和高效的生成质量，符合AI原生标准。技术路径具有独特性，解决了复杂问题，商业模式与用户价值紧密结合。"}, "raw": {"published": "2026-02-04T17:41:53Z", "ai_summary": {"tldr": "提出了一种名为Light Forcing的稀疏注意力机制，以提升自回归视频生成模型的效率和质量。", "motivation": "现有的稀疏注意力解决方案在自回归模型中表现不佳，主要由于对生成块的孤立考虑和未充分利用过去信息的上下文。", "method": "Light Forcing引入了块感知增长机制和分层稀疏注意力策略，以定量估计每块的贡献并在生成过程中继承先前的知识。", "conclusion": "实验结果表明，Light Forcing在生成质量和效率上均优于现有稀疏注意力方法，并在RTX 5090 GPU上实现了显著的速度提升。"}}}
{"id": "ax-2026-02-04-14", "source": "arxiv", "date": "2026-02-04", "rank": 14, "title": "Protein Autoregressive Modeling via Multiscale Structure Generation", "url": "https://arxiv.org/abs/2602.04883v1", "detail_url": "https://arxiv.org/pdf/2602.04883v1.pdf", "description_en": "We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.", "description_zh": "提出了一种名为蛋白质自回归建模（PAR）的多尺度框架，用于蛋白质骨架的生成，能够有效缓解生成过程中的曝光偏差问题。", "keywords": ["蛋白质", "自回归模型", "多尺度", "生成", "变换器", "结构生成", "条件嵌入", "训练", "生成质量", "无监督学习", "transformer"], "tags": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "metrics": {"authors": ["Yanru Qu", "Cheng-Yen Hsieh", "Zaixiang Zheng", "Ge Liu", "Quanquan Gu"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer", "embedding", "context"], "hit_excludes": []}, "score": {"total": 72, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "PAR框架具备多尺度自回归建模能力，能够有效生成蛋白质结构，且展现出强大的零-shot 泛化能力，符合AI原生要求。技术路径独特，解决复杂问题，具备行业壁垒。商业模式与高价值用户紧密结合，团队背景强大。"}, "raw": {"published": "2026-02-04T18:59:49Z", "ai_summary": {"tldr": "提出了一种名为蛋白质自回归建模（PAR）的多尺度框架，用于蛋白质骨架的生成，能够有效缓解生成过程中的曝光偏差问题。", "motivation": "蛋白质结构生成的准确性和灵活性对于生物学和药物设计至关重要，因此需要一种新的框架来提升结构生成的质量和泛化能力。", "method": "PAR框架通过多尺度下采样、基于自回归的变换器和流式解码器来实现蛋白质骨架的生成，同时采用噪声上下文学习和调度采样来克服曝光偏差。", "conclusion": "PAR在无条件生成基准测试中表现出色，能够学习蛋白质分布并生成高质量的骨架，展示出强大的零-shot 泛化能力，适用于人类提示的条件生成。"}}}
{"id": "ax-2026-02-04-15", "source": "arxiv", "date": "2026-02-04", "rank": 15, "title": "Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism", "url": "https://arxiv.org/abs/2602.04870v1", "detail_url": "https://arxiv.org/pdf/2602.04870v1.pdf", "description_en": "Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.", "description_zh": "提出了一种新架构Multi-Head LatentMoE和Head Parallel，显著降低了稀疏专家模型的通信成本和不平衡问题，同时加速训练。", "keywords": ["多头", "LatentMoE", "MoE", "专家并行", "训练加速", "稀疏混合专家", "负载均衡", "确定性通信", "语义搜索", "深度学习", "agent"], "tags": ["cs.LG"], "metrics": {"authors": ["Chenwei Cui", "Rockwell Jackson", "Benjamin Joseph Herrera", "Ana María Tárano", "Hannah Kerner"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该项目提出的新架构显著降低了MoE模型的通信成本，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，导致评分略低。"}, "raw": {"published": "2026-02-04T18:57:19Z", "ai_summary": {"tldr": "提出了一种新架构Multi-Head LatentMoE和Head Parallel，显著降低了稀疏专家模型的通信成本和不平衡问题，同时加速训练。", "motivation": "大型语言模型训练成本高，稀疏Mixture of Experts (MoE)通过条件计算来解决这一问题，但现有的专家并行方法存在通信成本和负载不平衡等限制。", "method": "提出了Multi-Head LatentMoE和Head Parallel架构，实现了与激活专家数量无关的O(1)通信成本，采用IO感知路由和专家计算加速训练。", "conclusion": "与专家并行的MoE相比，Multi-Head LatentMoE和Head Parallel训练速度提高了1.61倍，且在性能上保持一致，使多亿参数基础模型的研究更加可及。"}}}
{"id": "ax-2026-02-04-16", "source": "arxiv", "date": "2026-02-04", "rank": 16, "title": "CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation", "url": "https://arxiv.org/abs/2602.04868v1", "detail_url": "https://arxiv.org/pdf/2602.04868v1.pdf", "description_en": "Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.", "description_zh": "CRoSS是一个新颖的持续强化学习基准套件，专为多任务和真实物理模拟的机器人而设计。", "keywords": ["持续学习", "强化学习", "机器人模拟", "任务多样性", "Gazebo", "代理", "深度学习", "控制算法", "kinematics", "物理仿真", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Yannick Denker", "Alexander Gepperth"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 14, "team": 10, "bonus": 4, "penalty": 0}, "reason": "CRoSS展示了高任务多样性和真实物理模拟的能力，具备自我改进的潜力。技术路径独特，解决复杂问题，具备深度绑定的行业应用。商业模式与高价值用户需求紧密结合，团队背景强大，具备快速迭代能力。"}, "raw": {"published": "2026-02-04T18:54:26Z", "ai_summary": {"tldr": "CRoSS是一个新颖的持续强化学习基准套件，专为多任务和真实物理模拟的机器人而设计。", "motivation": "持续强化学习需要智能体在学习新任务的同时保持对已学策略的记忆，因此需要一个高任务多样性和真实物理模拟的基准。", "method": "CRoSS基于Gazebo模拟器，利用两种机器人平台（差动驱动机器人和七关节机械臂）进行多种任务的评估，并提供了易于扩展的容器化设置以确保可复现性。", "conclusion": "CRoSS作为一个可扩展且可复现的基准，适合用于机器人领域的持续强化学习研究，支持多种传感器的使用。"}}}
{"id": "ax-2026-02-04-17", "source": "arxiv", "date": "2026-02-04", "rank": 17, "title": "Subliminal Effects in Your Data: A General Mechanism via Log-Linearity", "url": "https://arxiv.org/abs/2602.04863v1", "detail_url": "https://arxiv.org/pdf/2602.04863v1.pdf", "description_en": "Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.   We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.", "description_zh": "该论文提出了一种通过Logit-Linear-Selection方法揭示数据集中隐含的潜在效应的机制，进而影响大型语言模型的行为。", "keywords": ["潜在效应", "数据集", "大语言模型", "LLM", "Logit-Linear-Selection", "隐藏效果", "训练方法", "模型行为", "数据选择", "语言响应"], "tags": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "metrics": {"authors": ["Ishaq Aden-Ali", "Noah Golowich", "Allen Liu", "Abhishek Shetty", "Ankur Moitra", "Nika Haghtalab"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "llm"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "该项目提出了数据集对模型行为的潜在影响机制，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，整体上较为学术化，未能完全体现出 AI Native 的特征。"}, "raw": {"published": "2026-02-04T18:50:46Z", "ai_summary": {"tldr": "该论文提出了一种通过Logit-Linear-Selection方法揭示数据集中隐含的潜在效应的机制，进而影响大型语言模型的行为。", "motivation": "随着大型语言模型（LLM）训练的复杂性增加，理解数据集对模型属性的影响变得至关重要，尤其是在数据集传递不可直接观察信号的情况下。", "method": "引入Logit-Linear-Selection（LLS）方法，以选择通用偏好数据集的子集，从而发现数据集中潜在的隐含效应。", "conclusion": "所提出的方法在不同模型架构上均能保持其效果，证明了其普遍性和广泛适用性。"}}}
{"id": "ax-2026-02-04-18", "source": "arxiv", "date": "2026-02-04", "rank": 18, "title": "From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures", "url": "https://arxiv.org/abs/2602.04861v1", "detail_url": "https://arxiv.org/pdf/2602.04861v1.pdf", "description_en": "Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an \"in-the-loop\" model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.", "description_zh": "论文提出了一种新的评估指标BSCT，旨在通过检测量子势能面光滑性来指导机器学习原子间势的设计与优化。", "keywords": ["机器学习", "量子势能面", "深度学习", "变换器", "模型设计", "迭代优化", "分子动力学", "平滑性评估", "物理挑战", "machine learning"], "tags": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "metrics": {"authors": ["Ryan Liu", "Eric Qu", "Tobias Kreiman", "Samuel M. Blau", "Aditi S. Krishnapriyan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "transformer"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 4, "penalty": 0}, "reason": "项目提出了新的评估指标BSCT，推动机器学习原子间势的设计与优化，具备一定的原生AI特性。技术路径独特，解决了复杂问题，但商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T18:50:10Z", "ai_summary": {"tldr": "论文提出了一种新的评估指标BSCT，旨在通过检测量子势能面光滑性来指导机器学习原子间势的设计与优化。", "motivation": "现有的机器学习原子间势评估方法效率低且主要集中在平衡态，导致无法有效捕捉潜在的物理问题。", "method": "提出的BSCT通过控制键变形来探测势能面光滑性，能够有效识别不连续性、人工极小值和虚假力，同时成本远低于传统的分子动力学模拟。", "conclusion": "通过基于BSCT的系统优化，所设计的机器学习模型不仅降低了传统的能量/力回归误差，还实现了稳定的分子动力学模拟和可靠的原子性质预测，证明了BSCT在模型设计中的重要性。"}}}
{"id": "ax-2026-02-04-19", "source": "arxiv", "date": "2026-02-04", "rank": 19, "title": "The Key to State Reduction in Linear Attention: A Rank-based Perspective", "url": "https://arxiv.org/abs/2602.04852v1", "detail_url": "https://arxiv.org/pdf/2602.04852v1.pdf", "description_en": "Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.", "description_zh": "本文提出了一种基于秩的线性注意力状态简化方法，通过结构性修剪和理论分析，显著减少模型状态大小，同时保持性能。", "keywords": ["线性注意力", "低秩结构", "检索误差", "硬件感知", "结构化剪枝", "CUDA", "QR分解", "模型压缩", "性能优化", "retrieval"], "tags": ["cs.LG"], "metrics": {"authors": ["Philipp Nazari", "T. Konstantin Rusch"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "retrieval"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 20, "tech_niche": 15, "business": 10, "team": 5, "bonus": 0, "penalty": 0}, "reason": "项目提出了线性注意力的状态简化方法，但缺乏用户交互和反馈机制，未形成闭环自我改进；技术路径有一定创新性，但未能展示强大的行业壁垒；商业模式不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T18:39:38Z", "ai_summary": {"tldr": "本文提出了一种基于秩的线性注意力状态简化方法，通过结构性修剪和理论分析，显著减少模型状态大小，同时保持性能。", "motivation": "线性注意力模型的训练状态常表现出低秩结构，表明其未充分利用模型容量，导致检索错误增加。", "method": "提出了一种新颖的硬件感知方法，通过结构性修剪关键和查询矩阵，结合基于秩揭示QR分解的结构化修剪策略。", "conclusion": "实验结果表明，该框架能够在仅轻微增加困惑度的情况下，去除50%的查询和关键通道，提升模型效率。"}}}
{"id": "ax-2026-02-04-20", "source": "arxiv", "date": "2026-02-04", "rank": 20, "title": "Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning", "url": "https://arxiv.org/abs/2602.04821v1", "detail_url": "https://arxiv.org/pdf/2602.04821v1.pdf", "description_en": "Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\\% coverage efficiency, controls FDR at 4.1\\% under verified dependence, and improves safety rate to 95.2\\% compared to 69\\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.", "description_zh": "本文提出了一种名为STREAM-RL的城市交通控制框架，利用不确定性感知的预测和强化学习提高交通管理的安全性和效率。", "keywords": ["城市交通管理", "不确定性预测", "强化学习", "流网络", "安全控制", "预测不确定性", "自适应模型", "anomaly detection", "STREAM-RL", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Joydeep Chandra", "Satyam Kumar Navneet", "Aleksandr Algazinov", "Yong Zhang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "rag"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 0, "penalty": 0}, "reason": "该项目在AI原生程度上表现突出，具备自我改进和闭环能力，技术路径独特且难以替代，但商业模式尚不明确，缺乏高价值用户的强绑定。"}, "raw": {"published": "2026-02-04T18:10:59Z", "ai_summary": {"tldr": "本文提出了一种名为STREAM-RL的城市交通控制框架，利用不确定性感知的预测和强化学习提高交通管理的安全性和效率。", "motivation": "城市交通管理需要能够预测未来状况、检测异常并采取安全措施的系统，同时提供可靠性保证。", "method": "STREAM-RL框架结合了三种新算法，分别是基于不确定性的自适应符合预测、符合残差流网络和不确定性引导的安全世界模型强化学习代理。", "conclusion": "实验结果表明，STREAM-RL在覆盖效率、安全率和奖励上均优于传统方法，展示了其在真实交通数据中的有效性。"}}}
{"id": "ax-2026-02-04-21", "source": "arxiv", "date": "2026-02-04", "rank": 21, "title": "Beyond Rewards in Reinforcement Learning for Cyber Defence", "url": "https://arxiv.org/abs/2602.04809v1", "detail_url": "https://arxiv.org/pdf/2602.04809v1.pdf", "description_en": "Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.", "description_zh": "本文探讨了稀疏奖励在网络防御中的应用，表明其比密集奖励更能有效训练安全代理并降低风险。", "keywords": ["深度学习", "强化学习", "自主代理", "网络防御", "奖励函数", "稀疏奖励", "政策梯度", "行为特征", "网络安全", "复杂环境", "agent"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Elizabeth Bates", "Chris Hicks", "Vasilios Mavroudis"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "autonomous"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 12, "team": 10, "bonus": 5, "penalty": 0}, "reason": "项目在稀疏奖励的应用上具有创新性，能有效提升网络防御能力，体现出较强的AI原生程度和技术壁垒，但商业模式和团队信息不足，导致分数略低。"}, "raw": {"published": "2026-02-04T17:55:23Z", "ai_summary": {"tldr": "本文探讨了稀疏奖励在网络防御中的应用，表明其比密集奖励更能有效训练安全代理并降低风险。", "motivation": "随着自动化网络防御代理的兴起，研究如何优化奖励函数以提升安全性和有效性变得尤为重要。", "method": "通过对不同奖励函数的结构进行评估，结合多种网络环境和RL算法，使用创新的真实性评估方法进行比较。", "conclusion": "稀疏奖励在目标对齐和频繁遭遇的情况下，不仅提高了训练的可靠性，还能够生成更符合网络防御目标的低风险策略。"}}}
{"id": "ax-2026-02-04-22", "source": "arxiv", "date": "2026-02-04", "rank": 22, "title": "Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning", "url": "https://arxiv.org/abs/2602.04807v1", "detail_url": "https://arxiv.org/pdf/2602.04807v1.pdf", "description_en": "We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.", "description_zh": "本论文提出了一种生物启发的Afferent学习框架，通过适应性内部风险信号促进损伤避免学习。", "keywords": ["生物启发模型", "适应性", "风险信号", "强化学习", "进化优化", "计算性传入轨迹", "政策学习", "生物机械数字双胞胎", "age-robustness", "damage-avoidance", "context"], "tags": ["cs.LG"], "metrics": {"authors": ["Wolfgang Maass", "Sabine Janzen", "Prajvi Saxena", "Sach Mukherjee"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "context"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目展示了生物启发的学习框架，具备一定的自我改进能力，但缺乏明确的商业模式和团队背景信息，导致整体评分较低。"}, "raw": {"published": "2026-02-04T17:53:28Z", "ai_summary": {"tldr": "本论文提出了一种生物启发的Afferent学习框架，通过适应性内部风险信号促进损伤避免学习。", "motivation": "研究旨在通过生物系统的启发，提升损伤避免学习的效率和适应性。", "method": "该框架采用两级架构，外层通过进化优化发现有效的感知架构，内层使用强化学习训练损伤避免策略。", "conclusion": "CAT基于进化的架构在效率和年龄鲁棒性上显著优于手工设计的基线，且能够实现年龄依赖的行为适应。"}}}
{"id": "ax-2026-02-04-23", "source": "arxiv", "date": "2026-02-04", "rank": 23, "title": "Maximum-Volume Nonnegative Matrix Factorization", "url": "https://arxiv.org/abs/2602.04795v1", "detail_url": "https://arxiv.org/pdf/2602.04795v1.pdf", "description_en": "Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.", "description_zh": "本文提出了一种新的非负矩阵分解方法——最大体积非负矩阵分解（MaxVol NMF），通过最大化矩阵H的体积来提高稀疏分解的效果。", "keywords": ["非负矩阵分解", "数据嵌入", "机器学习", "稀疏分解", "聚类", "MaxVol NMF", "最小体积 NMF", "噪声处理", "超光谱解混合", "embedding"], "tags": ["cs.LG", "eess.SP", "math.NA", "stat.ML"], "metrics": {"authors": ["Olivier Vu Thanh", "Nicolas Gillis"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "embedding", "context"], "hit_excludes": []}, "score": {"total": 60, "breakdown": {"ai_native": 15, "tech_niche": 18, "business": 12, "team": 10, "bonus": 0, "penalty": 0}, "reason": "项目提出了一种新方法，但缺乏用户交互和自我改进机制，未能完全体现AI原生能力。技术路径有一定创新性，但未显示出明显的行业壁垒。商业模式和团队背景信息不足，整体发展潜力有限。"}, "raw": {"published": "2026-02-04T17:43:25Z", "ai_summary": {"tldr": "本文提出了一种新的非负矩阵分解方法——最大体积非负矩阵分解（MaxVol NMF），通过最大化矩阵H的体积来提高稀疏分解的效果。", "motivation": "传统的最小体积非负矩阵分解（MinVol NMF）在噪声环境下表现不佳，因此需要探索新的方法以提供更稳定和可解释的解决方案。", "method": "提出了MaxVol NMF方法，旨在最大化矩阵H的体积，并且证明了其在无噪声条件下的可识别性，同时提供了两种求解算法及其归一化变体。", "conclusion": "MaxVol NMF在提取稀疏分解方面更有效，并且与MinVol NMF相比，其解决方案对应于将数据列聚类为不相交的簇，避免了秩缺陷。"}}}
{"id": "ax-2026-02-04-24", "source": "arxiv", "date": "2026-02-04", "rank": 24, "title": "Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation", "url": "https://arxiv.org/abs/2602.04785v1", "detail_url": "https://arxiv.org/pdf/2602.04785v1.pdf", "description_en": "While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.", "description_zh": "本文提出了一种名为Team-then-Trim (T$^2$) 的框架，通过协作的LLM团队和严格的数据质量控制流程合成高质量的表格数据。", "keywords": ["生成框架", "表格数据", "大规模语言模型", "数据质量控制", "协同生成", "多阶段评估", "机器学习应用", "合作团队", "machine learning"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Congjing Zhang", "Ryan Feng Lin", "Ruoxuan Bao", "Shuai Huang"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "machine learning", "ml", "llm"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目通过协作LLM团队生成高质量表格数据，具备一定的自我改进能力和闭环机制，技术路径独特且解决复杂问题，但商业模式尚不明确，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:34:41Z", "ai_summary": {"tldr": "本文提出了一种名为Team-then-Trim (T$^2$) 的框架，通过协作的LLM团队和严格的数据质量控制流程合成高质量的表格数据。", "motivation": "高质量的表格数据获取通常劳动密集且成本高，现有数据集存在严重不足，迫切需要有效的生成方法。", "method": "T$^2$框架将表格数据生成视为制造过程，通过专业化的LLM团队依照领域知识逐步生成数据组件，并在多个维度上进行质量评估。", "conclusion": "实证结果表明，T$^2$在生成高质量表格数据方面优于现有最先进的方法，展示了其在实际应用中的潜力。"}}}
{"id": "ax-2026-02-04-25", "source": "arxiv", "date": "2026-02-04", "rank": 25, "title": "Dynamical Regimes of Multimodal Diffusion Models", "url": "https://arxiv.org/abs/2602.04780v1", "detail_url": "https://arxiv.org/pdf/2602.04780v1.pdf", "description_en": "Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.", "description_zh": "本文提出了一个理论框架，揭示了多模态扩散模型生成的动态机制，特别是通过耦合的Ornstein-Uhlenbeck过程分析了交互时间尺度的谱层次结构。", "keywords": ["多模态", "扩散模型", "生成模型", "深度学习", "神经网络", "交互时间尺度", "同步间隙", "统计物理", "训练实验", "MNIST", "generative"], "tags": ["cs.LG"], "metrics": {"authors": ["Emil Albrychiewicz", "Andrés Franco Valiente", "Li-Ching Chen"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 10, "team": 8, "bonus": 0, "penalty": 0}, "reason": "项目提出了多模态扩散模型的理论框架，具备一定的AI原生性，但缺乏在线学习和自我改进机制。技术路径创新，解决复杂问题，具备一定的行业壁垒。商业模式尚不明确，团队信息不足，无法充分评估进化能力。"}, "raw": {"published": "2026-02-04T17:16:12Z", "ai_summary": {"tldr": "本文提出了一个理论框架，揭示了多模态扩散模型生成的动态机制，特别是通过耦合的Ornstein-Uhlenbeck过程分析了交互时间尺度的谱层次结构。", "motivation": "尽管扩散生成模型在合成高维数据方面取得了显著成功，但多模态生成的理论机制仍不清楚，因此需要深入研究其背后的动态规律。", "method": "通过研究耦合的Ornstein-Uhlenbeck过程，利用非平衡统计物理学中的动态相变理论，分析不同时间尺度下的相互作用，并推导出相应的分析条件。", "conclusion": "研究结果表明，耦合强度作为谱滤波器，能够在生成过程中强制执行可调的时间层次，这为多模态生成提供了新的时间依赖耦合调度策略。"}}}
{"id": "ax-2026-02-04-26", "source": "arxiv", "date": "2026-02-04", "rank": 26, "title": "Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification", "url": "https://arxiv.org/abs/2602.04775v1", "detail_url": "https://arxiv.org/pdf/2602.04775v1.pdf", "description_en": "In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.", "description_zh": "提出了一种针对区间值预测的不确定性感知ROC框架，并引入了新的评估指标AUC_L和AUC_U，以优化决策过程中的不确定性处理。", "keywords": ["不确定性分类", "预测模型", "ROC曲线", "AUC", "interval-valued predictions", "选择性预测", "排序性能", "可靠性优化", "实验验证", "决策支持", "rag"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuqi Li", "Matthew M. Engelhard"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "rag"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "项目提出了不确定性感知的ROC框架，具备一定的AI原生能力，但缺乏在线学习和自我改进机制。技术路径独特，解决复杂问题，具备行业壁垒。商业模式较弱，团队背景信息不足。"}, "raw": {"published": "2026-02-04T17:12:04Z", "ai_summary": {"tldr": "提出了一种针对区间值预测的不确定性感知ROC框架，并引入了新的评估指标AUC_L和AUC_U，以优化决策过程中的不确定性处理。", "motivation": "在高风险预测中，通过区间值预测量化不确定性对于可靠决策至关重要，现有的AUC工具无法有效捕捉这种不确定性对排名性能的影响。", "method": "提出了一种新的不确定性感知ROC框架，包含对ROC平面的三区域分解，并引入两个新指标AUC_L和AUC_U，以支持选择性预测和优化不确定性处理。", "conclusion": "实验验证了所提框架的正确性和实用性，展示了其在不确定性感知评估和决策中的有效应用。"}}}
{"id": "ax-2026-02-04-27", "source": "arxiv", "date": "2026-02-04", "rank": 27, "title": "Generative Modeling via Drifting", "url": "https://arxiv.org/abs/2602.04770v1", "detail_url": "https://arxiv.org/pdf/2602.04770v1.pdf", "description_en": "Generative modeling can be formulated as learning a mapping f such that its pushforward distribution matches the data distribution. The pushforward behavior can be carried out iteratively at inference time, for example in diffusion and flow-based models. In this paper, we propose a new paradigm called Drifting Models, which evolve the pushforward distribution during training and naturally admit one-step inference. We introduce a drifting field that governs the sample movement and achieves equilibrium when the distributions match. This leads to a training objective that allows the neural network optimizer to evolve the distribution. In experiments, our one-step generator achieves state-of-the-art results on ImageNet at 256 x 256 resolution, with an FID of 1.54 in latent space and 1.61 in pixel space. We hope that our work opens up new opportunities for high-quality one-step generation.", "description_zh": "该论文提出了一种新的生成建模方法，即漂移模型，通过训练中演化推前分布实现高质量的一步生成。", "keywords": ["生成模型", "深度学习", "神经网络", "生成", "漂移模型", "训练目标", "一步推理", "图像生成", "ImageNet", "neural network"], "tags": ["cs.LG", "cs.CV"], "metrics": {"authors": ["Mingyang Deng", "He Li", "Tianhong Li", "Yilun Du", "Kaiming He"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "neural network", "generative", "diffusion"], "hit_excludes": []}, "score": {"total": 67, "breakdown": {"ai_native": 25, "tech_niche": 18, "business": 10, "team": 10, "bonus": 4, "penalty": 0}, "reason": "该项目提出了一种新型生成模型，具备自我进化能力，且在实验中表现出色，符合AI原生标准；技术路径独特，具备一定壁垒；商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T17:06:49Z", "ai_summary": {"tldr": "该论文提出了一种新的生成建模方法，即漂移模型，通过训练中演化推前分布实现高质量的一步生成。", "motivation": "当前生成模型在推前分布匹配数据分布时存在效率和质量的挑战，因此需要一种新方法来改进这一过程。", "method": "作者提出了一个漂移场，通过控制样本移动来演化推前分布，并在训练中实现分布的平衡，从而优化生成过程。", "conclusion": "实验表明，提出的一步生成器在ImageNet数据集上实现了最先进的结果，开启了高质量一步生成的新机会。"}}}
{"id": "ax-2026-02-04-28", "source": "arxiv", "date": "2026-02-04", "rank": 28, "title": "Billion-Scale Graph Foundation Models", "url": "https://arxiv.org/abs/2602.04768v1", "detail_url": "https://arxiv.org/pdf/2602.04768v1.pdf", "description_en": "Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.", "description_zh": "本文提出了GraphBFF，这是一个用于构建十亿参数规模图基础模型的端到端框架，能够有效处理异构大规模图数据。", "keywords": ["图神经网络", "生成模型", "预训练", "微调", "Transformer", "图数据", "大规模模型", "任务评估", "零样本学习"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Maya Bechler-Speicher", "Yoel Gottlieb", "Andrey Isakov", "David Abensur", "Ami Tavory", "Daniel Haimovich", "Ido Guy", "Udi Weinsberg"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "transformer"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "GraphBFF展示了强大的图模型能力，但缺乏用户交互和自我改进的闭环，商业模式不够明确。技术路径和团队背景较强，具有一定的行业壁垒。"}, "raw": {"published": "2026-02-04T17:03:51Z", "ai_summary": {"tldr": "本文提出了GraphBFF，这是一个用于构建十亿参数规模图基础模型的端到端框架，能够有效处理异构大规模图数据。", "motivation": "随着图结构数据在多个关键应用中的重要性不断提升，如何将大型预训练模型的成功经验扩展到图数据上成为一项重大挑战。", "method": "GraphBFF框架结合了GraphBFF Transformer架构，提供了预训练和微调的具体方法论，能够处理十亿规模的图数据。", "conclusion": "GraphBFF在多个真实世界的下游任务中展现出卓越的零-shot和少-shot性能，表明该框架为图学习提供了实用的基础模型构建方案。"}}}
{"id": "ax-2026-02-04-29", "source": "arxiv", "date": "2026-02-04", "rank": 29, "title": "Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty", "url": "https://arxiv.org/abs/2602.04763v1", "detail_url": "https://arxiv.org/pdf/2602.04763v1.pdf", "description_en": "Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.", "description_zh": "提出了一种新方法A2MAML，旨在处理多智能体系统中的不确定性，优化多模态合作。", "keywords": ["多智能体", "多模态学习", "不确定性", "协同工作", "模态融合", "agent", "Bayesian", "事故检测", "自动驾驶"], "tags": ["cs.LG", "cs.AI"], "metrics": {"authors": ["Rui Liu", "Pratap Tokekar", "Ming Lin"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "ml", "agent", "autonomous", "multi-agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 24, "tech_niche": 18, "business": 10, "team": 8, "bonus": 6, "penalty": 0}, "reason": "A2MAML在多智能体系统中处理不确定性，具备较强的AI原生特征；技术路径独特且解决复杂问题，具备一定的行业壁垒；商业模式尚不明确，团队信息不足。"}, "raw": {"published": "2026-02-04T17:01:31Z", "ai_summary": {"tldr": "提出了一种新方法A2MAML，旨在处理多智能体系统中的不确定性，优化多模态合作。", "motivation": "随着多智能体系统普及，异构多模态传感器带来了感知能力的提升，但也引入了特定模态和代理相关的不确定性，限制了系统在传感器损坏情况下的鲁棒性。", "method": "A2MAML通过将每个模态特征建模为带有不确定性预测的随机估计，主动选择可靠的代理-模态对，并通过贝叶斯逆方差加权聚合信息，实现细粒度的模态级融合。", "conclusion": "在协作事故检测的实验中，A2MAML在事故检测率上比单代理和合作基线高出最多18.7%。"}}}
{"id": "ax-2026-02-04-30", "source": "arxiv", "date": "2026-02-04", "rank": 30, "title": "A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates", "url": "https://arxiv.org/abs/2602.04757v1", "detail_url": "https://arxiv.org/pdf/2602.04757v1.pdf", "description_en": "Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.", "description_zh": "提出了一种双阶段TransUNet框架，融合多源降水数据以提高降水估计的准确性和极端天气事件的检测能力。", "keywords": ["深度学习", "多源降水", "TransUNet", "机器学习", "预测模型", "数据融合", "极端事件检测", "语义搜索", "人机协作", "deep learning"], "tags": ["cs.LG"], "metrics": {"authors": ["Yuchen Ye", "Zixuan Qi", "Shixuan Li", "Wei Qi", "Yanpeng Cai", "Chaoxia Yuan"]}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "deep learning", "retrieval"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 20, "business": 12, "team": 8, "bonus": 4, "penalty": 0}, "reason": "项目提出了双阶段的TransUNet框架，具备一定的自我改进能力，但缺乏用户交互和商业化应用的明确性。技术路径独特，解决复杂问题，具备一定的行业壁垒。"}, "raw": {"published": "2026-02-04T16:55:43Z", "ai_summary": {"tldr": "提出了一种双阶段TransUNet框架，融合多源降水数据以提高降水估计的准确性和极端天气事件的检测能力。", "motivation": "现有多源降水产品在空间异质性偏差和极端天气估计上存在不足，限制了其在水文气候监测中的应用。", "method": "开发了一个双阶段的TransUNet模型，其中第一阶段通过分类器估计降水发生概率，第二阶段通过回归器结合多种物理预测因子估计降水量。", "conclusion": "该框架在季节性表现和极端降水事件检测上优于传统模型，且在数据稀缺区域显示出良好的适用性。"}}}
{"id": "gh-2026-02-05-1", "source": "github", "date": "2026-02-05", "rank": 1, "title": "aquasecurity/trivy", "url": "https://github.com/aquasecurity/trivy", "detail_url": "https://github.com/aquasecurity/trivy", "description_en": "Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more", "description_zh": "该项目旨在帮助用户发现容器、Kubernetes、代码仓库、云环境等中的漏洞、错误配置、机密信息及软件物料清单（SBOM）。主要功能包括自动化安全扫描和风险评估，适用于开发人员、运维团队和安全专家等用户场景。核心技术涉及人工智能算法和机器学习模型，以提高漏洞识别的准确性和效率。", "keywords": ["漏洞检测", "misconfigurations", "SBOM", "Kubernetes", "容器安全", "代码仓库", "生成模型", "语义搜索", "自主代理", "agent"], "tags": ["Go"], "metrics": {"stars": 0, "forks": 2907, "stars_today": 23}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的AI原生特性，但用户反馈与系统自我提升的闭环尚不明确。技术路径具有独特性，深度绑定于安全领域。商业模式与高价值用户紧密关联，团队背景较强。"}, "raw": {}}
{"id": "gh-2026-02-05-2", "source": "github", "date": "2026-02-05", "rank": 2, "title": "topoteretes/cognee", "url": "https://github.com/topoteretes/cognee", "detail_url": "https://github.com/topoteretes/cognee", "description_en": "Memory for AI Agents in 6 lines of code", "description_zh": "项目简介：这是一个用于 AI 代理的内存管理工具，仅需 6 行代码即可实现。它的主要功能是为 AI 代理提供短期和长期记忆，帮助其更好地理解和处理上下文信息。目标用户为开发者和研究人员，尤其是在构建智能应用或聊天机器人时。核心技术包括自然语言处理和机器学习算法，旨在提升 AI 代理的智能交互能力。", "keywords": ["记忆", "AI Agents", "代码", "深度学习", "神经网络", "生成模型", "语义搜索", "代理工作流", "自主代理", "助手"], "tags": ["Python"], "metrics": {"stars": 0, "forks": 1150, "stars_today": 69}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent"], "hit_excludes": []}, "score": {"total": 62, "breakdown": {"ai_native": 18, "tech_niche": 15, "business": 12, "team": 10, "bonus": 7, "penalty": 0}, "reason": "该项目提供了AI代理的记忆管理工具，但缺乏自我学习和能力提升的闭环设计。技术路径较为常见，商业模式尚不明确。团队背景信息不足，无法确认其能力。"}, "raw": {}}
{"id": "gh-2026-02-05-3", "source": "github", "date": "2026-02-05", "rank": 3, "title": "obra/superpowers", "url": "https://github.com/obra/superpowers", "detail_url": "https://github.com/obra/superpowers", "description_en": "An agentic skills framework & software development methodology that works.", "description_zh": "一个有效的代理技能框架与软件开发方法论。该项目旨在帮助软件开发团队提升协作效率和技术能力，尤其适合需要高效管理复杂项目的企业。核心技术包括人工智能驱动的技能评估与匹配系统，能够实时分析团队成员的技能水平并提供个性化培训建议。", "keywords": ["智能代理", "代理技能框架", "软件开发方法论", "任务自动化", "多智能体系统", "agent"], "tags": ["Shell"], "metrics": {"stars": 0, "forks": 3409, "stars_today": 893}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["agent"], "hit_excludes": []}, "score": {"total": 70, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目具备一定的代理技能框架和自动化能力，但在自我进化和用户数据反馈方面尚显不足。技术路径和市场定位清晰，团队背景较强，商业模式与高价值用户绑定良好。"}, "raw": {}}
{"id": "gh-2026-02-05-4", "source": "github", "date": "2026-02-05", "rank": 4, "title": "bytedance/UI-TARS-desktop", "url": "https://github.com/bytedance/UI-TARS-desktop", "detail_url": "https://github.com/bytedance/UI-TARS-desktop", "description_en": "The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra", "description_zh": "开源多模态 AI 代理栈：连接前沿 AI 模型与代理基础设施\n\n该项目的主要功能是整合多种AI模型，提供一个高效的代理架构，支持多模态任务的处理。目标用户为开发者和研究人员，适用于构建智能代理、虚拟助手等应用场景。核心技术包括深度学习、自然语言处理和计算机视觉，尤其注重多模态数据的融合与应用。", "keywords": ["多模态", "AI代理", "连接", "先进模型", "代理基础设施", "语义搜索", "生成模型", "深度学习", "神经网络", "助手"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 2584, "stars_today": 862}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "agent", "agent infra"], "hit_excludes": []}, "score": {"total": 66, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 12, "team": 10, "bonus": 6, "penalty": 0}, "reason": "项目整合多种AI模型，具备一定的自我改进能力，但缺乏明确的在线学习闭环。技术路径选择较为独特，具有一定的行业壁垒。商业模式与用户价值绑定较弱，团队背景信息不足。"}, "raw": {}}
{"id": "gh-2026-02-05-5", "source": "github", "date": "2026-02-05", "rank": 5, "title": "thedotmack/claude-mem", "url": "https://github.com/thedotmack/claude-mem", "detail_url": "https://github.com/thedotmack/claude-mem", "description_en": "A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.", "description_zh": "Claude Code 插件能够自动记录您在编码过程中Claude的所有操作，通过AI（使用Claude的agent-sdk）对这些信息进行压缩，并在未来的会话中注入相关上下文。该插件的主要功能是提升编码效率和上下文理解，目标用户主要是软件开发者和编程学习者，特别适合需要长时间编码和多次调试的场景。核心技术包括AI算法和上下文感知处理，旨在为用户提供智能化的编程辅助。", "keywords": ["Claude", "代码插件", "自动捕获", "上下文注入", "编程助手", "生成式模型", "AI 压缩", "机器学习", "深度学习"], "tags": ["TypeScript"], "metrics": {"stars": 0, "forks": 1535, "stars_today": 1899}, "media": {"image": null}, "ai_flags": {"is_ai": true, "hit_keywords": ["ai", "claude", "agent", "context"], "hit_excludes": []}, "score": {"total": 68, "breakdown": {"ai_native": 20, "tech_niche": 18, "business": 14, "team": 10, "bonus": 6, "penalty": 0}, "reason": "该插件通过记录和注入上下文提升编码效率，具备一定的自我学习能力，但在用户转化为数据标注员方面表现一般。技术路径较为独特，且服务于特定开发者群体，商业模式与高价值用户绑定较好。"}, "raw": {}}
