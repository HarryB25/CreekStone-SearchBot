# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-23

> å…± 15 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (7 ç¯‡)
- [cs.AI](#csAI) (3 ç¯‡)
- [cs.CV](#csCV) (3 ç¯‡)
- [cs.CL](#csCL) (2 ç¯‡)

---

## cs.AI

## [1. Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](https://arxiv.org/abs/2602.20426v1)

**ä½œè€…**ï¼šRuocheng Guo, Kaiwen Dong, Xiang Gao ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºTrace-Free+é€šè¿‡â€œé‡å†™å·¥å…·æè¿°/æ¥å£â€è€Œéåªå¾®è°ƒAgentï¼Œåœ¨æ— æ‰§è¡Œè½¨è¿¹æ¡ä»¶ä¸‹ä¹Ÿèƒ½æ˜¾è‘—æå‡LLM-Agentçš„å·¥å…·é€‰æ‹©ä¸è°ƒç”¨å¯é æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å·¥å…·æ¥å£å¤šä¸ºäººç±»è®¾è®¡ï¼Œé¢å¯¹ä¸Šç™¾å€™é€‰å·¥å…·æ—¶ä¼šæˆä¸ºLLM-Agentä½¿ç”¨ç“¶é¢ˆï¼›è€ŒåŸºäºæ‰§è¡Œè½¨è¿¹çš„æ¥å£ä¼˜åŒ–åœ¨å†·å¯åŠ¨æˆ–éšç§å—é™åœºæ™¯å¸¸ä¸å¯ç”¨ï¼Œä¸”é€å·¥å…·ä¼˜åŒ–éš¾ä»¥æ‰©å±•åˆ°æœªè§å·¥å…·ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šTrace-Free+é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ï¼ŒæŠŠç›‘ç£ä»â€œæœ‰è½¨è¿¹è®­ç»ƒâ€é€æ­¥è¿ç§»åˆ°â€œæ— è½¨è¿¹éƒ¨ç½²â€è®¾ç½®ï¼Œä¿ƒä½¿æ¨¡å‹æŠ½è±¡å¯å¤ç”¨çš„æ¥å£ä½¿ç”¨æ¨¡å¼ä¸ç»“æœå¯¼å‘ä¿¡å·ï¼›åŒæ—¶é€šè¿‡ç»“æ„åŒ–æµç¨‹æ„å»ºå¤§è§„æ¨¡é«˜è´¨é‡å·¥å…·æ¥å£æ•°æ®ï¼Œç”¨äºå­¦ä¹ è‡ªåŠ¨é‡å†™å·¥å…·æè¿°ä¸å‚æ•°schemaä»¥æ›´é€‚é…Agentã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨StableToolBenchä¸RestBenchä¸Šï¼Œè¯¥æ–¹æ³•å¯¹æœªè§å·¥å…·æŒç»­æå‡ã€è·¨åŸŸæ³›åŒ–å¼ºï¼Œå¹¶åœ¨å€™é€‰å·¥å…·è§„æ¨¡æ‰©å¤§åˆ°100+æ—¶ä»ä¿æŒç¨³å¥ï¼Œè¡¨æ˜å·¥å…·æ¥å£ä¼˜åŒ–æ˜¯å¯éƒ¨ç½²ä¸”èƒ½è¡¥å……Agentå¾®è°ƒçš„æœ‰æ•ˆè·¯å¾„ã€‚

**å…³é”®è¯**ï¼šå·¥å…·æ¥å£ä¼˜åŒ–, å·¥å…·æè¿°é‡å†™, å‚æ•°æ¨¡å¼è®¾è®¡, æ— æ‰§è¡Œè½¨è¿¹å­¦ä¹ , è¯¾ç¨‹å­¦ä¹ , å†·å¯åŠ¨éƒ¨ç½², éšç§å—é™è®­ç»ƒ, å¤§è§„æ¨¡å·¥å…·é€‰æ‹©, è·¨åŸŸæ³›åŒ–, æœªè§å·¥å…·æ³›åŒ–

**è¯„åˆ†**ï¼š42

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20426v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20426v1.pdf)

---

## [2. Implicit Intelligence -- Evaluating Agents on What Users Don't Say](https://arxiv.org/abs/2602.20424v1)

**ä½œè€…**ï¼šVed Sirdeshmukh, Marc Wetter  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI agents can move beyond prompt-following to become genuine goal-fulfillers, paired with Agent-as-a-World (AaW), a harness where interactive worlds are defined in human-readable YAML files and simulated by language models. Our scenarios feature apparent simplicity in user requests, hidden complexity in correct solutions, and discoverability of constraints through environmental exploration. Evaluating 16 frontier and open-weight models across 205 scenarios, we find that even the best-performing model achieves only 48.3% scenario pass rate, revealing substantial room for improvement in bridging the gap between literal instruction-following and human-like contextual reasoning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºâ€œImplicit Intelligenceâ€è¯„æµ‹æ¡†æ¶ï¼Œç”¨äºè¡¡é‡AIä»£ç†åœ¨ç”¨æˆ·æœªæ˜è¯´çš„éšå«çº¦æŸä¸‹æ˜¯å¦èƒ½çœŸæ­£å®Œæˆç›®æ ‡ï¼Œè€Œä¸ä»…æ˜¯æœºæ¢°éµå¾ªæç¤ºã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçœŸå®ç”¨æˆ·è¯·æ±‚å¾€å¾€ä¿¡æ¯ä¸è¶³ä¸”ä¾èµ–å…±äº«è¯­å¢ƒï¼ŒåŒ…å«å¯è®¿é—®æ€§ã€éšç§è¾¹ç•Œã€é£é™©è§„é¿ç­‰éšå«è¦æ±‚ï¼›ä½†ç°æœ‰åŸºå‡†å¤šåªè€ƒå¯Ÿæ˜¾å¼æŒ‡ä»¤éµå¾ªï¼Œæ— æ³•è¯„ä¼°è¿™ç§â€œè¯»æ‡‚æ½œå°è¯â€çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºImplicit IntelligenceåŸºå‡†ï¼Œå¹¶é…å¥—Agent-as-a-Worldï¼ˆAaWï¼‰æµ‹è¯•å¹³å°ï¼šç”¨å¯è¯»YAMLå®šä¹‰äº¤äº’ä¸–ç•Œï¼Œç”±è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿç¯å¢ƒï¼Œåœºæ™¯è¡¨é¢ç®€å•ä½†æ­£ç¡®è§£éœ€é€šè¿‡æ¢ç´¢å‘ç°éšè—çº¦æŸï¼›åœ¨205ä¸ªåœºæ™¯ä¸Šè¯„æµ‹16ä¸ªå‰æ²¿ä¸å¼€æºæƒé‡æ¨¡å‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šå³ä¾¿è¡¨ç°æœ€ä½³çš„æ¨¡å‹åœºæ™¯é€šè¿‡ç‡ä¹Ÿä»…48.3%ï¼Œè¡¨æ˜å½“å‰æ¨¡å‹åœ¨ä»å­—é¢æ‰§è¡Œåˆ°åŸºäºä¸Šä¸‹æ–‡æ¨æ–­éšå«éœ€æ±‚çš„èƒ½åŠ›ä¸Šä»æœ‰æ˜¾è‘—å·®è·ã€‚

**å…³é”®è¯**ï¼šéšå¼éœ€æ±‚æ¨ç†, æ¬ è§„èŒƒåŒ–æŒ‡ä»¤, ä¸Šä¸‹æ–‡çº¦æŸæ¨æ–­, æ™ºèƒ½ä½“è¯„æµ‹åŸºå‡†, ç›®æ ‡æ»¡è¶³å‹æ™ºèƒ½ä½“, äº¤äº’å¼ç¯å¢ƒè¯„æµ‹, ç¯å¢ƒæ¢ç´¢, YAML åœºæ™¯å®šä¹‰, éšç§è¾¹ç•Œçº¦æŸ, å¯è®¿é—®æ€§éœ€æ±‚, ç¾éš¾æ€§é£é™©çº¦æŸ, LLM æ¨¡æ‹Ÿç¯å¢ƒ

**è¯„åˆ†**ï¼š42

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20424v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20424v1.pdf)

---

## [3. Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422v1)

**ä½œè€…**ï¼šHanping Zhang, Yuhong Guo  
**åˆ†ç±»**ï¼šcs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDMEMMé€šè¿‡æ˜¾å¼å»ºæ¨¡å¹¶æ³¨å…¥ç¯å¢ƒè½¬ç§»åŠ¨åŠ›å­¦ä¸å¥–åŠ±æœºåˆ¶æ¥è°ƒåˆ¶æ‰©æ•£å¼è½¨è¿¹ç”Ÿæˆï¼Œä»è€Œæå‡ç¦»çº¿RLè§„åˆ’çš„å¯è¡Œæ€§ä¸æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰æ‰©æ•£è§„åˆ’å¾€å¾€åªæ‹Ÿåˆæ•°æ®åˆ†å¸ƒï¼Œå¿½ç•¥RLè½¨è¿¹ä¸­è½¬ç§»ä¸€è‡´æ€§ä¸ç¯å¢ƒæœºåˆ¶çº¦æŸï¼Œå¯¼è‡´ç”Ÿæˆè½¨è¿¹ä¸çœŸå®ç¯å¢ƒåŠ¨åŠ›å­¦/å¥–åŠ±ä¸åŒ¹é…ã€è½åœ°æ‰§è¡Œåå·®å¤§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨æ‰©æ•£æ¨¡å‹è®­ç»ƒ/ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥ç¯å¢ƒæœºåˆ¶å»ºæ¨¡ï¼Œåˆ©ç”¨è½¬ç§»åŠ¨åŠ›å­¦ä¸å¥–åŠ±å‡½æ•°å¯¹å»å™ªè¿‡ç¨‹è¿›è¡Œè°ƒåˆ¶ï¼ˆçº¦æŸ/å¼•å¯¼ï¼‰ï¼Œä»¥ä¿è¯ç›¸é‚»çŠ¶æ€-åŠ¨ä½œè½¬ç§»çš„è¿è´¯æ€§å¹¶åå¥½é«˜å›æŠ¥è½¨è¿¹ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜DMEMMåœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ è§„åˆ’ä»»åŠ¡ä¸Šè¾¾åˆ°SOTAï¼Œèƒ½ç”Ÿæˆæ›´ç¬¦åˆç¯å¢ƒæœºåˆ¶ã€æ‰§è¡Œæ›´ä¸€è‡´ä¸”å›æŠ¥æ›´é«˜çš„è½¨è¿¹ã€‚

**å…³é”®è¯**ï¼šç¦»çº¿å¼ºåŒ–å­¦ä¹ , è½¨è¿¹ç”Ÿæˆ, Diffusion, æ‰©æ•£è§„åˆ’, ç¯å¢ƒæœºåˆ¶å»ºæ¨¡, è½¬ç§»åŠ¨åŠ›å­¦å»ºæ¨¡, å¥–åŠ±å‡½æ•°å»ºæ¨¡, ä¸€è‡´æ€§çº¦æŸ

**è¯„åˆ†**ï¼š34

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20422v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20422v1.pdf)

---

## cs.CL

## [4. Case-Aware LLM-as-a-Judge Evaluation for Enterprise-Scale RAG Systems](https://arxiv.org/abs/2602.20379v1)

**ä½œè€…**ï¼šMukul Chhabra, Luigi Medrano, Arush Verma  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Enterprise Retrieval-Augmented Generation (RAG) assistants operate in multi-turn, case-based workflows such as technical support and IT operations, where evaluation must reflect operational constraints, structured identifiers (e.g., error codes, versions), and resolution workflows. Existing RAG evaluation frameworks are primarily designed for benchmark-style or single-turn settings and often fail to capture enterprise-specific failure modes such as case misidentification, workflow misalignment, and partial resolution across turns.   We present a case-aware LLM-as-a-Judge evaluation framework for enterprise multi-turn RAG systems. The framework evaluates each turn using eight operationally grounded metrics that separate retrieval quality, grounding fidelity, answer utility, precision integrity, and case/workflow alignment. A severity-aware scoring protocol reduces score inflation and improves diagnostic clarity across heterogeneous enterprise cases. The system uses deterministic prompting with strict JSON outputs, enabling scalable batch evaluation, regression testing, and production monitoring.   Through a comparative study of two instruction-tuned models across short and long workflows, we show that generic proxy metrics provide ambiguous signals, while the proposed framework exposes enterprise-critical tradeoffs that are actionable for system improvement.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§é¢å‘ä¼ä¸šå¤šè½®RAGâ€œå·¥å•/æ¡ˆä»¶â€åœºæ™¯çš„LLM-as-a-Judgeè¯„æµ‹æ¡†æ¶ï¼Œç”¨æ›´è´´è¿‘çœŸå®è¿ç»´æµç¨‹çš„æŒ‡æ ‡ä¸ä¸¥é‡åº¦è¯„åˆ†æ­ç¤ºå…³é”®å¤±æ•ˆæ¨¡å¼ä¸å¯è¡ŒåŠ¨æ”¹è¿›ç‚¹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ä¸šçº§RAGå¸¸åœ¨å¤šè½®ã€åŸºäºæ¡ˆä»¶çš„æ”¯æŒ/è¿ç»´æµç¨‹ä¸­å·¥ä½œï¼Œéœ€å…³æ³¨é”™è¯¯ç /ç‰ˆæœ¬ç­‰ç»“æ„åŒ–æ ‡è¯†ä¸æµç¨‹é—­ç¯ï¼Œè€Œç°æœ‰åå•è½®/åŸºå‡†é›†çš„è¯„æµ‹å¾€å¾€æ— æ³•è¯†åˆ«æ¡ˆä»¶é”™é…ã€æµç¨‹åç¦»å’Œè·¨è½®æ¬¡éƒ¨åˆ†è§£å†³ç­‰ä¼ä¸šç‰¹æœ‰é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºâ€œcase-awareâ€çš„é€è½®è¯„æµ‹ï¼šç”¨8ä¸ªè´´è¿‘è¿è¥çš„æŒ‡æ ‡åˆ†åˆ«è¡¡é‡æ£€ç´¢è´¨é‡ã€ä¾æ®ä¸€è‡´æ€§(grounding)ã€å›ç­”æ•ˆç”¨ã€ç²¾ç¡®æ€§å®Œæ•´æ€§ï¼Œä»¥åŠæ¡ˆä»¶/å·¥ä½œæµå¯¹é½ï¼›å¹¶å¼•å…¥ä¸¥é‡åº¦æ„ŸçŸ¥çš„è¯„åˆ†åè®®ä»¥æŠ‘åˆ¶åˆ†æ•°è™šé«˜ï¼Œé‡‡ç”¨ç¡®å®šæ€§æç¤ºè¯ä¸ä¸¥æ ¼JSONè¾“å‡ºä»¥æ”¯æŒæ‰¹é‡è¯„æµ‹ã€å›å½’æµ‹è¯•ä¸çº¿ä¸Šç›‘æ§ã€‚

**ä¸»è¦ç»“è®º**ï¼šå¯¹ä¸¤ç§æŒ‡ä»¤å¾®è°ƒæ¨¡å‹åœ¨çŸ­/é•¿æµç¨‹å¯¹æ¯”æ˜¾ç¤ºï¼Œé€šç”¨ä»£ç†æŒ‡æ ‡ä¿¡å·æ¨¡ç³Šï¼Œè€Œè¯¥æ¡†æ¶èƒ½æ¸…æ™°æš´éœ²ä¼ä¸šå…³é”®å–èˆä¸å¤±è´¥ç‚¹ï¼ˆå¦‚æ¡ˆä»¶/æµç¨‹å¯¹é½é—®é¢˜ï¼‰ï¼Œä»è€Œæä¾›æ›´å…·å¯æ“ä½œæ€§çš„ç³»ç»Ÿæ”¹è¿›è¯Šæ–­ã€‚

**å…³é”®è¯**ï¼šå¤šè½®å¯¹è¯è¯„æµ‹, æ¡ˆä¾‹æ„ŸçŸ¥è¯„æµ‹, å·¥ä½œæµå¯¹é½, æ£€ç´¢è´¨é‡è¯„ä¼°, äº‹å®ä¸€è‡´æ€§è¯„ä¼°, ä¸¥é‡åº¦æ„ŸçŸ¥è¯„åˆ†, ç¡®å®šæ€§æç¤º, JSONç»“æ„åŒ–è¾“å‡º, å›å½’æµ‹è¯•ä¸çº¿ä¸Šç›‘æ§

**è¯„åˆ†**ï¼š44

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20379v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20379v1.pdf)

---

## [5. How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity](https://arxiv.org/abs/2602.20372v1)

**ä½œè€…**ï¼šChundra Cathcart, Arne Rubehn, Katja Bocklage ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æŒ‡å‡ºä»¥å¾€å…³äºâ€œç²¾ç¡®é€’å½’æ•°è¯ç³»ç»Ÿåœ¨è¯æ±‡è§„æ¨¡ä¸å½¢æ€å¥æ³•å¤æ‚åº¦ä¹‹é—´å®ç°äº¤é™…æ•ˆç‡æœ€ä¼˜â€çš„ç»“è®ºå¯èƒ½è¢«é«˜ä¼°ï¼Œå› ä¸ºåœ¨æ›´ç»†è‡´çš„å¤æ‚åº¦æ ‡æ³¨ä¸‹ï¼Œè®¸å¤šè¯­è¨€çš„æ•°è¯ç³»ç»Ÿæ˜æ˜¾ä½äºé¢„æœŸæ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè¿‘æœŸç ”ç©¶ä¸»å¼ æ•°è¯ç³»ç»Ÿä¼šåœ¨â€œæ•°è¯è¯åº“å¤§å°â€ä¸â€œæ•°è¯è¡¨è¾¾çš„å¹³å‡å½¢æ€å¥æ³•å¤æ‚åº¦â€ä¹‹é—´åšæœ€ä¼˜æƒè¡¡ï¼Œä½†ä½œè€…è®¤ä¸ºè¿™äº›ç ”ç©¶æœªå……åˆ†åˆ»ç”»è¯­è¨€ä¸­å¤æ‚åº¦å·®å¼‚ï¼Œå°¤å…¶å¿½ç•¥äº†å½¢å¼å˜ä½“ï¼ˆallomorphyï¼‰çš„å¯é¢„æµ‹æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æ”¶é›†52ç§è°±ç³»å¤šæ ·è¯­è¨€çš„æ•°æ®ï¼Œå¹¶é‡‡ç”¨èƒ½åŒºåˆ†â€œå¯é¢„æµ‹/ä¸å¯é¢„æµ‹â€å¼‚å½¢åŒæ€ï¼ˆå½¢å¼å˜ä½“ï¼‰çš„æ ‡æ³¨æ–¹æ¡ˆï¼Œå¯¹æ•°è¯è¡¨è¾¾çš„å¤æ‚åº¦è¿›è¡Œæ›´ç²¾ç»†é‡åŒ–ï¼Œå†æ®æ­¤è¯„ä¼°å…¶äº¤é™…æ•ˆç‡ç›¸å¯¹ç†è®ºæƒè¡¡æ›²çº¿çš„ä½ç½®ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨è¯¥æ ‡æ³¨æ¡†æ¶ä¸‹ï¼Œè®¸å¤šä¸–ç•Œè¯­è¨€çš„æ•°è¯ç³»ç»Ÿå¹¶æœªæ¥è¿‘æ‰€è°“çš„äº¤é™…æ•ˆç‡æœ€ä¼˜å‰æ²¿ï¼Œè€Œæ˜¯æ˜¾è‘—æ›´ä½æ•ˆï¼›è¿™è¡¨æ˜æ•°è¯ç³»ç»Ÿçš„æ¼”åŒ–å¯èƒ½å—éæ•ˆç‡å› ç´ æˆ–æ›´å¤æ‚çº¦æŸå½±å“ï¼Œéœ€é‡æ–°å®¡è§†ä»¥å¾€å…³äºæ•ˆç‡é©±åŠ¨çš„è§£é‡Šã€‚

**å…³é”®è¯**ï¼šç²¾ç¡®é€’å½’æ•°è¯ç³»ç»Ÿ, äº¤é™…æ•ˆç‡, è¯æ±‡è¡¨è§„æ¨¡, å½¢æ€å¥æ³•å¤æ‚åº¦, è¯­ç´ é•¿åº¦, æ•°è¯è¯æ±‡, å¯é¢„æµ‹å¼‚å½¢ä½“, ä¸å¯é¢„æµ‹å¼‚å½¢ä½“, è·¨è¯­è¨€ç±»å‹å­¦, è¯­è¨€æ•ˆç‡åç¦», è¯­è¨€è¿›åŒ–, è¯­è¨€æ ‡æ³¨æ–¹æ¡ˆ

**è¯„åˆ†**ï¼š14

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20372v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20372v1.pdf)

---

## cs.CV

## [6. gQIR: Generative Quanta Image Reconstruction](https://arxiv.org/abs/2602.20417v1)

**ä½œè€…**ï¼šAryan Garg, Sizhuo Ma, Mohit Gupta  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Capturing high-quality images from only a few detected photons is a fundamental challenge in computational imaging. Single-photon avalanche diode (SPAD) sensors promise high-quality imaging in regimes where conventional cameras fail, but raw \emph{quanta frames} contain only sparse, noisy, binary photon detections. Recovering a coherent image from a burst of such frames requires handling alignment, denoising, and demosaicing (for color) under noise statistics far outside those assumed by standard restoration pipelines or modern generative models. We present an approach that adapts large text-to-image latent diffusion models to the photon-limited domain of quanta burst imaging. Our method leverages the structural and semantic priors of internet-scale diffusion models while introducing mechanisms to handle Bernoulli photon statistics. By integrating latent-space restoration with burst-level spatio-temporal reasoning, our approach produces reconstructions that are both photometrically faithful and perceptually pleasing, even under high-speed motion. We evaluate the method on synthetic benchmarks and new real-world datasets, including the first color SPAD burst dataset and a challenging \textit{Deforming (XD)} video benchmark. Across all settings, the approach substantially improves perceptual quality over classical and modern learning-based baselines, demonstrating the promise of adapting large generative priors to extreme photon-limited sensing. Code at \href{https://github.com/Aryan-Garg/gQIR}{https://github.com/Aryan-Garg/gQIR}.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šgQIR å°†å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒçš„æ½œç©ºé—´æ‰©æ•£æ¨¡å‹é€‚é…åˆ°SPADé‡å­çªå‘æˆåƒï¼Œåœ¨æå°‘å…‰å­ä¸è¿åŠ¨åœºæ™¯ä¸‹ä»ç¨€ç–äºŒå€¼â€œquanta framesâ€é‡å»ºå‡ºæ›´çœŸå®ä¸”æ›´ç¾è§‚çš„å›¾åƒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šSPADåœ¨æä½ç…§åº¦ä¸‹å¯å·¥ä½œï¼Œä½†å…¶é‡å­å¸§å‘ˆç°ä¼¯åŠªåˆ©ç»Ÿè®¡ä¸‹çš„ç¨€ç–ã€å™ªå£°äºŒå€¼è§‚æµ‹ï¼Œä¼ ç»Ÿå¯¹é½/å»å™ª/å»é©¬èµ›å…‹æµç¨‹ä¸å¸¸è§„ç”Ÿæˆæ¨¡å‹çš„å™ªå£°å‡è®¾éƒ½ä¸é€‚ç”¨ï¼Œå¯¼è‡´é‡å»ºè´¨é‡å—é™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ–¹æ³•å°†äº’è”ç½‘çº§æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰ä¸ç»“æ„å…ˆéªŒå¼•å…¥å…‰å­å—é™é‡å»ºï¼Œå¹¶é€šè¿‡é¢å‘ä¼¯åŠªåˆ©å…‰å­ç»Ÿè®¡çš„æœºåˆ¶åœ¨æ½œç©ºé—´åšæ¢å¤ï¼›åŒæ—¶ç»“åˆburstçº§æ—¶ç©ºæ¨ç†ä»¥å¤„ç†å¸§é—´å¯¹é½ä¸è¿åŠ¨ï¼Œä»è€Œè”åˆå®Œæˆå»å™ªã€å¯¹é½ä¸ï¼ˆå½©è‰²ï¼‰å»é©¬èµ›å…‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨åˆæˆåŸºå‡†ä¸æ–°é‡‡é›†çœŸå®æ•°æ®ï¼ˆå«é¦–ä¸ªå½©è‰²SPAD burstä¸XDå½¢å˜è§†é¢‘ï¼‰ä¸Šï¼ŒgQIRç›¸è¾ƒç»å…¸ä¸å­¦ä¹ å‹åŸºçº¿æ˜¾è‘—æå‡æ„ŸçŸ¥è´¨é‡ï¼Œå¹¶åœ¨é«˜é€Ÿè¿åŠ¨ä¸‹ä»ä¿æŒè¾ƒå¥½çš„å…‰åº¦ä¸€è‡´æ€§ï¼ŒéªŒè¯äº†â€œå¤§ç”Ÿæˆå…ˆéªŒ+æç«¯ä¼ æ„Ÿâ€é€‚é…çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è¯**ï¼šå…‰å­å—é™æˆåƒ, å•å…‰å­é›ªå´©äºŒæç®¡ï¼ˆSPADï¼‰, å›¾åƒé‡å»º, æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£å…ˆéªŒ, ä¼¯åŠªåˆ©å…‰å­ç»Ÿè®¡, è¿åŠ¨é²æ£’é‡å»º, gQIR, Generative

**è¯„åˆ†**ï¼š33

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20417v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20417v1.pdf)

---

## [7. SimLBR: Learning to Detect Fake Images by Learning to Detect Real Images](https://arxiv.org/abs/2602.20412v1)

**ä½œè€…**ï¼šAayush Dhakal, Subash Khanal, Srikumar Sastry ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The rapid advancement of generative models has made the detection of AI-generated images a critical challenge for both research and society. Recent works have shown that most state-of-the-art fake image detection methods overfit to their training data and catastrophically fail when evaluated on curated hard test sets with strong distribution shifts. In this work, we argue that it is more principled to learn a tight decision boundary around the real image distribution and treat the fake category as a sink class. To this end, we propose SimLBR, a simple and efficient framework for fake image detection using Latent Blending Regularization (LBR). Our method significantly improves cross-generator generalization, achieving up to +24.85\% accuracy and +69.62\% recall on the challenging Chameleon benchmark. SimLBR is also highly efficient, training orders of magnitude faster than existing approaches. Furthermore, we emphasize the need for reliability-oriented evaluation in fake image detection, introducing risk-adjusted metrics and worst-case estimates to better assess model robustness. All code and models will be released on HuggingFace and GitHub.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSimLBRé€šè¿‡å­¦ä¹ çœŸå®å›¾åƒåˆ†å¸ƒæ¥æé«˜å‡å›¾åƒæ£€æµ‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œæ£€æµ‹AIç”Ÿæˆå›¾åƒæˆä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶ä¸ç¤¾ä¼šæŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†åˆ†å¸ƒå˜åŒ–æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä¸€ç§åä¸ºSimLBRçš„æ¡†æ¶ï¼Œé‡‡ç”¨æ½œåœ¨æ··åˆæ­£åˆ™åŒ–ï¼ˆLBRï¼‰æŠ€æœ¯ï¼Œä»¥æé«˜è·¨ç”Ÿæˆå™¨çš„æ³›åŒ–èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šSimLBRåœ¨ChameleonåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ£€æµ‹å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼Œå¹¶å¼ºè°ƒäº†ä½¿ç”¨é£é™©è°ƒæ•´æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹çš„å¯é æ€§ã€‚

**å…³é”®è¯**ï¼šä¼ªé€ å›¾åƒæ£€æµ‹, ç”Ÿæˆå›¾åƒæ£€æµ‹, è·¨ç”Ÿæˆå™¨æ³›åŒ–, åˆ†å¸ƒç§»ä½é²æ£’æ€§, çœŸå®åˆ†å¸ƒå†³ç­–è¾¹ç•Œ, æ±‡ç±»åˆ†ç±», æ½œå˜é‡æ··åˆæ­£åˆ™åŒ–ï¼ˆLBRï¼‰, å¯é æ€§å¯¼å‘è¯„æµ‹, é£é™©è°ƒæ•´æŒ‡æ ‡, æœ€åæƒ…å†µä¼°è®¡

**è¯„åˆ†**ï¼š29

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20412v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20412v1.pdf)

---

## [8. CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation](https://arxiv.org/abs/2602.20409v1)

**ä½œè€…**ï¼šMainak Singha, Sarthak Mehrotra, Paolo Casari ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent vision-language models (VLMs) such as CLIP demonstrate impressive cross-modal reasoning, extending beyond images to 3D perception. Yet, these models remain fragile under domain shifts, especially when adapting from synthetic to real-world point clouds. Conventional 3D domain adaptation approaches rely on heavy trainable encoders, yielding strong accuracy but at the cost of efficiency. We introduce CLIPoint3D, the first framework for few-shot unsupervised 3D point cloud domain adaptation built upon CLIP. Our approach projects 3D samples into multiple depth maps and exploits the frozen CLIP backbone, refined through a knowledge-driven prompt tuning scheme that integrates high-level language priors with geometric cues from a lightweight 3D encoder. To adapt task-specific features effectively, we apply parameter-efficient fine-tuning to CLIP's encoders and design an entropy-guided view sampling strategy for selecting confident projections. Furthermore, an optimal transport-based alignment loss and an uncertainty-aware prototype alignment loss collaboratively bridge source-target distribution gaps while maintaining class separability. Extensive experiments on PointDA-10 and GraspNetPC-10 benchmarks show that CLIPoint3D achieves consistent 3-16% accuracy gains over both CLIP-based and conventional encoder-based baselines. Codes are available at https://github.com/SarthakM320/CLIPoint3D.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCLIPoint3D åˆ©ç”¨å†»ç»“çš„ CLIP è§†è§‰-è¯­è¨€èƒ½åŠ›ä¸è½»é‡3Då‡ ä½•ç¼–ç å™¨ï¼Œé€šè¿‡æç¤ºè°ƒä¼˜ä¸å¯¹é½æŸå¤±å®ç°å°‘æ ·æœ¬æ— ç›‘ç£3Dç‚¹äº‘è·¨åŸŸé€‚é…ï¼Œå¹¶åœ¨åŸºå‡†ä¸Šæ˜¾è‘—æå‡å‡†ç¡®ç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰3DåŸŸé€‚é…æ–¹æ³•å¤šä¾èµ–é‡å‹å¯è®­ç»ƒç¼–ç å™¨ï¼Œç²¾åº¦é«˜ä½†æ•ˆç‡å·®ï¼›è€ŒCLIPç­‰VLMè™½å…·è·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›ï¼Œå´åœ¨åˆæˆåˆ°çœŸå®ç‚¹äº‘çš„åŸŸåç§»ä¸‹è¡¨ç°è„†å¼±ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†ç‚¹äº‘æŠ•å½±ä¸ºå¤šè§†è§’æ·±åº¦å›¾è¾“å…¥å†»ç»“CLIPï¼Œå¹¶ç»“åˆçŸ¥è¯†é©±åŠ¨çš„prompt tuningï¼ˆè¯­è¨€å…ˆéªŒ+å‡ ä½•çº¿ç´¢ï¼‰ä¸å‚æ•°é«˜æ•ˆå¾®è°ƒæ¥é€‚é…ä»»åŠ¡ç‰¹å¾ï¼›åŒæ—¶ç”¨ç†µå¼•å¯¼è§†è§’é‡‡æ ·é€‰å–é«˜ç½®ä¿¡æŠ•å½±ï¼Œå¹¶ä»¥æœ€ä¼˜ä¼ è¾“å¯¹é½æŸå¤±+ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„åŸå‹å¯¹é½æŸå¤±ç¼©å°æº/ç›®æ ‡åˆ†å¸ƒå·®å¼‚å¹¶ä¿æŒç±»é—´å¯åˆ†ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨PointDA-10ä¸GraspNetPC-10ä¸Šï¼ŒCLIPoint3D ç›¸æ¯”CLIPç±»ä¸ä¼ ç»Ÿç¼–ç å™¨åŸºçº¿å‡è·å¾—ç¨³å®šçš„3â€“16%å‡†ç¡®ç‡æå‡ï¼Œè¯æ˜å†»ç»“VLMé…åˆè½»é‡å‡ ä½•ä¸é«˜æ•ˆå¯¹é½ç­–ç•¥å¯æœ‰æ•ˆåº”å¯¹3Dç‚¹äº‘åŸŸè¿ç§»ã€‚

**å…³é”®è¯**ï¼š3Dç‚¹äº‘, é¢†åŸŸé€‚åº”, æ— ç›‘ç£å­¦ä¹ , å°‘æ ·æœ¬å­¦ä¹ , æ·±åº¦å›¾, çŸ¥è¯†é©±åŠ¨, å‚æ•°é«˜æ•ˆå¾®è°ƒ, å®éªŒè¯„æµ‹

**è¯„åˆ†**ï¼š29

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20409v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20409v1.pdf)

---

## cs.LG

## [9. GauS: Differentiable Scheduling Optimization via Gaussian Reparameterization](https://arxiv.org/abs/2602.20427v1)

**ä½œè€…**ï¼šYaohui Cai, Vesal Bakhtazad, Cunxi Yu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AR  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Efficient operator scheduling is a fundamental challenge in software compilation and hardware synthesis. While recent differentiable approaches have sought to replace traditional ones like exact solvers or heuristics with gradient-based search, they typically rely on categorical distributions that fail to capture the ordinal nature of time and suffer from a parameter space that scales poorly. In this paper, we propose a novel differentiable framework, GauS, that models operator scheduling as a stochastic relaxation using Gaussian distributions, which fully utilize modern parallel computing devices like GPUs. By representing schedules as continuous Gaussian variables, we successfully capture the ordinal nature of time and reduce the optimization space by orders of magnitude. Our method is highly flexible to represent various objectives and constraints, which provides the first differentiable formulation for the complex pipelined scheduling problem. We evaluate our method on a range of benchmarks, demonstrating that Gaus achieves Pareto-optimal results.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šGauSç”¨é«˜æ–¯é‡å‚æ•°åŒ–å°†ç®—å­è°ƒåº¦è¿ç»­åŒ–å¹¶å¯å¾®ä¼˜åŒ–ï¼Œåœ¨GPUä¸Šé«˜æ•ˆè¿›è¡Œæ¢¯åº¦æœç´¢ï¼Œå–å¾—å¤šç›®æ ‡ä¸‹çš„Paretoæœ€ä¼˜è°ƒåº¦ç»“æœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¯å¾®è°ƒåº¦å¤šç”¨ç±»åˆ«åˆ†å¸ƒå»ºæ¨¡ï¼Œæ—¢éš¾è¡¨è¾¾æ—¶é—´çš„åºå…³ç³»ï¼ˆordinalï¼‰ï¼Œåˆå¯¼è‡´å‚æ•°ç©ºé—´éšæ—¶é—´/å€™é€‰è§„æ¨¡è†¨èƒ€ã€ä¼˜åŒ–æ•ˆç‡å·®ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†æ¯ä¸ªç®—å­å¼€å§‹æ—¶é—´/è°ƒåº¦å†³ç­–æ¾å¼›ä¸ºè¿ç»­é«˜æ–¯éšæœºå˜é‡ï¼Œé€šè¿‡é«˜æ–¯é‡å‚æ•°åŒ–å®ç°ç«¯åˆ°ç«¯å¯å¾®çš„æ¢¯åº¦ä¼˜åŒ–ï¼Œå¹¶ä»¥å¯ç»„åˆçš„ç›®æ ‡ä¸çº¦æŸé¡¹ç»Ÿä¸€è¡¨è¾¾ï¼ˆå«å¤æ‚æµæ°´çº¿pipelinedè°ƒåº¦ï¼‰ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å¤šç»„åŸºå‡†ä¸Šï¼ŒGauSåœ¨ä¸åŒç›®æ ‡æƒè¡¡ä¸‹è¾¾åˆ°æˆ–é€¼è¿‘Paretoæœ€ä¼˜ï¼ŒåŒæ—¶ç›¸æ¯”ç±»åˆ«åŒ–æ–¹æ³•æ˜¾è‘—é™ä½ä¼˜åŒ–ç»´åº¦å¹¶æ›´å¥½åˆ©ç”¨å¹¶è¡Œç¡¬ä»¶åŠ é€Ÿã€‚

**å…³é”®è¯**ï¼šå¯å¾®åˆ†è°ƒåº¦ä¼˜åŒ–, ç®—å­è°ƒåº¦, é«˜æ–¯é‡å‚æ•°åŒ–, éšæœºæ¾å¼›, è¿ç»­è°ƒåº¦è¡¨ç¤º, æ¢¯åº¦ä¼˜åŒ–æœç´¢, ç¼–è¯‘å™¨ä¼˜åŒ–, ç¡¬ä»¶ç»¼åˆ, æµæ°´çº¿è°ƒåº¦, å¤šç›®æ ‡å¸•ç´¯æ‰˜ä¼˜åŒ–, è°ƒåº¦çº¦æŸå»ºæ¨¡

**è¯„åˆ†**ï¼š33

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20427v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20427v1.pdf)

---

## [10. CREDIT: Certified Ownership Verification of Deep Neural Networks Against Model Extraction Attacks](https://arxiv.org/abs/2602.20419v1)

**ä½œè€…**ï¼šBolin Shen, Zhan Cheng, Neil Zhenqiang Gong ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Machine Learning as a Service (MLaaS) has emerged as a widely adopted paradigm for providing access to deep neural network (DNN) models, enabling users to conveniently leverage these models through standardized APIs. However, such services are highly vulnerable to Model Extraction Attacks (MEAs), where an adversary repeatedly queries a target model to collect input-output pairs and uses them to train a surrogate model that closely replicates its functionality. While numerous defense strategies have been proposed, verifying the ownership of a suspicious model with strict theoretical guarantees remains a challenging task. To address this gap, we introduce CREDIT, a certified ownership verification against MEAs. Specifically, we employ mutual information to quantify the similarity between DNN models, propose a practical verification threshold, and provide rigorous theoretical guarantees for ownership verification based on this threshold. We extensively evaluate our approach on several mainstream datasets across different domains and tasks, achieving state-of-the-art performance. Our implementation is publicly available at: https://github.com/LabRAI/CREDIT.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCREDIT æå‡ºä¸€ç§å¯¹æŠ—æ¨¡å‹æŠ½å–æ”»å‡»çš„â€œå¯è®¤è¯â€ç¥ç»ç½‘ç»œæ‰€æœ‰æƒéªŒè¯æ–¹æ³•ï¼Œç”¨äº’ä¿¡æ¯åº¦é‡æ¨¡å‹ç›¸ä¼¼æ€§å¹¶ç»™å‡ºå¸¦ç†è®ºä¿è¯çš„åˆ¤å®šé˜ˆå€¼ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šMLaaS åœºæ™¯ä¸‹æ¨¡å‹æ˜“è¢«åå¤æŸ¥è¯¢å¹¶è®­ç»ƒå‡ºé«˜ç›¸ä¼¼çš„æ›¿ä»£æ¨¡å‹ï¼Œç°æœ‰é˜²å¾¡å¤šä½†å¯¹â€œå¦‚ä½•ä¸¥æ ¼è¯æ˜æŸå¯ç–‘æ¨¡å‹æ˜¯å¦ä¸ºè¢«ç›—æ‹·è´â€ç¼ºä¹å¯éªŒè¯çš„ç†è®ºä¿éšœã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç”¨äº’ä¿¡æ¯ï¼ˆmutual informationï¼‰é‡åŒ–ç›®æ ‡æ¨¡å‹ä¸å¯ç–‘æ¨¡å‹åœ¨è¾“å‡ºè¡Œä¸ºä¸Šçš„ç›¸ä¼¼åº¦ï¼Œæ„å»ºä¸€ä¸ªå¯å®è·µçš„éªŒè¯é˜ˆå€¼ï¼Œå¹¶å›´ç»•è¯¥é˜ˆå€¼æ¨å¯¼æ‰€æœ‰æƒåˆ¤å®šçš„ä¸¥æ ¼ç†è®ºä¿è¯ï¼›éšååœ¨å¤šæ•°æ®é›†ã€å¤šä»»åŠ¡ä¸Šè¿›è¡Œå®è¯è¯„ä¼°ã€‚

**ä¸»è¦ç»“è®º**ï¼šCREDIT åœ¨ä¸åŒé¢†åŸŸä¸ä»»åŠ¡çš„æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„æ‰€æœ‰æƒéªŒè¯æ•ˆæœï¼Œå¹¶èƒ½åœ¨æ¨¡å‹æŠ½å–æ”»å‡»èƒŒæ™¯ä¸‹æä¾›æ›´å¼ºçš„ã€å¯è¯æ˜çš„æ‰€æœ‰æƒåˆ¤å®šä¾æ®ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ å³æœåŠ¡, æ·±åº¦ç¥ç»ç½‘ç»œ, æ¨¡å‹æå–æ”»å‡», æ¨¡å‹æ‰€æœ‰æƒéªŒè¯, è®¤è¯é²æ£’æ€§, æ¨¡å‹ç›¸ä¼¼åº¦åº¦é‡, éªŒè¯é˜ˆå€¼, ç†è®ºä¿è¯, æ›¿ä»£æ¨¡å‹æ£€æµ‹

**è¯„åˆ†**ï¼š30

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20419v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20419v1.pdf)

---

## [11. CITED: A Decision Boundary-Aware Signature for GNNs Towards Model Extraction Defense](https://arxiv.org/abs/2602.20418v1)

**ä½œè€…**ï¼šBolin Shen, Md Shamim Seraj, Zhan Cheng ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Graph neural networks (GNNs) have demonstrated superior performance in various applications, such as recommendation systems and financial risk management. However, deploying large-scale GNN models locally is particularly challenging for users, as it requires significant computational resources and extensive property data. Consequently, Machine Learning as a Service (MLaaS) has become increasingly popular, offering a convenient way to deploy and access various models, including GNNs. However, an emerging threat known as Model Extraction Attacks (MEAs) presents significant risks, as adversaries can readily obtain surrogate GNN models exhibiting similar functionality. Specifically, attackers repeatedly query the target model using subgraph inputs to collect corresponding responses. These input-output pairs are subsequently utilized to train their own surrogate models at minimal cost. Many techniques have been proposed to defend against MEAs, but most are limited to specific output levels (e.g., embedding or label) and suffer from inherent technical drawbacks. To address these limitations, we propose a novel ownership verification framework CITED which is a first-of-its-kind method to achieve ownership verification on both embedding and label levels. Moreover, CITED is a novel signature-based method that neither harms downstream performance nor introduces auxiliary models that reduce efficiency, while still outperforming all watermarking and fingerprinting approaches. Extensive experiments demonstrate the effectiveness and robustness of our CITED framework. Code is available at: https://github.com/LabRAI/CITED.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCITEDæå‡ºä¸€ç§â€œå†³ç­–è¾¹ç•Œæ„ŸçŸ¥â€çš„GNNç­¾åæ¡†æ¶ï¼Œå¯åœ¨ä¸æŸå®³æ¨¡å‹æ€§èƒ½ä¸æ•ˆç‡çš„å‰æä¸‹ï¼ŒåŒæ—¶åœ¨åµŒå…¥ä¸æ ‡ç­¾ä¸¤å±‚é¢å®ç°å¯¹æŠ—æ¨¡å‹æŠ½å–æ”»å‡»çš„æ‰€æœ‰æƒéªŒè¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šGNNä»¥MLaaSå½¢å¼éƒ¨ç½²æ—¶æ˜“é­æ¨¡å‹æŠ½å–æ”»å‡»ï¼Œæ”»å‡»è€…é€šè¿‡å¤§é‡å­å›¾æŸ¥è¯¢è®­ç»ƒåŠŸèƒ½ç›¸è¿‘çš„æ›¿ä»£æ¨¡å‹ï¼›ç°æœ‰é˜²å¾¡å¤šä»…è¦†ç›–å•ä¸€è¾“å‡ºå±‚çº§ï¼ˆåµŒå…¥æˆ–æ ‡ç­¾ï¼‰ä¸”å¸¸ä¼´éšæ€§èƒ½/æ•ˆç‡ä»£ä»·ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCITEDæ„å»ºåŸºäºå†³ç­–è¾¹ç•Œçš„ç­¾åæœºåˆ¶ï¼Œå°†å¯éªŒè¯çš„â€œæ‰€æœ‰æƒç‰¹å¾â€åŒæ—¶æ³¨å…¥/ç»‘å®šåˆ°åµŒå…¥è¡¨ç¤ºä¸æœ€ç»ˆæ ‡ç­¾è¾“å‡ºä¸­ï¼›è¯¥æ–¹æ³•æ— éœ€é¢å¤–è¾…åŠ©æ¨¡å‹ã€å¯¹ä¸‹æ¸¸ä»»åŠ¡ç²¾åº¦å½±å“å°ï¼Œå¹¶ä½œä¸ºç­¾åå¼éªŒè¯ä¼˜äºä¼ ç»Ÿæ°´å°/æŒ‡çº¹æ–¹æ¡ˆã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜CITEDåœ¨åµŒå…¥ä¸æ ‡ç­¾åŒå±‚é¢çš„æ‰€æœ‰æƒéªŒè¯ä¸Šæ›´æœ‰æ•ˆä¸”é²æ£’ï¼Œèƒ½åœ¨ä¿æŒä¸‹æ¸¸æ€§èƒ½ä¸æ¨ç†æ•ˆç‡çš„åŒæ—¶ï¼Œå¯¹æŠ—å¤šç§æ¨¡å‹æŠ½å–åœºæ™¯å¹¶æ•´ä½“ä¼˜äºç°æœ‰æ°´å°ä¸æŒ‡çº¹æ–¹æ³•ã€‚

**å…³é”®è¯**ï¼šå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰, æ¨¡å‹æŠ½å–æ”»å‡»ï¼ˆMEAï¼‰, æ¨¡å‹æ‰€æœ‰æƒéªŒè¯, å†³ç­–è¾¹ç•Œæ„ŸçŸ¥, æ¨¡å‹ç­¾å, æ°´å°é˜²æŠ¤, æ¨¡å‹æŒ‡çº¹, åµŒå…¥çº§éªŒè¯, æ ‡ç­¾çº§éªŒè¯, å­å›¾æŸ¥è¯¢æ”»å‡»

**è¯„åˆ†**ï¼š29

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20418v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20418v1.pdf)

---

## [12. $Îº$-Explorer: A Unified Framework for Active Model Estimation in MDPs](https://arxiv.org/abs/2602.20404v1)

**ä½œè€…**ï¼šXihe Gu, Urbashi Mitra, Tara Javidi  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

In tabular Markov decision processes (MDPs) with perfect state observability, each trajectory provides active samples from the transition distributions conditioned on state-action pairs. Consequently, accurate model estimation depends on how the exploration policy allocates visitation frequencies in accordance with the intrinsic complexity of each transition distribution. Building on recent work on coverage-based exploration, we introduce a parameterized family of decomposable and concave objective functions $U_Îº$ that explicitly incorporate both intrinsic estimation complexity and extrinsic visitation frequency. Moreover, the curvature $Îº$ provides a unified treatment of various global objectives, such as the average-case and worst-case estimation error objectives. Using the closed-form characterization of the gradient of $U_Îº$, we propose $Îº$-Explorer, an active exploration algorithm that performs Frank-Wolfe-style optimization over state-action occupancy measures. The diminishing-returns structure of $U_Îº$ naturally prioritizes underexplored and high-variance transitions, while preserving smoothness properties that enable efficient optimization. We establish tight regret guarantees for $Îº$-Explorer and further introduce a fully online and computationally efficient surrogate algorithm for practical use. Experiments on benchmark MDPs demonstrate that $Îº$-Explorer provides superior performance compared to existing exploration strategies.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºÎº-Explorerç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡å¯è°ƒæ›²ç‡Îºçš„ç›®æ ‡å‡½æ•°åœ¨MDPä¸­è‡ªé€‚åº”åˆ†é…è®¿é—®é¢‘æ¬¡ï¼Œå®ç°æ›´é«˜æ•ˆçš„ä¸»åŠ¨æ¨¡å‹ä¼°è®¡ä¸æ›´ä¼˜æ¢ç´¢æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨è¡¨æ ¼å‹MDPä¸­ï¼Œæ¨¡å‹ä¼°è®¡è¯¯å·®å–å†³äºæ¢ç´¢ç­–ç•¥å¦‚ä½•åœ¨ä¸åŒ(s,a)ä¸Šåˆ†é…é‡‡æ ·æ¬¡æ•°ï¼Œä½†ä¸åŒè½¬ç§»åˆ†å¸ƒçš„å†…åœ¨ä¼°è®¡éš¾åº¦ï¼ˆå¦‚æ–¹å·®ï¼‰ä¸ä¸€ï¼Œç°æœ‰è¦†ç›–å¼æ–¹æ³•éš¾ä»¥åŒæ—¶å…¼é¡¾å¹³å‡ä¸æœ€åæƒ…å†µç­‰ä¸åŒå…¨å±€ç›®æ ‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„é€ ä¸€æ—å¯åˆ†è§£ä¸”å‡¹çš„ç›®æ ‡å‡½æ•°U_Îºï¼Œå°†â€œå†…åœ¨ä¼°è®¡å¤æ‚åº¦â€å’Œâ€œå¤–åœ¨è®¿é—®é¢‘æ¬¡â€æ˜¾å¼ç»“åˆï¼Œå¹¶ç”¨æ›²ç‡Îºç»Ÿä¸€åˆ»ç”»å¹³å‡/æœ€åç­‰è¯¯å·®ç›®æ ‡ï¼›åŸºäºU_Îºæ¢¯åº¦çš„é—­å¼å½¢å¼ï¼Œé‡‡ç”¨Frank-Wolfeé£æ ¼åœ¨çŠ¶æ€-åŠ¨ä½œå ç”¨åº¦é‡ä¸Šåšä¼˜åŒ–å¾—åˆ°Îº-Explorerï¼Œå¹¶ç»™å‡ºåœ¨çº¿ã€è®¡ç®—æ›´é«˜æ•ˆçš„æ›¿ä»£å®ç°ã€‚

**ä¸»è¦ç»“è®º**ï¼šç†è®ºä¸Šè¯æ˜Îº-Explorerå…·æœ‰ç´§çš„é—æ†¾ï¼ˆregretï¼‰ä¿è¯ï¼Œèƒ½è‡ªç„¶ä¼˜å…ˆæ¢ç´¢ä½è¦†ç›–ä¸”é«˜æ–¹å·®çš„è½¬ç§»ï¼›å®éªŒä¸Šåœ¨åŸºå‡†MDPä¸­ä¼˜äºç°æœ‰æ¢ç´¢ç­–ç•¥ï¼Œä½“ç°å‡ºæ›´å‡†ç¡®çš„æ¨¡å‹ä¼°è®¡ä¸æ›´å¥½çš„æ€»ä½“æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šä¸»åŠ¨æ¨¡å‹ä¼°è®¡, è½¬ç§»æ¦‚ç‡ä¼°è®¡, è¦†ç›–å¼æ¢ç´¢, å‡¹ç›®æ ‡å‡½æ•°, æ›²ç‡å‚æ•°Îº, å¹³å‡-æœ€åè¯¯å·®ç»Ÿä¸€, é«˜æ–¹å·®è½¬ç§»ä¼˜å…ˆ, é—æ†¾ç•Œ

**è¯„åˆ†**ï¼š39

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20404v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20404v1.pdf)

---

## [13. Three Concrete Challenges and Two Hopes for the Safety of Unsupervised Elicitation](https://arxiv.org/abs/2602.20400v1)

**ä½œè€…**ï¼šCallum Canavan, Aditya Shrivastava, Allison Qi ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

To steer language models towards truthful outputs on tasks which are beyond human capability, previous work has suggested training models on easy tasks to steer them on harder ones (easy-to-hard generalization), or using unsupervised training algorithms to steer models with no external labels at all (unsupervised elicitation). Although techniques from both paradigms have been shown to improve model accuracy on a wide variety of tasks, we argue that the datasets used for these evaluations could cause overoptimistic evaluation results. Unlike many real-world datasets, they often (1) have no features with more salience than truthfulness, (2) have balanced training sets, and (3) contain only data points to which the model can give a well-defined answer. We construct datasets that lack each of these properties to stress-test a range of standard unsupervised elicitation and easy-to-hard generalization techniques. We find that no technique reliably performs well on any of these challenges. We also study ensembling and combining easy-to-hard and unsupervised techniques, and find they only partially mitigate performance degradation due to these challenges. We believe that overcoming these challenges should be a priority for future work on unsupervised elicitation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æŒ‡å‡ºç°æœ‰â€œæ— ç›‘ç£è¯±å¯¼/ç”±æ˜“åˆ°éš¾æ³›åŒ–â€è¯„æµ‹æ•°æ®é›†è¿‡äºç†æƒ³åŒ–ï¼Œå¹¶æ„é€ ä¸‰ç±»æ›´è´´è¿‘ç°å®çš„å‹åŠ›æµ‹è¯•æ•°æ®é›†åå‘ç°ä¸»æµæ–¹æ³•åœ¨è¿™äº›æŒ‘æˆ˜ä¸‹éƒ½ä¸ç¨³å®šã€éš¾ä»¥å¯é æå‡çœŸå®æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨è¶…å‡ºäººç±»èƒ½åŠ›çš„ä»»åŠ¡ä¸ŠéªŒè¯æ¨¡å‹æ˜¯å¦â€œè¯´çœŸè¯â€å¾ˆéš¾ï¼Œç°æœ‰å·¥ä½œä¾èµ–æ˜“ä»»åŠ¡ç›‘ç£æˆ–æ— ç›‘ç£ä¿¡å·æ¥å¯¹é½ï¼Œä½†ä½œè€…æ€€ç–‘å¸¸ç”¨åŸºå‡†å› æ•°æ®åˆ†å¸ƒè¿‡äºå¹²å‡€è€Œé«˜ä¼°äº†æ–¹æ³•æ•ˆæœã€‚ä¸ºæ­¤éœ€è¦åœ¨æ›´ç°å®çš„æ¡ä»¶ï¼ˆå¼ºå¹²æ‰°ç‰¹å¾ã€ç±»åˆ«ä¸å¹³è¡¡ã€å­˜åœ¨æ— æ˜ç¡®ç­”æ¡ˆæ ·æœ¬ï¼‰ä¸‹æ£€éªŒè¿™äº›æ–¹æ³•çš„é²æ£’æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…åˆ†åˆ«æ„é€ ç¼ºå¤±ä¸‰ç§â€œç†æƒ³æ€§è´¨â€çš„æ•°æ®é›†ï¼š(1) å­˜åœ¨æ¯”çœŸå®æ€§æ›´æ˜¾è‘—çš„ç‰¹å¾å¹²æ‰°ï¼Œ(2) è®­ç»ƒé›†ç±»åˆ«ä¸å¹³è¡¡ï¼Œ(3) åŒ…å«æ¨¡å‹æ— æ³•ç»™å‡ºå®šä¹‰è‰¯å¥½ç­”æ¡ˆçš„æ•°æ®ç‚¹ï¼›ç„¶åç³»ç»Ÿè¯„æµ‹å¤šç§æ ‡å‡†æ— ç›‘ç£è¯±å¯¼ä¸ç”±æ˜“åˆ°éš¾æ³›åŒ–æŠ€æœ¯ï¼Œå¹¶è¿›ä¸€æ­¥æµ‹è¯•é›†æˆ(ensembling)åŠä¸¤ç±»æ–¹æ³•çš„ç»„åˆèƒ½å¦ç¼“è§£é€€åŒ–ã€‚

**ä¸»è¦ç»“è®º**ï¼šç»“æœæ˜¾ç¤ºï¼šåœ¨ä»»ä¸€æŒ‘æˆ˜è®¾ç½®ä¸‹ï¼Œæ²¡æœ‰ä¸€ç§æŠ€æœ¯èƒ½ç¨³å®šä¿æŒè‰¯å¥½è¡¨ç°ï¼Œé›†æˆæˆ–ç»„åˆæ–¹æ³•åªèƒ½éƒ¨åˆ†ç¼“è§£æ€§èƒ½ä¸‹é™ä½†æ— æ³•æ ¹æ²»ï¼›ä½œè€…å› æ­¤è®¤ä¸ºè§£å†³è¿™ä¸‰é¡¹ç°å®æ•°æ®æŒ‘æˆ˜åº”æˆä¸ºæœªæ¥æ— ç›‘ç£è¯±å¯¼ç ”ç©¶çš„ä¼˜å…ˆæ–¹å‘ã€‚

**å…³é”®è¯**ï¼šæ— ç›‘ç£å¼•å‡º, æ˜“åˆ°éš¾æ³›åŒ–, LLM çœŸå®è¾“å‡º, è¶…äººä»»åŠ¡å¯¹é½, è¯„æµ‹é›†åå·®, åˆ†å¸ƒå¤–è¯„æµ‹, ç‰¹å¾æ˜¾è‘—æ€§å¹²æ‰°, ç±»åˆ«ä¸å¹³è¡¡, ä¸å¯åˆ¤å®šæ ·æœ¬, å‹åŠ›æµ‹è¯•æ•°æ®é›†, æ¨¡å‹é›†æˆ

**è¯„åˆ†**ï¼š27

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20400v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20400v1.pdf)

---

## [14. GeoPT: Scaling Physics Simulation via Lifted Geometric Pre-Training](https://arxiv.org/abs/2602.20399v1)

**ä½œè€…**ï¼šHaixu Wu, Minghao Guo, Zongyi Li ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Neural simulators promise efficient surrogates for physics simulation, but scaling them is bottlenecked by the prohibitive cost of generating high-fidelity training data. Pre-training on abundant off-the-shelf geometries offers a natural alternative, yet faces a fundamental gap: supervision on static geometry alone ignores dynamics and can lead to negative transfer on physics tasks. We present GeoPT, a unified pre-trained model for general physics simulation based on lifted geometric pre-training. The core idea is to augment geometry with synthetic dynamics, enabling dynamics-aware self-supervision without physics labels. Pre-trained on over one million samples, GeoPT consistently improves industrial-fidelity benchmarks spanning fluid mechanics for cars, aircraft, and ships, and solid mechanics in crash simulation, reducing labeled data requirements by 20-60% and accelerating convergence by 2$\times$. These results show that lifting with synthetic dynamics bridges the geometry-physics gap, unlocking a scalable path for neural simulation and potentially beyond. Code is available at https://github.com/Physics-Scaling/GeoPT.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šGeoPTé€šè¿‡â€œåˆæˆåŠ¨åŠ›å­¦â€å¢å¼ºå‡ ä½•è‡ªç›‘ç£é¢„è®­ç»ƒï¼Œæ˜¾è‘—é™ä½é«˜ä¿çœŸç‰©ç†ä»¿çœŸç¥ç»æ¨¡å‹å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–å¹¶åŠ é€Ÿæ”¶æ•›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç¥ç»ç‰©ç†ä»¿çœŸæ‰©å±•å—é™äºé«˜ä¿çœŸè®­ç»ƒæ•°æ®ç”Ÿæˆæˆæœ¬ï¼›ä»…ç”¨é™æ€å‡ ä½•åšé¢„è®­ç»ƒå¿½ç•¥åŠ¨åŠ›å­¦ä¿¡æ¯ï¼Œå®¹æ˜“åœ¨çœŸå®ç‰©ç†ä»»åŠ¡ä¸Šäº§ç”Ÿè´Ÿè¿ç§»ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºLifted Geometric Pre-Trainingï¼šåœ¨æ— ç‰©ç†æ ‡ç­¾æ¡ä»¶ä¸‹ä¸ºå‡ ä½•æ ·æœ¬æ³¨å…¥åˆæˆåŠ¨åŠ›å­¦ä¿¡å·ï¼Œè¿›è¡ŒåŠ¨åŠ›å­¦æ„ŸçŸ¥çš„è‡ªç›‘ç£é¢„è®­ç»ƒï¼Œå¾—åˆ°ç»Ÿä¸€çš„é€šç”¨ç‰©ç†ä»¿çœŸé¢„è®­ç»ƒæ¨¡å‹GeoPTã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨æ±½è½¦/é£æœº/èˆ¹èˆ¶æµä½“ä¸ç¢°æ’å›ºä½“ç­‰å·¥ä¸šçº§åŸºå‡†ä¸Šï¼ŒGeoPTç¨³å®šæå‡æ€§èƒ½ï¼Œæ ‡æ³¨æ•°æ®éœ€æ±‚å‡å°‘20-60%ï¼Œæ”¶æ•›é€Ÿåº¦æå‡çº¦2å€ï¼ŒéªŒè¯åˆæˆåŠ¨åŠ›å­¦å¯å¼¥åˆå‡ ä½•-ç‰©ç†é¸¿æ²Ÿå¹¶æ”¯æŒè§„æ¨¡åŒ–ç¥ç»ä»¿çœŸã€‚

**å…³é”®è¯**ï¼šç¥ç»ç‰©ç†ä»¿çœŸå™¨, ç‰©ç†ä»¿çœŸæ›¿ä»£æ¨¡å‹, å‡ ä½•é¢„è®­ç»ƒ, æå‡å¼è¡¨ç¤ºå­¦ä¹ , åˆæˆåŠ¨åŠ›å­¦, åŠ¨åŠ›å­¦æ„ŸçŸ¥è‡ªç›‘ç£, æ— æ ‡ç­¾é¢„è®­ç»ƒ, å‡ ä½•-ç‰©ç†è¿ç§», è´Ÿè¿ç§», å·¥ä¸šçº§æµä½“åŠ›å­¦ä»¿çœŸ, å·¥ä¸šçº§å›ºä½“åŠ›å­¦ä»¿çœŸ, æ ‡æ³¨æ•°æ®ç¼©å‡

**è¯„åˆ†**ï¼š41

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20399v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20399v1.pdf)

---

## [15. cc-Shapley: Measuring Multivariate Feature Importance Needs Causal Context](https://arxiv.org/abs/2602.20396v1)

**ä½œè€…**ï¼šJÃ¶rg Martin, Stefan Haufe  
**åˆ†ç±»**ï¼šcs.LG, stat.ME  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-23

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Explainable artificial intelligence promises to yield insights into relevant features, thereby enabling humans to examine and scrutinize machine learning models or even facilitating scientific discovery. Considering the widespread technique of Shapley values, we find that purely data-driven operationalization of multivariate feature importance is unsuitable for such purposes. Even for simple problems with two features, spurious associations due to collider bias and suppression arise from considering one feature only in the observational context of the other, which can lead to misinterpretations. Causal knowledge about the data-generating process is required to identify and correct such misleading feature attributions. We propose cc-Shapley (causal context Shapley), an interventional modification of conventional observational Shapley values leveraging knowledge of the data's causal structure, thereby analyzing the relevance of a feature in the causal context of the remaining features. We show theoretically that this eradicates spurious association induced by collider bias. We compare the behavior of Shapley and cc-Shapley values on various, synthetic, and real-world datasets. We observe nullification or reversal of associations compared to univariate feature importance when moving from observational to cc-Shapley.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šcc-Shapleyå°†Shapleyç‰¹å¾é‡è¦æ€§ä»â€œè§‚æµ‹å…³è”â€æ”¹ä¸ºåŸºäºå› æœç»“æ„çš„â€œå¹²é¢„è¯­å¢ƒâ€ï¼Œä»¥æ¶ˆé™¤ç¢°æ’åå·®ç­‰å¯¼è‡´çš„è™šå‡å¤šå˜é‡å½’å› ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»ŸShapleyå€¼åœ¨å¤šç‰¹å¾è®¾ç½®ä¸‹ä»…ä¾èµ–è§‚æµ‹åˆ†å¸ƒï¼Œå®¹æ˜“å› ç¢°æ’å™¨åå·®ä¸æŠ‘åˆ¶æ•ˆåº”æŠŠç›¸å…³æ€§è¯¯å½“å› æœè´¡çŒ®ï¼Œä»è€Œè¯¯å¯¼è§£é‡Šä¸ç§‘å­¦å‘ç°ã€‚ä½œè€…è®¤ä¸ºè¦å¾—åˆ°å¯ä¿¡çš„ç‰¹å¾å½’å› ï¼Œå¿…é¡»å¼•å…¥æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„å› æœçŸ¥è¯†ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºcc-Shapleyï¼ˆcausal context Shapleyï¼‰ï¼Œåˆ©ç”¨å·²çŸ¥å› æœå›¾å¯¹æŸç‰¹å¾è¿›è¡Œå¹²é¢„å¼æ›¿æ¢/å–å€¼ï¼Œå¹¶åœ¨â€œå…¶ä½™ç‰¹å¾çš„å› æœè¯­å¢ƒâ€ä¸‹è®¡ç®—è¾¹é™…è´¡çŒ®ï¼Œä»è€Œæ›¿ä»£çº¯è§‚æµ‹æ¡ä»¶ä¸‹çš„Shapleyè®¡ç®—ã€‚ç†è®ºä¸Šè¯æ˜è¯¥æ”¹åŠ¨å¯æ¶ˆé™¤ç”±ç¢°æ’å™¨åå·®å¼•èµ·çš„è™šå‡å…³è”ï¼Œå¹¶åœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå¯¹æ¯”å…¶ä¸å¸¸è§„Shapleyçš„å·®å¼‚ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å¤šå˜é‡é‡è¦æ€§è¯„ä¼°ä¸­ï¼Œå¿½ç•¥å› æœç»“æ„ä¼šäº§ç”Ÿç³»ç»Ÿæ€§è¯¯å½’å› ï¼›cc-Shapleyèƒ½åœ¨ç†è®ºä¸Šæ ¹é™¤ç¢°æ’å™¨åå·®å¸¦æ¥çš„è™šå‡é‡è¦æ€§ã€‚å®éªŒæ˜¾ç¤ºä»è§‚æµ‹Shapleyè½¬å‘cc-Shapleyåï¼ŒæŸäº›ç‰¹å¾çš„é‡è¦æ€§ä¼šè¢«â€œå½’é›¶â€ç”šè‡³æ–¹å‘åè½¬ï¼Œå¼ºè°ƒè§£é‡Šéœ€è¦å› æœè¯­å¢ƒã€‚

**å…³é”®è¯**ï¼šå¤šå˜é‡ç‰¹å¾é‡è¦æ€§, ç‰¹å¾å½’å› , å› æœæ¨æ–­, è§‚æµ‹å½’å› åå·®, å› æœç»“æ„å›¾ï¼ˆDAGï¼‰, cc-Shapley, Measuring, Multivariate

**è¯„åˆ†**ï¼š19

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.20396v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.20396v1.pdf)

---

