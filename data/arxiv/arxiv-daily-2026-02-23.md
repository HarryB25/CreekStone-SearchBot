# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-23

> å…± 30 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (13 ç¯‡)
- [cs.CL](#csCL) (7 ç¯‡)
- [cs.CV](#csCV) (9 ç¯‡)
- [cs.AI](#csAI) (1 ç¯‡)

---

## cs.AI

## [1. Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291v1)

**ä½œè€…**ï¼šZhuoran Li, Hai Zhong, Xun Wang ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºOMADæ¡†æ¶ï¼Œå°†æ‰©æ•£ç­–ç•¥å¼•å…¥åœ¨çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡æ”¾æ¾çš„ç†µç›®æ ‡ä¸åˆ†å¸ƒå¼ä»·å€¼å‡½æ•°å®ç°é«˜æ•ˆååŒä¸æ˜¾è‘—æå‡æ ·æœ¬æ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰åœ¨çº¿å¤šæ™ºèƒ½ä½“RLåœ¨ç­–ç•¥è¡¨è¾¾èƒ½åŠ›å’Œå¤æ‚ååŒä»»åŠ¡çš„æ¢ç´¢æ–¹é¢å—é™ï¼Œè€Œæ‰©æ•£æ¨¡å‹è™½å…·å¼ºè¡¨è¾¾åŠ›ï¼Œå´å› ä¼¼ç„¶éš¾ä»¥è®¡ç®—éš¾ä»¥ç›´æ¥ç”¨äºéœ€è¦ç†µæ­£åˆ™çš„åœ¨çº¿MARLã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºåœ¨çº¿ç¦»ç­–ç•¥å¤šæ™ºèƒ½ä½“æ‰©æ•£ç­–ç•¥æ¡†æ¶OMADï¼š1ï¼‰è®¾è®¡åŸºäºâ€œç¼©æ”¾è”åˆç†µâ€çš„æ”¾æ¾ç­–ç•¥ç›®æ ‡ï¼Œåœ¨æ— éœ€å¯ tractable ä¼¼ç„¶çš„å‰æä¸‹å®ç°æ¢ç´¢ä¸åè°ƒï¼›2ï¼‰åœ¨CTDEæ¶æ„ä¸‹å¼•å…¥è”åˆåˆ†å¸ƒå¼ä»·å€¼å‡½æ•°ï¼Œé€šè¿‡å¯è®¡ç®—çš„ç†µå¢å¼ºç›®æ ‡è”åˆä¼˜åŒ–å¤šä¸ªå»ä¸­å¿ƒåŒ–æ‰©æ•£ç­–ç•¥ï¼Œä¿è¯ç¨³å®šååŒæ›´æ–°ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨MPEä¸MAMuJoCoçš„10ä¸ªä»»åŠ¡ä¸Šï¼ŒOMADå–å¾—æ–°çš„SOTAè¡¨ç°ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•æ ·æœ¬æ•ˆç‡æå‡çº¦2.5â€“5å€ï¼ŒéªŒè¯äº†æ‰©æ•£ç­–ç•¥åœ¨åœ¨çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ä¸ååŒèƒ½åŠ›ä¼˜åŠ¿ã€‚

**å…³é”®è¯**ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ , æ‰©æ•£æ¨¡å‹, ç”Ÿæˆå¼ç­–ç•¥, è”åˆç†µæœ€å¤§åŒ–, é›†ä¸­è®­ç»ƒåˆ†æ•£æ‰§è¡Œ, åˆ†å¸ƒå¼ä»·å€¼å‡½æ•°, MPEç¯å¢ƒ, MAMuJoCoåè°ƒæ§åˆ¶, agent

**è¯„åˆ†**ï¼š40

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18291v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18291v1.pdf)

---

## cs.CL

## [2. VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429v1)

**ä½œè€…**ï¼šHarshul Raj Surana, Arijit Maji, Aryan Vats ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.IR  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºå°åº¦æ–‡åŒ–å¤šè·³æ¨ç†æ•°æ®é›† VIRAASATï¼Œå¹¶é€šè¿‡ç¬¦å·åŒ–çš„ Chain-of-Manipulation è®­ç»ƒæ¡†æ¶ SCoMï¼Œæ˜¾è‘—æå‡å¤§æ¨¡å‹åœ¨å°åº¦æ–‡åŒ–æ¨ç†ä¸Šçš„è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤§æ¨¡å‹åœ¨éœ€è¦ä¸°å¯Œç¤¾ä¼šæ–‡åŒ–ä¸æœ¬åœ°èƒŒæ™¯çŸ¥è¯†ï¼ˆå°¤å…¶æ˜¯å°åº¦æ–‡åŒ–ï¼‰çš„å¤šè·³æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è¾ƒå·®ï¼Œè€Œç°æœ‰æ–‡åŒ–åŸºå‡†å¤šä¸ºäººå·¥å•è·³é—®ç­”ï¼Œè§„æ¨¡å°ä¸”éš¾æ‰©å±•ï¼Œæ— æ³•ç³»ç»Ÿè¡¡é‡è¿™ä¸€ç¼ºé™·ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºåŒ…å«700+ä¸“å®¶æ ‡æ³¨æ–‡åŒ–å®ä½“å’Œ13ç±»å±æ€§çš„çŸ¥è¯†å›¾è°±ï¼Œè¦†ç›–å°åº¦å…¨éƒ¨28é‚¦å’Œ8ä¸ªè”é‚¦å±åœ°ï¼ŒåŠè‡ªåŠ¨ç”Ÿæˆ3200+å¤šè·³æ–‡åŒ–é—®ç­”æ•°æ®é›† VIRAASATï¼›å¹¶æå‡º SCoM æ¡†æ¶ï¼Œè®©æ¨¡å‹åœ¨å†…éƒ¨æ¨¡æ‹Ÿå¯¹çŸ¥è¯†å›¾è°±çš„åŸå­æ“ä½œï¼Œä»è€Œå­¦ä¹ å›¾ç»“æ„éå†å’Œç¬¦å·åŒ–å¤šè·³æ¨ç†ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ç›‘ç£å¾®è°ƒåœºæ™¯ä¸‹ï¼ŒSCoM ç›¸æ¯”æ ‡å‡† Chain-of-Thought åŸºçº¿åœ¨ VIRAASAT ä¸Šå¯æå‡æœ€é«˜çº¦20%çš„è¡¨ç°ï¼Œè¡¨æ˜é€šè¿‡ç¬¦å·åŒ–å›¾æ“ä½œæ˜¾å¼å»ºæ¨¡å¤šè·³æ¨ç†ï¼Œæœ‰åŠ©äºæ„å»ºæ›´å…·æ–‡åŒ–æ„ŸçŸ¥èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹ï¼›ä½œè€…åŒæ—¶å…¬å¼€æ•°æ®é›†ä¸å®éªŒç»“æœï¼Œä»¥æ¨åŠ¨æ–‡åŒ–æ¨ç†ç ”ç©¶ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, LLM, æ–‡åŒ–æ¨ç†, çŸ¥è¯†å›¾è°±é—®ç­”, å¤šè·³æ¨ç†, å°åº¦æ–‡åŒ–æ•°æ®é›†, Chain-of-Thought, Symbolic Chain-of-Manipulation, SFTå¾®è°ƒ, æ‹“æ‰‘ç»“æ„éå†

**è¯„åˆ†**ï¼š26

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18429v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18429v1.pdf)

---

## [3. RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425v1)

**ä½œè€…**ï¼šDeniz Qian, Hung-Ting Chen, Eunsol Choi  
**åˆ†ç±»**ï¼šcs.CL, cs.IR  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºå¤šè½®æ£€ç´¢æ¡†æ¶RVRï¼Œé€šè¿‡â€œæ£€ç´¢-éªŒè¯-å†æ£€ç´¢â€çš„å¾ªç¯æ˜¾è‘—æå‡å¤šç­”æ¡ˆé—®é¢˜çš„å…¨é¢å¬å›ç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿå•è½®æ£€ç´¢éš¾ä»¥è¦†ç›–å¤šç­”æ¡ˆé—®é¢˜ä¸­åˆ†å¸ƒå¹¿æ³›ä¸”å¤šæ ·çš„ç›¸å…³æ–‡æ¡£ï¼Œå¯¼è‡´ç­”æ¡ˆè¦†ç›–ä¸å…¨ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦â€œæ‰€æœ‰æ­£ç¡®ç­”æ¡ˆâ€çš„åœºæ™¯ä¸­è¡¨ç°ä¸è¶³ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šRVRå…ˆç”¨åŸºç¡€æ£€ç´¢å™¨å¯¹åŸå§‹é—®é¢˜æ£€ç´¢å¾—åˆ°å€™é€‰æ–‡æ¡£ï¼Œå†ç”±éªŒè¯å™¨ç­›é€‰å‡ºé«˜è´¨é‡å­é›†ï¼›éšåå°†è¿™äº›å·²éªŒè¯æ–‡æ¡£æ‹¼æ¥å…¥æ‰©å±•æŸ¥è¯¢ï¼Œè¿›è¡Œå¤šè½®æ–°çš„æ£€ç´¢ï¼Œä»¥è¡¥å…¨å°šæœªè¦†ç›–çš„ç­”æ¡ˆï¼ŒåŒæ—¶è¿˜æ¢ç´¢é’ˆå¯¹è¯¥è¿­ä»£æ¨ç†åœºæ™¯å¯¹æ£€ç´¢å™¨è¿›è¡Œå¾®è°ƒã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨QAMPARIå¤šç­”æ¡ˆæ£€ç´¢æ•°æ®é›†ä¸Šï¼ŒRVRç›¸å¯¹åŸºçº¿åœ¨å®Œæ•´å¬å›ç‡ä¸Šè‡³å°‘æå‡10%ç›¸å¯¹å€¼ã€3%ç»å¯¹å€¼ï¼Œå¹¶åœ¨QUESTä¸WebQuestionsSPç­‰è·¨é¢†åŸŸæ•°æ®é›†å’Œä¸åŒåº•å±‚æ£€ç´¢å™¨ä¸Šå‡å–å¾—ä¸€è‡´æå‡ï¼Œè¡¨æ˜å€ŸåŠ©éªŒè¯å™¨é©±åŠ¨çš„è¿­ä»£æ£€ç´¢æ˜¯æå‡ç»¼åˆç­”æ¡ˆå¬å›çš„æœ‰æ•ˆèŒƒå¼ã€‚

**å…³é”®è¯**ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ, å¤šè½®æ£€ç´¢, verifieréªŒè¯æ¨¡å‹, queryé‡å†™, è¯­ä¹‰æ£€ç´¢, å‘é‡æ£€ç´¢, agenticæ£€ç´¢, é—®ç­”ç³»ç»Ÿ

**è¯„åˆ†**ï¼š39

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18425v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18425v1.pdf)

---

## [4. SPQ: An Ensemble Technique for Large Language Model Compression](https://arxiv.org/abs/2602.18420v1)

**ä½œè€…**ï¼šJiamin Yao, Eren Gultepe  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSPQ æå‡ºä¸€ç§å°†SVDã€å‰ªæå’Œé‡åŒ–ç»„åˆçš„é›†æˆå‹ç¼©æ–¹æ³•ï¼Œåœ¨å¤§å¹…é™ä½LLMæ˜¾å­˜å ç”¨çš„åŒæ—¶ä¿æŒç”šè‡³æå‡å›°æƒ‘åº¦å’Œä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§æ¨¡å‹åœ¨æ˜¾å­˜ã€å­˜å‚¨å’Œæ¨ç†å»¶è¿Ÿä¸Šæˆæœ¬æé«˜ï¼Œç°æœ‰å•ä¸€å‹ç¼©æŠ€æœ¯ï¼ˆä»…å‰ªæã€ä»…ä½ç§©åˆ†è§£æˆ–ä»…é‡åŒ–ï¼‰å¾€å¾€éš¾ä»¥åœ¨é«˜å‹ç¼©ç‡ä¸‹åŒæ—¶å…¼é¡¾ç²¾åº¦ä¸æ•ˆç‡ï¼Œå› æ­¤éœ€è¦ä¸€ç§äº’è¡¥ã€å¤šç²’åº¦çš„ç»„åˆå‹ç¼©æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šSPQ é¢å‘ä¸åŒç»“æ„é‡‡ç”¨äº’è¡¥ç­–ç•¥ï¼šå¯¹ MLP å±‚åŸºäºæ¿€æ´»é‡è¦æ€§è¿›è¡Œç¥ç»å…ƒå‰ªæï¼Œå¯¹æ³¨æ„åŠ›æŠ•å½±çŸ©é˜µè¿›è¡Œä¿ç•™æ–¹å·®çº¦æŸçš„ä½ç§© SVD åˆ†è§£ï¼Œå¹¶å¯¹æ‰€æœ‰çº¿æ€§å±‚è¿›è¡Œ 8bit çº¿æ€§åè®­ç»ƒé‡åŒ–ï¼Œä»¥å±‚æ„ŸçŸ¥æ–¹å¼åœ¨æ•´ä½“ä¸Šæ§åˆ¶å‹ç¼©ç‡ä¸ç²¾åº¦æŸå¤±ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ LLaMA-2-7B ä¸Šï¼ŒSPQ åœ¨ç›¸åŒå‹ç¼©ç‡ä¸‹ä¼˜äºå•ä¸€æ–¹æ³•ï¼Œåœ¨æœ€é«˜çº¦ 75% å†…å­˜å‹ç¼©ä¸‹ä»èƒ½é™ä½ WikiText-2 å›°æƒ‘åº¦å¹¶ä¿æŒ C4ã€TruthfulQAã€GSM8K ç­‰ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼Œç›¸æ¯” GPTQ / SparseGPT æ—¢æ›´çœæ˜¾å­˜åˆæœ€é«˜å¯æå‡çº¦ 1.9Ã— æ¨ç†ååï¼Œè¡¨æ˜è¯¥é›†æˆå‹ç¼©æŠ€æœ¯é€‚åˆåœ¨å—é™ç¡¬ä»¶ç¯å¢ƒä¸­éƒ¨ç½²LLMã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, LLMå‹ç¼©, æ¨¡å‹å‰ªæ, ä½ç§©åˆ†è§£, SVD, 8bité‡åŒ–, æ¨ç†åŠ é€Ÿ, å†…å­˜ä¼˜åŒ–, æ¨¡å‹éƒ¨ç½²

**è¯„åˆ†**ï¼š38

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18420v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18420v1.pdf)

---

## [5. Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346v1)

**ä½œè€…**ï¼šPavithra PM Nair, Preethu Rose Anish  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šVichara æ˜¯ä¸€ä¸ªé¢å‘å°åº¦å¸æ³•ä½“ç³»çš„ä¸Šè¯‰åˆ¤å†³é¢„æµ‹ä¸è§£é‡Šæ¡†æ¶ï¼Œé€šè¿‡ç»“æ„åŒ–æ‹†è§£åˆ¤å†³æ–‡ä¹¦æ˜¾è‘—æå‡é¢„æµ‹å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°åº¦æ³•é™¢å­˜åœ¨å¤§é‡æ¡ˆä»¶ç§¯å‹ï¼Œå…¶ä¸­ä¸Šè¯‰æ¡ˆä»¶å æ¯”çªå‡ºï¼Œç°æœ‰åˆ¤å†³é¢„æµ‹æ–¹æ³•å¯¹å¤æ‚çš„ä¸Šè¯‰ç»“æ„ä¸æ³•å¾‹æ¨ç†å»ºæ¨¡ä¸è¶³ä¸”è§£é‡Šæ€§ä¸å¼ºï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæ—¢å‡†ç¡®åˆä¾¿äºæ³•å®˜å’Œå¾‹å¸ˆå®¡æŸ¥çš„é¢„æµ‹ä¸è§£é‡Šç³»ç»Ÿã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šVichara å°†è‹±æ–‡ä¸Šè¯‰æ¡ˆä»¶æ–‡ä¹¦è‡ªåŠ¨æ‹†è§£ä¸ºä¸€ç³»åˆ— decision pointsï¼ˆåŒ…å«æ³•å¾‹äº‰ç‚¹ã€è£å†³ä¸»ä½“ã€ç»“æœã€ç†ç”±ä¸æ—¶é—´èƒŒæ™¯ï¼‰ï¼Œå¹¶é‡‡ç”¨æ”¹é€ åçš„ IRAC ç»“æ„ç”Ÿæˆè§£é‡Šï¼›åœ¨ PredEx å’Œ ILDC_expert æ•°æ®é›†ä¸Šç”¨ GPT-4o miniã€Llama-3.1-8Bã€Mistral-7B å’Œ Qwen2.5-7B ç­‰å¤§æ¨¡å‹è¿›è¡Œè®­ç»ƒä¸è¯„ä¼°ã€‚

**ä¸»è¦ç»“è®º**ï¼šVichara åœ¨ PredEx å’Œ ILDC_expert ä¸Šå‡ä¼˜äºç°æœ‰åˆ¤å†³é¢„æµ‹åŸºçº¿ï¼Œå…¶ä¸­ GPT-4o mini çš„ F1 åˆ†åˆ«è¾¾åˆ° 81.5 å’Œ 80.3ï¼Œäººç±»è¯„ä¼°ä¹Ÿæ˜¾ç¤ºå…¶ç”Ÿæˆçš„è§£é‡Šåœ¨æ¸…æ™°åº¦ã€è®ºè¯é“¾æ¡å’Œå®ç”¨æ€§æ–¹é¢è¡¨ç°æœ€ä½³ï¼ŒéªŒè¯äº†è¯¥ç»“æ„åŒ–è¡¨ç¤ºä¸è§£é‡Šæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , å¤§è¯­è¨€æ¨¡å‹, æ³•å¾‹åˆ¤å†³é¢„æµ‹, IRACæ¨ç†æ¡†æ¶, å¸æ³•æ–‡ä¹¦åˆ†æ, ä¸Šè¯‰æ¡ˆä»¶åˆ¤å†³è§£é‡Š, å°åº¦å¸æ³•ç³»ç»Ÿ, artificial intelligence

**è¯„åˆ†**ï¼š47

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18346v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18346v1.pdf)

---

## [6. Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning](https://arxiv.org/abs/2602.18326v1)

**ä½œè€…**ï¼šTao Wu, Adam Kapelner  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We describe a modern deep learning system that automatically identifies informative contextual examples (\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ„å»ºå¹¶æ¯”è¾ƒå¤šç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨ç­›é€‰é€‚åˆé«˜ä¸­ç”Ÿè¯æ±‡å­¦ä¹ çš„é«˜è´¨é‡è¯­å¢ƒä¾‹å¥ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šäººå·¥æ‰‹å·¥æŒ‘é€‰è¯æ±‡æ•™å­¦ä¾‹å¥æˆæœ¬é«˜ä¸”éš¾ä»¥è§„æ¨¡åŒ–ï¼Œå› æ­¤éœ€è¦è‡ªåŠ¨æ–¹æ³•ä»å¤§é‡æ–‡æœ¬ä¸­ç­›é€‰çœŸæ­£æœ‰åŠ©è®°å¿†å’Œç†è§£çš„â€œå¥½è¯­å¢ƒâ€ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ¯”è¾ƒä¸‰ç§æ–¹æ³•ï¼š(1) ä½¿ç”¨MPNetè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ— ç›‘ç£ç­›é€‰ï¼›(2) åŸºäºå¸¦æ•™å­¦æŒ‡ä»¤å¾®è°ƒçš„Qwen3åµŒå…¥åŠ éçº¿æ€§å›å½’å¤´çš„æœ‰ç›‘ç£æ¨¡å‹ï¼›(3) åœ¨(2)çš„åŸºç¡€ä¸ŠåŠ å…¥æ‰‹å·¥è®¾è®¡çš„è¯­å¢ƒç‰¹å¾ï¼Œå¹¶æå‡ºRetention Competency Curveè¯„ä¼°â€œä¸¢å¤±å¥½ä¾‹å¥æ¯”ä¾‹â€ä¸â€œå¥½/åä¾‹å¥æ¯”â€ä¹‹é—´çš„æƒè¡¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šåŠ å…¥æ‰‹å·¥ç‰¹å¾çš„æœ‰ç›‘ç£æ¨¡å‹æ•ˆæœæœ€ä½³ï¼Œåœ¨ä»…ä¸¢å¼ƒçº¦70%çš„å¥½è¯­å¢ƒçš„æƒ…å†µä¸‹ï¼Œå®ç°çº¦440:1çš„å¥½/åä¾‹å¥æ¯”ï¼Œè¯´æ˜ç»“åˆç°ä»£åµŒå…¥æ¨¡å‹ä¸äººç±»æ ‡æ³¨ç›‘ç£å¯ä»¥ä½æˆæœ¬æ‰¹é‡ç”Ÿæˆè¿‘ä¹å®Œç¾çš„è¯æ±‡æ•™å­¦è¯­å¢ƒã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, è¯­ä¹‰æ£€ç´¢, æ–‡æœ¬åµŒå…¥, ç›‘ç£å­¦ä¹ , éçº¿æ€§å›å½’æ¨¡å‹, è¯æ±‡å­¦ä¹ åœºæ™¯, æ•™è‚²æŠ€æœ¯åº”ç”¨, ml

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18326v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18326v1.pdf)

---

## [7. PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324v1)

**ä½œè€…**ï¼šAlexandra Ciobotaru, Ana-Maria Bucur, Liviu P. Dinu  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ„å»ºå¹¶åˆæ­¥åˆ†æäº†é¦–ä¸ªç½—é©¬å°¼äºšè¯­æŠ‘éƒä¸ç„¦è™‘æ–‡æœ¬è¯­æ–™åº“ PsihoRoï¼Œç”¨äºå¿ƒç†å¥åº·ç›¸å…³çš„NLPç ”ç©¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¿ƒç†å¥åº·æ–‡æœ¬èµ„æºä¸»è¦é›†ä¸­åœ¨è‹±è¯­ï¼Œè€Œç½—é©¬å°¼äºšè¯­ç¼ºä¹å¼€æ”¾çš„å¿ƒç†å¥åº·è¯­æ–™åº“ï¼Œä¸”ç¤¾äº¤åª’ä½“æ•°æ®å­˜åœ¨æ ‡æ³¨å’Œæ¨æ–­åå·®ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªåŸºäºæ ‡å‡†é‡è¡¨ä¸å¼€æ”¾é—®ç­”æ„å»ºçš„å¯é å¿ƒç†è¯­æ–™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…é€šè¿‡åŒ…å«6ä¸ªå¼€æ”¾å¼é—®é¢˜çš„é—®å·ç»“åˆPHQ-9å’ŒGAD-7è‡ªè¯„é‡è¡¨ï¼Œä»205åå—è¯•è€…æ”¶é›†ç½—é©¬å°¼äºšè¯­æ–‡æœ¬ï¼Œå¹¶åˆ©ç”¨ç»Ÿè®¡åˆ†æã€ç½—é©¬å°¼äºšç‰ˆLIWCã€æƒ…ç»ªè¯†åˆ«ä¸ä¸»é¢˜å»ºæ¨¡ç­‰æ–¹æ³•å¯¹è¯­æ–™ç‰¹å¾è¿›è¡Œç³»ç»Ÿæ¢ç´¢ã€‚

**ä¸»è¦ç»“è®º**ï¼šPsihoRoè™½è§„æ¨¡æœ‰é™ï¼Œä½†ä½œä¸ºé¦–ä¸ªç½—é©¬å°¼äºšè¯­æŠ‘éƒä¸ç„¦è™‘è¯­æ–™åº“ï¼Œä¸ºç ”ç©¶ç½—é©¬å°¼äºšäººç¾¤å¿ƒç†å¥åº·ç›¸å…³æ–‡æœ¬æä¾›äº†åŸºç¡€èµ„æºï¼Œå¹¶é€šè¿‡å¤šç§åˆ†æå±•ç¤ºäº†è¯¥è¯­æ–™åœ¨å¿ƒç†ä¸æƒ…ç»ªè¯­è¨€ç ”ç©¶ä¸­çš„å¯ç”¨æ€§ä¸ä»·å€¼ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, æƒ…æ„Ÿåˆ†æ, å¿ƒç†å¥åº·æ£€æµ‹, ç½—é©¬å°¼äºšè¯­æ–‡æœ¬åˆ†ç±», æŠ‘éƒç„¦è™‘è¯†åˆ«, å¿ƒç†è¯­è¨€å­¦ç‰¹å¾åˆ†æ, æƒ…ç»ªè¯†åˆ«, ä¸»é¢˜æ¨¡å‹åˆ†æ, rag

**è¯„åˆ†**ï¼š16

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18324v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18324v1.pdf)

---

## [8. Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262v1)

**ä½œè€…**ï¼šAaron Louis Eidt, Nils Feldhus  
**åˆ†ç±»**ï¼šcs.CL, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºå¹¶å®ç°äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ ELIAï¼Œç»“åˆå¤šç§å¯è§£é‡Šæ€§æŠ€æœ¯ä¸è‡ªåŠ¨è‡ªç„¶è¯­è¨€è®²è§£ï¼Œå¸®åŠ©éä¸“å®¶ç†è§£å¤§è¯­è¨€æ¨¡å‹å†…éƒ¨æœºç†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå½“å‰æœºåˆ¶å¯è§£é‡Šæ€§å·¥å…·å¤æ‚åº¦é«˜ã€ä½¿ç”¨é—¨æ§›å¤§ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹å†…éƒ¨åˆ†æç»“æœéš¾ä»¥è¢«éä¸“ä¸šç”¨æˆ·ç†è§£ä¸ä½¿ç”¨ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»º ELIA Web ç³»ç»Ÿï¼Œå°†å½’å› åˆ†æã€åŠŸèƒ½å‘é‡åˆ†æå’Œç”µè·¯è¿½è¸ªä¸‰ç±»æ–¹æ³•é›†æˆåœ¨äº¤äº’å¼ç•Œé¢ä¸­ï¼Œå¹¶é¦–æ¬¡åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ä¸ºå¤æ‚å¯è§†åŒ–è‡ªåŠ¨ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼Œå†é€šè¿‡æ··åˆæ–¹æ³•ç”¨æˆ·ç ”ç©¶è¯„ä¼°æ•ˆæœã€‚

**ä¸»è¦ç»“è®º**ï¼šç»“æœè¡¨æ˜äº¤äº’å¼ã€å¯æ¢ç´¢ç•Œé¢ä¼˜äºé™æ€å¯è§†åŒ–ï¼ŒAI ç”Ÿæˆçš„è§£é‡Šæ˜¾è‘—ç¼©å°äº†ä¸åŒç»éªŒç”¨æˆ·é—´çš„ç†è§£å·®è·ï¼Œè¯´æ˜åœ¨ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è®¾è®¡ä¸‹ï¼ŒAI ç³»ç»Ÿå¯ä»¥æœ‰æ•ˆç®€åŒ–å¤æ‚æ¨¡å‹åˆ†æå¹¶æå‡å¯è§£é‡Šæ€§å¯è¾¾æ€§ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, è§£é‡Šæ€§åˆ†æ, å¯è§†åŒ–è§£é‡Š, è‡ªç„¶è¯­è¨€ç”Ÿæˆ, äº¤äº’å¼ç•Œé¢, ç”¨æˆ·ç ”ç©¶, æ¨¡å‹å¯è§£é‡Šæ€§, llm

**è¯„åˆ†**ï¼š40

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18262v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18262v1.pdf)

---

## cs.CV

## [9. CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424v1)

**ä½œè€…**ï¼šXia Su, Ruiqi Chen, Benlin Liu ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCapNav æå‡ºä¸€ä¸ªé¢å‘â€œå…·èº«èƒ½åŠ›çº¦æŸâ€çš„å®¤å†…å¯¼èˆªåŸºå‡†ï¼Œç”¨äºç³»ç»Ÿè¯„æµ‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸åŒæœºå™¨äºº/äººç±»èƒ½åŠ›æ¡ä»¶ä¸‹çš„å¯¼èˆªä¸ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è§†è§‰è¯­è¨€å¯¼èˆªç ”ç©¶å¤§å¤šå‡è®¾å¯¼èˆªä¸»ä½“æ— æ˜æ˜¾è¡ŒåŠ¨çº¦æŸï¼Œè€Œç°å®ä¸­çš„æœºå™¨äºº/äººç±»å…·æœ‰å°ºå¯¸ã€æœºåŠ¨æ–¹å¼å’Œäº¤äº’èƒ½åŠ›ç­‰å¤šç§ç‰©ç†é™åˆ¶ï¼Œéœ€è¦è¯„ä¼°æ¨¡å‹åœ¨è¿™äº›çœŸå®èƒ½åŠ›çº¦æŸä¸‹çš„å¯¼èˆªå†³ç­–ä¸ç©ºé—´ç†è§£ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æ„å»º CapNav åŸºå‡†ï¼šå®šä¹‰5ç±»å…¸å‹äºº/æœºå™¨äººä»£ç†ï¼ˆå«å°ºå¯¸ã€æœºåŠ¨ä¸äº¤äº’èƒ½åŠ›ï¼‰ï¼ŒåŸºäº45ä¸ªçœŸå®å®¤å†…åœºæ™¯è®¾è®¡473ä¸ªå¯¼èˆªä»»åŠ¡å’Œ2365ä¸ªé—®ç­”æ ·ä¾‹ï¼Œå¹¶åœ¨æ­¤ä¸Šç³»ç»Ÿè¯„æµ‹13ä¸ªä¸»æµVLMåœ¨ä¸åŒèƒ½åŠ›æ¡ä»¶å’Œéšœç¢ç±»å‹ä¸‹çš„è¡¨ç°ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒå‘ç°éšç€æœºåŠ¨çº¦æŸå˜å¼ºï¼Œç°æœ‰VLMå¯¼èˆªæ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œå°¤å…¶åœ¨éœ€è¦ç²¾ç¡®ç©ºé—´å°ºå¯¸ä¸éšœç¢ç±»å‹æ¨ç†çš„åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œè¯´æ˜å½“å‰æ¨¡å‹çš„å…·èº«æ„ŸçŸ¥ä¸èƒ½åŠ›æ„ŸçŸ¥å¯¼èˆªä»å¾ˆè–„å¼±ï¼Œæœªæ¥éœ€é‡ç‚¹æå‡é¢å‘å…·ä½“ä»£ç†èƒ½åŠ›çš„ç©ºé—´æ¨ç†ä¸å†³ç­–èƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šè§†è§‰è¯­è¨€æ¨¡å‹, å¤šæ¨¡æ€å¯¼èˆª, æ™ºèƒ½ä½“, å®¤å†…è·¯å¾„è§„åˆ’, å…·èº«æ™ºèƒ½, èƒ½åŠ›çº¦æŸåœºæ™¯, æœºå™¨äººå¯¼èˆªåŸºå‡†, ç©ºé—´æ¨ç†, agent

**è¯„åˆ†**ï¼š36

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18424v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18424v1.pdf)

---

## [10. Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422v1)

**ä½œè€…**ï¼šLinxi Xie, Lisong C. Sun, Ashley Neall ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥å·¥ä½œæå‡ºä¸€ç§é¢å‘XRçš„äººä½“ä¸­å¿ƒè§†é¢‘ä¸–ç•Œæ¨¡å‹ï¼Œå¯æ ¹æ®ç”¨æˆ·å¤´éƒ¨å’Œæ‰‹éƒ¨å§¿æ€å®æ—¶ç”Ÿæˆå…·èº«äº¤äº’çš„ç¬¬ä¸€äººç§°è™šæ‹Ÿç¯å¢ƒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è§†é¢‘ç”Ÿæˆ/ä¸–ç•Œæ¨¡å‹ä¸»è¦ä¾èµ–æ–‡æœ¬æˆ–æŒ‰é”®ç­‰ç²—ç²’åº¦æ§åˆ¶ï¼Œæ— æ³•åˆ©ç”¨XRè®¾å¤‡å¯è·å–çš„ç²¾ç»†å¤´éƒ¨ä¸æ‰‹éƒ¨è¿åŠ¨æ•°æ®ï¼Œé™åˆ¶äº†æ²‰æµ¸å¼ã€å…·èº«äº¤äº’ä½“éªŒã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…è®¾è®¡é€‚ç”¨äº3Då¤´éƒ¨å’Œå…³èŠ‚çº§æ‰‹åŠ¿çš„æ¡ä»¶æœºåˆ¶ï¼Œç³»ç»Ÿæ€§è¯„ä¼°å¤šç§æ‰©æ•£Transformeræ¡ä»¶ç­–ç•¥ï¼Œå¹¶ä»¥æ­¤è®­ç»ƒåŒå‘è§†é¢‘æ‰©æ•£æ•™å¸ˆæ¨¡å‹ï¼Œå†è’¸é¦ä¸ºå¯å› æœæ¨æ–­ã€å¯äº¤äº’çš„å®æ—¶ç¬¬ä¸€äººç§°è§†é¢‘ç”Ÿæˆç³»ç»Ÿã€‚

**ä¸»è¦ç»“è®º**ï¼šç”¨æˆ·å®éªŒæ˜¾ç¤ºï¼Œè¯¥â€œç”Ÿæˆç°å®â€ç³»ç»Ÿç›¸è¾ƒç›¸å…³åŸºçº¿æ˜¾è‘—æå‡ä»»åŠ¡å®Œæˆè¡¨ç°ï¼Œå¹¶è®©ç”¨æˆ·ä¸»è§‚æ„Ÿå—åˆ°æ›´å¼ºçš„åŠ¨ä½œæ§åˆ¶æ„Ÿï¼Œè¯æ˜äº†åŸºäºå¤´æ‰‹å§¿æ€æ¡ä»¶çš„äº¤äº’å¼è§†é¢‘ä¸–ç•Œæ¨¡å‹åœ¨XRä¸­çš„å®ç”¨ä»·å€¼ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆå¼è§†é¢‘, æ‰©æ•£æ¨¡å‹, Diffusion Transformer, ä¸‰ç»´æ‰‹åŠ¿æ§åˆ¶, å¤´éƒ¨å§¿æ€è·Ÿè¸ª, ç¬¬ä¸€äººç§°è™šæ‹Ÿç¯å¢ƒ, XRäº¤äº’, äººæœºäº¤äº’å®éªŒ

**è¯„åˆ†**ï¼š41

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18422v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18422v1.pdf)

---

## [11. Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges](https://arxiv.org/abs/2602.18406v1)

**ä½œè€…**ï¼šMinh Dinh, StÃ©phane Deny  
**åˆ†ç±»**ï¼šcs.CV, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ¢è®¨åœ¨æ½œåœ¨ç©ºé—´ä¸­å­¦ä¹ ç­‰å˜ç®—å­ï¼Œä»¥åœ¨æ— éœ€æ˜¾å¼å…ˆéªŒç¾¤çŸ¥è¯†çš„æƒ…å†µä¸‹å®ç°å¯¹æ—‹è½¬/å¹³ç§»ç­‰å¯¹ç§°å˜æ¢çš„ç¨³å¥æ³›åŒ–ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿå·ç§¯ç½‘ç»œéš¾ä»¥æ³›åŒ–åˆ°è®­ç»ƒä¸­å°‘è§çš„å§¿æ€ã€å°ºåº¦ã€ä½ç½®ç»„åˆï¼Œè€Œç¾¤ç­‰å˜ç½‘ç»œåˆä¾èµ–äº‹å…ˆçŸ¥é“ç²¾ç¡®çš„å¯¹ç§°ç¾¤ï¼Œé™åˆ¶äº†åœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ—¢èƒ½è‡ªåŠ¨å­¦ä¹ ç­‰å˜æ€§åˆå…·OODé²æ£’æ€§çš„æ¶æ„ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåˆ©ç”¨å¸¦å™ªå£°çš„æ—‹è½¬å’Œå¹³ç§»MNISTæ„å»ºå¯¹ç§°å˜æ¢æ ·æœ¬ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­å­¦ä¹ ç­‰å˜ç®—å­ï¼Œä½¿æ½œåœ¨è¡¨ç¤ºéšè¾“å…¥å›¾åƒçš„ç¾¤å˜æ¢æŒ‰è§„åˆ™å˜åŒ–ï¼Œå¹¶å°†è¯¥è¡¨ç¤ºç”¨äºåˆ†ç±»ï¼Œä»¥æ¯”è¾ƒä¼ ç»Ÿç½‘ç»œã€æ˜¾å¼ç­‰å˜ç½‘ç»œä¸æ½œåœ¨ç­‰å˜æ–¹æ³•åœ¨OODåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜æ½œåœ¨ç­‰å˜ç®—å­å¯ä»¥åœ¨æœªè§è¿‡çš„æ—‹è½¬/å¹³ç§»ç»„åˆä¸Šæ˜¾è‘—æå‡åˆ†ç±»æ€§èƒ½ï¼Œç¼“è§£ä¼ ç»Ÿä¸æ˜¾å¼ç­‰å˜ç½‘ç»œçš„å±€é™ï¼Œä½†ä½œè€…æŒ‡å‡ºåœ¨æ‰©å±•åˆ°æ›´å¤æ‚æ•°æ®é›†å’Œæ›´é«˜ç»´åº¦ç¾¤ç»“æ„æ—¶ä»é¢ä¸´å»ºæ¨¡éš¾åº¦ã€æ•°æ®éœ€æ±‚å’Œå¯æ‰©å±•æ€§ç­‰æŒ‘æˆ˜ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ç­‰å˜ç¥ç»ç½‘ç»œ, æ½œåœ¨è¡¨ç¤º, é²æ£’ç›®æ ‡è¯†åˆ«, å§¿æ€ä¸å˜æ€§, æ—‹è½¬å¹³ç§»ä¸å˜æ€§, OODæ³›åŒ–, MNISTæ•°æ®é›†, è®¡ç®—æœºè§†è§‰, deep learning

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18406v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18406v1.pdf)

---

## [12. Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394v1)

**ä½œè€…**ï¼šStefan Becker, Simon Weiss, Wolfgang HÃ¼bner ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.   We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.   To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.   Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºä¸€ç§åŸºäºâ€œé€€åŒ–æµå½¢â€çš„è‡ªæ„ŸçŸ¥ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œä½¿æ£€æµ‹å™¨èƒ½åœ¨å›¾åƒè´¨é‡é€€åŒ–æ—¶è‡ªè¯†åˆ«å‡ºå·²è¶…å‡ºå…¶æ­£å¸¸å·¥ä½œèŒƒå›´ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰ç›®æ ‡æ£€æµ‹å™¨åœ¨æ¨¡ç³Šã€å™ªå£°ã€å‹ç¼©ã€æ¶åŠ£å¤©æ°”å’Œåˆ†è¾¨ç‡å˜åŒ–ç­‰é€€åŒ–æ¡ä»¶ä¸‹å¯èƒ½æ— å£°å¤±è´¥ï¼Œä»…é æ£€æµ‹ç½®ä¿¡åº¦æ— æ³•å¯é åˆ¤æ–­è¾“å…¥æ˜¯å¦ä»åœ¨è®­ç»ƒåˆ†å¸ƒå†…ï¼Œå®‰å…¨å…³é”®åœºæ™¯å› æ­¤å­˜åœ¨é£é™©ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨å¸¸è§„æ£€æµ‹éª¨å¹²ç½‘ç»œä¸Šå¢åŠ ä¸€ä¸ªè½»é‡åµŒå…¥å¤´ï¼Œé€šè¿‡å¤šå±‚å¯¹æ¯”å­¦ä¹ ä½¿ç‰¹å¾ç©ºé—´æŒ‰â€œé€€åŒ–ç±»å‹ä¸å¼ºåº¦â€è€Œéè¯­ä¹‰è¿›è¡Œå‡ ä½•ç»„ç»‡ï¼šç›¸åŒé€€åŒ–é…ç½®çš„å›¾åƒè¢«æ‹‰è¿‘ã€ä¸åŒé…ç½®è¢«æ¨è¿œï¼Œå¹¶é€šè¿‡å¹²å‡€è®­ç»ƒæ ·æœ¬çš„åµŒå…¥ä¼°è®¡â€œå®Œå¥½åŸå‹â€ä½œä¸ºåä¹‰å·¥ä½œç‚¹ï¼Œåˆ©ç”¨ä¸è¯¥åŸå‹çš„å‡ ä½•åç§»åº¦é‡è‡ªæ„ŸçŸ¥ç¨‹åº¦ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šç§åˆæˆé€€åŒ–ã€è·¨æ•°æ®é›†é›¶æ ·æœ¬è¿ç§»åŠçœŸå®å¤©æ°”åˆ†å¸ƒåç§»ä¸‹éƒ½èƒ½å®ç°å¹²å‡€ä¸é€€åŒ–å›¾åƒçš„è‰¯å¥½å¯åˆ†æ€§ï¼Œè·¨æ£€æµ‹æ¶æ„è¡¨ç°ä¸€è‡´ä¸”å¯¹è¯­ä¹‰åˆ†å¸ƒå˜åŒ–å…·æœ‰é²æ£’æ³›åŒ–æ€§ï¼Œè¯´æ˜åŸºäºé€€åŒ–æ„ŸçŸ¥å‡ ä½•è¡¨ç¤ºæ˜¯ä¸€ç§å®ç”¨ä¸”ä¸æ£€æµ‹å™¨æ— å…³çš„è‡ªæ„ŸçŸ¥åŸºç¡€ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, åµŒå…¥è¡¨ç¤º, å¯¹æ¯”å­¦ä¹ , ç›®æ ‡æ£€æµ‹, å›¾åƒé€€åŒ–, é²æ£’æ€§è¯„ä¼°, åˆ†å¸ƒå¤–æ£€æµ‹, è‡ªç›‘ç£å­¦ä¹ , å®‰å…¨å…³é”®åœºæ™¯, embedding

**è¯„åˆ†**ï¼š39

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18394v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18394v1.pdf)

---

## [13. G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329v1)

**ä½œè€…**ï¼šQingsong Wang, Jiaxing He, Bingzhe Hou ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, math.AT  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºä¸€ç§åŸºäºé«˜æ–¯-æ‹‰æ™®æ‹‰æ–¯ç®—å­çš„G-LoGåŒå‚æ•°è¿‡æ»¤æ–¹æ³•ï¼Œç”¨æ‹“æ‰‘ç‰¹å¾å®ç°åŒ»å­¦å›¾åƒåˆ†ç±»ï¼Œåœ¨MedMNISTä¸Šæ¥è¿‘ç”šè‡³åª²ç¾å¤æ‚æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå•å‚æ•°TDAè¿‡æ»¤åœ¨æ•æ‰åŒ»å­¦å›¾åƒä¸­å¤æ‚çš„æ‹“æ‰‘ä¸å‡ ä½•ç»“æ„æ–¹é¢å­˜åœ¨å±€é™ï¼Œä¸”éœ€è¦æ›´ç¨³å®šã€å¯ç”¨äºå¤šå‚æ•°æŒä¹…åŒè°ƒçš„ç‰¹å¾æ¥æå‡åŒ»å­¦å½±åƒåˆ†ç±»è¡¨ç°ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†ä¸‰ç»´åŒ»å­¦å›¾åƒå»ºæ¨¡ä¸ºæœ‰ç•Œå‡½æ•°ï¼Œå¼•å…¥ç»“åˆé«˜æ–¯ä¸LoGçš„G-LoGåŒå‚æ•°è¿‡æ»¤æ„é€ å¤šå‚æ•°æŒä¹…æ¨¡ï¼Œå¹¶è¯æ˜å…¶åœ¨æœ€å¤§èŒƒæ•°æ„ä¹‰ä¸‹çš„ç¨³å®šæ€§ï¼Œç„¶åç”¨MLPå¯¹ç”Ÿæˆçš„æ‹“æ‰‘ç‰¹å¾è¿›è¡Œåˆ†ç±»å¹¶ä¸ä¸»æµæ·±åº¦å­¦ä¹ å’ŒAutoMLæ–¹æ³•æ¯”è¾ƒã€‚

**ä¸»è¦ç»“è®º**ï¼šG-LoGåŒå‚æ•°è¿‡æ»¤ç›¸è¾ƒå•å‚æ•°è¿‡æ»¤åœ¨MedMNISTä¸Šæ˜¾è‘—æå‡åˆ†ç±»æ€§èƒ½ï¼Œä¸”ç®€å•MLPåŸºäºå…¶æ‹“æ‰‘ç‰¹å¾å³å¯è¾¾åˆ°ä¸å¤æ‚æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸å½“çš„æ•ˆæœï¼Œè¡¨æ˜è¯¥TDAæ–¹æ³•åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­å…·æœ‰å®é™…å¯ç”¨æ€§å’Œç«äº‰åŠ›ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, å¤šå±‚æ„ŸçŸ¥æœºMLP, åŒ»å­¦å›¾åƒåˆ†ç±», æ‹“æ‰‘æ•°æ®åˆ†æTDA, å¤šå‚æ•°æŒä¹…åŒè°ƒ, ç‰¹å¾æå–, MedMNISTæ•°æ®é›†

**è¯„åˆ†**ï¼š32

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18329v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18329v1.pdf)

---

## [14. Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322v1)

**ä½œè€…**ï¼šZiteng Cui, Shuhong Liu, Xiaoyu Dong ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šLuminance-GS++åœ¨ä¿æŒ3Dé«˜æ–¯æ¸²æŸ“æ¡†æ¶ä¸å˜çš„å‰æä¸‹ï¼Œé€šè¿‡è§†è§’è‡ªé€‚åº”äº®åº¦æ›²çº¿å’Œå±€éƒ¨é¢œè‰²æ®‹å·®æ ¡æ­£ï¼Œå®ç°åœ¨å¤æ‚å…‰ç…§æ¡ä»¶ä¸‹æ›´é²æ£’çš„ä¸‰ç»´æ–°è§†è§’åˆæˆã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°å®å¤šè§†è§’é‡‡é›†ä¸­ç”±äºå…‰ç…§å˜åŒ–ã€ç›¸æœºä¼ æ„Ÿå™¨å·®å¼‚å’ŒISPé…ç½®ä¸ä¸€è‡´ï¼Œå¯¼è‡´å›¾åƒé—´å…‰åº¦å’Œè‰²å½©ä¸ä¸€è‡´ï¼Œç ´åNeRF/3DGSä¾èµ–çš„å…‰åº¦ä¸€è‡´æ€§å‡è®¾ï¼Œä»è€Œé™ä½é‡å»ºå’Œæ¸²æŸ“è´¨é‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåŸºäº3D Gaussian Splattingæ¡†æ¶ï¼Œæå‡ºå…¨å±€è§†è§’è‡ªé€‚åº”çš„äº®åº¦è°ƒæ•´æ›²çº¿ç»“åˆé€åƒç´ æ®‹å·®é¢œè‰²ç²¾ä¿®ï¼Œå¹¶é€šè¿‡æ— ç›‘ç£æŸå¤±è”åˆçº¦æŸäº®åº¦æ ¡æ­£ã€å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§å’Œå…‰åº¦ä¸€è‡´æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ä½ç…§åº¦ã€è¿‡æ›åŠå¤æ‚äº®åº¦/è‰²å½©å˜åŒ–åœºæ™¯ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒ3DGSæ˜¾å¼è¡¨ç¤ºå’Œå®æ—¶æ¸²æŸ“æ•ˆç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†é‡å»ºå’Œæ–°è§†è§’æ¸²æŸ“è´¨é‡ï¼Œè¾¾åˆ°æˆ–è¶…è¿‡ç°æœ‰æ–¹æ³•çš„æœ€æ–°æ°´å¹³ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, NeRFæ–°è§†å›¾åˆæˆ, 3DGaussianSplatting, ä¸‰ç»´é‡å»ºæ¸²æŸ“, å…‰ç…§è‡ªé€‚åº”æ ¡æ­£, é¢œè‰²æ’å¸¸æ€§, å¤šè§†å›¾ä¸€è‡´æ€§çº¦æŸ, å®æ—¶æ¸²æŸ“æ¡†æ¶, agent

**è¯„åˆ†**ï¼š25

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18322v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18322v1.pdf)

---

## [15. Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314v1)

**ä½œè€…**ï¼šTianyi Song, Danail Stoyanov, Evangelos Mazomenos ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.GR, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDiff2DGSé€šè¿‡â€œæ‰©æ•£è§†é¢‘è¡¥å…¨ + å¯å½¢å˜2D Gaussian Splattingâ€ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå®ç°å¯¹è¢«å™¨æ¢°é®æŒ¡çš„æ‰‹æœ¯åœºæ™¯è¿›è¡Œæ›´ç²¾ç¡®ã€æ›´ç¨³å®šçš„å®æ—¶3Dé‡å»ºã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰åŸºäºæ‰‹æœ¯å†…çª¥é•œè§†é¢‘çš„3Dé‡å»ºåœ¨é®æŒ¡åŒºåŸŸé‡å»ºè´¨é‡å·®ä¸”ç¼ºä¹å¸¦çœŸå®3Då‡ ä½•çœŸå€¼çš„æ•°æ®é›†ï¼Œå¯¼è‡´å½¢å˜ç»„ç»‡çš„æ·±åº¦å’Œå‡ ä½•ç²¾åº¦éš¾ä»¥å¯é è¯„ä¼°ä¸æå‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé¦–å…ˆä½¿ç”¨å¼•å…¥æ—¶é—´å…ˆéªŒçš„æ‰©æ•£å¼è§†é¢‘ä¿®è¡¥æ¨¡å—ï¼Œå¯¹è¢«æ‰‹æœ¯å™¨æ¢°é®æŒ¡çš„ç»„ç»‡åŒºåŸŸè¿›è¡Œæ—¶ç©ºä¸€è‡´çš„è¡¥å…¨ï¼›éšåç»“åˆå¯å­¦ä¹ å½¢å˜æ¨¡å‹çš„2D Gaussian Splattingï¼Œå¯¹åŠ¨æ€ç»„ç»‡å½¢å˜å’Œè§£å‰–å‡ ä½•è¿›è¡Œå»ºæ¨¡ä¸æ¸²æŸ“ï¼Œå¹¶åœ¨SCAREDæ•°æ®é›†ä¸ŠåŠ å…¥æ·±åº¦ç²¾åº¦ä¼˜åŒ–ä¸è¯„ä¼°ã€‚

**ä¸»è¦ç»“è®º**ï¼šDiff2DGSåœ¨EndoNeRFä¸StereoMISä¸Šæ˜¾è‘—æå‡PSNRå¹¶åœ¨å¤–è§‚å’Œå‡ ä½•ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å®éªŒè¡¨æ˜ä»…ä¼˜åŒ–å›¾åƒè´¨é‡æ— æ³•ä¿è¯3Då‡ ä½•ç²¾åº¦ï¼Œå› æ­¤å¼•å…¥æ·±åº¦è´¨é‡ä¼˜åŒ–å¯è·å¾—æ›´åŠ å¯é ã€é€¼çœŸçš„æ‰‹æœ¯åœºæ™¯3Dé‡å»ºã€‚

**å…³é”®è¯**ï¼šæ‰©æ•£æ¨¡å‹, æ·±åº¦å­¦ä¹ , ç”Ÿæˆå¼, ç¥ç»ç½‘ç»œ, è§†é¢‘ä¿®å¤, 2DGaussianSplatting, å¯å˜å½¢åœºæ™¯é‡å»º, æœºå™¨äººæ‰‹æœ¯å¯¼èˆª, å†…çª¥é•œä¸‰ç»´é‡å»º, æ·±åº¦ä¼°è®¡ä¸è¯„ä¼°, diffusion

**è¯„åˆ†**ï¼š43

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18314v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18314v1.pdf)

---

## [16. Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309v1)

**ä½œè€…**ï¼šZiyue Liu, Davide Talon, Federico Girella ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥è®ºæ–‡æå‡ºLOTSæ¡†æ¶ï¼Œé€šè¿‡å¤šå±‚æ¬¡ç»“åˆå…¨å±€è‰å›¾å’Œå±€éƒ¨æ–‡æœ¬-è‰å›¾å¯¹ï¼Œå®ç°æ›´ç²¾ç¡®çš„æœè£…å›¾åƒç”Ÿæˆã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰æ—¶å°šå›¾åƒç”Ÿæˆæ–¹æ³•éš¾ä»¥åŒæ—¶ä¸¥æ ¼éµå®ˆè‰å›¾ç»“æ„å¹¶ç»†è‡´åæ˜ å±€éƒ¨æ–‡æœ¬æè¿°ï¼ˆå¦‚æè´¨ã€é¢œè‰²ã€ç»†èŠ‚ï¼‰ï¼Œå°¤å…¶åœ¨éä¸“ä¸šè‰å›¾åœºæ™¯ä¸‹é²æ£’æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šLOTSé¦–å…ˆåœ¨å¤šçº§æ¡ä»¶ç¼–ç é˜¶æ®µï¼Œå°†å…¨å±€è‰å›¾å’Œå¤šä¸ªå±€éƒ¨æ–‡æœ¬-è‰å›¾å¯¹ç¼–ç åˆ°å…±äº«æ½œç©ºé—´ï¼Œæ—¢ä¿æŒæ•´ä½“ç»“æ„åˆæ•æ‰å±€éƒ¨ç‰¹å¾ï¼›éšååœ¨æ‰©æ•£ç”Ÿæˆä¸­é€šè¿‡æ³¨æ„åŠ›å¼•å¯¼çš„â€œDiffusion Pair Guidanceâ€ï¼Œåœ¨æ¯ä¸€æ­¥å»å™ªä¸­èåˆå…¨å±€ä¸å±€éƒ¨æ¡ä»¶çº¦æŸã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ä½œè€…æ„å»ºçš„Sketchyå¤šæ–‡æœ¬-è‰å›¾å¯¹æ—¶å°šæ•°æ®é›†ï¼ˆå«ä¸“ä¸šä¸â€œé‡å¤–â€éä¸“ä¸šè‰å›¾ï¼‰ä¸Šï¼ŒLOTSæ˜¾è‘—æå‡äº†å¯¹å…¨å±€ç»“æ„çš„éµä»ä¸å±€éƒ¨è¯­ä¹‰ç»†èŠ‚çš„è¡¨è¾¾æ•ˆæœï¼Œä¼˜äºç°æœ‰æœ€æ–°æ–¹æ³•ï¼Œç›¸å…³æ•°æ®é›†ä¸ä»£ç å·²å¼€æºã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , æ‰©æ•£æ¨¡å‹, å¤šæ¨¡æ€ç”Ÿæˆ, æ¡ä»¶å›¾åƒç”Ÿæˆ, æ—¶å°šå›¾åƒç”Ÿæˆ, è‰å›¾åˆ°å›¾åƒ, æ–‡æœ¬å¼•å¯¼ç”Ÿæˆ, æ³¨æ„åŠ›æœºåˆ¶, æ½œåœ¨ç©ºé—´ç¼–ç , å±€éƒ¨ç‰¹å¾å¯¹é½, diffusion

**è¯„åˆ†**ï¼š38

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18309v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18309v1.pdf)

---

## [17. DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282v1)

**ä½œè€…**ï¼šShiyan Du, Conghan Yue, Xinyu Cheng ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDEIGæå‡ºä¸€ç§ç»†ç²’åº¦ã€å¯æ§çš„å¤šå®ä¾‹ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡æ›´ç²¾ç¡®çš„å®ä¾‹è¯­ä¹‰å»ºæ¨¡ä¸æ³¨æ„åŠ›æ§åˆ¶ï¼Œå®ç°ä¸å¤æ‚æ–‡æœ¬æè¿°é«˜åº¦åŒ¹é…çš„å›¾åƒç”Ÿæˆã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤šå®ä¾‹ç”Ÿæˆæ–¹æ³•åœ¨é¢å¯¹å¤æ‚ã€ç»†ç²’åº¦æ–‡æœ¬æè¿°æ—¶ï¼Œå®¹æ˜“å‡ºç°è¯­ä¹‰ç†è§£ä¸è¶³å’Œè·¨å®ä¾‹å±æ€§æ··æ·†ï¼Œéš¾ä»¥ä¿è¯ç©ºé—´ä¸€è‡´æ€§ä¸å±æ€§ç²¾ç¡®ç»‘å®šã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šDEIGè®¾è®¡äº†å®ä¾‹ç»†èŠ‚æå–å™¨IDEï¼Œå°†æ–‡æœ¬ç¼–ç å™¨çš„åµŒå…¥å‹ç¼©ä¸ºå®ä¾‹çº§è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶é€šè¿‡ç»†èŠ‚èåˆæ¨¡å—DFMçš„å®ä¾‹æ©ç æ³¨æ„åŠ›æŠ‘åˆ¶å±æ€§æ³„æ¼ï¼›åŒæ—¶æ„å»ºé«˜è´¨é‡ç»†ç²’åº¦å®ä¾‹æè¿°æ•°æ®é›†å’Œå¸¦åŒºåŸŸæ ‡æ³¨ã€å¤šå±æ€§æç¤ºçš„DEIG-Benchç”¨äºç›‘ç£ä¸è¯„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼ŒDEIGåœ¨ç©ºé—´ä¸€è‡´æ€§ã€è¯­ä¹‰å‡†ç¡®æ€§å’Œç»„åˆæ³›åŒ–æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”ä½œä¸ºå³æ’å³ç”¨æ¨¡å—å¯æ— ç¼é›†æˆåˆ°æ ‡å‡†æ‰©æ•£æ¨¡å‹æµæ°´çº¿ä¸­ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ç”Ÿæˆå¼æ¨¡å‹, å¤šå®ä¾‹å›¾åƒç”Ÿæˆ, ç»†ç²’åº¦è¯­ä¹‰æ§åˆ¶, æ–‡æœ¬åµŒå…¥è¡¨ç¤º, æ©ç æ³¨æ„åŠ›æœºåˆ¶, æ‰©æ•£æ¨¡å‹, å¯ç»„åˆå›¾åƒåˆæˆ, åŸºå‡†æ•°æ®é›†æ„å»º, diffusion

**è¯„åˆ†**ï¼š34

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18282v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18282v1.pdf)

---

## cs.LG

## [18. Assigning Confidence: K-partition Ensembles](https://arxiv.org/abs/2602.18435v1)

**ä½œè€…**ï¼šAggelos Semoglou, John Pavlopoulos  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºCAKEæ¡†æ¶ï¼Œé€šè¿‡èšç±»é›†æˆè¯„ä¼°æ¯ä¸ªæ ·æœ¬çš„èšç±»ç½®ä¿¡åº¦ï¼Œç»™å‡º0åˆ°1ä¹‹é—´çš„å¯è§£é‡Šæ‰“åˆ†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿèšç±»åªèƒ½ç»™å‡ºæ•´ä½“ç»“æœï¼Œæ— æ³•è¡¡é‡å•ä¸ªç‚¹è¢«åˆ†é…åˆ°æŸç°‡æ˜¯å¦å¯é ï¼Œå°¤å…¶åœ¨å¯¹åˆå§‹åŒ–æ•æ„Ÿçš„ç®—æ³•ï¼ˆå¦‚k-meansï¼‰ä¸­ï¼Œç‚¹çº§ä¸ç¨³å®šä¼šå½±å“å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„é€ å¤šæ¬¡èšç±»çš„k-partitioné›†æˆï¼Œä»ä¸­è®¡ç®—æ¯ä¸ªç‚¹çš„ä¸¤ç±»ç»Ÿè®¡é‡ï¼šè·¨è¿è¡Œçš„ä¸€è‡´æ€§ï¼ˆassignment stabilityï¼‰å’Œåœ¨å„ç°‡å±€éƒ¨å‡ ä½•ç»“æ„ä¸­çš„æ‹Ÿåˆä¸€è‡´æ€§ï¼Œå¹¶å°†äºŒè€…èåˆä¸ºä¸€ä¸ªç½®ä¿¡åº¦å¾—åˆ†ã€‚

**ä¸»è¦ç»“è®º**ï¼šç†è®ºåˆ†æè¡¨æ˜CAKEåœ¨å™ªå£°ä¸‹ä»èƒ½åŒºåˆ†ç¨³å®šä¸ä¸ç¨³å®šç‚¹ï¼›å®éªŒç»“æœæ˜¾ç¤ºå…¶èƒ½æœ‰æ•ˆæ ‡å‡ºæ¨¡ç³Šè¾¹ç•Œç‚¹å’Œç¨³å®šæ ¸å¿ƒç‚¹ï¼Œä¸ºè¿‡æ»¤æˆ–ä¼˜å…ˆå¤„ç†æ ·æœ¬ä»¥æå‡èšç±»è´¨é‡æä¾›äº†æœ‰ç”¨çš„ç½®ä¿¡æ’åºã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , èšç±»ä¸ç¡®å®šæ€§è¯„ä¼°, æ— ç›‘ç£ç»“æ„å‘ç°, èšç±»é›†æˆæ–¹æ³•, ç‚¹çº§ç½®ä¿¡åº¦è¯„åˆ†, å±€éƒ¨å‡ ä½•ä¸€è‡´æ€§, èšç±»ç»“æœç¨³å®šæ€§, å™ªå£°é²æ£’æ€§åˆ†æ, æ•°æ®ç‚¹ä¼˜å…ˆçº§ç­›é€‰, agent

**è¯„åˆ†**ï¼š18

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18435v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18435v1.pdf)

---

## [19. The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning](https://arxiv.org/abs/2602.18428v1)

**ä½œè€…**ï¼šMojtaba Sahraee-Ardakan, Mauricio Delbracio, Peyman Milanfar  
**åˆ†ç±»**ï¼šcs.LG, cs.CV, eess.IV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$, where $p(\mathbf{u}) = \int p(\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡ä»å‡ ä½•ä¸èƒ½é‡è§†è§’è§£é‡Šäº†ä¸ºä½•æ— éœ€æ˜¾å¼å™ªå£°æ¡ä»¶çš„â€œè‡ªæ´½/ç›²â€æ‰©æ•£æ¨¡å‹ä¾ç„¶å¯ä»¥ç¨³å®šé‡‡æ ·ï¼Œå¹¶æœ¬è´¨ä¸Šåœ¨æ‰§è¡Œå¯¹è¾¹ç¼˜èƒ½é‡çš„é»æ›¼æ¢¯åº¦æµã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰ç›²æ‰©æ•£å’ŒEquilibrium Matchingç­‰å™ªå£°æ— å…³æ¨¡å‹åœ¨å®è·µä¸Šæ•ˆæœè‰¯å¥½ï¼Œä½†ç†è®ºä¸Šå­˜åœ¨ä¸¤ä¸ªæ‚–è®ºï¼šä¸€æ˜¯å½“å™ªå£°æ°´å¹³æ˜¯éšæœºå˜é‡æ—¶ç©¶ç«Ÿåœ¨ä¼˜åŒ–ä»€ä¹ˆèƒ½é‡æ™¯è§‚ï¼ŒäºŒæ˜¯å•ä¸€æœ‰ç•Œå‘é‡åœºåœ¨é è¿‘æ•°æ®æµå½¢å¤„å¦‚ä½•é¿å…æ¢¯åº¦å‘æ•£å¹¶ä¿æŒé‡‡æ ·ç¨³å®šã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…å½¢å¼åŒ–å®šä¹‰äº†å¯¹æ‰€æœ‰å™ªå£°æ°´å¹³åŠ æƒç§¯åˆ†å¾—åˆ°çš„â€œè¾¹ç¼˜èƒ½é‡â€E_margï¼Œå¹¶è¯æ˜å™ªå£°æ— å…³æ¨¡å‹å­¦ä¹ åˆ°çš„æ˜¯åœ¨ä¸€ä¸ªå±€éƒ¨å…±å½¢åº¦é‡ä¸‹å¯¹è¯¥èƒ½é‡è¿›è¡Œçš„é»æ›¼æ¢¯åº¦æµï¼›åŒæ—¶é€šè¿‡ç›¸å¯¹èƒ½é‡åˆ†è§£åˆ†æå¥‡å¼‚æ€§è¢«åº¦é‡ç²¾ç¡®æŠµæ¶ˆçš„æœºåˆ¶ï¼Œå¹¶å¯¹ä¸åŒå‚æ•°åŒ–ï¼ˆå™ªå£°é¢„æµ‹ vs é€Ÿåº¦é¢„æµ‹ï¼‰å»ºç«‹å¢ç›Šä¸ç¨³å®šæ€§æ¡ä»¶ã€‚

**ä¸»è¦ç»“è®º**ï¼š1ï¼‰è‡ªä¸»/ç›²æ‰©æ•£å¹¶éç®€å•ç›²å»å™ªï¼Œè€Œæ˜¯åœ¨è¾¹ç¼˜èƒ½é‡ä¸Šçš„å‡ ä½•æ¢¯åº¦æµï¼›2ï¼‰åŸå§‹èƒ½é‡åœ¨æ³•å‘æ–¹å‘å…·1/t^på¥‡å¼‚åŠ¿é˜±ï¼Œä½†å­¦ä¹ åˆ°çš„æ—¶é—´ä¸å˜å‘é‡åœºéšå¼å¼•å…¥çš„å…±å½¢åº¦é‡å¯å°†å…¶è½¬åŒ–ä¸ºç¨³å®šå¸å¼•å­ï¼›3ï¼‰å™ªå£°é¢„æµ‹å‚æ•°åŒ–å­˜åœ¨â€œJensen Gapâ€ï¼Œä½¿ä¼°è®¡è¯¯å·®è¢«é«˜å¢ç›Šæ”¾å¤§ï¼Œå¯¼è‡´ç¡®å®šæ€§ç›²æ¨¡å‹ç¾éš¾æ€§å¤±æ•ˆï¼›4ï¼‰é€Ÿåº¦å‚æ•°åŒ–æ»¡è¶³æœ‰ç•Œå¢ç›Šæ¡ä»¶ï¼Œå¯å°†åéªŒä¸ç¡®å®šæ€§å¸æ”¶åˆ°å¹³æ»‘æ¼‚ç§»é¡¹ä¸­ï¼Œå› æ­¤å¤©ç„¶æ›´ç¨³å®šã€‚

**å…³é”®è¯**ï¼šæ‰©æ•£æ¨¡å‹, ç”Ÿæˆæ¨¡å‹, å‘é‡åœºå­¦ä¹ , å™ªå£°æ— å…³å»ºæ¨¡, è¾¹ç¼˜èƒ½é‡å‡½æ•°, é»æ›¼æ¢¯åº¦æµ, ç¨³å®šé‡‡æ ·ç†è®º, é€Ÿåº¦å‚æ•°åŒ–, autonomous

**è¯„åˆ†**ï¼š36

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18428v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18428v1.pdf)

---

## [20. Unifying approach to uniform expressivity of graph neural networks](https://arxiv.org/abs/2602.18409v1)

**ä½œè€…**ï¼šHuan Luo, Jonni Virtema  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.LO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºæ¨¡æ¿GNNï¼ˆT-GNNï¼‰åŠå…¶å¯¹åº”é€»è¾‘æ¡†æ¶ï¼Œç»Ÿä¸€åˆ»ç”»å¹¶æå‡å›¾ç¥ç»ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰GNNå¤šå±€é™äºå±€éƒ¨é‚»å±…æˆ–å…¨å±€è¯»å‡ºï¼Œå¯¹å¤æ‚å­ç»“æ„ï¼ˆå¦‚ç¯ã€ç‰¹å®šå­å›¾ï¼‰è¡¨è¾¾åŠ›ä¸è¶³ï¼Œä¸”ç¼ºä¹ç»Ÿä¸€çš„ç†è®ºåˆ†ææ¡†æ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…å¼•å…¥ä»¥â€œå›¾æ¨¡æ¿â€ä¸ºå•ä½èšåˆä¿¡æ¯çš„T-GNNæ¡†æ¶ï¼Œå¹¶æå‡ºå¯¹åº”çš„åˆ†çº§æ¨¡æ¿æ¨¡æ€é€»è¾‘GML(T)ã€æ¨¡æ¿åŒæ¨¡æ‹Ÿä¸æ¨¡æ¿ç‰ˆWLç®—æ³•ï¼Œå»ºç«‹T-GNNä¸GML(T)åœ¨è¡¨è¾¾èƒ½åŠ›ä¸Šçš„ç­‰ä»·ã€‚

**ä¸»è¦ç»“è®º**ï¼šT-GNNä¸ºGNNçš„å­ç»“æ„å¢å¼ºæä¾›äº†ç»Ÿä¸€æè¿°ä¸åˆ†æå·¥å…·ï¼Œè¯æ˜äº†å…¶é€»è¾‘è¡¨è¾¾åŠ›å¹¶å±•ç¤ºäº†æ ‡å‡†AC-GNNåŠè‹¥å¹²å˜ä½“éƒ½å¯è§†ä¸ºT-GNNå®ä¾‹ï¼Œä»è€Œç»Ÿä¸€äº†å¤šç§æå‡GNNè¡¨è¾¾åŠ›çš„æ¶æ„è®¾è®¡ã€‚

**å…³é”®è¯**ï¼šå›¾ç¥ç»ç½‘ç»œ, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œè¡¨è¾¾èƒ½åŠ›, æ¨¡æ¿GNN, T-GNNæ¡†æ¶, å›¾ç»“æ„å­å›¾åŒ¹é…, å›¾åŒæ„æµ‹è¯•, é€»è¾‘å¯è¡¨è¾¾æ€§åˆ†æ, Weisfeiler-Lemanç®—æ³•, å­ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ , ml

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18409v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18409v1.pdf)

---

## [21. Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study](https://arxiv.org/abs/2602.18403v1)

**ä½œè€…**ï¼šOrfeas Bourchas, George Papalambrou  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºä¸€ç§å°†ç‰©ç†æ¨è¿›å®šå¾‹ä¸æ•°æ®é©±åŠ¨æ®‹å·®å­¦ä¹ ç›¸ç»“åˆçš„æ··åˆæ¨¡å‹ï¼Œç”¨äºæ›´å‡†ç¡®ä¸”å¯å¤–æ¨çš„èˆ¹èˆ¶ä¸»æœºåŠŸç‡é¢„æµ‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçº¯æœºå™¨å­¦ä¹ æ¨¡å‹è™½èƒ½æ‹Ÿåˆéçº¿æ€§ï¼Œä½†éš¾ä»¥ä¿è¯æ»¡è¶³åŠŸç‡-èˆªé€Ÿçš„èºæ—‹æ¡¨å®šå¾‹ï¼Œåœ¨è®­ç»ƒæ•°æ®ç¨€ç–åŒºé—´å¤–æ¨æ€§èƒ½å·®ï¼Œå½±å“èˆ¹èˆ¶èŠ‚èƒ½ä¸æ’æ”¾åˆè§„ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå…ˆåˆ©ç”¨é™æ°´è¯•èˆªå¾—åˆ°å½¢å¦‚ P=cV^n çš„ç‰©ç†åŸºçº¿æ¨¡å‹ï¼Œå†ç”¨XGBoostã€ç®€å•ç¥ç»ç½‘ç»œå’ŒPINNç­‰æ¨¡å‹ä»…å­¦ä¹ â€œå®æµ‹åŠŸç‡âˆ’åŸºçº¿åŠŸç‡â€çš„æ®‹å·®ï¼Œå®ç°ç‰©ç†çº¦æŸä¸‹çš„éçº¿æ€§ä¿®æ­£ï¼Œå¹¶ä¸ä¸å«åŸºçº¿çš„çº¯æ•°æ®é©±åŠ¨ç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å®èˆ¹è¿è¥æ•°æ®éªŒè¯ä¸­ï¼Œç‰©ç†å¼•å¯¼çš„æ··åˆæ¨¡å‹åœ¨æ•°æ®ç¨€ç–åŒºåŸŸæ˜¾è‘—ä¼˜äºçº¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œåœ¨æ•°æ®å¯†é›†åŒºåŸŸæ€§èƒ½ç›¸å½“ï¼Œä¸”å…·æœ‰è‰¯å¥½ç‰©ç†ä¸€è‡´æ€§ä¸è®¡ç®—æ•ˆç‡ï¼Œé€‚ç”¨äºèˆ¹èˆ¶æ€§èƒ½ç›‘æµ‹ä¸èƒ½æ•ˆä¼˜åŒ–å†³ç­–ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , äººå·¥ç¥ç»ç½‘ç»œ, ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ, é›†æˆå­¦ä¹ , XGBoost, èˆ¹èˆ¶èƒ½æ•ˆé¢„æµ‹, æ®‹å·®å­¦ä¹ , æ··åˆå»ºæ¨¡, èˆªè¡Œå·¥å†µå»ºæ¨¡, åŠŸç‡æ›²çº¿æ‹Ÿåˆ, machine learning

**è¯„åˆ†**ï¼š24

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18403v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18403v1.pdf)

---

## [22. Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay](https://arxiv.org/abs/2602.18401v1)

**ä½œè€…**ï¼šJosue Casco-Rodriguez, Nanda H. Krishna, Richard G. Baraniuk  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, q-bio.NC, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Biological neural networks (like the hippocampus) can internally generate "replay" resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡é€šè¿‡åœ¨å™ªå£°RNNä¸­å¼•å…¥éšè—æ€æ³„éœ²ä¸äºŒé˜¶åŠ¨åŠ›å­¦ï¼ˆåŠ¨é‡ï¼‰ï¼Œç³»ç»Ÿæ€§æ”¹è¿›äº†ç±»æµ·é©¬ä½“çš„è·¯å¾„é‡æ”¾è´¨é‡ä¸é€Ÿåº¦ï¼Œå¹¶ç”¨é‡‡æ ·è§†è§’ç»Ÿä¸€è§£é‡Šè¿™äº›æœºåˆ¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å°†æµ·é©¬ä½“é‡æ”¾å»ºæ¨¡ä¸ºå™ªå£°RNNçš„å·¥ä½œå¤šç”¨Langeviné‡‡æ ·è§£é‡Šï¼Œä½†éš¾ä»¥è¯´æ˜ä¸ºä½•åŠ å…¥æ³„éœ²ã€é€‚åº”ç­‰ä¿®é¥°ä¼šæ˜¾è‘—æ”¹å˜é‡æ”¾ç‰¹æ€§ï¼Œå› æ­¤éœ€è¦ä»ä¸¥æ ¼çš„é‡‡æ ·ä¸åŠ¨åŠ›å­¦è§’åº¦é‡æ–°åˆ†æå¹¶è®¾è®¡æ›´é«˜æ•ˆçš„é‡æ”¾æœºåˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…å°†è·¯å¾„ç§¯åˆ†RNNçš„é‡æ”¾å½¢å¼åŒ–ä¸ºæ—¶é—´å˜åŒ–çš„é‡‡æ ·è¿‡ç¨‹ï¼Œç†è®ºæ¨å¯¼å‡ºç†æƒ³é‡æ”¾çš„æ¢¯åº¦æ€§è´¨ï¼Œè¿›è€Œå¼•å…¥éšè—æ€æ³„éœ²ã€è´Ÿåé¦ˆé€‚åº”ä¸éšè—æ€åŠ¨é‡ï¼ˆç±»æ¬ é˜»å°¼Langevinï¼‰ï¼Œå¹¶åœ¨2Dè¿·å®«ä¸é«˜ç»´ä½ç½®ç»†èƒæ´»åŠ¨è·¯å¾„ä¸Šç³»ç»Ÿå®éªŒéªŒè¯å¯¹æ¢ç´¢æ€§ã€é€Ÿåº¦ä¸æ—¶é—´å‹ç¼©çš„å½±å“ã€‚

**ä¸»è¦ç»“è®º**ï¼šï¼ˆ1ï¼‰ç†æƒ³é‡æ”¾å¯¹åº”çš„æ¢¯åº¦æ˜¯æ—¶å˜ä¸”éš¾ä¼°è®¡ï¼Œä½†è‡ªç„¶æŒ‡å‘åœ¨RNNä¸­åŠ å…¥éšè—æ€æ³„éœ²ï¼›ï¼ˆ2ï¼‰éšè—æ€é€‚åº”èƒ½ä¿ƒè¿›çŠ¶æ€ç©ºé—´æ¢ç´¢ï¼Œå´å¼•å…¥éé©¬å°”å¯å¤«æ€§å¹¶å‡æ…¢é‡æ”¾ï¼›ï¼ˆ3ï¼‰åŠ å…¥éšè—æ€åŠ¨é‡å¯å®ç°æ—¶é—´å‹ç¼©å¼é‡æ”¾ï¼Œå¹¶ä¸é€‚åº”äº’è¡¥ï¼Œåœ¨ä¿æŒæ¢ç´¢æ€§çš„åŒæ—¶æ˜¾è‘—åŠ å¿«é‡æ”¾ï¼Œä¸ºç±»æµ·é©¬ä½“RNNé‡æ”¾æä¾›äº†ç»Ÿä¸€çš„äºŒé˜¶åŠ¨åŠ›å­¦é‡‡æ ·æ¡†æ¶ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, å¾ªç¯ç¥ç»ç½‘ç»œRNN, å™ªå£°RNN, åºåˆ—å»ºæ¨¡, è½¨è¿¹é‡æ”¾, è·¯å¾„ç§¯åˆ†, ç¥ç»è¡¨å¾å­¦ä¹ , æµ·é©¬ä½“å¯å‘æ¨¡å‹, neural network

**è¯„åˆ†**ï¼š16

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18401v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18401v1.pdf)

---

## [23. PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing](https://arxiv.org/abs/2602.18396v1)

**ä½œè€…**ï¼šEhsan Lari, Reza Arablouei, Stefan Werner  
**åˆ†ç±»**ï¼šcs.LG, eess.SP, math.PR, stat.AP, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary's perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šPRISM-FCP æå‡ºäº†ä¸€ç§åœ¨è®­ç»ƒä¸æ ¡å‡†ä¸¤é˜¶æ®µå‡å…·æ‹œå åº­é²æ£’æ€§çš„è”é‚¦å…±å½¢é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡éƒ¨åˆ†å‚æ•°å…±äº«ä¸é²æ£’é‡åŒ–ç¡®ä¿åœ¨æ”»å‡»ä¸‹ä»ä¿æŒæœ‰æ•ˆç½®ä¿¡åŒºé—´ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è”é‚¦å…±å½¢é¢„æµ‹æ–¹æ³•é€šå¸¸åªåœ¨æ ¡å‡†é˜¶æ®µé˜²å¾¡æ¶æ„å®¢æˆ·ç«¯ï¼Œå¯¼è‡´è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æ˜“è¢«æŠ•æ¯’ä¸”ç½®ä¿¡åŒºé—´åœ¨æ”»å‡»ä¸‹ä¸¥é‡è†¨èƒ€ï¼Œç¼ºä¹ç«¯åˆ°ç«¯çš„é²æ£’ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨è®­ç»ƒé˜¶æ®µï¼ŒPRISM-FCP æ¯è½®ä»…ä» D ä¸ªå‚æ•°ä¸­éšæœºå…±äº« M ä¸ªï¼Œä½¿æ¶æ„æ‰°åŠ¨åœ¨èšåˆä¸­çš„èƒ½é‡ç¼©å°çº¦ M/Dï¼Œä»è€Œé™ä½ MSEï¼›åœ¨æ ¡å‡†é˜¶æ®µï¼Œå°†éä¸€è‡´æ€§è¯„åˆ†è½¬æ¢ä¸ºè¡¨å¾å‘é‡ï¼ŒåŸºäºè·ç¦»è®¡ç®—â€œæ¶æ„åº¦â€å¹¶å¯¹å¯ç–‘å®¢æˆ·ç«¯çš„è´¡çŒ®è¿›è¡Œé™æƒæˆ–è¿‡æ»¤åå†ä¼°è®¡å…±å½¢åˆ†ä½æ•°ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨åˆæˆæ•°æ®åŠ UCI Superconductivity æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPRISM-FCP åœ¨å­˜åœ¨æ‹œå åº­æ”»å‡»æ—¶ä»èƒ½ç»´æŒåä¹‰è¦†ç›–ç‡ï¼Œé¿å…æ ‡å‡† FCP ç½®ä¿¡åŒºé—´è†¨èƒ€ï¼Œå¹¶åŒæ—¶å®ç°é²æ£’æ€§ä¸é€šä¿¡æ•ˆç‡çš„å¹³è¡¡ã€‚

**å…³é”®è¯**ï¼šè”é‚¦å­¦ä¹ , æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , åˆ†å¸ƒå¼è®­ç»ƒ, å¯¹æŠ—é²æ£’æ€§, æ‹œå åº­å®¹é”™, ä¸ç¡®å®šæ€§é‡åŒ–, ä¿åºé¢„æµ‹, å‚æ•°éƒ¨åˆ†å…±äº«, æ¶æ„å®¢æˆ·ç«¯æ£€æµ‹, rag

**è¯„åˆ†**ï¼š34

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18396v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18396v1.pdf)

---

## [24. FedZMG: Efficient Client-Side Optimization in Federated Learning](https://arxiv.org/abs/2602.18384v1)

**ä½œè€…**ï¼šFotios Zantalis, Evangelos Zervas, Grigorios Koulouras  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šFedZMG æå‡ºä¸€ç§åœ¨è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ä¾§è¿›è¡Œé›¶å‡å€¼æ¢¯åº¦æŠ•å½±çš„æ— å‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨éIIDæ•°æ®ä¸‹å…¼é¡¾é«˜æ•ˆæ€§ä¸æ›´å¿«æ”¶æ•›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è”é‚¦å­¦ä¹ åœ¨éIIDæ•°æ®ä¸‹å­˜åœ¨ä¸¥é‡client-drifté—®é¢˜ï¼Œè€Œè¯¸å¤šè‡ªé€‚åº”ä¼˜åŒ–å™¨è™½èƒ½ç¼“è§£ä½†è®¡ç®—ä¸é€šä¿¡å¼€é”€è¿‡å¤§ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™çš„è¾¹ç¼˜/ç‰©è”ç½‘è®¾å¤‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šFedZMG åœ¨æœ¬åœ°è®­ç»ƒæ—¶å¯¹æ¢¯åº¦è¿›è¡Œâ€œé›¶å‡å€¼è¶…å¹³é¢â€æŠ•å½±ï¼ˆåŸºäºæ¢¯åº¦ä¸­å¿ƒåŒ–æ€æƒ³ï¼‰ï¼Œé€šè¿‡å»é™¤æ¢¯åº¦ä¸­çš„å…¨å±€åç§»æˆåˆ†æ¥é™ä½æœ‰æ•ˆæ¢¯åº¦æ–¹å·®ï¼Œæ— éœ€é¢å¤–é€šä¿¡æˆ–è¶…å‚æ•°è°ƒèŠ‚ï¼Œå¹¶ç»™å‡ºæ”¶æ•›æ€§ç†è®ºåˆ†æã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ EMNISTã€CIFAR100 å’Œ Shakespeare ç­‰æ•°æ®é›†çš„é«˜åº¦éIIDåœºæ™¯ä¸­ï¼ŒFedZMG ç›¸æ¯” FedAvg ä¸ FedAdam å®éªŒä¸Šè¡¨ç°å‡ºæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„æœ€ç»ˆéªŒè¯ç²¾åº¦ï¼Œå¹¶åœ¨ç†è®ºä¸Šè¯æ˜å…¶å…·æœ‰æ›´ç´§çš„æ”¶æ•›ç•Œã€‚

**å…³é”®è¯**ï¼šè”é‚¦å­¦ä¹ , æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , è¾¹ç¼˜è®¡ç®—, å®¢æˆ·ç«¯ä¼˜åŒ–, æ¢¯åº¦é›†ä¸­åŒ–, FedZMGç®—æ³•, éIIDæ•°æ®, æ”¶æ•›æ€§åˆ†æ, ç‰©è”ç½‘åœºæ™¯, agent

**è¯„åˆ†**ï¼š21

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18384v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18384v1.pdf)

---

## [25. Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering](https://arxiv.org/abs/2602.18348v1)

**ä½œè€…**ï¼šMatheus Camilo da Silva, Leonardo Arrighi, Ana Carolina Lorena ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡ç³»ç»Ÿæ¢³ç†AutoClusteringä¸­çš„æ•°æ®é›†å…ƒç‰¹å¾ï¼Œå¹¶ç”¨å¯è§£é‡Šæ€§æŠ€æœ¯åˆ†æè¿™äº›å…ƒç‰¹å¾å¦‚ä½•å½±å“è‡ªåŠ¨èšç±»ç®—æ³•ä¸è¶…å‚æ•°æ¨èï¼Œä»è€Œæå‡AutoMLå†³ç­–é€æ˜åº¦ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰AutoClusteringè™½ç„¶èƒ½è‡ªåŠ¨å®Œæˆç®—æ³•é€‰æ‹©å’Œè¶…å‚æœç´¢ï¼Œä½†å…¶åŸºäºå…ƒç‰¹å¾çš„å†³ç­–è¿‡ç¨‹ä¸é€æ˜ï¼Œéš¾ä»¥è¯Šæ–­åå·®ã€æ”¹è¿›å…ƒç‰¹å¾å·¥ç¨‹æˆ–æå‡ç³»ç»Ÿå¯é æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…ç»¼è¿°å¹¶å½’ç±»22ç§æ–¹æ³•ä¸­çš„æ•°æ®é›†å…ƒç‰¹å¾ï¼Œæ„å»ºå…ƒç‰¹å¾åˆ†ç±»ä½“ç³»ï¼›åœ¨é€‰å®šæ¡†æ¶ä¸Šç”¨å…¨å±€è§£é‡Šæ–¹æ³•ï¼ˆDecision Predicate Graphsï¼‰åˆ†æå…ƒæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§ï¼Œå¹¶ç»“åˆå±€éƒ¨è§£é‡Šå·¥å…·SHAPæ·±å…¥å‰–æå…·ä½“èšç±»å†³ç­–ã€‚

**ä¸»è¦ç»“è®º**ï¼šç»“æœè¡¨æ˜ä¸åŒæ–¹æ³•åœ¨å…ƒç‰¹å¾é‡è¦æ€§ä¸Šå­˜åœ¨ç¨³å®šæ¨¡å¼ï¼Œä¹Ÿæš´éœ²å‡ºå½“å‰å…ƒå­¦ä¹ ç­–ç•¥ä¸­å¯èƒ½å¯¼è‡´æ¨èåå·®çš„ç»“æ„æ€§é—®é¢˜ï¼Œå¹¶æ®æ­¤æå‡ºæ›´å¯è§£é‡Šçš„AutoML/AutoClusteringè®¾è®¡å»ºè®®ï¼Œä¸ºæå‡æ— ç›‘ç£è‡ªåŠ¨åŒ–å­¦ä¹ çš„å†³ç­–é€æ˜åº¦æä¾›å®è·µåŸºç¡€ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, AutoMLè‡ªåŠ¨æœºå™¨å­¦ä¹ , æ— ç›‘ç£å­¦ä¹ èšç±», ç®—æ³•é€‰æ‹©AS, è¶…å‚æ•°ä¼˜åŒ–HPO, å…ƒå­¦ä¹ meta-learning, æ¨¡å‹å¯è§£é‡Šæ€§, ç‰¹å¾é‡è¦æ€§åˆ†æ, SHAPè§£é‡Šæ–¹æ³•, å†³ç­–è°“è¯å›¾DPG

**è¯„åˆ†**ï¼š21

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18348v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18348v1.pdf)

---

## [26. On the "Induction Bias" in Sequence Models](https://arxiv.org/abs/2602.18333v1)

**ä½œè€…**ï¼šM. Reza Ebrahimi, MichaÃ«l Defferrard, Sunny Panchal ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡ç³»ç»Ÿæ¯”è¾ƒäº†Transformerä¸RNNåœ¨çŠ¶æ€è·Ÿè¸ªä»»åŠ¡ä¸Šçš„å½’çº³åç½®ï¼Œå‘ç°Transformerå³ä¾¿åœ¨åˆ†å¸ƒå†…ä¹Ÿæ˜æ˜¾ä¸å¦‚RNNæ•°æ®é«˜æ•ˆï¼Œä¸”éš¾ä»¥åœ¨ä¸åŒåºåˆ—é•¿åº¦ä¹‹é—´å…±äº«å·²å­¦åˆ°çš„çŠ¶æ€è·Ÿè¸ªæœºåˆ¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰æ‰¹è¯„å¤šé›†ä¸­åœ¨Transformeråœ¨é•¿åº¦å¤–æ¨ç­‰OODåœºæ™¯ä¸­çš„å¤±è´¥ï¼Œè¿™ç¯‡å·¥ä½œå…³æ³¨ï¼šåœ¨è®­ç»ƒå’Œæµ‹è¯•åˆ†å¸ƒä¸€è‡´æ—¶ï¼ŒTransformeråœ¨çŠ¶æ€è·Ÿè¸ªæ–¹é¢æ˜¯å¦ä»å­˜åœ¨æ ¹æœ¬æ€§å±€é™ï¼Œå¹¶ä¸RNNçš„å½’çº³åç½®å·®å¼‚ä½•åœ¨ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æ„é€ å¤šç§éœ€è¦æ˜¾å¼çŠ¶æ€è·Ÿè¸ªçš„åºåˆ—ä»»åŠ¡ï¼Œåœ¨å¤šç§ç›‘ç£è®¾å®šä¸‹ï¼Œç³»ç»Ÿæ¯”è¾ƒTransformerä¸RNNçš„æ ·æœ¬å¤æ‚åº¦ï¼ˆéšçŠ¶æ€ç©ºé—´å¤§å°ä¸åºåˆ—é•¿åº¦å˜åŒ–ï¼‰ï¼Œå¹¶é€šè¿‡è·¨é•¿åº¦è®­ç»ƒ/æµ‹è¯•åˆ†ææ¨¡å‹åœ¨ä¸åŒåºåˆ—é•¿åº¦ä¸Šçš„æƒé‡å…±äº«å’Œâ€œæ‘Šè¿˜å­¦ä¹ â€èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šTransformeråœ¨çŠ¶æ€ç©ºé—´è§„æ¨¡å’Œåºåˆ—é•¿åº¦å¢å¤§æ—¶ï¼Œæ‰€éœ€è®­ç»ƒæ•°æ®å¢é•¿è¿œå¿«äºRNNï¼Œä¸”å…¶å­¦åˆ°çš„è§£å¼ºçƒˆä¾èµ–å…·ä½“é•¿åº¦ï¼Œè·¨é•¿åº¦æƒé‡å…±äº«ç”šå¾®ç”šè‡³æœ‰è´Ÿæ•ˆåº”ï¼›è€ŒRNNåˆ™èƒ½æœ‰æ•ˆå¤ç”¨å‚æ•°è¿›è¡Œæ‘Šè¿˜å­¦ä¹ ï¼Œè¯´æ˜å³ä½¿åœ¨åˆ†å¸ƒå†…ï¼ŒçŠ¶æ€è·Ÿè¸ªä»æ˜¯Transformerçš„æ ¹æœ¬æŒ‘æˆ˜ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , transformer, ç¥ç»ç½‘ç»œ, åºåˆ—å»ºæ¨¡, çŠ¶æ€è·Ÿè¸ª, é•¿åº¦å¤–æ¨, æ•°æ®æ•ˆç‡, ç›‘ç£å­¦ä¹ , é•¿åº¦æ³›åŒ–, æƒé‡å…±äº«

**è¯„åˆ†**ï¼š24

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18333v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18333v1.pdf)

---

## [27. JPmHC Dynamical Isometry via Orthogonal Hyper-Connections](https://arxiv.org/abs/2602.18308v1)

**ä½œè€…**ï¼šBiswa Sengupta, Jinhua Wang, Leo Brunswic  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºJPmHCæ¡†æ¶ï¼Œç”¨å—çº¦æŸçš„å¯è®­ç»ƒçº¿æ€§æ··åˆå™¨æ›¿ä»£ä¼ ç»Ÿæ®‹å·®/Hyper-Connectionsä¸­çš„æ’ç­‰è·³è¿ï¼Œåœ¨ä¿æŒè‰¯å¥½Jacobianè°±çš„åŒæ—¶æå‡è®­ç»ƒç¨³å®šæ€§ä¸æ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰Hyper-Connectionsè™½ç„¶é€šè¿‡æ›´å®½å’Œæ›´å¤æ‚çš„æ®‹å·®æµæå‡æ€§èƒ½ï¼Œä½†ç ´åäº†æ’ç­‰æ˜ å°„ç‰¹æ€§ï¼Œå¯¼è‡´æ¢¯åº¦ä¸ç¨³å®šã€éš¾ä»¥æ‰©å±•ã€å†…å­˜å¼€é”€å¤§ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ—¢ä¿æŒè°±è‰¯å¥½åˆå¯æ‰©å±•çš„è¿æ¥æœºåˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†nè·¯å¹¶è¡Œæ®‹å·®æµé€šè¿‡å—æµå½¢çº¦æŸçš„çº¿æ€§æ··åˆå™¨Mï¼ˆå¦‚åŒéšæœºã€Stiefelã€Grassmannï¼‰è¿›è¡Œç»„åˆï¼Œåˆ©ç”¨è‡ªç”±æ¦‚ç‡åˆ†æé¢„æµ‹å¹¶è®¾è®¡Jacobianè°±ï¼Œç”¨éšå¼å¾®åˆ†æå‡æŠ•å½±è®¡ç®—çš„å†…å­˜æ•ˆç‡ï¼Œå¹¶é€šè¿‡Cayleyå˜æ¢å®ç°Stiefelçº¦æŸä¸‹çš„æ­£äº¤æ··åˆå™¨ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ARC-AGIç­‰ä»»åŠ¡ä¸Šï¼ŒJPmHCç›¸è¾ƒåŒéšæœºåŸºçº¿å®ç°æ›´å¿«æ”¶æ•›ã€æ›´é«˜ç²¾åº¦å’Œæ›´ä½è®¡ç®—æˆæœ¬ï¼Œå±•ç¤ºå‡ºä½œä¸ºä¸€ç§å¯æ‰©å±•ã€è°±æ„ŸçŸ¥ä¸”ç¨³å®šé«˜æ•ˆçš„Hyper-Connectionæ‰©å±•å½¢å¼ï¼Œå¯¹æ‹“æ‰‘åŒ–ç½‘ç»œç»“æ„è®¾è®¡å’ŒåŸºç¡€æ¨¡å‹æ¼”åŒ–å…·æœ‰å¯å‘æ„ä¹‰ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, æ®‹å·®è¿æ¥, è¶…è¿æ¥æ¶æ„, æ­£äº¤çº¦æŸ, Stiefelæµå½¢, Cayleyå˜æ¢, è°±å½’ä¸€åŒ–, ç¨³å®šè®­ç»ƒ, é«˜æ•ˆæ¢¯åº¦ä¼ æ’­, deep learning

**è¯„åˆ†**ï¼š20

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18308v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18308v1.pdf)

---

## [28. Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory](https://arxiv.org/abs/2602.18297v1)

**ä½œè€…**ï¼šUsman Anwar, Tim Bakker, Dana Kianfar ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CL, cs.IT  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡ç”¨ä¿¡æ¯è®ºå½¢å¼åŒ–åˆ†æâ€œæ€ç»´é“¾ç›‘æ§â€çš„å¯ç›‘æ§æ€§æ¡ä»¶ï¼Œå¹¶é€šè¿‡æ–°è®­ç»ƒç›®æ ‡æ˜¾è‘—æå‡ç›‘æ§å™¨åœ¨é˜²æ­¢å¥–åŠ±é»‘å®¢ç­‰åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰åŸºäºæ€ç»´é“¾ï¼ˆCoTï¼‰çš„ç›‘æ§å™¨è™½èƒ½æŸ¥çœ‹æ¨ç†è¿‡ç¨‹ï¼Œä½†ç¼ºä¹å¯¹â€œä½•æ—¶ã€åœ¨ä½•ç§æ¡ä»¶ä¸‹â€è¿™äº› CoT çœŸæ­£æœ‰åŠ©äºå¯é ç›‘æ§çš„ç†è®ºç†è§£ï¼Œä¹Ÿç¼ºä¹ç³»ç»Ÿæå‡å¯ç›‘æ§æ€§çš„è®­ç»ƒæ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…ç”¨äº’ä¿¡æ¯å½¢å¼åŒ– CoT ä¸è¾“å‡ºä¹‹é—´çš„ä¿¡æ¯å…³ç³»ï¼Œæå‡ºâ€œä¿¡æ¯ç¼ºå£â€å’Œâ€œå¼•å‡ºè¯¯å·®â€ä¸¤ç±»è¿‘ä¼¼è¯¯å·®ï¼Œå¹¶è®¾è®¡ä¸¤ç§æå‡æ–¹æ¡ˆï¼šä¸€æ˜¯åŸºäºâ€œç›‘ç£è€…ï¼ˆoracleï¼‰â€çš„è®­ç»ƒï¼Œç›´æ¥å¥–åŠ±æ¨¡å‹ç”Ÿæˆèƒ½æœ€å¤§åŒ–ç›‘æ§å‡†ç¡®ç‡çš„ CoTï¼›äºŒæ˜¯æ— éœ€æ ‡ç­¾ã€æœ€å¤§åŒ–è¾“å‡ºä¸ CoT æ¡ä»¶äº’ä¿¡æ¯çš„è®­ç»ƒç›®æ ‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¿¡æ¯è®ºåˆ†æè¡¨æ˜ï¼šCoT ä¸è¾“å‡ºå­˜åœ¨éé›¶äº’ä¿¡æ¯æ˜¯å¯ç›‘æ§çš„å¿…è¦éå……åˆ†æ¡ä»¶ï¼Œè€Œå®é™…ç›‘æ§æ€§èƒ½å—é™äºä¿¡æ¯ç¼ºå£ä¸å¼•å‡ºè¯¯å·®ï¼›é€šè¿‡æå‡ºçš„æœ‰ç›‘ç£ä¸æ— ç›‘ç£ä¸¤ç§ç›®æ ‡ä¼˜åŒ– CoTï¼Œå¯åœ¨å¤šç§ç¯å¢ƒä¸‹æ˜¾è‘—æå‡ç›‘æ§å‡†ç¡®ç‡ã€é¿å… CoT é€€åŒ–ï¼Œå¹¶åœ¨å¥–åŠ±ä¸å®Œç¾è®¾å®šæ—¶æœ‰æ•ˆç¼“è§£å¥–åŠ±é»‘å®¢é—®é¢˜ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, é“¾å¼æ€ç»´, transformer, ä¿¡æ¯è®ºåˆ†æ, äº’ä¿¡æ¯ä¼˜åŒ–, ç›‘æ§æ¨¡å‹è®­ç»ƒ, æµ‹è¯•è§„é¿æ£€æµ‹, ä»£ç ç”Ÿæˆå®‰å…¨, å¥–åŠ±é»‘å®¢é˜²æŠ¤

**è¯„åˆ†**ï¼š52

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18297v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18297v1.pdf)

---

## [29. PRISM: Parallel Reward Integration with Symmetry for MORL](https://arxiv.org/abs/2602.18277v1)

**ä½œè€…**ï¼šFinn van der Knaap, Kejiang Qian, Zheng Xu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

This work studies heterogeneous Multi-Objective Reinforcement Learning (MORL), where objectives can differ sharply in temporal frequency. Such heterogeneity allows dense objectives to dominate learning, while sparse long-horizon rewards receive weak credit assignment, leading to poor sample efficiency. We propose a Parallel Reward Integration with Symmetry (PRISM) algorithm that enforces reflectional symmetry as an inductive bias in aligning reward channels. PRISM introduces ReSymNet, a theory-motivated model that reconciles temporal-frequency mismatches across objectives, using residual blocks to learn a scaled opportunity value that accelerates exploration while preserving the optimal policy. We also propose SymReg, a reflectional equivariance regulariser that enforces agent mirroring and constrains policy search to a reflection-equivariant subspace. This restriction provably reduces hypothesis complexity and improves generalisation. Across MuJoCo benchmarks, PRISM consistently outperforms both a sparse-reward baseline and an oracle trained with full dense rewards, improving Pareto coverage and distributional balance: it achieves hypervolume gains exceeding 100\% over the baseline and up to 32\% over the oracle. The code is at \href{https://github.com/EVIEHub/PRISM}{https://github.com/EVIEHub/PRISM}.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šPRISMé€šè¿‡å¹¶è¡Œå¥–åŠ±æ•´åˆä¸åå°„å¯¹ç§°å½’çº³åç½®ï¼Œè§£å†³å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¸­ç¨€ç–ä¸ç¨ å¯†å¥–åŠ±é¢‘ç‡ä¸åŒ¹é…å¯¼è‡´çš„è®­ç»ƒå¤±è¡¡é—®é¢˜ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œä¸åŒç›®æ ‡çš„æ—¶é—´é¢‘ç‡å·®å¼‚ä¼šå¯¼è‡´ç¨ å¯†å¥–åŠ±ä¸»å¯¼å­¦ä¹ ã€ç¨€ç–é•¿æ—¶åºç›®æ ‡éš¾ä»¥è·å¾—æœ‰æ•ˆå›ä¼ ï¼Œé€ æˆæ ·æœ¬æ•ˆç‡ä½å’Œå¤šç›®æ ‡æ€§èƒ½ä¸å‡è¡¡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºPRISMæ¡†æ¶ï¼Œå¼•å…¥ReSymNeté€šè¿‡æ®‹å·®ç»“æ„å­¦ä¹ â€œç¼©æ”¾çš„æœºä¼šå€¼â€ä»¥å¯¹é½ä¸åŒé¢‘ç‡çš„å¥–åŠ±é€šé“å¹¶åŠ é€Ÿæ¢ç´¢ï¼ŒåŒæ—¶è®¾è®¡å¯¹ç§°ç­‰å˜æ­£åˆ™SymRegå¼ºåˆ¶ç­–ç•¥æ»¡è¶³ç©ºé—´åå°„å¯¹ç§°æ€§ï¼Œä»è€Œå‹ç¼©å‡è®¾ç©ºé—´å¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨MuJoCoå¤šç›®æ ‡åŸºå‡†ä¸Šï¼ŒPRISMç›¸è¾ƒç¨€ç–å¥–åŠ±åŸºçº¿å’Œä½¿ç”¨å®Œæ•´ç¨ å¯†å¥–åŠ±çš„oracleå‡å–å¾—æ˜¾è‘—ä¼˜åŠ¿ï¼Œåœ¨Paretoè¦†ç›–åº¦å’Œåˆ†å¸ƒå¹³è¡¡ä¸Šæœ‰æ˜æ˜¾æå‡ï¼Œè¶…ä½“ç§¯æŒ‡æ ‡ç›¸å¯¹åŸºçº¿æé«˜è¶…è¿‡100%ã€ç›¸å¯¹oracleæœ€é«˜æé«˜çº¦32%ã€‚

**å…³é”®è¯**ï¼šå¼ºåŒ–å­¦ä¹ , å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ , æ·±åº¦å­¦ä¹ , agent, å¥–åŠ±å»ºæ¨¡, å¯¹ç§°æ€§æ­£åˆ™, ç­–ç•¥ä¼˜åŒ–, æ¢ç´¢æ•ˆç‡, MuJoCoä»¿çœŸç¯å¢ƒ, Paretoå‰æ²¿

**è¯„åˆ†**ï¼š40

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18277v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18277v1.pdf)

---

## [30. A Probabilistic Framework for LLM-Based Model Discovery](https://arxiv.org/abs/2602.18266v1)

**ä½œè€…**ï¼šStefan Wahl, Raphaela Schenk, Ali Farnoud ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-20

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Automated methods for discovering mechanistic simulator models from observational data offer a promising path toward accelerating scientific progress. Such methods often take the form of agentic-style iterative workflows that repeatedly propose and revise candidate models by imitating human discovery processes. However, existing LLM-based approaches typically implement such workflows via hand-crafted heuristic procedures, without an explicit probabilistic formulation. We recast model discovery as probabilistic inference, i.e., as sampling from an unknown distribution over mechanistic models capable of explaining the data. This perspective provides a unified way to reason about model proposal, refinement, and selection within a single inference framework. As a concrete instantiation of this view, we introduce ModelSMC, an algorithm based on Sequential Monte Carlo sampling. ModelSMC represents candidate models as particles which are iteratively proposed and refined by an LLM, and weighted using likelihood-based criteria. Experiments on real-world scientific systems illustrate that this formulation discovers models with interpretable mechanisms and improves posterior predictive checks. More broadly, this perspective provides a probabilistic lens for understanding and developing LLM-based approaches to model discovery.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡å°†åˆ©ç”¨LLMè¿›è¡Œæœºç†æ¨¡å‹å‘ç°çš„é—®é¢˜å½¢å¼åŒ–ä¸ºä¸€æ¬¡æ¦‚ç‡æ¨æ–­è¿‡ç¨‹ï¼Œå¹¶æå‡ºåŸºäºé¡ºåºè’™ç‰¹å¡æ´›çš„ModelSMCæ¡†æ¶æ¥ç»Ÿä¸€å¤„ç†æ¨¡å‹ç”Ÿæˆã€ä¿®æ­£ä¸é€‰æ‹©ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰åŸºäºLLMçš„ç§‘å­¦æ¨¡å‹å‘ç°å¤šä¾èµ–æ‰‹å·¥è®¾è®¡çš„å¯å‘å¼â€œæ™ºèƒ½ä½“å¼â€å·¥ä½œæµï¼Œç¼ºä¹ç»Ÿä¸€çš„æ¦‚ç‡è§†è§’ï¼Œéš¾ä»¥ç³»ç»Ÿæ€§è¯„ä¼°å’Œæ”¹è¿›æ¨¡å‹ç”Ÿæˆä¸é€‰æ‹©è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…å°†â€œå‘ç°æœºç†æ¨¡å‹â€è§†ä¸ºä»èƒ½è§£é‡Šè§‚æµ‹æ•°æ®çš„æ¨¡å‹åéªŒåˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå¼•å…¥ModelSMCç®—æ³•ï¼šæŠŠå€™é€‰æ¨¡å‹è§†ä¸ºç²’å­ï¼Œç”±LLMè¿­ä»£ç”Ÿæˆä¸æ”¹å†™ï¼Œå¹¶é€šè¿‡ä¼¼ç„¶ç›¸å…³çš„æƒé‡è¿›è¡Œè¯„ä¼°ä¸é‡é‡‡æ ·ï¼Œä»è€Œå®ç°æ¦‚ç‡åŒ–çš„æ¨¡å‹æœç´¢ä¸ç²¾ç‚¼ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨çœŸå®ç§‘å­¦ç³»ç»Ÿä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒModelSMCèƒ½å‘ç°å…·æœ‰å¯è§£é‡Šæœºç†çš„æ¨¡å‹å¹¶æå‡åéªŒé¢„æµ‹æ£€éªŒè¡¨ç°ï¼ŒåŒæ—¶è¯¥æ¦‚ç‡æ¡†æ¶ä¸ºè®¾è®¡å’Œåˆ†æLLMé©±åŠ¨çš„æ¨¡å‹å‘ç°æ–¹æ³•æä¾›äº†ç»Ÿä¸€çš„ç†è®ºè§†è§’ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, LLM, agentic workflow, æ¨¡å‹å‘ç°, æ¦‚ç‡æ¨ç†, Sequential Monte Carlo, æ¨¡å‹ç”Ÿæˆä¸æ”¹è¿›, ç§‘å­¦æœºåˆ¶å»ºæ¨¡, åéªŒé¢„æµ‹æ£€æŸ¥

**è¯„åˆ†**ï¼š41

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18266v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18266v1.pdf)

---

