# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-05

> å…± 30 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (13 ç¯‡)
- [cs.AI](#csAI) (5 ç¯‡)
- [cs.CV](#csCV) (8 ç¯‡)
- [cs.CL](#csCL) (4 ç¯‡)

---

## cs.AI

## [1. DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching](https://arxiv.org/abs/2602.06039v1)

**ä½œè€…**ï¼šYuxing Lu, Yucheng Hu, Xukai Zhao ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDyTopoæ˜¯ä¸€ç§åŠ¨æ€æ‹“æ‰‘è·¯ç”±æ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰åŒ¹é…ä¼˜åŒ–å¤šä»£ç†ç³»ç»Ÿçš„é€šä¿¡æ•ˆç‡å’Œé—®é¢˜è§£å†³èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„å¤šä»£ç†ç³»ç»Ÿé€šå¸¸ä¾èµ–äºå›ºå®šçš„é€šä¿¡æ¨¡å¼ï¼Œéš¾ä»¥æ»¡è¶³è¿­ä»£é—®é¢˜è§£å†³ä¸­é˜¶æ®µæ€§éœ€æ±‚ï¼Œå› æ­¤éœ€è¦ä¸€ç§çµæ´»çš„é€šä¿¡æœºåˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šDyTopoé€šè¿‡ç®¡ç†è€…æŒ‡å¯¼ï¼Œåœ¨æ¯ä¸€è½®é‡æ„ç¨€ç–çš„æœ‰å‘é€šä¿¡å›¾ï¼ŒåŸºäºä»£ç†çš„éœ€æ±‚å’Œæä¾›æè¿°ç¬¦è¿›è¡Œè¯­ä¹‰åŒ¹é…ï¼Œä»…åœ¨æœ‰æ•ˆè¾¹ä¸Šè·¯ç”±ç§å¯†æ¶ˆæ¯ã€‚

**ä¸»è¦ç»“è®º**ï¼šDyTopoåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œä¸ä»…æé«˜äº†å‡†ç¡®æ€§ï¼Œè¿˜æä¾›äº†å¯è§£é‡Šçš„åè°ƒè½¨è¿¹ï¼Œä¾¿äºå¯¹é€šä¿¡è·¯å¾„çš„å®šæ€§æ£€æŸ¥ã€‚

**å…³é”®è¯**ï¼šå¤šæ™ºèƒ½ä½“, è¯­ä¹‰åŒ¹é…, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ä»£ç†, è‡ªä¸»ä»£ç†, ä»£ç ç”Ÿæˆ, æ•°å­¦æ¨ç†, è¿­ä»£é—®é¢˜è§£å†³, è¯­ä¹‰æœç´¢, llm

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06039v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06039v1.pdf)

---

## [2. Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023v1)

**ä½œè€…**ï¼šChristopher A. McClurg, Alan R. Wagner  
**åˆ†ç±»**ï¼šcs.AI, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäºè™šæ‹Ÿç°å®çš„ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼Œç”¨äºè¯„ä¼°å­¦æ ¡å®‰å…¨å¹²é¢„ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè™šæ‹Ÿç°å®åœ¨é«˜é£é™©åœºæ™¯ä¸‹è¯„ä¼°å­¦æ ¡å®‰å…¨æªæ–½çš„èƒ½åŠ›å—é™äºéœ€è¦ä¸ºæ¯ä¸ªæ¡ä»¶æ‹›å‹Ÿæ–°å‚ä¸è€…ï¼Œä»è€Œå½±å“å¤§è§„æ¨¡å’Œè¿­ä»£è¯„ä¼°çš„å¯è¡Œæ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶è€…å¼€å‘äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼Œæ¨¡æ‹Ÿå°„æ‰‹çš„ç§»åŠ¨å’Œè¡Œä¸ºï¼Œä»¥ä»è™šæ‹Ÿç°å®ç ”ç©¶ä¸­çš„å‚ä¸è€…è¡Œä¸ºä¸­å­¦ä¹ ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¨¡æ‹Ÿå™¨èƒ½å¤Ÿæœ‰æ•ˆå¤åˆ¶å…³é”®çš„å®è¯æ¨¡å¼ï¼Œä»è€Œæ”¯æŒå¯¹å¹²é¢„ç­–ç•¥çš„å¯æ‰©å±•è¯„ä¼°å’Œå­¦ä¹ ï¼Œæä¾›äº†å¼€å‘å’Œè¯„ä¼°è‡ªä¸»å­¦æ ¡å®‰å…¨å¹²é¢„çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚

**å…³é”®è¯**ï¼šè™šæ‹Ÿç°å®, äº‹ä»¶é©±åŠ¨æ¨¡æ‹Ÿå™¨, æ·±åº¦å­¦ä¹ , æœºå™¨äººå¹²é¢„, è‡ªä¸»ç³»ç»Ÿ, å­¦ä¹ ç­–ç•¥, è¡Œä¸ºæ¨¡æ‹Ÿ, æ•°æ®é©±åŠ¨, è¯„ä¼°æ–¹æ³•, autonomous

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06023v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06023v1.pdf)

---

## [3. AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008v1)

**ä½œè€…**ï¼šXianyang Liu, Shangding Gu, Dawn Song  
**åˆ†ç±»**ï¼šcs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šAgenticPayæ˜¯ä¸€ä¸ªå¤šä»£ç†LLMçš„è°ˆåˆ¤ç³»ç»Ÿï¼Œä¸“æ³¨äºä¹°å–äº¤æ˜“ä¸­çš„è¯­è¨€é©±åŠ¨çš„ç»æµäº’åŠ¨è¯„ä¼°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå½“å‰çš„è¯„ä¼°åŸºå‡†ç¼ºä¹å¯¹å¤šä»£ç†è¯­è¨€ä¸­ä»‹ç»æµäº’åŠ¨çš„ç³»ç»Ÿæ€§è®¾ç½®ï¼Œæ€¥éœ€ä¸€ä¸ªèƒ½æœ‰æ•ˆè¯„ä¼°è°ˆåˆ¤èƒ½åŠ›çš„æ¡†æ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šAgenticPayæä¾›äº†ä¸€ä¸ªæ¨¡æ‹Ÿæ¡†æ¶ï¼Œæ”¯æŒè¶…è¿‡110ä¸ªä»»åŠ¡ï¼Œä»åŒè¾¹è°ˆåˆ¤åˆ°å¤šå¯¹å¤šå¸‚åœºï¼Œè¯„ä¼°è°ˆåˆ¤çš„å¯è¡Œæ€§ã€æ•ˆç‡å’Œç¦åˆ©ã€‚

**ä¸»è¦ç»“è®º**ï¼šåŸºå‡†æµ‹è¯•æ­ç¤ºäº†ç°æœ‰LLMåœ¨è°ˆåˆ¤è¡¨ç°ä¸Šçš„æ˜¾è‘—å·®è·ï¼Œå¹¶çªå‡ºäº†åœ¨é•¿æœŸæˆ˜ç•¥æ¨ç†ä¸­çš„æŒ‘æˆ˜ï¼Œä¸ºä»£ç†å•†ä¸šå’ŒåŸºäºè¯­è¨€çš„å¸‚åœºäº’åŠ¨ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚

**å…³é”®è¯**ï¼šå¤šä»£ç†, LLM, è¯­è¨€æ¨¡å‹, åå•†, äº¤æ˜“, è‡ªåŠ¨åŒ–, ç»æµäº¤äº’, å¤šè½®è°ˆåˆ¤, å¸‚åœºæ¨¡æ‹Ÿ, è¡ŒåŠ¨æå–

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06008v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06008v1.pdf)

---

## [4. Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000v1)

**ä½œè€…**ï¼šAli Shendabadi, Parnia Izadirad, Mostafa Salehi ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ¢è®¨åˆ©ç”¨OpenAIçš„Whisperæ¨¡å‹åŠæ³¨æ„åŠ›æ± åŒ–æ–¹æ³•è¿›è¡Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼Œå–å¾—äº†åœ¨ShEMOæ•°æ®é›†ä¸Šçš„æœ€ä½³ç»“æœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶é¢ä¸´æ ‡å‡†åŒ–å’Œå¤§è§„æ¨¡æ•°æ®é›†ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰ç ”ç©¶å·²å¼€å§‹åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–ç‰¹å¾ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºä¸¤ç§åŸºäºæ³¨æ„åŠ›çš„æ± åŒ–æ–¹æ³•ï¼šå¤šå¤´æ³¨æ„åŠ›å¹³å‡æ± åŒ–å’ŒQKVæ± åŒ–ï¼Œä»¥æœ‰æ•ˆé™ä½Whisperè¡¨å¾çš„ç»´åº¦å¹¶ä¿ç•™æƒ…æ„Ÿç‰¹å¾ã€‚

**ä¸»è¦ç»“è®º**ï¼šWhisperä½œä¸ºæƒ…æ„Ÿè¯†åˆ«çš„è¡¨å¾æå–å™¨å…·æœ‰æ½œåŠ›ï¼Œä¸”æ³¨æ„åŠ›æ± åŒ–æ–¹æ³•åœ¨é™ç»´æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚

**å…³é”®è¯**ï¼šæƒ…æ„Ÿè¯†åˆ«, è¯­éŸ³å¤„ç†, é¢„è®­ç»ƒæ¨¡å‹, Whisper, å¤šå¤´æ³¨æ„åŠ›, ç‰¹å¾æå–, ç»´åº¦å‡å°‘, ASRç³»ç»Ÿ, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , rag

**è¯„åˆ†**ï¼š67

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06000v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06000v1.pdf)

---

## [5. Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins](https://arxiv.org/abs/2602.05983v1)

**ä½œè€…**ï¼šKreÅ¡imir KuÅ¡iÄ‡, Vinny Cahill, Ivana Dusparic  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate predicted traffic conditions in addition to real-time observations. Due to the spatio-temporal complexity and the time-variant, non-linear nature of traffic dynamics, predicting motorway traffic remains a difficult problem. Sequence-based deep-learning models offer clear advantages over classical machine learning and statistical models in capturing long-range, temporal dependencies in time-series traffic data, yet limitations in forecasting accuracy and model complexity point to the need for further improvements. To improve motorway traffic forecasting, this paper introduces a Geographically-aware Transformer-based Traffic Forecasting GATTF model, which exploits the geographical relationships between distributed sensors using their mutual information (MI). The model has been evaluated using real-time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer, without increasing model complexity.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åœ°ç†æ„ŸçŸ¥çš„åŸºäºTransformerçš„äº¤é€šé¢„æµ‹æ¨¡å‹ï¼Œä»¥æé«˜åŸå¸‚é«˜é€Ÿå…¬è·¯çš„äº¤é€šé¢„æµ‹å‡†ç¡®æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šé«˜é€Ÿå…¬è·¯æ•°å­—åŒèƒèƒæŠ€æœ¯çš„æœ‰æ•ˆæ€§ä¾èµ–äºé«˜åˆ†è¾¨ç‡å®æ—¶äº¤é€šæ•°æ®çš„æŒç»­æµåŠ¨ï¼ŒåŒæ—¶éœ€ç»“åˆé¢„æµ‹çš„äº¤é€šçŠ¶å†µä»¥æ”¯æŒå†³ç­–ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºçš„GATTFæ¨¡å‹åˆ©ç”¨åˆ†å¸ƒå¼ä¼ æ„Ÿå™¨ä¹‹é—´çš„äº’ä¿¡æ¯æ¥æ•æ‰åœ°ç†å…³ç³»ï¼Œæ”¹å–„äº¤é€šé¢„æµ‹æ€§èƒ½ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨äº’ä¿¡æ¯å¢å¼ºåœ°ç†æ„ŸçŸ¥å¯ä»¥æé«˜GATTFæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºæ ‡å‡†Transformeræ¨¡å‹ï¼Œå¤æ‚åº¦æœªå¢åŠ ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , Transformer, äº¤é€šé¢„æµ‹, æ•°å­—åŒèƒèƒ, æ—¶åºæ•°æ®, åœ°ç†ä¿¡æ¯, å®æ—¶æ•°æ®, æœºå™¨å­¦ä¹ , é¢„æµ‹æ¨¡å‹

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05983v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05983v1.pdf)

---

## cs.CL

## [6. Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025v1)

**ä½œè€…**ï¼šHaozhen Zhang, Haodong Yue, Tao Feng ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åä¸ºBudgetMemçš„è¿è¡Œæ—¶ä»£ç†å†…å­˜æ¡†æ¶ï¼Œé€šè¿‡æŸ¥è¯¢æ„ŸçŸ¥çš„é¢„ç®—åˆ†å±‚è·¯ç”±æ¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½æˆæœ¬çš„å¹³è¡¡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå½“å‰å¤§è¯­è¨€æ¨¡å‹ä»£ç†çš„å†…å­˜æ„å»ºå¤šä¸ºç¦»çº¿ä¸”ä¸è€ƒè™‘æŸ¥è¯¢ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±å’Œæ•ˆç‡ä½ä¸‹ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ›´çµæ´»çš„å†…å­˜ç®¡ç†æ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šBudgetMemå°†å†…å­˜å¤„ç†ç»“æ„åŒ–ä¸ºå¤šç§é¢„ç®—å±‚æ¬¡çš„å†…å­˜æ¨¡å—ï¼Œå¹¶åˆ©ç”¨è½»é‡çº§è·¯ç”±å™¨åœ¨æ¨¡å—é—´è¿›è¡Œé¢„ç®—å±‚è·¯ç”±ï¼Œä»¥å¹³è¡¡ä»»åŠ¡æ€§èƒ½å’Œå†…å­˜æˆæœ¬ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å¤šé¡¹æµ‹è¯•ä¸­ï¼ŒBudgetMemåœ¨é«˜é¢„ç®—è®¾ç½®ä¸‹ä¼˜äºåŸºçº¿è¡¨ç°ï¼Œå¹¶åœ¨ç´§é¢„ç®—ä¸‹æä¾›æ›´å¥½çš„å‡†ç¡®æ€§å’Œæˆæœ¬å¹³è¡¡ï¼ŒåŒæ—¶æ­ç¤ºäº†ä¸åŒå±‚æ¬¡ç­–ç•¥çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚

**å…³é”®è¯**ï¼šæŸ¥è¯¢æ„ŸçŸ¥, é¢„ç®—åˆ†å±‚, è¿è¡Œæ—¶ä»£ç†, è®°å¿†æ¡†æ¶, å¼ºåŒ–å­¦ä¹ , ç¥ç»ç½‘ç»œ, LLM, æ€§èƒ½æ§åˆ¶, ä»»åŠ¡æ€§èƒ½, è®°å¿†æ„å»ºæˆæœ¬

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06025v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06025v1.pdf)

---

## [7. A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies](https://arxiv.org/abs/2602.06015v1)

**ä½œè€…**ï¼šPanagiotis Kaliosis, Adithya V Ganesan, Oscar N. E. Kjell ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶è¯„ä¼°äº†11ç§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨PTSDä¸¥é‡ç¨‹åº¦è¯„ä¼°ä¸­çš„è¡¨ç°ï¼Œå¼ºè°ƒäº†ä¸Šä¸‹æ–‡çŸ¥è¯†å’Œå»ºæ¨¡ç­–ç•¥çš„é‡è¦æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¿ƒç†å¥åº·è¯„ä¼°ä¸­çš„åº”ç”¨å¢åŠ ï¼Œäº†è§£å½±å“å…¶å‡†ç¡®æ€§çš„å› ç´ å˜å¾—å°¤ä¸ºé‡è¦ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½¿ç”¨1437ä¸ªä¸ªä½“çš„ä¸´åºŠæ•°æ®é›†ï¼Œé€šè¿‡ç³»ç»Ÿæ€§å˜åŒ–ä¸Šä¸‹æ–‡çŸ¥è¯†å’Œå»ºæ¨¡ç­–ç•¥æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**ä¸»è¦ç»“è®º**ï¼šé€‰æ‹©åˆé€‚çš„ä¸Šä¸‹æ–‡çŸ¥è¯†å’Œå»ºæ¨¡ç­–ç•¥å¯¹äºå‡†ç¡®è¯„ä¼°å¿ƒç†å¥åº·è‡³å…³é‡è¦ï¼Œæ¨¡å‹æ€§èƒ½å—å¤šç§å› ç´ å½±å“ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, PTSD, è¯„ä¼°, ä¸Šä¸‹æ–‡çŸ¥è¯†, å»ºæ¨¡ç­–ç•¥, æœºå™¨å­¦ä¹ , ç”Ÿæˆæ¨¡å‹, è¯­ä¹‰æœç´¢, é›¶-shot, å¤šæ¨¡å‹é›†æˆ, llm

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06015v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06015v1.pdf)

---

## [8. DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs](https://arxiv.org/abs/2602.05992v1)

**ä½œè€…**ï¼šLizhuo Luo, Shenggui Li, Yonggang Wen ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åŠ¨æ€æ»‘åŠ¨å—è°ƒåº¦æ–¹æ³•DSBï¼Œä»¥æé«˜æ‰©æ•£å¤§å‹è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡å’Œæ¨ç†æ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„å›ºå®šå—è°ƒåº¦å¿½è§†è¯­ä¹‰éš¾åº¦ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡çš„ä¸‹é™ï¼Œå› æ­¤éœ€è¦åŠ¨æ€è°ƒæ•´è°ƒåº¦ç­–ç•¥ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šDSBæ˜¯ä¸€ç§è®­ç»ƒæ— å…³çš„æ»‘åŠ¨å—è°ƒåº¦æ–¹æ³•ï¼Œç»“åˆäº†åŠ¨æ€å¤§å°çš„æ»‘åŠ¨å—å’ŒDSB Cacheæœºåˆ¶ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼ŒDSBåŠå…¶ç¼“å­˜æœºåˆ¶åœ¨å¤šä¸ªæ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡å’Œæ¨ç†æ•ˆç‡ã€‚

**å…³é”®è¯**ï¼šåŠ¨æ€æ»‘å—è°ƒåº¦, æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹, å—æ¨ç†, è¯­ä¹‰éš¾åº¦, KV-cacheæœºåˆ¶, ç”Ÿæˆè´¨é‡, æ¨ç†æ•ˆç‡, æ— éœ€è®­ç»ƒ, è‡ªé€‚åº”è°ƒåº¦, llm

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05992v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05992v1.pdf)

---

## [9. Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space](https://arxiv.org/abs/2602.05971v1)

**ä½œè€…**ï¼šFelipe D. Toro-HernÃ¡ndez, Jesuino Vieira Filho, Rodrigo M. Cabral-Carvalho  
**åˆ†ç±»**ï¼šcs.CL, cs.LG, q-bio.NC  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶é€šè¿‡æ„å»ºåµŒå…¥ç©ºé—´ä¸­çš„è¯­ä¹‰è½¨è¿¹ï¼Œæ­ç¤ºäººç±»åœ¨æ¦‚å¿µç”Ÿäº§ä¸­çš„è¯­ä¹‰å¯¼èˆªè¿‡ç¨‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶äººç±»å¦‚ä½•åœ¨ç»“æ„åŒ–å’ŒåŠ¨æ€çš„çŸ¥è¯†ç©ºé—´ä¸­æ£€ç´¢å’Œæ“ä½œæ„ä¹‰ï¼Œä»¥æ·±å…¥ç†è§£è¯­ä¹‰è¡¨ç¤ºçš„å¯¼èˆªæœºåˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåˆ©ç”¨ä¸åŒçš„å˜æ¢å™¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œæ„å»ºå‚ä¸è€…ç‰¹å®šçš„è¯­ä¹‰è½¨è¿¹ï¼Œå¹¶æå–å‡ ä½•å’ŒåŠ¨æ€æŒ‡æ ‡æ¥åˆ†æè¿™äº›è½¨è¿¹ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¡†æ¶æœ‰æ•ˆåŒºåˆ†ä¸´åºŠç»„å’Œæ¦‚å¿µç±»å‹ï¼Œæä¾›äº†ä¸€ç§æ•°å­¦æ–¹æ³•ä»¥é‡åŒ–è¯­ä¹‰è¡¨ç¤ºåŠ¨æ€ï¼Œé€‚ç”¨äºä¸´åºŠç ”ç©¶å’Œè·¨è¯­è¨€åˆ†æã€‚

**å…³é”®è¯**ï¼šè¯­ä¹‰å¯¼èˆª, åµŒå…¥ç©ºé—´, å˜æ¢å™¨, è¯­ä¹‰è¡¨ç¤º, è¯­ä¹‰è½¨è¿¹, è¯­ä¹‰æ£€ç´¢, å¤šè¯­è¨€åˆ†æ, ä¸´åºŠç ”ç©¶, äººæœºåä½œ, è®¤çŸ¥å»ºæ¨¡, generative

**è¯„åˆ†**ï¼š52

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05971v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05971v1.pdf)

---

## cs.CV

## [10. Thinking with Geometry: Active Geometry Integration for Spatial Reasoning](https://arxiv.org/abs/2602.06037v1)

**ä½œè€…**ï¼šHaoyuan Li, Qihang Cao, Tao Tang ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, which often induces semantic-geometry misalignment and redundant signals. We propose GeoThinker, a framework that shifts the paradigm from passive fusion to active perception. Instead of feature mixing, GeoThinker enables the model to selectively retrieve geometric evidence conditioned on its internal reasoning demands. GeoThinker achieves this through Spatial-Grounded Fusion applied at carefully selected VLM layers, where semantic visual priors selectively query and integrate task-relevant geometry via frame-strict cross-attention, further calibrated by Importance Gating that biases per-frame attention toward task-relevant structures. Comprehensive evaluation results show that GeoThinker sets a new state-of-the-art in spatial intelligence, achieving a peak score of 72.6 on the VSI-Bench. Furthermore, GeoThinker demonstrates robust generalization and significantly improved spatial perception across complex downstream scenarios, including embodied referring and autonomous driving. Our results indicate that the ability to actively integrate spatial structures is essential for next-generation spatial intelligence. Code can be found at https://github.com/Li-Hao-yuan/GeoThinker.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šGeoThinkeræå‡ºäº†ä¸€ç§ä¸»åŠ¨å‡ ä½•é›†æˆæ¡†æ¶ï¼Œé€šè¿‡é€‰æ‹©æ€§æ£€ç´¢å‡ ä½•è¯æ®æ¥æå‡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„å‡ ä½•é›†æˆç­–ç•¥å¤šä¸ºè¢«åŠ¨èåˆï¼Œå¯¼è‡´è¯­ä¹‰ä¸å‡ ä½•çš„ä¸åŒ¹é…ï¼Œå½±å“ç©ºé—´æ¨ç†æ•ˆæœã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šGeoThinkeré€šè¿‡åœ¨ç‰¹å®šçš„è§†è§‰è¯­è¨€æ¨¡å‹å±‚åº”ç”¨ç©ºé—´åŸºç¡€èåˆï¼Œä½¿è¯­ä¹‰è§†è§‰å…ˆéªŒæœ‰é€‰æ‹©åœ°æŸ¥è¯¢å’Œæ•´åˆä»»åŠ¡ç›¸å…³çš„å‡ ä½•ä¿¡æ¯ï¼Œå¹¶é€šè¿‡é‡è¦æ€§é—¨æ§è¿›ä¸€æ­¥ä¼˜åŒ–æ³¨æ„åŠ›åˆ†é…ã€‚

**ä¸»è¦ç»“è®º**ï¼šGeoThinkeråœ¨ç©ºé—´æ™ºèƒ½æ–¹é¢å–å¾—äº†æ–°çš„æœ€ä½³æˆç»©ï¼Œè¡¨æ˜ä¸»åŠ¨é›†æˆç©ºé—´ç»“æ„å¯¹ä¸‹ä¸€ä»£ç©ºé—´æ™ºèƒ½è‡³å…³é‡è¦ã€‚

**å…³é”®è¯**ï¼šå‡ ä½•æ€ç»´, ç©ºé—´æ¨ç†, å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹, 3Dç¼–ç å™¨, ä¸»åŠ¨æ„ŸçŸ¥, ç©ºé—´èåˆ, è§†è§‰å…ˆéªŒ, ä»»åŠ¡ç›¸å…³å‡ ä½•, è‡ªä¸»é©¾é©¶, ç©ºé—´æ™ºèƒ½, ml

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06037v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06037v1.pdf)

---

## [11. InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions](https://arxiv.org/abs/2602.06035v1)

**ä½œè€…**ï¼šSirui Xu, Samuel Schulter, Morteza Ziyadi ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.GR, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Humans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, and manipulation can emerge naturally from underlying physical and motor priors. Scaling such priors is key to enabling humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. To this end, we introduce InterPrior, a scalable framework that learns a unified generative controller through large-scale imitation pretraining and post-training by reinforcement learning. InterPrior first distills a full-reference imitation expert into a versatile, goal-conditioned variational policy that reconstructs motion from multimodal observations and high-level intent. While the distilled policy reconstructs training behaviors, it does not generalize reliably due to the vast configuration space of large-scale human-object interactions. To address this, we apply data augmentation with physical perturbations, and then perform reinforcement learning finetuning to improve competence on unseen goals and initializations. Together, these steps consolidate the reconstructed latent skills into a valid manifold, yielding a motion prior that generalizes beyond the training data, e.g., it can incorporate new behaviors such as interactions with unseen objects. We further demonstrate its effectiveness for user-interactive control and its potential for real robot deployment.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šInterPrioræ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„ç”Ÿæˆæ§åˆ¶æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡ä»¿é¢„è®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ æå‡äººç±»-ç‰©ä½“äº¤äº’ä¸­çš„è¿åŠ¨åè°ƒèƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šäººç±»åœ¨ä¸ç‰©ä½“çš„äº¤äº’ä¸­å¾€å¾€ä¾èµ–äºé«˜å±‚æ¬¡çš„æ„å›¾å’Œè‡ªç„¶çš„è¿åŠ¨åè°ƒï¼Œè€Œä¸æ˜¯æ˜ç¡®çš„å…¨èº«åŠ¨ä½œè§„åˆ’ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šInterPrioré€šè¿‡å¤§è§„æ¨¡æ¨¡ä»¿é¢„è®­ç»ƒå’Œåç»­çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œå­¦ä¹ ä¸€ä¸ªç»Ÿä¸€çš„ç›®æ ‡æ¡ä»¶å˜åˆ†ç­–ç•¥ï¼Œä»¥é‡æ„æ¥è‡ªå¤šæ¨¡æ€è§‚å¯Ÿå’Œé«˜å±‚æ„å›¾çš„è¿åŠ¨ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ–¹æ³•åœ¨ç”¨æˆ·äº¤äº’æ§åˆ¶ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨çœŸå®æœºå™¨äººéƒ¨ç½²ä¸­çš„æ½œåŠ›ï¼Œèƒ½å¤Ÿè¶…è¶Šè®­ç»ƒæ•°æ®ç”Ÿæˆæ–°çš„äº¤äº’è¡Œä¸ºã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ§åˆ¶, ç‰©ç†äº¤äº’, ç”Ÿæˆæ¨¡å‹, å¼ºåŒ–å­¦ä¹ , è¿åŠ¨é‡å»º, ç›®æ ‡å¯¼å‘, å¤šæ¨¡æ€è§‚å¯Ÿ, æœºå™¨äººéƒ¨ç½², humanoid, è¿åŠ¨å…ˆéªŒ, generative

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06035v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06035v1.pdf)

---

## [12. V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval](https://arxiv.org/abs/2602.06034v1)

**ä½œè€…**ï¼šDongyang Chen, Chaoyang Wang, Dezhao SU ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šV-Retrveræå‡ºäº†ä¸€ç§åŸºäºè¯æ®é©±åŠ¨çš„å¤šæ¨¡æ€æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡è§†è§‰æ£€æŸ¥å¢å¼ºæ¨ç†è¿‡ç¨‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ£€ç´¢ä¸­ä¸»è¦ä¾èµ–è¯­è¨€é©±åŠ¨ï¼Œç¼ºä¹æœ‰æ•ˆçš„è§†è§‰è¯æ®éªŒè¯ï¼Œå¯¼è‡´æ¨ç†ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šV-Retrverå°†å¤šæ¨¡æ€æ£€ç´¢é‡æ„ä¸ºä¸€ç§ä»£ç†æ¨ç†è¿‡ç¨‹ï¼Œç»“åˆè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­é€‰æ‹©æ€§è·å–è§†è§‰è¯æ®ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜V-Retrveråœ¨æ£€ç´¢å‡†ç¡®æ€§ã€æ¨ç†å¯é æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸Šéƒ½æœ‰æ˜¾è‘—æå‡ï¼Œå¹³å‡æé«˜23.0%ã€‚

**å…³é”®è¯**ï¼šå¤šæ¨¡æ€, å¤§è¯­è¨€æ¨¡å‹, ä»£ç†æ¨ç†, è§†è§‰æ£€ç´¢, è¯æ®é©±åŠ¨, å¼ºåŒ–å­¦ä¹ , ç›‘ç£å­¦ä¹ , ç›®æ ‡è§†è§‰éªŒè¯, äº¤æ›¿æ¨ç†, ml

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06034v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06034v1.pdf)

---

## [13. Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation](https://arxiv.org/abs/2602.06032v1)

**ä½œè€…**ï¼šDavid Shavin, Sagie Benaim  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Vision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this end, we introduce Splat and Distill, a framework that instills robust 3D awareness into 2D VFMs by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. Given 2D features produced by a teacher model, our method first lifts these features into an explicit 3D Gaussian representation, in a feedforward manner. These 3D features are then ``splatted" onto novel viewpoints, producing a set of novel 2D feature maps used to supervise the student model, ``distilling" geometrically grounded knowledge. By replacing slow per-scene optimization of prior work with our feed-forward lifting approach, our framework avoids feature-averaging artifacts, creating a dynamic learning process where the teacher's consistency improves alongside that of the student. We conduct a comprehensive evaluation on a suite of downstream tasks, including monocular depth estimation, surface normal estimation, multi-view correspondence, and semantic segmentation. Our method significantly outperforms prior works, not only achieving substantial gains in 3D awareness but also enhancing the underlying semantic richness of 2D features. Project page is available at https://davidshavin4.github.io/Splat-and-Distill/

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°æ¡†æ¶Splat and Distillï¼Œé€šè¿‡å¿«é€Ÿçš„å‰é¦ˆ3Dé‡å»ºå¢å¼º2Dè§†è§‰åŸºç¡€æ¨¡å‹çš„3Dæ„è¯†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡è§†è§‰åŸºç¡€æ¨¡å‹åœ¨2Dä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨3Dæ„è¯†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè¯¥æ–¹æ³•é€šè¿‡å°†2Dç‰¹å¾æå‡ä¸ºæ˜¾å¼çš„3Dé«˜æ–¯è¡¨ç¤ºï¼Œå¹¶å°†å…¶æŠ•å½±åˆ°æ–°è§†è§’ç”Ÿæˆæ–°çš„2Dç‰¹å¾å›¾ï¼Œä»¥ç›‘ç£å­¦ç”Ÿæ¨¡å‹å¹¶æç‚¼å‡ ä½•çŸ¥è¯†ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå…ˆå‰çš„å·¥ä½œï¼Œæå‡äº†3Dæ„è¯†å’Œ2Dç‰¹å¾çš„è¯­ä¹‰ä¸°å¯Œæ€§ã€‚

**å…³é”®è¯**ï¼š3Dé‡å»º, è§†è§‰åŸºç¡€æ¨¡å‹, 2Dç‰¹å¾, æ•™å¸ˆæ¨¡å‹, å­¦ç”Ÿæ¨¡å‹, çŸ¥è¯†è’¸é¦, è¯­ä¹‰åˆ†å‰², æ·±åº¦å­¦ä¹ , feed-forward, rag

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06032v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06032v1.pdf)

---

## [14. Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028v1)

**ä½œè€…**ï¼šShuo Chen, Cong Wei, Sun Sun ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºContext Forcingçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡é•¿ä¸Šä¸‹æ–‡æ•™å¸ˆè®­ç»ƒé•¿ä¸Šä¸‹æ–‡å­¦ç”Ÿï¼Œä»è€Œæå‡è§†é¢‘ç”Ÿæˆçš„ä¸€è‡´æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è§†é¢‘ç”Ÿæˆæ–¹æ³•å­˜åœ¨å­¦ç”Ÿä¸æ•™å¸ˆä¹‹é—´çš„çŸ­æœŸå’Œé•¿æœŸä¸Šä¸‹æ–‡ä¸åŒ¹é…é—®é¢˜ï¼Œé™åˆ¶äº†æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šContext Forcingæ¡†æ¶é€šè¿‡å¼•å…¥é•¿ä¸Šä¸‹æ–‡æ•™å¸ˆï¼Œæ¶ˆé™¤ç›‘ç£ä¸åŒ¹é…ï¼Œå¹¶ä½¿ç”¨Slow-Fast Memoryæ¶æ„æ¥ç®¡ç†å’Œä¼˜åŒ–ä¸Šä¸‹æ–‡å¤„ç†ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆè¶…è¿‡20ç§’çš„é•¿è§†é¢‘æ—¶ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œæå‡äº†é•¿æ—¶é—´ä¸€è‡´æ€§ã€‚

**å…³é”®è¯**ï¼šè§†é¢‘ç”Ÿæˆ, é•¿æœŸä¸€è‡´æ€§, ä¸Šä¸‹æ–‡ç®¡ç†, æ·±åº¦å­¦ä¹ , ç”Ÿæˆæ¨¡å‹, é•¿æœŸä¾èµ–, Slow-Fast Memory, è®­ç»ƒæ¡†æ¶, ç›‘ç£åŒ¹é…, rag

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06028v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06028v1.pdf)

---

## [15. GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?](https://arxiv.org/abs/2602.06013v1)

**ä½œè€…**ï¼šRuihang Li, Leigang Qu, Jingxu Zhang ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide spectrum of visual generation tasks. Our analysis reveals that this paradigm is limited due to stochastic inconsistency and poor alignment with human perception. To resolve these limitations, we introduce GenArena, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human-aligned evaluation. Crucially, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off-the-shelf open-source models to outperform top-tier proprietary models. Notably, our method boosts evaluation accuracy by over 20% and achieves a Spearman correlation of 0.86 with the authoritative LMArena leaderboard, drastically surpassing the 0.36 correlation of pointwise methods. Based on GenArena, we benchmark state-of-the-art visual generation models across diverse tasks, providing the community with a rigorous and automated evaluation standard for visual generation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†GenArenaæ¡†æ¶ï¼Œé€šè¿‡å¯¹æ¯”è¯„ä¼°æé«˜è§†è§‰ç”Ÿæˆä»»åŠ¡çš„äººç±»å¯¹é½è¯„ä¼°çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€è§†è§‰ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œä¼ ç»Ÿè¯„ä¼°æ–¹æ³•å·²æ— æ³•æ»¡è¶³éœ€æ±‚ï¼Œå› æ­¤éœ€è¦å¯»æ±‚æ›´ç¬¦åˆäººç±»æ„ŸçŸ¥çš„è¯„ä¼°æ ‡å‡†ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¼•å…¥GenArenaä½œä¸ºç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œé‡‡ç”¨æˆå¯¹æ¯”è¾ƒçš„æ–¹æ³•ï¼Œå…‹æœç°æœ‰ç»å¯¹è¯„åˆ†æ ‡å‡†çš„ä¸è¶³ã€‚

**ä¸»è¦ç»“è®º**ï¼šGenArenaæ˜¾è‘—æé«˜äº†è¯„ä¼°å‡†ç¡®æ€§ï¼Œä¸”é€šè¿‡åŸºå‡†æµ‹è¯•ä¸ºè§†è§‰ç”Ÿæˆæ¨¡å‹æä¾›äº†ä¸¥æ ¼çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è¯**ï¼šè§†è§‰ç”Ÿæˆ, è¯„ä¼°æ¡†æ¶, äººç±»å¯¹é½, Vision-Language Models, pairwise comparison, ç”Ÿæˆæ¨¡å‹, è¯„ä»·å‡†ç¡®æ€§, LMArena, è§†è§‰ä»»åŠ¡

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06013v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06013v1.pdf)

---

## [16. RISE-Video: Can Video Generators Decode Implicit World Rules?](https://arxiv.org/abs/2602.05986v1)

**ä½œè€…**ï¼šMingxin Liu, Shuran Ma, Shibei Meng ç­‰ 12 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: \textit{Reasoning Alignment}, \textit{Temporal Consistency}, \textit{Physical Rationality}, and \textit{Visual Quality}. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šRISE-Videoæ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†é¢‘ç”Ÿæˆæ¨¡å‹ç†è§£éšå«ä¸–ç•Œè§„åˆ™èƒ½åŠ›çš„åŸºå‡†ï¼Œå¼ºè°ƒè®¤çŸ¥æ¨ç†è€Œéä»…ä»…è§†è§‰ç¾æ„Ÿã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡ç”Ÿæˆè§†é¢‘æ¨¡å‹åœ¨è§†è§‰æ•ˆæœä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨å†…åŒ–å’Œæ¨ç†éšå«ä¸–ç•Œè§„åˆ™æ–¹é¢ä»å­˜åœ¨ä¸è¶³ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šRISE-VideoåŒ…å«467ä¸ªç»è¿‡äººå·¥æ³¨é‡Šçš„æ ·æœ¬ï¼Œè®¾å®šäº†å¤šç»´åº¦çš„è¯„ä¼°åè®®ï¼Œé‡‡ç”¨å››ä¸ªæŒ‡æ ‡æ¥æµ‹è¯•æ¨¡å‹çš„æ™ºèƒ½ï¼ŒåŒ…æ‹¬æ¨ç†ä¸€è‡´æ€§ã€æ—¶é—´ä¸€è‡´æ€§ã€ç‰©ç†åˆç†æ€§å’Œè§†è§‰è´¨é‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šå¯¹11ä¸ªæœ€å…ˆè¿›çš„TI2Væ¨¡å‹çš„å¹¿æ³›å®éªŒæ˜¾ç¤ºï¼Œåœ¨å¤æ‚åœºæ™¯ä¸‹çš„éšå«çº¦æŸæ¨¡æ‹Ÿä¸­å­˜åœ¨æ™®éç¼ºé™·ï¼Œä¸ºæœªæ¥ç”Ÿæˆæ¨¡å‹çš„å‘å±•æä¾›äº†é‡è¦è§è§£ã€‚

**å…³é”®è¯**ï¼šè§†é¢‘ç”Ÿæˆ, ç”Ÿæˆæ¨¡å‹, è®¤çŸ¥æ¨ç†, å¤šæ¨¡æ€æ¨¡å‹, è¯„ä¼°åè®®, æ·±åº¦å­¦ä¹ , è¯­ä¹‰æœç´¢, ä»£ç†å·¥ä½œæµ, è‡ªåŠ¨åŒ–è¯„ä¼°, generative

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05986v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05986v1.pdf)

---

## [17. LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation](https://arxiv.org/abs/2602.05966v1)

**ä½œè€…**ï¼šMirlan Karimov, Teodora Spasojevic, Markus Braun ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, limiting their utility as scalable and generalizable data engines. In this work, we propose Localized Semantic Alignment (LSA), a simple yet effective framework for fine-tuning pre-trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground-truth and generated video clips. Specifically, we compare the output of an off-the-shelf feature extraction model between the ground-truth and generated video clips localized around dynamic objects inducing a semantic feature consistency loss. We fine-tune the base model by combining this loss with the standard diffusion loss. The model fine-tuned for a single epoch with our novel loss outperforms the baselines in common video generation evaluation metrics. To further test the temporal consistency in generated videos we adapt two additional metrics from object detection task, namely mAP and mIoU. Extensive experiments on nuScenes and KITTI datasets show the effectiveness of our approach in enhancing temporal consistency in video generation without the need for external control signals during inference and any computational overheads.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§å±€éƒ¨è¯­ä¹‰å¯¹é½æ¡†æ¶ï¼Œç”¨äºå¢å¼ºäº¤é€šè§†é¢‘ç”Ÿæˆçš„æ—¶é—´ä¸€è‡´æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è§†é¢‘ç”Ÿæˆæ–¹æ³•ä¾èµ–æ¨ç†æ—¶çš„æ§åˆ¶ä¿¡å·ï¼Œé™åˆ¶äº†å…¶ä½œä¸ºå¯æ‰©å±•æ•°æ®å¼•æ“çš„å®ç”¨æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¯¹æ¯”çœŸå®è§†é¢‘ä¸ç”Ÿæˆè§†é¢‘çš„è¯­ä¹‰ç‰¹å¾ï¼Œç»“åˆæ ‡å‡†æ‰©æ•£æŸå¤±æ¥å¾®è°ƒé¢„è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨nuSceneså’ŒKITTIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæå‡äº†è§†é¢‘ç”Ÿæˆçš„æ—¶é—´ä¸€è‡´æ€§ï¼Œæ— éœ€å¤–éƒ¨æ§åˆ¶ä¿¡å·ä¸”æ²¡æœ‰é¢å¤–è®¡ç®—å¼€é”€ã€‚

**å…³é”®è¯**ï¼šè§†é¢‘ç”Ÿæˆ, äº¤é€šåœºæ™¯, è¯­ä¹‰å¯¹é½, æ—¶åºä¸€è‡´æ€§, æ·±åº¦å­¦ä¹ , ç”Ÿæˆæ¨¡å‹, ç‰¹å¾æå–, æ§åˆ¶ä¿¡å·, åŸºç¡€æ¨¡å‹, mAP, mIoU, autonomous

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05966v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05966v1.pdf)

---

## cs.LG

## [18. Shared LoRA Subspaces for almost Strict Continual Learning](https://arxiv.org/abs/2602.06043v1)

**ä½œè€…**ï¼šPrakhar Kaushik, Ankit Vaidya, Shravan Chaudhari ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, facilitating forward knowledge transfer, while minimizing catastrophic interference. This approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task-specific LoRA adapters, supporting scalable, asynchronous continual learning. Experiments across image classification, natural language understanding, 3D pose estimation, and text-to-image generation validate its effectiveness, making Share a practical and scalable solution for lifelong learning in large-scale AI systems.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šShareæ˜¯ä¸€ç§æ–°é¢–çš„ä½ç§©å­ç©ºé—´å…±äº«æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„æŒç»­å­¦ä¹ ï¼Œå‡å°‘ç¾éš¾æ€§é—å¿˜å¹¶æ”¯æŒå¤šä»»åŠ¡é€‚åº”ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæœ‰æ•ˆä¸”æŒç»­åœ°å°†å¤§å‹é¢„è®­ç»ƒæ¨¡å‹é€‚åº”æ–°ä»»åŠ¡æ˜¯ç°å®éƒ¨ç½²ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ç¾éš¾æ€§é—å¿˜å’Œé‡è®­ç»ƒæˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šShareé€šè¿‡å­¦ä¹ å’ŒåŠ¨æ€æ›´æ–°ä¸€ä¸ªå…±äº«çš„ä½ç§©å­ç©ºé—´ï¼Œæå–è¿‡å»ä»»åŠ¡çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œå¹¶é€æ­¥æ•´åˆæ–°ä¿¡æ¯ï¼Œä»è€Œå®ç°ä»»åŠ¡ä¹‹é—´çš„æ— ç¼é€‚åº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå®ç°äº†é«˜è¾¾100å€çš„å‚æ•°å‡å°‘å’Œ281å€çš„å†…å­˜èŠ‚çœï¼Œæ”¯æŒå¯æ‰©å±•çš„å¼‚æ­¥æŒç»­å­¦ä¹ ã€‚

**å…³é”®è¯**ï¼šå…±äº«LoRAå­ç©ºé—´, ä½ç§©é€‚åº”, æŒç»­å­¦ä¹ , çŸ¥è¯†é›†æˆ, å‚æ•°é«˜æ•ˆ, å¤šä»»åŠ¡é€‚åº”, å›¾åƒåˆ†ç±», è‡ªç„¶è¯­è¨€ç†è§£, 3Då§¿æ€ä¼°è®¡, æ–‡æœ¬ç”Ÿæˆ, ml

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06043v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06043v1.pdf)

---

## [19. Pseudo-Invertible Neural Networks](https://arxiv.org/abs/2602.06042v1)

**ä½œè€…**ï¼šYamit Ehrlich, Nimrod Berman, Assaf Shocher  
**åˆ†ç±»**ï¼šcs.LG, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The Moore-Penrose Pseudo-inverse (PInv) serves as the fundamental solution for linear systems. In this paper, we propose a natural generalization of PInv to the nonlinear regime in general and to neural networks in particular. We introduce Surjective Pseudo-invertible Neural Networks (SPNN), a class of architectures explicitly designed to admit a tractable non-linear PInv. The proposed non-linear PInv and its implementation in SPNN satisfy fundamental geometric properties. One such property is null-space projection or "Back-Projection", $x' = x + A^\dagger(y-Ax)$, which moves a sample $x$ to its closest consistent state $x'$ satisfying $Ax=y$. We formalize Non-Linear Back-Projection (NLBP), a method that guarantees the same consistency constraint for non-linear mappings $f(x)=y$ via our defined PInv. We leverage SPNNs to expand the scope of zero-shot inverse problems. Diffusion-based null-space projection has revolutionized zero-shot solving for linear inverse problems by exploiting closed-form back-projection. We extend this method to non-linear degradations. Here, "degradation" is broadly generalized to include any non-linear loss of information, spanning from optical distortions to semantic abstractions like classification. This approach enables zero-shot inversion of complex degradations and allows precise semantic control over generative outputs without retraining the diffusion prior.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä¼ªå¯é€†ç¥ç»ç½‘ç»œæ¶æ„ï¼Œæ‰©å±•äº†ä¼ªé€†çš„åº”ç”¨äºéçº¿æ€§ç³»ç»Ÿï¼Œç‰¹åˆ«æ˜¯åœ¨é›¶-shot é€†é—®é¢˜ä¸­çš„åº”ç”¨ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶çš„åŠ¨æœºåœ¨äºå°†ç»å…¸çš„çº¿æ€§ä¼ªé€†æ–¹æ³•æ¨å¹¿åˆ°éçº¿æ€§é¢†åŸŸï¼Œä»¥è§£å†³å¤æ‚çš„é€†é—®é¢˜å¹¶ä¿æŒä¸€è‡´æ€§çº¦æŸã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†å¯æ˜ å°„ä¼ªå¯é€†ç¥ç»ç½‘ç»œï¼ˆSPNNï¼‰å’Œéçº¿æ€§å›æŠ•å½±ï¼ˆNLBPï¼‰æ–¹æ³•ï¼Œä»¥å®ç°éçº¿æ€§ç³»ç»Ÿçš„æœ‰æ•ˆé€†æŠ•å½±ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥ç ”ç©¶è¡¨æ˜ï¼ŒSPNNèƒ½å¤Ÿåœ¨ä¸éœ€è¦é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå¯¹å¤æ‚çš„éçº¿æ€§é€€åŒ–è¿›è¡Œé›¶-shot é€†è½¬ï¼Œå¹¶å®ç°å¯¹ç”Ÿæˆè¾“å‡ºçš„ç²¾ç¡®è¯­ä¹‰æ§åˆ¶ã€‚

**å…³é”®è¯**ï¼šä¼ªå¯é€†ç¥ç»ç½‘ç»œ, éçº¿æ€§, åæŠ•å½±, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, é›¶-shot, ç”Ÿæˆæ§åˆ¶, åå‘æŠ•å½±, PInv, SPNN, neural network

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06042v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06042v1.pdf)

---

## [20. Can vision language models learn intuitive physics from interaction?](https://arxiv.org/abs/2602.06033v1)

**ä½œè€…**ï¼šLuca M. Schulze Buschoff, Konstantinos Voudouris, Can Demircan ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Pre-trained vision language models do not have good intuitions about the physical world. Recent work has shown that supervised fine-tuning can improve model performance on simple physical tasks. However, fine-tuned models do not appear to learn robust physical rules that can generalize to new contexts. Based on research in cognitive science, we hypothesize that models need to interact with an environment to properly learn its physical dynamics. We train models that learn through interaction with the environment using reinforcement learning. While learning from interaction allows models to improve their within-task performance, it fails to produce models with generalizable physical intuitions. We find that models trained on one task do not reliably generalize to related tasks, even if the tasks share visual statistics and physical principles, and regardless of whether the models are trained through interaction.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºäº¤äº’å­¦ä¹ çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç‰©ç†ç›´è§‰ä¸Šæœªèƒ½å®ç°è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šé¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ç¼ºä¹å¯¹ç‰©ç†ä¸–ç•Œçš„ç›´è§‰ï¼Œè€Œç›‘ç£å¾®è°ƒè™½èƒ½æå‡ç®€å•ç‰©ç†ä»»åŠ¡çš„è¡¨ç°ï¼Œä½†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»ç„¶ä¸è¶³ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’å­¦ä¹ ç‰©ç†åŠ¨æ€ã€‚

**ä¸»è¦ç»“è®º**ï¼šå°½ç®¡äº¤äº’å­¦ä¹ æé«˜äº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡å†…çš„è¡¨ç°ï¼Œä½†æ¨¡å‹ä»æ— æ³•åœ¨ç›¸å…³ä»»åŠ¡ä¹‹é—´å¯é åœ°æ³›åŒ–ã€‚

**å…³é”®è¯**ï¼šè§†è§‰è¯­è¨€æ¨¡å‹, ç‰©ç†ç›´è§‰, å¼ºåŒ–å­¦ä¹ , äº¤äº’å­¦ä¹ , æ·±åº¦å­¦ä¹ , è¯­ä¹‰æœç´¢, ç”Ÿæˆæ¨¡å‹, å¤šæ™ºèƒ½ä½“, ä»»åŠ¡æ³›åŒ–, context

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06033v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06033v1.pdf)

---

## [21. Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference](https://arxiv.org/abs/2602.06029v1)

**ä½œè€…**ï¼šYingke Li, Anjali Parashar, Enlu Zhou ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç†è®ºæ¡†æ¶ï¼Œç¡®ä¿ä¸»åŠ¨æ¨ç†ä¸­çš„è¶³å¤Ÿå¥½å¥‡å¿ƒå¯ä»¥å®ç°è‡ªæ´½å­¦ä¹ å’Œæ— æ‚”ä¼˜åŒ–ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨è§£å†³åœ¨ä¸»åŠ¨æ¨ç†ä¸­ï¼Œå¦‚ä½•å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„å†³ç­–å’Œå­¦ä¹ ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å»ºç«‹ç†è®ºä¿è¯ï¼Œæå‡ºè¶³å¤Ÿçš„å¥½å¥‡å¿ƒæ˜¯å®ç°è´å¶æ–¯åéªŒä¸€è‡´æ€§å’Œæœ‰ç•Œç´¯ç§¯æ‚”æ¨çš„å•ä¸€è¦æ±‚ã€‚

**ä¸»è¦ç»“è®º**ï¼šç»“æœè¡¨æ˜ï¼Œåˆå§‹ä¸ç¡®å®šæ€§ã€å¯è¯†åˆ«æ€§å’Œç›®æ ‡å¯¹é½å¯¹æœºåˆ¶çš„å½±å“ï¼Œä¸ºæ··åˆå­¦ä¹ -ä¼˜åŒ–é—®é¢˜ä¸­çš„çŸ¥è¯†ä¸å®ç”¨æ€§æƒè¡¡æä¾›äº†å®é™…è®¾è®¡æŒ‡å¯¼ã€‚

**å…³é”®è¯**ï¼šè‡ªæˆ‘ä¸€è‡´å­¦ä¹ , ä¸»åŠ¨æ¨ç†, æœŸæœ›è‡ªç”±èƒ½, å¥½å¥‡å¿ƒç³»æ•°, è´å¶æ–¯ä¼˜åŒ–, ä»»åŠ¡æ€§èƒ½, ä¿¡æ¯å¢ç›Š, é«˜æ•ˆå†³ç­–, agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06029v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06029v1.pdf)

---

## [22. Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering](https://arxiv.org/abs/2602.06022v1)

**ä½œè€…**ï¼šMiranda Muqing Miao, Young-Min Cho, Lyle Ungar  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimize proxies for correctness rather than correctness itself. We introduce CORAL (Correctness-Optimized Residual Activation Lens), a regularized inference-time steering method that captures distributed correctness signals from model internal activations using weight-decay MLP probes. We evaluate CORAL across three 7B-parameter models and find that it consistently improves accuracy by 10\% and expected calibration error (ECE) by 50\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held-out benchmarks (ARC-Challenge, HellaSwag, Math-MC, OpenBookQA), averaging 14\% accuracy improvements and 49\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute-efficient, transferable, and calibration-aware approach to improve MCQA performance during inference.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCORALæ˜¯ä¸€ç§ä¼˜åŒ–æ¨ç†æ—¶æ ¡å‡†å’Œå‡†ç¡®æ€§çš„è½»é‡çº§æ–¹æ³•ï¼Œé€šè¿‡æ¨¡å‹å†…éƒ¨æ¿€æ´»çš„åˆ†å¸ƒå¼ä¿¡å·æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŒ‡ä»¤è°ƒä¼˜å’Œåå¥½å¯¹é½åå¸¸å¸¸å‡ºç°è¯¯æ ¡å‡†ï¼Œé‡æ–°è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤éœ€è¦ä¸€ç§æœ‰æ•ˆçš„æ¨ç†æ—¶è°ƒæ•´æ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCORALé€šè¿‡ä½¿ç”¨æƒé‡è¡°å‡çš„å¤šå±‚æ„ŸçŸ¥æœºæ¢é’ˆæ¥æ•æ‰æ¨¡å‹å†…éƒ¨æ¿€æ´»çš„åˆ†å¸ƒå¼æ­£ç¡®æ€§ä¿¡å·ï¼Œè¿›è¡Œæ­£åˆ™åŒ–æ¨ç†æ—¶è°ƒæ•´ã€‚

**ä¸»è¦ç»“è®º**ï¼šCORALæ˜¾è‘—æå‡äº†ä¸‰ç§7Bå‚æ•°æ¨¡å‹çš„å‡†ç¡®æ€§å’ŒæœŸæœ›æ ¡å‡†è¯¯å·®ï¼Œå¹¶ä¸”è¿™äº›æå‡åœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹èƒ½å¤Ÿè½¬ç§»åˆ°å…¶ä»–æµ‹è¯•é›†ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , å¤§è¯­è¨€æ¨¡å‹, æ ¡å‡†, æ¨ç†, ä»£ç†, è¿ç§»å­¦ä¹ , CORAL, æ­£ç¡®æ€§ä¼˜åŒ–, æ¿€æ´»ä¿¡å·, å¤šæ¨¡å‹è¯„ä¼°, ml

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06022v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06022v1.pdf)

---

## [23. Mechanisms of AI Protein Folding in ESMFold](https://arxiv.org/abs/2602.06020v1)

**ä½œè€…**ï¼šKevin Lu, Jannik Brinkmann, Stefan Huber ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, q-bio.BM  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions on model latents, we identify two computational stages in the folding trunk. In the first stage, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second stage, late blocks develop pairwise spatial features: distance and contact information accumulate in the pairwise representation. We demonstrate that the mechanisms underlying structural decisions of ESMFold can be localized, traced through interpretable representations, and manipulated with strong causal effects.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æ¢è®¨äº†ESMFoldåœ¨æŠ˜å è›‹ç™½è´¨æ—¶çš„ä¸¤ä¸ªè®¡ç®—é˜¶æ®µåŠå…¶æœºåˆ¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶è›‹ç™½è´¨ç»“æ„é¢„æµ‹æ¨¡å‹å¦‚ä½•æŠ˜å è›‹ç™½è´¨ï¼Œä»¥æé«˜å¯¹å…¶å†³ç­–æœºåˆ¶çš„ç†è§£ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¯¹æ¨¡å‹æ½œå˜é‡çš„åäº‹å®å¹²é¢„ï¼Œè¯†åˆ«ESMFoldæŠ˜å è¿‡ç¨‹ä¸­çš„æ—©æœŸå’Œæ™šæœŸè®¡ç®—é˜¶æ®µã€‚

**ä¸»è¦ç»“è®º**ï¼šESMFoldçš„ç»“æ„å†³ç­–æœºåˆ¶å¯ä»¥è¢«å±€éƒ¨åŒ–ã€è¿½è¸ªå¹¶é€šè¿‡å¯è§£é‡Šçš„è¡¨ç¤ºè¿›è¡Œæ“æ§ï¼Œå…·æœ‰æ˜¾è‘—çš„å› æœæ•ˆåº”ã€‚

**å…³é”®è¯**ï¼šè›‹ç™½è´¨æŠ˜å , ç»“æ„é¢„æµ‹æ¨¡å‹, ESMFold, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, è®¡ç®—é˜¶æ®µ, è¯­ä¹‰è¡¨ç¤º, åµŒå…¥, ç”Ÿæˆæ¨¡å‹, åäº‹å®å¹²é¢„, agent

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06020v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06020v1.pdf)

---

## [24. Optimism Stabilizes Thompson Sampling for Adaptive Inference](https://arxiv.org/abs/2602.06014v1)

**ä½œè€…**ï¼šShunxing Yan, Han Zhong  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, math.OC, math.ST, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \emph{optimism} as a key mechanism for restoring \emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \citep{halder2025stable} is stable for any $K \ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šä¹è§‚ç­–ç•¥ç¨³å®šäº†æ±¤æ™®æ£®é‡‡æ ·ï¼Œä»è€Œå®ç°äº†å¤šè‡‚èµŒåšæœºä¸­çš„æ¸è¿‘æœ‰æ•ˆæ¨æ–­ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæ±¤æ™®æ£®é‡‡æ ·åœ¨è‡ªé€‚åº”æ•°æ®æ”¶é›†ä¸‹çš„æ¨æ–­æ€§è´¨å¤æ‚ï¼Œéœ€è¦æ‰¾åˆ°æœºåˆ¶æ¢å¤å…¶ç¨³å®šæ€§ä»¥ä¿è¯æœ‰æ•ˆæ¨æ–­ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶è€…é€šè¿‡è¯æ˜æ–¹å·®è†¨èƒ€çš„æ±¤æ™®æ£®é‡‡æ ·åœ¨ä»»æ„Kè‡‚æƒ…å†µä¸‹çš„ç¨³å®šæ€§ï¼Œå¹¶åˆ†æäº†å¦ä¸€ç§ä¹è§‚ä¿®æ”¹ç­–ç•¥ï¼Œç¡®ä¿åéªŒå‡å€¼å¢åŠ ã€‚

**ä¸»è¦ç»“è®º**ï¼šé€‚å½“å®æ–½çš„ä¹è§‚ç­–ç•¥å¯ä»¥ç¨³å®šæ±¤æ™®æ£®é‡‡æ ·ï¼Œä½¿å…¶åœ¨å¤šè‡‚èµŒåšæœºä¸­å®ç°æ¸è¿‘æœ‰æ•ˆæ¨æ–­ï¼ŒåŒæ—¶ä»…å¢åŠ è½»å¾®çš„é¢å¤–é—æ†¾æˆæœ¬ã€‚

**å…³é”®è¯**ï¼šå…³é”®è¯ï¼šé‡‡æ ·, è‡ªé€‚åº”æ¨æ–­, å¤šè‡‚èµŒåšæœº, ç¨³å®šæ€§, åéªŒå‡å€¼, å˜å¼‚è†¨èƒ€, ä¼˜åŒ–, å¼ºåŒ–å­¦ä¹ , ç»Ÿè®¡æ¨æ–­, agent

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.06014v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06014v1.pdf)

---

## [25. On Computation and Reinforcement Learning](https://arxiv.org/abs/2602.05999v1)

**ä½œè€…**ï¼šRaj Ghugare, MichaÅ‚ Bortkiewicz, Alicja Ziarko ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

How does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, still benefit from additional compute? The standard RL framework does not provide a language to answer these questions formally. Empirically, deep RL policies are often parameterized as neural networks with static architectures, conflating the amount of compute and the number of parameters. In this paper, we formalize compute bounded policies and prove that policies which use more compute can solve problems and generalize to longer-horizon tasks that are outside the scope of policies with less compute. Building on prior work in algorithmic learning and model-free planning, we propose a minimal architecture that can use a variable amount of compute. Our experiments complement our theory. On a set 31 different tasks spanning online and offline RL, we show that $(1)$ this architecture achieves stronger performance simply by using more compute, and $(2)$ stronger generalization on longer-horizon test tasks compared to standard feedforward networks or deep residual network using up to 5 times more parameters.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ¢è®¨äº†è®¡ç®—èµ„æºå¯¹å¼ºåŒ–å­¦ä¹ æ”¿ç­–å­¦ä¹ çš„å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§èƒ½çµæ´»ä½¿ç”¨è®¡ç®—èµ„æºçš„æœ€å°æ¶æ„ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨è§£ç­”è®¡ç®—èµ„æºä¸å¼ºåŒ–å­¦ä¹ æ”¿ç­–ä¹‹é—´çš„å…³ç³»ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ä½¿å›ºå®šå‚æ•°çš„æ”¿ç­–ä»é¢å¤–çš„è®¡ç®—ä¸­å—ç›Šã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä¸€ç§è®¡ç®—å—é™æ”¿ç­–çš„å½¢å¼åŒ–å®šä¹‰ï¼Œå¼€å‘äº†ä¸€ç§æœ€å°æ¶æ„ä»¥çµæ´»ä½¿ç”¨ä¸åŒæ•°é‡çš„è®¡ç®—èµ„æºï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜å…¶æœ‰æ•ˆæ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨æ›´å¤šè®¡ç®—èµ„æºçš„æ”¿ç­–åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°æ›´å¼ºï¼Œå¹¶åœ¨é•¿æ—¶é—´æµ‹è¯•ä»»åŠ¡ä¸Šå…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šè®¡ç®—, å¼ºåŒ–å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ç®—æ³•å­¦ä¹ , åœ¨çº¿å­¦ä¹ , æ¨¡å‹æ— å…³è§„åˆ’, è®¡ç®—é™åˆ¶æ”¿ç­–, é•¿æœŸä»»åŠ¡, æ€§èƒ½æå‡, neural network

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05999v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05999v1.pdf)

---

## [26. Orthogonal Self-Attention](https://arxiv.org/abs/2602.05996v1)

**ä½œè€…**ï¼šLeo Zhang, James Martens  
**åˆ†ç±»**ï¼šcs.LG, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Softmax Self-Attention (SSA) is a key component of Transformer architectures. However, when utilised within skipless architectures, which aim to improve representation learning, recent work has highlighted the inherent instability of SSA due to inducing rank collapse and poorly-conditioned Jacobians. In this work, we design a novel attention mechanism: Orthogonal Self-Attention (OSA), which aims to bypass these issues with SSA, in order to allow for (non-causal) Transformers without skip connections and normalisation layers to be more easily trained. In particular, OSA parametrises the attention matrix to be orthogonal via mapping a skew-symmetric matrix, formed from query-key values, through the matrix exponential. We show that this can be practically implemented, by exploiting the low-rank structure of our query-key values, resulting in the computational complexity and memory cost of OSA scaling linearly with sequence length. Furthermore, we derive an initialisation scheme for which we prove ensures that the Jacobian of OSA is well-conditioned.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ­£äº¤è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè‡ªæ³¨æ„åŠ›çš„ç¨³å®šæ€§é—®é¢˜ï¼Œä»¥ä¾¿æ›´æœ‰æ•ˆåœ°è®­ç»ƒæ— è·³è¿æ¥çš„Transformeræ¨¡å‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„Softmaxè‡ªæ³¨æ„åŠ›åœ¨æ— è·³è¿æ¥æ¶æ„ä¸­è¡¨ç°ä¸ç¨³å®šï¼Œå¯¼è‡´è¡¨ç¤ºå­¦ä¹ æ•ˆæœä¸ä½³ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶æ¥å…‹æœè¿™äº›é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ­£äº¤è‡ªæ³¨æ„åŠ›ï¼ˆOSAï¼‰é€šè¿‡å°†æŸ¥è¯¢-é”®å€¼å½¢æˆçš„æ–œå¯¹ç§°çŸ©é˜µæ˜ å°„åˆ°æ­£äº¤çŸ©é˜µï¼Œåˆ©ç”¨ä½ç§©ç»“æ„å®ç°é«˜æ•ˆè®¡ç®—ï¼ŒåŒæ—¶æä¾›äº†ä¸€ç§ä¿è¯é›…å¯æ¯”çŸ©é˜µè‰¯å¥½æ¡ä»¶çš„åˆå§‹åŒ–æ–¹æ¡ˆã€‚

**ä¸»è¦ç»“è®º**ï¼šOSAçš„è®¾è®¡ä½¿å¾—åœ¨ä¸ä½¿ç”¨è·³è¿æ¥å’Œå½’ä¸€åŒ–å±‚çš„æƒ…å†µä¸‹ï¼ŒTransformerèƒ½å¤Ÿæ›´å®¹æ˜“åœ°è¿›è¡Œè®­ç»ƒï¼Œä¸”å…¶è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜å¼€é”€ä¸åºåˆ—é•¿åº¦çº¿æ€§ç›¸å…³ã€‚

**å…³é”®è¯**ï¼šè‡ªæ³¨æ„åŠ›, å˜æ¢å™¨, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, è¡¨ç¤ºå­¦ä¹ , è®­ç»ƒç¨³å®šæ€§, ä½ç§©ç»“æ„, æ³¨æ„åŠ›æœºåˆ¶, Orthogonal Self-Attention, æ— è·³è·ƒè¿æ¥, transformer

**è¯„åˆ†**ï¼š55

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05996v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05996v1.pdf)

---

## [27. Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps](https://arxiv.org/abs/2602.05993v1)

**ä½œè€…**ï¼šPeter Holderrieth, Douglas Chen, Luca Eyring ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an afterthought, and redesign the model for adaptability. We propose "Diamond Maps", stochastic flow map models that enable efficient and accurate alignment to arbitrary rewards at inference time. Diamond Maps amortize many simulation steps into a single-step sampler, like flow maps, while preserving the stochasticity required for optimal reward alignment. This design makes search, sequential Monte Carlo, and guidance scalable by enabling efficient and consistent estimation of the value function. Our experiments show that Diamond Maps can be learned efficiently via distillation from GLASS Flows, achieve stronger reward alignment performance, and scale better than existing methods. Our results point toward a practical route to generative models that can be rapidly adapted to arbitrary preferences and constraints at inference time.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDiamond Mapsæ˜¯ä¸€ç§é«˜æ•ˆçš„éšæœºæµæ˜ å°„æ¨¡å‹ï¼Œå¯ä»¥åœ¨æ¨ç†æ—¶å®ç°ä¸ä»»æ„å¥–åŠ±çš„æœ‰æ•ˆå¯¹é½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„ç”Ÿæˆæ¨¡å‹åœ¨è®­ç»ƒåé€‚åº”ç”¨æˆ·åå¥½å’Œçº¦æŸçš„è¿‡ç¨‹æ—¢è´¹æ—¶åˆè„†å¼±ï¼Œå› æ­¤éœ€è¦å°†é«˜æ•ˆçš„å¥–åŠ±å¯¹é½ä½œä¸ºç”Ÿæˆæ¨¡å‹çš„å†…åœ¨å±æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†Diamond Mapsæ¨¡å‹ï¼Œé€šè¿‡å°†å¤šä¸ªä»¿çœŸæ­¥éª¤å‹ç¼©ä¸ºå•æ­¥é‡‡æ ·ï¼Œä¿æŒäº†æ‰€éœ€çš„éšæœºæ€§ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„å¥–åŠ±å¯¹é½ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒDiamond Mapsåœ¨å¥–åŠ±å¯¹é½æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½å¿«é€Ÿé€‚åº”ä»»æ„åå¥½å’Œçº¦æŸï¼Œå…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚

**å…³é”®è¯**ï¼šå¥–åŠ±å¯¹é½, ç”Ÿæˆæ¨¡å‹, æµæ¨¡å‹, éšæœºæµå›¾, ä»·å€¼å‡½æ•°, é€‚åº”æ€§, è’¸é¦, é«˜æ•ˆå­¦ä¹ , æ¨¡å‹è®¾è®¡, generative

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05993v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05993v1.pdf)

---

## [28. Clifford Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.05977v1)

**ä½œè€…**ï¼šMatthias Wolff, Francesco Alesiani, Christof Duhme ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering, and is validated in synthetic and physics inspired tasks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šClifford Kolmogorov-Arnold Network (ClKAN) æ˜¯ä¸€ç§çµæ´»é«˜æ•ˆçš„æ¶æ„ï¼Œç”¨äºåœ¨ä»»æ„Cliffordä»£æ•°ç©ºé—´ä¸­è¿›è¡Œå‡½æ•°é€¼è¿‘ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨è§£å†³é«˜ç»´ä»£æ•°ç›¸å…³çš„æŒ‡æ•°æ‰©å±•é—®é¢˜ï¼Œå¹¶æ¨åŠ¨ç§‘å­¦å‘ç°ä¸å·¥ç¨‹åº”ç”¨ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºéšæœºå‡†è’™ç‰¹å¡ç½—ç½‘æ ¼ç”Ÿæˆæ–¹æ³•å’Œæ–°çš„æ‰¹é‡å½’ä¸€åŒ–ç­–ç•¥ï¼Œä»¥å¤„ç†å¯å˜é¢†åŸŸè¾“å…¥ã€‚

**ä¸»è¦ç»“è®º**ï¼šClKANåœ¨åˆæˆå’Œç‰©ç†å¯å‘ä»»åŠ¡ä¸­å¾—åˆ°äº†éªŒè¯ï¼Œå±•ç°å‡ºåœ¨ç§‘å­¦ä¸å·¥ç¨‹é¢†åŸŸçš„å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šå…‹åˆ©ç¦å¾·, ç§‘å°”è«æˆˆç½—å¤«-é˜¿è¯ºå¾·ç½‘ç»œ, å‡½æ•°é€¼è¿‘, éšæœºå‡†è’™ç‰¹å¡ç½—, æ‰¹é‡å½’ä¸€åŒ–, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ä»£ç†, è‡ªä¸»æ™ºèƒ½, ç§‘å­¦å‘ç°, agent

**è¯„åˆ†**ï¼š55

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05977v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05977v1.pdf)

---

## [29. Inverse Depth Scaling From Most Layers Being Similar](https://arxiv.org/abs/2602.05970v1)

**ä½œè€…**ï¼šYizhou Liu, Sara Kangaslahti, Ziming Liu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, math.DS, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Neural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely proportional to depth in LLMs, probably due to functionally similar layers reducing error through ensemble averaging rather than compositional learning or discretizing smooth dynamics. This regime is inefficient yet robust and may arise from the architectural bias of residual networks and target functions incompatible with smooth dynamics. The findings suggest that improving LLM efficiency may require architectural innovations to encourage compositional use of depth.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦å¯¹å¤§è¯­è¨€æ¨¡å‹æŸå¤±çš„å½±å“ï¼Œå‘ç°æŸå¤±ä¸æ·±åº¦å‘ˆåæ¯”å…³ç³»ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„ç¥ç»ç½‘ç»œæ‰©å±•è§„å¾‹æœªèƒ½å……åˆ†è§£é‡Šæ·±åº¦å’Œå®½åº¦å¯¹æ€§èƒ½çš„ä¸åŒè´¡çŒ®ï¼Œéœ€è¿›è¡Œæ›´æ·±å…¥çš„ç ”ç©¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡åˆ†æå¤§è¯­è¨€æ¨¡å‹å’Œç®€å•çš„æ®‹å·®ç½‘ç»œï¼Œé‡åŒ–æ·±åº¦å¯¹æŸå¤±çš„å½±å“ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæé«˜å¤§è¯­è¨€æ¨¡å‹æ•ˆç‡å¯èƒ½éœ€è¦åœ¨æ¶æ„ä¸Šè¿›è¡Œåˆ›æ–°ï¼Œä»¥ä¿ƒè¿›æ·±åº¦çš„ç»„åˆä½¿ç”¨ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, LLM, æ¨¡å‹è§„æ¨¡, é€†æ·±åº¦ç¼©æ”¾, æ¶æ„åˆ›æ–°, æ€§èƒ½åˆ†æ, è¯¯å·®å‡å°‘, é›†æˆå¹³å‡

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05970v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05970v1.pdf)

---

## [30. A Hybrid Data-Driven Algorithm for Real-Time Friction Force Estimation in Hydraulic Cylinders](https://arxiv.org/abs/2602.05967v1)

**ä½œè€…**ï¼šMohamad Amin Jamshidi, Mehrbod Zarifi, Zolfa Anvari ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, eess.SY  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Hydraulic systems are widely utilized in industrial applications due to their high force generation, precise control, and ability to function in harsh environments. Hydraulic cylinders, as actuators in these systems, apply force and position through the displacement of hydraulic fluid, but their operation is significantly influenced by friction force. Achieving precision in hydraulic cylinders requires an accurate friction model under various operating conditions. Existing analytical models, often derived from experimental tests, necessitate the identification or estimation of influencing factors but are limited in adaptability and computational efficiency. This research introduces a data-driven, hybrid algorithm based on Long Short-Term Memory (LSTM) networks and Random Forests for nonlinear friction force estimation. The algorithm effectively combines feature detection and estimation processes using training data acquired from an experimental hydraulic test setup. It achieves a consistent and stable model error of less than 10% across diverse operating conditions and external load variations, ensuring robust performance in complex situations. The computational cost of the algorithm is 1.51 milliseconds per estimation, making it suitable for real-time applications. The proposed method addresses the limitations of analytical models by delivering high precision and computational efficiency. The algorithm's performance is validated through detailed analysis and experimental results, including direct comparisons with the LuGre model. The comparison highlights that while the LuGre model offers a theoretical foundation for friction modeling, its performance is limited by its inability to dynamically adjust to varying operational conditions of the hydraulic cylinder, further emphasizing the advantages of the proposed hybrid approach in real-time applications.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºLSTMå’Œéšæœºæ£®æ—çš„æ··åˆæ•°æ®é©±åŠ¨ç®—æ³•ï¼Œç”¨äºå®æ—¶ä¼°è®¡æ¶²å‹ç¼¸ä¸­çš„æ‘©æ“¦åŠ›ï¼Œå…·æœ‰é«˜ç²¾åº¦å’Œä½è®¡ç®—æˆæœ¬ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæ¶²å‹ç¼¸åœ¨å·¥ä¸šåº”ç”¨ä¸­å¹¿æ³›ä½¿ç”¨ï¼Œå…¶æ€§èƒ½å—åˆ°æ‘©æ“¦åŠ›çš„æ˜¾è‘—å½±å“ï¼Œç°æœ‰çš„è§£ææ¨¡å‹åœ¨é€‚åº”æ€§å’Œè®¡ç®—æ•ˆç‡ä¸Šå­˜åœ¨å±€é™ï¼Œå› æ­¤éœ€è¦æ›´å¥½çš„æ‘©æ“¦æ¨¡å‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶é‡‡ç”¨åŸºäºé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰å’Œéšæœºæ£®æ—çš„æ··åˆç®—æ³•ï¼Œé€šè¿‡å®éªŒæ•°æ®è¿›è¡Œç‰¹å¾æ£€æµ‹å’Œæ‘©æ“¦åŠ›ä¼°è®¡ï¼Œå®ç°äº†åœ¨å¤šç§æ“ä½œæ¡ä»¶ä¸‹çš„éçº¿æ€§æ‘©æ“¦åŠ›ä¼°è®¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥ç®—æ³•åœ¨å¤æ‚æƒ…å†µä¸‹è¡¨ç°å‡ºè¶…è¿‡10%çš„ç¨³å®šæ¨¡å‹è¯¯å·®ï¼Œè®¡ç®—æˆæœ¬ä»…ä¸º1.51æ¯«ç§’ï¼Œä¼˜äºä¼ ç»Ÿçš„LuGreæ¨¡å‹ï¼Œé€‚åˆå®æ—¶åº”ç”¨ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, LSTM, éšæœºæ£®æ—, å®æ—¶ä¼°è®¡, æ‘©æ“¦åŠ›æ¨¡å‹, æ•°æ®é©±åŠ¨ç®—æ³•, ç‰¹å¾æ£€æµ‹, å¤æ‚æƒ…å†µ, agent

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.05967v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05967v1.pdf)

---

