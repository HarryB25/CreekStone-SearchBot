# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-17

> å…± 15 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (8 ç¯‡)
- [cs.CL](#csCL) (2 ç¯‡)
- [cs.AI](#csAI) (4 ç¯‡)
- [cs.CV](#csCV) (1 ç¯‡)

---

## cs.AI

## [1. Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066v1)

**ä½œè€…**ï¼šMartin Klissarov, Jonathan Cook, Diego Antognini ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºå°†â€œä»è‡ªç„¶è¯­è¨€çº é”™åé¦ˆä¸­äº¤äº’å¼å­¦ä¹ â€ä½œä¸ºå¯è®­ç»ƒèƒ½åŠ›ï¼Œé€šè¿‡æ„é€ å¤šè½®æ•™å­¦å¼äº¤äº’è¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æå‡æ¨¡å‹åœ¨å¤šè½®æ¨ç†ä¸­çš„è‡ªæˆ‘ä¿®æ­£ä¸è·¨é¢†åŸŸè¿ç§»èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤§æ¨¡å‹ä¸»è¦ä»é™æ€è¯­æ–™ä¸­å­¦ä¹ ï¼Œç¼ºå°‘å¯¹â€œåœ¨åä½œä¸­æ ¹æ®è¯­è¨€åé¦ˆåŠ¨æ€è°ƒæ•´æ¨ç†è¿‡ç¨‹â€çš„ç³»ç»Ÿè®­ç»ƒï¼Œå¯¼è‡´åœ¨å›°éš¾æ¨ç†ä»»åŠ¡ä¸Šéš¾ä»¥æœ‰æ•ˆå¸æ”¶çº é”™æ„è§å¹¶æ”¹è¿›åç»­å›ç­”ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†å•è½®å¯éªŒè¯ä»»åŠ¡æ‰©å±•ä¸ºç”±ä¿¡æ¯ä¸å¯¹ç§°é©±åŠ¨çš„å¤šè½®â€œæ•™å¸ˆ-å­¦ç”Ÿâ€çº é”™å¯¹è¯æ•°æ®ï¼Œè®­ç»ƒæ¨¡å‹åœ¨å¤šè½®ä¸­ç†è§£æ‰¹è¯„ã€æ›´æ–°è§£é¢˜ç­–ç•¥å¹¶ç»™å‡ºæ”¹è¿›ç­”æ¡ˆï¼›è¿›ä¸€æ­¥è®©æ¨¡å‹å­¦ä¹ é¢„æµ‹æ•™å¸ˆçš„æ‰¹è¯„ï¼Œä»è€Œå†…åŒ–åé¦ˆç¯å¢ƒï¼Œå®ç°æ— æ•™å¸ˆæ—¶çš„è‡ªæˆ‘çº é”™ã€‚

**ä¸»è¦ç»“è®º**ï¼šç»äº¤äº’å¼è®­ç»ƒåï¼Œå°æ¨¡å‹çš„å¤šè½®è¡¨ç°å‡ ä¹é€¼è¿‘å¤§ä¸€ä¸ªæ•°é‡çº§çš„æ¨¡å‹ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–ä»»åŠ¡ä¸Šç¨³å¥æ³›åŒ–ï¼ˆæ•°å­¦è®­ç»ƒå¯è¿ç§»åˆ°ç¼–ç¨‹ã€è°œé¢˜ã€è¿·å®«ç­‰ï¼‰ï¼›æå‡ä¸»è¦æ¥è‡ªæ›´å¼ºçš„in-contextå¯å¡‘æ€§ï¼Œå¹¶ä¸ºæ¨¡å‹è‡ªæˆ‘æ”¹è¿›æä¾›ç»Ÿä¸€è·¯å¾„ã€‚

**å…³é”®è¯**ï¼šäº¤äº’å¼ä¸Šä¸‹æ–‡å­¦ä¹ , è‡ªç„¶è¯­è¨€åé¦ˆ, çº é”™åé¦ˆèåˆ, å¤šè½®æ•™å­¦äº¤äº’, ä¿¡æ¯ä¸å¯¹ç§°ä»»åŠ¡æ„é€ , å›°éš¾æ¨ç†ä»»åŠ¡, ä¸Šä¸‹æ–‡å¯å¡‘æ€§, åˆ†å¸ƒå¤–æ³›åŒ–, å°æ¨¡å‹æ€§èƒ½è¿½èµ¶, æ‰¹è¯„é¢„æµ‹è®­ç»ƒ, å¯æ‰©å±•è®­ç»ƒæ¡†æ¶

**è¯„åˆ†**ï¼š53

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16066v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16066v1.pdf)

---

## [2. Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination](https://arxiv.org/abs/2602.16050v1)

**ä½œè€…**ï¼šAmir Hosseinian, MohammadReza Zare Shahneh, Umer Mansoor ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºç­–å±•è¯æ®åº“ä¸ç»“æ„åŒ–æ¨ç†çš„ä¸´åºŠç³»ç»Ÿ January Mirror åœ¨2025å†…åˆ†æ³Œä¸“ç§‘æ¿è€ƒé¢˜ä¸Šæ˜¾è‘—ä¼˜äºå…·å¤‡å®æ—¶è”ç½‘æ£€ç´¢çš„å‰æ²¿LLMï¼Œå¹¶æä¾›å¯å®¡è®¡çš„è¯æ®æº¯æºã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šé€šç”¨LLMåœ¨ç»¼åˆåŒ»å­¦è€ƒè¯•è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æŒ‡å—å¿«é€Ÿæ›´æ–°ã€è¯æ®å±‚çº§å¤æ‚çš„ä¸“ç§‘æ¨ç†ä¸­ä»æ˜“å‡ºé”™ä¸”éš¾ä»¥å®¡è®¡ï¼›å› æ­¤éœ€è¦æ›´â€œè¯æ®å¯è¿½æº¯â€çš„æ¨ç†æœºåˆ¶æ¥æ”¯æŒä¸´åºŠéƒ¨ç½²ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨120é¢˜å†…åˆ†æ³Œæ¿è€ƒé£æ ¼è¯•å·ä¸Šå¯¹æ¯” Mirror ä¸ GPT-5/GPT-5.2/Gemini-3-Proï¼šMirror åœ¨â€œé—­å·è¯æ®çº¦æŸâ€ä¸‹ä»…ä½¿ç”¨å†…åˆ†æ³Œä¸å¿ƒä»£è°¢ç­–å±•è¯æ®è¯­æ–™ï¼Œå¹¶ç”¨ç»“æ„åŒ–æ¨ç†è¾“å‡ºå¸¦è¯æ®é“¾æ¥çš„ç­”æ¡ˆï¼›å¯¹ç…§LLMå…è®¸å®æ—¶è”ç½‘æ£€ç´¢æŒ‡å—ä¸æ–‡çŒ®ã€‚

**ä¸»è¦ç»“è®º**ï¼šMirror å‡†ç¡®ç‡87.5%ï¼ˆå›°éš¾é¢˜76.7%ï¼‰é«˜äºäººç±»å‚è€ƒä¸å„å‰æ²¿LLMï¼ˆçº¦69.8%â€“74.6%ï¼‰ï¼ŒTop-2å‡†ç¡®ç‡ä¹Ÿæ›´é«˜ï¼›å…¶è¾“å‡ºä¸­74.2%å¼•ç”¨æŒ‡å—çº§æ¥æºä¸”äººå·¥æ ¸éªŒå¼•ç”¨å‡†ç¡®ç‡100%ï¼Œè¯´æ˜é«˜è´¨é‡ç­–å±•è¯æ®+æ˜¾å¼æº¯æºå¯ä¼˜äºä¸å—é™çš„ç½‘é¡µæ£€ç´¢å¹¶å¢å¼ºä¸´åºŠå¯å®¡è®¡æ€§ã€‚

**å…³é”®è¯**ï¼šè¯æ®é©±åŠ¨æ¨ç†, äºšä¸“ç§‘ä¸´åºŠæ¨ç†, å†…åˆ†æ³Œå­¦è€ƒè¯•è¯„æµ‹, å°é—­è¯æ®çº¦æŸ, è¯æ®è¯­æ–™åº“æ„å»º, ç»“æ„åŒ–æ¨ç†æ¶æ„, è¯æ®æº¯æº, å¿ƒä»£è°¢åŒ»å­¦, LLMåŸºå‡†è¯„æµ‹, è”ç½‘æ£€ç´¢å¯¹æ¯”

**è¯„åˆ†**ï¼š46

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16050v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16050v1.pdf)

---

## [3. How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039v1)

**ä½œè€…**ï¼šHang Li, Kaiqi Yang, Xianxuan Long ç­‰ 12 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡ç³»ç»ŸåŸºå‡†è¯„æµ‹äº†å¤šç§ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•åœ¨LLMè‡ªåŠ¨è¯„åˆ†ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºä¸åŒæ¨¡å‹ã€ä»»åŠ¡ä¸è§£ç è®¾ç½®ä¸‹ä¸ç¡®å®šæ€§çš„è§„å¾‹ä¸ä¼˜åŠ£ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šLLMç”¨äºè‡ªåŠ¨è¯„æµ‹è™½çµæ´»å¼ºå¤§ï¼Œä½†è¾“å‡ºå…·æœ‰æ¦‚ç‡æ€§å¯¼è‡´è¯„åˆ†ä¸ç¡®å®šï¼›è‹¥ä¸ç¡®å®šæ€§ä¼°è®¡ä¸å¯é æˆ–æ ¡å‡†å·®ï¼Œä¼šè¯¯å¯¼åé¦ˆä¸æ•™å­¦å†³ç­–å¹¶å¸¦æ¥è´Ÿé¢å­¦ä¹ å½±å“ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…åœ¨å¤šä¸ªè¯„æµ‹æ•°æ®é›†ã€ä¸åŒLLMå®¶æ—ä¸ç”Ÿæˆæ§åˆ¶/è§£ç ç­–ç•¥ä¸‹ï¼Œç»Ÿä¸€å¯¹æ¯”ä¸€ç³»åˆ—ä¸ç¡®å®šæ€§æŒ‡æ ‡ä¸é‡åŒ–æ–¹æ³•ï¼Œåˆ†æå…¶ä¸ç¡®å®šæ€§è¡Œä¸ºæ¨¡å¼ã€ç¨³å®šæ€§ä¸é€‚ç”¨æ€§ï¼Œå¹¶è€ƒå¯Ÿå…³é”®å› ç´ å¯¹ä¼°è®¡ç»“æœçš„å½±å“ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¸ç¡®å®šæ€§åœ¨è‡ªåŠ¨è¯„åˆ†åœºæ™¯ä¸­å‘ˆç°æ˜ç¡®ä¸”å—æ¨¡å‹å®¶æ—ã€ä»»åŠ¡ç±»å‹ä¸è§£ç ç­–ç•¥æ˜¾è‘—å½±å“çš„æ¨¡å¼ï¼›ä¸åŒä¸ç¡®å®šæ€§æŒ‡æ ‡å„æœ‰ä¼˜åŠ¿ä¸å±€é™ï¼Œéœ€é’ˆå¯¹æ•™è‚²è¯„åˆ†åœºæ™¯é€‰æ‹©/è®¾è®¡æ›´å¯é ã€å¯æ ¡å‡†çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„åˆ†æ–¹æ¡ˆã€‚

**å…³é”®è¯**ï¼šè‡ªåŠ¨è¯„åˆ†, æ•™è‚²æµ‹è¯„, LLMè¯„æµ‹åŸºå‡†, ä¸ç¡®å®šæ€§é‡åŒ–, ä¸ç¡®å®šæ€§æŒ‡æ ‡, ç½®ä¿¡åº¦æ ¡å‡†, ç”Ÿæˆè§£ç ç­–ç•¥, æ¨¡å‹å®¶æ—å¯¹æ¯”, è·¨æ•°æ®é›†åˆ†æ, ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„åˆ†

**è¯„åˆ†**ï¼š20

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16039v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16039v1.pdf)

---

## [4. Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037v1)

**ä½œè€…**ï¼šCameron Cagan, Pedram Fard, Jiazi Tian ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.MA  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡å‘ç°è‡ªä¸»ä»£ç†å¼æç¤ºä¼˜åŒ–åœ¨ä½æ‚£ç—…ç‡ç—‡çŠ¶æ£€æµ‹ä¸­ä¼šå‡ºç°â€œè¶Šä¼˜åŒ–è¶Šå˜å·®â€çš„ä¸ç¨³å®šç°è±¡ï¼Œè€Œé€šè¿‡äº‹åâ€œé€‰æ‹©æœ€ä½³è¿­ä»£â€çš„ç›‘ç£å¯æ˜¾è‘—ç¨³å®šå¹¶æå‡æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè‡ªä¸»è¿­ä»£æ”¹è¿›çš„agenticå·¥ä½œæµè¢«å¯„äºˆåšæœ›ï¼Œä½†å…¶å¤±è´¥æ¨¡å¼æœªè¢«å……åˆ†åˆ»ç”»ï¼Œå°¤å…¶åœ¨ä¸´åºŠä½é˜³æ€§ç‡ä»»åŠ¡ä¸­å¸¸è§„æŒ‡æ ‡ä¼šæ©ç›–ç¾éš¾æ€§æ¼æ£€é£é™©ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½¿ç”¨å¼€æºè‡ªåŠ¨æç¤ºä¼˜åŒ–æ¡†æ¶Pythiaï¼Œåœ¨ä¸‰ç§ä¸åŒæ‚£ç—…ç‡çš„ç—‡çŠ¶ï¼ˆ23%ã€12%ã€3%ï¼‰ä¸Šå¤šè½®è¿­ä»£è¯„ä¼°æ•æ„Ÿæ€§/å‡†ç¡®ç‡ç­‰è¡¨ç°ï¼Œå¹¶å¯¹æ¯”ä¸¤ç§å¹²é¢„ï¼šä¸»åŠ¨â€œå¼•å¯¼agentâ€çº åä¸äº‹åâ€œé€‰æ‹©å™¨agentâ€ä»å†å²è¿­ä»£ä¸­æŒ‘é€‰æœ€ä½³ç‰ˆæœ¬ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¼˜åŒ–è¿‡ç¨‹ä¸­éªŒè¯é›†æ•æ„Ÿæ€§å¯åœ¨0åˆ°1é—´å‰§çƒˆæŒ¯è¡ä¸”ä½æ‚£ç—…ç‡æ›´ä¸¥é‡ï¼Œç”šè‡³å‡ºç°95%å‡†ç¡®ç‡ä½†0é˜³æ€§æ£€å‡ºçš„æŒ‡æ ‡é™·é˜±ï¼›å¼•å¯¼agentä¼šåŠ å‰§è¿‡æ‹Ÿåˆï¼Œè€Œé€‰æ‹©å™¨agentèƒ½é¿å…ç¾éš¾æ€§å¤±è´¥å¹¶åœ¨è„‘é›¾/èƒ¸ç—›æ£€æµ‹ä¸Šåˆ†åˆ«è¾ƒä¸“å®¶è¯å…¸æå‡F1 331%/7%ã€‚

**å…³é”®è¯**ï¼šä¸´åºŠç—‡çŠ¶æ£€æµ‹, è‡ªä¸»æ™ºèƒ½ä½“å·¥ä½œæµ, æç¤ºè¯ä¼˜åŒ–, ä¼˜åŒ–ä¸ç¨³å®šæ€§, ä½æ‚£ç—…ç‡åˆ†ç±», ç±»åˆ«ä¸å¹³è¡¡, è¿‡æ‹Ÿåˆ, å›é¡¾å¼é€‰æ‹©, æ™ºèƒ½ä½“å¹²é¢„ç­–ç•¥, è¯„ä»·æŒ‡æ ‡å¤±çœŸï¼ˆå‡†ç¡®ç‡é™·é˜±ï¼‰

**è¯„åˆ†**ï¼š42

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16037v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16037v1.pdf)

---

## cs.CL

## [5. Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085v1)

**ä½œè€…**ï¼šSean Trott, Samuel Taylor, Cameron Jones ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè·³è¿‡

**ç ”ç©¶åŠ¨æœº**ï¼šè·³è¿‡

**æ ¸å¿ƒæ–¹æ³•**ï¼šè·³è¿‡

**ä¸»è¦ç»“è®º**ï¼šè·³è¿‡

**å…³é”®è¯**ï¼šé”™è¯¯ä¿¡å¿µæ¨ç†, å¿ƒæ™ºç†è®º, å¿ƒç†çŠ¶æ€æ¨ç†, çŸ¥è¯†çŠ¶æ€æ¨æ–­, çŸ¥è¯†çº¿ç´¢æ•ˆåº”, éäº‹å®æ€§åŠ¨è¯, è¯­è¨€åˆ†å¸ƒç»Ÿè®¡, å¼€æºæƒé‡è¯­è¨€æ¨¡å‹, æ¨¡å‹è§„æ¨¡æ•ˆåº”, è·¨æ¨¡å‹è¯„æµ‹, å¿ƒç†æµ‹é‡é¢„æµ‹åŠ›

**è¯„åˆ†**ï¼š12

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16085v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16085v1.pdf)

---

## [6. A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023v1)

**ä½œè€…**ï¼šJunghyun Min, Na-Rae Han, Jena D. Hwang ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡ç³»ç»Ÿè€ƒå¯ŸéŸ©è¯­ä¸€ç§åç½®è¯æ€§åŠ¨è¯å¤šè¯è¡¨è¾¾ï¼ˆPVCsï¼‰ï¼Œå¹¶æå‡ºå¯ä¸è·¨è¯­è¨€æ¡†æ¶å¯¹é½çš„æ ‡æ³¨æŒ‡å—ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰PARSEMEç­‰è·¨è¯­è¨€MWEæ ‡æ³¨æ¡†æ¶ä¸­éŸ©è¯­èµ„æºä¸åˆ†æä¸è¶³ï¼Œå°¤å…¶æ˜¯å¤šè¯ä»‹è¯/åç½®è¯ç±»è¡¨è¾¾ç¼ºä¹ç³»ç»Ÿç ”ç©¶ä¸å¯å¤ç”¨æ ‡æ³¨è§„èŒƒã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåŸºäºéŸ©è¯­ç»´åŸºç™¾ç§‘è¯­æ–™æŠ½å–å¹¶æ¢³ç†å¤šç§PVCå®ä¾‹ï¼Œåˆ†æå…¶å½¢å¼ä¸åŠŸèƒ½ç‰¹å¾ï¼Œå¹¶ä¸ç»“æ„ç›¸è¿‘ä½†ä¸å±äºMWEçš„è¡¨è¾¾åŠè½»åŠ¨è¯ç»“æ„ï¼ˆLVCsï¼‰è¿›è¡Œå¯¹æ¯”ï¼Œè¿›è€Œå½’çº³åˆ¤åˆ«æ ‡å‡†å¹¶åˆ¶å®šæ ‡æ³¨æŒ‡å—ã€‚

**ä¸»è¦ç»“è®º**ï¼šPVCså¯ä½œä¸ºéŸ©è¯­åŠŸèƒ½æ€§å¤šè¯è¡¨è¾¾ä¸­çš„ä¸€ç±»ç‹¬ç«‹ä¸”å¯æ“ä½œçš„æ ‡æ³¨å¯¹è±¡ï¼›æ‰€ææŒ‡å—ä¸ºæ„å»ºéŸ©è¯­å¤šè¯åç½®è¯èµ„æºã€å‡å°‘ä¸éMWE/LVCæ··æ·†å¹¶ä¸å¤šè¯­è¨€æ ‡æ³¨æ¡†æ¶è¡”æ¥æä¾›äº†åŸºç¡€ã€‚

**å…³é”®è¯**ï¼šéŸ©è¯­å¤šè¯è¡¨è¾¾, å¤šè¯åç½®è¯, åç½®è¯åŠ¨è¯æ„å¼(PVC, åŠŸèƒ½æ€§å¤šè¯è¡¨è¾¾, è·¨è¯­è¨€æ ‡æ³¨æ¡†æ¶, è½»åŠ¨è¯æ„å¼(LVC, éŸ©è¯­ç»´åŸºç™¾ç§‘è¯­æ–™, å¤šè¯è¡¨è¾¾æ ‡æ³¨æŒ‡å—, å¤šè¯­è¨€æ¡†æ¶å¯¹é½, éŸ©è¯­è¯­è¨€èµ„æºæ„å»º

**è¯„åˆ†**ï¼š18

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16023v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16023v1.pdf)

---

## cs.CV

## [7. MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019v1)

**ä½œè€…**ï¼šAhmad Elallaf, Yu Zhang, Yuktha Priya Masupalli ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMedProbCLIPå°†èƒ¸ç‰‡ä¸æ”¾å°„æŠ¥å‘Šè¡¨ç¤ºä¸ºå¸¦ä¸ç¡®å®šæ€§çš„é«˜æ–¯åµŒå…¥ï¼Œé€šè¿‡æ¦‚ç‡å¯¹æ¯”å­¦ä¹ æå‡æ£€ç´¢ä¸é›¶æ ·æœ¬åˆ†ç±»çš„å¯é æ€§ä¸æ ¡å‡†æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹å¤šä¸ºç¡®å®šæ€§åµŒå…¥ï¼Œéš¾ä»¥è¡¨è¾¾åŒ»å­¦å½±åƒ-æ–‡æœ¬çš„å¤šå¯¹å¤šå¯¹åº”å…³ç³»ä¸ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´é«˜é£é™©åœºæ™¯ä¸‹æ£€ç´¢/é¢„æµ‹è¿‡åº¦è‡ªä¿¡ä¸”ä¸å¯é ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºæ¦‚ç‡å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå°†å›¾åƒä¸æ–‡æœ¬ç¼–ç ä¸ºé«˜æ–¯åˆ†å¸ƒåµŒå…¥å¹¶æ˜¾å¼å»ºæ¨¡ä¸ç¡®å®šæ€§ï¼›å¼•å…¥å˜åˆ†ä¿¡æ¯ç“¶é¢ˆæŠ‘åˆ¶è¿‡åº¦è‡ªä¿¡ï¼ŒåŒæ—¶è®­ç»ƒæ—¶ä½¿ç”¨å¤šè§†è§’èƒ¸ç‰‡ç¼–ç ä¸å¤šç« èŠ‚æŠ¥å‘Šç¼–ç æä¾›æ›´ç»†ç²’åº¦ç›‘ç£ï¼Œæ¨ç†ä»…éœ€å•å¼ èƒ¸ç‰‡ä¸å•ä»½æŠ¥å‘Šã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨MIMIC-CXRä¸Šç›¸è¾ƒCLIPã€CXR-CLIPä¸PCME++ç­‰åŸºçº¿å–å¾—æ›´ä¼˜çš„åŒå‘æ£€ç´¢ä¸é›¶æ ·æœ¬åˆ†ç±»è¡¨ç°ï¼Œå¹¶åœ¨æ ¡å‡†ã€é£é™©-è¦†ç›–ã€é€‰æ‹©æ€§æ£€ç´¢å¯é æ€§åŠå¯¹ä¸´åºŠç›¸å…³æ‰°åŠ¨çš„é²æ£’æ€§æ–¹é¢æ˜¾è‘—æå‡ï¼Œè¡¨æ˜æ¦‚ç‡åŒ–å»ºæ¨¡èƒ½å¢å¼ºæ”¾å°„æ£€ç´¢ç³»ç»Ÿçš„å¯ä¿¡ä¸å®‰å…¨æ€§ã€‚

**å…³é”®è¯**ï¼šåŒ»å­¦è§†è§‰-è¯­è¨€æ¨¡å‹, èƒ¸éƒ¨Xå…‰, å½±åƒ-æŠ¥å‘Šæ£€ç´¢, åŒå‘æ£€ç´¢, æ¦‚ç‡åµŒå…¥, é«˜æ–¯åµŒå…¥, ä¸ç¡®å®šæ€§å»ºæ¨¡, æ¦‚ç‡å¯¹æ¯”å­¦ä¹ , å˜åˆ†ä¿¡æ¯ç“¶é¢ˆ, æ¨¡å‹æ ¡å‡†, é€‰æ‹©æ€§æ£€ç´¢, é›¶æ ·æœ¬åˆ†ç±»

**è¯„åˆ†**ï¼š28

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16019v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16019v1.pdf)

---

## cs.LG

## [8. Quantifying LLM Attention-Head Stability: Implications for Circuit Universality](https://arxiv.org/abs/2602.16740v1)

**ä½œè€…**ï¼šKaran Bali, Jack Stanley, Praneet Suresh ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

In mechanistic interpretability, recent work scrutinizes transformer "circuits" - sparse, mono or multi layer sub computations, that may reflect human understandable functions. Yet, these network circuits are rarely acid-tested for their stability across different instances of the same deep learning architecture. Without this, it remains unclear whether reported circuits emerge universally across labs or turn out to be idiosyncratic to a particular estimation instance, potentially limiting confidence in safety-critical settings. Here, we systematically study stability across-refits in increasingly complex transformer language models of various sizes. We quantify, layer by layer, how similarly attention heads learn representations across independently initialized training runs. Our rigorous experiments show that (1) middle-layer heads are the least stable yet the most representationally distinct; (2) deeper models exhibit stronger mid-depth divergence; (3) unstable heads in deeper layers become more functionally important than their peers from the same layer; (4) applying weight decay optimization substantially improves attention-head stability across random model initializations; and (5) the residual stream is comparatively stable. Our findings establish the cross-instance robustness of circuits as an essential yet underappreciated prerequisite for scalable oversight, drawing contours around possible white-box monitorability of AI systems.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡é‡åŒ–æ¯”è¾ƒåŒä¸€Transformeræ¶æ„åœ¨ä¸åŒéšæœºåˆå§‹åŒ–é‡è®­ä¸‹çš„æ³¨æ„åŠ›å¤´ä¸€è‡´æ€§ï¼Œå‘ç°ä¸­å±‚å¤´æœ€ä¸ç¨³å®šä½†æœ€â€œç‹¬ç‰¹â€ï¼Œä¸”æƒé‡è¡°å‡èƒ½æ˜¾è‘—æå‡è·¨å®ä¾‹ç¨³å®šæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæœºåˆ¶å¯è§£é‡Šæ€§å¸¸å®£ç§°å‘ç°å¯å¤ç”¨çš„â€œç”µè·¯â€(circuits)ï¼Œä½†å¾ˆå°‘æ£€éªŒè¿™äº›ç»“æ„åœ¨ä¸åŒè®­ç»ƒå®ä¾‹é—´æ˜¯å¦ç¨³å®šå¯å¤ç°ï¼›è‹¥ä¸ç¨³å®šï¼Œç™½ç›’ç›‘æ§ä¸å®‰å…¨ç»“è®ºå¯èƒ½åªå¯¹å•ä¸ªæ¨¡å‹å¶ç„¶æˆç«‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¯¹ä¸åŒè§„æ¨¡/æ·±åº¦çš„è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šæ¬¡ç‹¬ç«‹é‡è®­(refits)ï¼Œé€å±‚é‡åŒ–æ³¨æ„åŠ›å¤´åœ¨è¡¨ç¤ºå­¦ä¹ ä¸Šçš„ç›¸ä¼¼åº¦/å¯¹é½ç¨‹åº¦ï¼Œå¹¶åˆ†æä¸ç¨³å®šå¤´çš„åŠŸèƒ½é‡è¦æ€§ä¸æ®‹å·®æµ(residual stream)çš„ç¨³å®šæ€§ï¼ŒåŒæ—¶å¯¹æ¯”åŠ å…¥weight decayç­‰ä¼˜åŒ–å¯¹ç¨³å®šæ€§çš„å½±å“ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¸­é—´å±‚æ³¨æ„åŠ›å¤´è·¨å®ä¾‹æœ€ä¸ç¨³å®šä½†è¡¨å¾å·®å¼‚æœ€å¤§ï¼Œä¸”æ¨¡å‹è¶Šæ·±ä¸­å±‚åˆ†åŒ–è¶Šå¼ºï¼›æ·±å±‚ä¸­ä¸ç¨³å®šå¤´å¾€å¾€æ›´å…³é”®ï¼Œè€Œweight decayå¯æ˜¾è‘—æå‡æ³¨æ„åŠ›å¤´ç¨³å®šæ€§ï¼Œæ®‹å·®æµæ•´ä½“ç›¸å¯¹ç¨³å®šï¼Œæç¤ºâ€œç”µè·¯â€å¯å¤ç°æ€§åº”æˆä¸ºå¯æ‰©å±•ç›‘ç£çš„å‰ç½®æ¡ä»¶ã€‚

**å…³é”®è¯**ï¼šæœºåˆ¶å¯è§£é‡Šæ€§, æ³¨æ„åŠ›å¤´ç¨³å®šæ€§, è·¨é‡è®­ä¸€è‡´æ€§, è¡¨å¾ç›¸ä¼¼æ€§è¯„ä¼°, ä¸­å±‚è¡¨å¾åˆ†åŒ–, æ·±å±‚æ¨¡å‹åˆ†æ­§, æƒé‡è¡°å‡æ­£åˆ™åŒ–, æ®‹å·®æµç¨³å®šæ€§, ç™½ç›’å¯ç›‘æ§æ€§, å¯æ‰©å±•ç›‘ç£

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16740v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16740v1.pdf)

---

## [9. Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research](https://arxiv.org/abs/2602.16072v2)

**ä½œè€…**ï¼šChenda Duan, Yipeng Zhang, Sotaro Kanai ç­‰ 12 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, q-bio.NC  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\textbf{302 patients}$ and $\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at omni-ieeg.github.io/omni-ieeg.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šOmni-iEEGæ•´åˆå¤šæ¥æºæœ¯å‰é¢…å†…è„‘ç”µæ•°æ®ä¸ä¸“å®¶æ ‡æ³¨ï¼Œæä¾›å¤§è§„æ¨¡æ ‡å‡†åŒ–æ•°æ®é›†ä¸ä¸´åºŠç›¸å…³åŸºå‡†ä»»åŠ¡ä»¥æ¨åŠ¨å¯å¤ç°ã€å¯æ³›åŒ–çš„ç™«ç—«AIç ”ç©¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰iEEGç ”ç©¶å¤šä¾èµ–å•ä¸­å¿ƒæ•°æ®ï¼Œæ ¼å¼/å…ƒæ•°æ®ä¸ä¸€è‡´ä¸”ç¼ºå°‘æ ‡å‡†åŸºå‡†ä¸ç—…ç†äº‹ä»¶æ ‡æ³¨ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥å¤ç°ã€è·¨ä¸­å¿ƒéªŒè¯ä¸ä¸´åºŠè½¬åŒ–ã€‚ä¸´åºŠEZå®šä½ä»é«˜åº¦ä¾èµ–äººå·¥é˜…ç‰‡ï¼ŒäºŸéœ€è§„æ¨¡åŒ–ã€ç»“æ„åŒ–èµ„æºæ”¯æ’‘è‡ªåŠ¨åŒ–æ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…å¯¹å…¬å¼€iEEGèµ„æºè¿›è¡Œå¼‚æ„æ ¼å¼ä¸å…ƒæ•°æ®å¯¹é½ï¼Œæ„å»ºå«302ä¾‹æ‚£è€…ã€178å°æ—¶é«˜åˆ†è¾¨ç‡è®°å½•çš„Omni-iEEGï¼Œå¹¶ç”±è®¤è¯ç™«ç—«ä¸“å®¶ç»Ÿä¸€æ ¡éªŒä¸´åºŠå…ƒæ•°æ®ï¼ˆSOZã€åˆ‡é™¤åŒºã€æœ¯åç»“å±€ï¼‰ä¸36K+ç—…ç†äº‹ä»¶æ ‡æ³¨ã€‚åŸºäºä¸´åºŠå…ˆéªŒå®šä¹‰ç»Ÿä¸€è¯„æµ‹æŒ‡æ ‡ä¸åŸºå‡†ä»»åŠ¡ï¼Œå¹¶å±•ç¤ºé•¿ç‰‡æ®µç«¯åˆ°ç«¯å»ºæ¨¡åŠè·¨åŸŸé¢„è®­ç»ƒè¡¨å¾çš„å¯è¿ç§»æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šOmni-iEEGé€šè¿‡æ ‡å‡†åŒ–æ•°æ®ã€ä¸°å¯Œä¸´åºŠå…ƒä¿¡æ¯å’Œå¤§è§„æ¨¡ä¸“å®¶æ ‡æ³¨ï¼Œæ˜¾è‘—é™ä½è·¨æ•°æ®æºç ”ç©¶é—¨æ§›å¹¶æå‡è¯„æµ‹ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜åœ¨ä¸´åºŠè®¾å®šä¸‹å¯ç³»ç»Ÿæ¯”è¾ƒæ¨¡å‹ï¼Œä¸”é•¿ç¨‹å»ºæ¨¡ä¸è·¨åŸŸé¢„è®­ç»ƒå¯¹iEEGä»»åŠ¡å…·æœ‰æ½œåŠ›ï¼Œä¸ºæ›´å…·ä¸´åºŠå¯è¯‘æ€§çš„ç™«ç—«ç ”ç©¶å¥ å®šåŸºç¡€ã€‚

**å…³é”®è¯**ï¼šé¢…å†…è„‘ç”µï¼ˆiEEGï¼‰, ç™«ç—«æ‰‹æœ¯è¯„ä¼°, è‡´ç—«åŒºå®šä½, å‘ä½œèµ·å§‹åŒºï¼ˆSOZï¼‰, ç—…ç†äº‹ä»¶æ ‡æ³¨, ä¸´åºŠå…ƒæ•°æ®æ ‡å‡†åŒ–, è·¨ä¸­å¿ƒæ•°æ®æ•´åˆ, ç™«ç—«ç”Ÿç‰©æ ‡å¿—ç‰©, ç»Ÿä¸€è¯„æµ‹åŸºå‡†, é•¿æ—¶åºç«¯åˆ°ç«¯å»ºæ¨¡, è¿ç§»å­¦ä¹ é¢„è®­ç»ƒè¡¨å¾

**è¯„åˆ†**ï¼š38

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16072v2) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16072v2.pdf)

---

## [10. Real-time Secondary Crash Likelihood Prediction Excluding Post Primary Crash Features](https://arxiv.org/abs/2602.16739v1)

**ä½œè€…**ï¼šLei Han, Mohamed Abdel-Aty, Zubayer Islam ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Secondary crash likelihood prediction is a critical component of an active traffic management system to mitigate congestion and adverse impacts caused by secondary crashes. However, existing approaches mainly rely on post-crash features (e.g., crash type and severity) that are rarely available in real time, limiting their practical applicability. To address this limitation, we propose a hybrid secondary crash likelihood prediction framework that does not depend on post-crash features. A dynamic spatiotemporal window is designed to extract real-time traffic flow and environmental features from primary crash locations and their upstream segments. The framework includes three models: a primary crash model to estimate the likelihood of secondary crash occurrence, and two secondary crash models to evaluate traffic conditions at crash and upstream segments under different comparative scenarios. An ensemble learning strategy integrating six machine learning algorithms is developed to enhance predictive performance, and a voting-based mechanism combines the outputs of the three models. Experiments on Florida freeways demonstrate that the proposed hybrid framework correctly identifies 91% of secondary crashes with a low false alarm rate of 0.20. The Area Under the ROC Curve improves from 0.654, 0.744, and 0.902 for the individual models to 0.952 for the hybrid model, outperforming previous studies.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§ä¸ä¾èµ–äº‹æ•…åç‰¹å¾çš„å®æ—¶äºŒæ¬¡äº‹æ•…é£é™©é¢„æµ‹æ··åˆæ¡†æ¶ï¼Œé€šè¿‡é›†æˆå­¦ä¹ ä¸æŠ•ç¥¨èåˆæ˜¾è‘—æå‡é¢„æµ‹æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰äºŒæ¬¡äº‹æ•…é¢„æµ‹å¤šä¾èµ–äº‹æ•…ç±»å‹ã€ä¸¥é‡åº¦ç­‰â€œäº‹åç‰¹å¾â€ï¼Œéš¾ä»¥åœ¨äº‹æ•…å‘ç”Ÿåç¬¬ä¸€æ—¶é—´è·å–ï¼Œå¯¼è‡´å®æ—¶åº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè®¾è®¡åŠ¨æ€æ—¶ç©ºçª—å£ï¼Œä»ä¸»äº‹æ•…ç‚¹åŠå…¶ä¸Šæ¸¸è·¯æ®µæå–å®æ—¶äº¤é€šæµä¸ç¯å¢ƒç‰¹å¾ï¼›æ„å»º1ä¸ªä¸»äº‹æ•…æ¨¡å‹+2ä¸ªäºŒæ¬¡äº‹æ•…æ¨¡å‹ï¼Œå¹¶ç”¨6ç§æœºå™¨å­¦ä¹ ç®—æ³•åšé›†æˆå­¦ä¹ ï¼Œæœ€åä»¥æŠ•ç¥¨æœºåˆ¶èåˆä¸‰æ¨¡å‹è¾“å‡ºã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ä½›ç½—é‡Œè¾¾é«˜é€Ÿå®éªŒä¸­ï¼Œæ··åˆæ¨¡å‹ä»¥0.20çš„è¾ƒä½è¯¯æŠ¥ç‡è¯†åˆ«å‡º91%çš„äºŒæ¬¡äº‹æ•…ï¼ŒAUCä»å•æ¨¡å‹çš„0.654/0.744/0.902æå‡è‡³0.952ï¼Œæ•´ä½“ä¼˜äºä»¥å¾€ç ”ç©¶ã€‚

**å…³é”®è¯**ï¼šäºŒæ¬¡äº‹æ•…é£é™©é¢„æµ‹, ä¸»åŠ¨äº¤é€šç®¡ç†, å®æ—¶é¢„æµ‹, åŠ¨æ€æ—¶ç©ºçª—å£, äº¤é€šæµç‰¹å¾, ç¯å¢ƒç‰¹å¾, ä¸Šæ¸¸è·¯æ®µåˆ†æ, äº‹åç‰¹å¾å‰”é™¤, é›†æˆå­¦ä¹ , æŠ•ç¥¨èåˆ, é«˜é€Ÿå…¬è·¯äº‹æ•…æ•°æ®

**è¯„åˆ†**ï¼š28

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16739v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16739v1.pdf)

---

## [11. Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated Recursive Training](https://arxiv.org/abs/2602.16065v1)

**ä½œè€…**ï¼šKevin Wang, Hongqian Niu, Didong Li  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, math.ST, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Generative Artificial Intelligence (AI), such as large language models (LLMs), has become a transformative force across science, industry, and society. As these systems grow in popularity, web data becomes increasingly interwoven with this AI-generated material and it is increasingly difficult to separate them from naturally generated content. As generative models are updated regularly, later models will inevitably be trained on mixtures of human-generated data and AI-generated data from earlier versions, creating a recursive training process with data contamination. Existing theoretical work has examined only highly simplified settings, where both the real data and the generative model are discrete or Gaussian, where it has been shown that such recursive training leads to model collapse. However, real data distributions are far more complex, and modern generative models are far more flexible than Gaussian and linear mechanisms. To fill this gap, we study recursive training in a general framework with minimal assumptions on the real data distribution and allow the underlying generative model to be a general universal approximator. In this framework, we show that contaminated recursive training still converges, with a convergence rate equal to the minimum of the baseline model's convergence rate and the fraction of real data used in each iteration. To the best of our knowledge, this is the first (positive) theoretical result on recursive training without distributional assumptions on the data. We further extend the analysis to settings where sampling bias is present in data collection and support all theoretical results with empirical studies.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡ç ”ç©¶ç”Ÿæˆæ¨¡å‹åœ¨â€œé€’å½’è®­ç»ƒ+æ•°æ®è¢«æ—§æ¨¡å‹ç”Ÿæˆå†…å®¹æ±¡æŸ“â€çš„ç°å®åœºæ™¯ä¸‹æ˜¯å¦ä»èƒ½ç¨³å®šå­¦ä¹ ï¼Œå¹¶ç»™å‡ºåœ¨æå¼±åˆ†å¸ƒå‡è®¾ä¸‹ä»å¯æ”¶æ•›çš„ç†è®ºä¿è¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€LLMç­‰ç”Ÿæˆå¼AIå†…å®¹æ¸—å…¥äº’è”ç½‘ï¼Œæ–°æ¨¡å‹è®­ç»ƒæ•°æ®ä¸å¯é¿å…æ··å…¥æ—§æ¨¡å‹ç”Ÿæˆæ–‡æœ¬ï¼Œæ—¢æœ‰ç†è®ºå¤šåœ¨ç¦»æ•£/é«˜æ–¯ç­‰ç®€åŒ–è®¾å®šä¸‹å¾—åˆ°â€œæ¨¡å‹å´©æºƒâ€ç»“è®ºï¼Œéš¾ä»¥è§£é‡ŠçœŸå®å¤æ‚åˆ†å¸ƒä¸å¼ºæ¨¡å‹èƒ½åŠ›ä¸‹çš„è¡Œä¸ºã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºä¸€ä¸ªå¯¹çœŸå®æ•°æ®åˆ†å¸ƒå‡ ä¹ä¸ä½œå‡è®¾ã€å¹¶å°†ç”Ÿæˆæ¨¡å‹è§†ä¸ºé€šç”¨é€¼è¿‘å™¨çš„é€’å½’è®­ç»ƒæ¡†æ¶ï¼›åˆ†ææ¯è½®æ··å…¥ä¸€å®šæ¯”ä¾‹çœŸå®æ•°æ®æ—¶çš„æ”¶æ•›æ€§ä¸é€Ÿç‡ï¼Œå¹¶è¿›ä¸€æ­¥æ‰©å±•åˆ°å­˜åœ¨é‡‡æ ·åå·®çš„æ•°æ®æ”¶é›†æƒ…å½¢ï¼ŒåŒæ—¶ç”¨å®éªŒéªŒè¯ç†è®ºç»“è®ºã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨è¯¥ä¸€èˆ¬æ¡†æ¶ä¸‹ï¼Œæ±¡æŸ“çš„é€’å½’è®­ç»ƒä¾ç„¶æ”¶æ•›ï¼Œå…¶æ”¶æ•›é€Ÿç‡ç”±â€œåŸºç¡€è®­ç»ƒç®—æ³•çš„é€Ÿç‡â€å’Œâ€œæ¯è½®çœŸå®æ•°æ®å æ¯”â€ä¸¤è€…çš„è¾ƒå°è€…å†³å®šï¼›æ­¤å¤–åœ¨å­˜åœ¨é‡‡æ ·åå·®æ—¶ä»å¯å¾—åˆ°ç›¸åº”çš„ç†è®ºä¿è¯ï¼Œå¹¶æœ‰å®éªŒæ”¯æŒã€‚

**å…³é”®è¯**ï¼šé€’å½’è®­ç»ƒ, æ•°æ®æ±¡æŸ“, åˆæˆæ•°æ®æ··å…¥, äººç±»æ•°æ®æ¯”ä¾‹, æ”¶æ•›æ€§ä¿è¯, æ”¶æ•›é€Ÿç‡åˆ†æ, åˆ†å¸ƒæ— å…³ç†è®º, æ¨¡å‹åå¡Œ, é‡‡æ ·åå·®

**è¯„åˆ†**ï¼š25

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16065v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16065v1.pdf)

---

## [12. Extracting and Analyzing Rail Crossing Behavior Signatures from Videos using Tensor Methods](https://arxiv.org/abs/2602.16057v2)

**ä½œè€…**ï¼šDawon Ahn, Het Patel, Aemal Khattak ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Railway crossings present complex safety challenges where driver behavior varies by location, time, and conditions. Traditional approaches analyze crossings individually, limiting the ability to identify shared behavioral patterns across locations. We propose a multi-view tensor decomposition framework that captures behavioral similarities across three temporal phases: Approach (warning activation to gate lowering), Waiting (gates down to train passage), and Clearance (train passage to gate raising). We analyze railway crossing videos from multiple locations using TimeSformer embeddings to represent each phase. By constructing phase-specific similarity matrices and applying non-negative symmetric CP decomposition, we discover latent behavioral components with distinct temporal signatures. Our tensor analysis reveals that crossing location appears to be a stronger determinant of behavior patterns than time of day, and that approach-phase behavior provides particularly discriminative signatures. Visualization of the learned component space confirms location-based clustering, with certain crossings forming distinct behavioral clusters. This automated framework enables scalable pattern discovery across multiple crossings, providing a foundation for grouping locations by behavioral similarity to inform targeted safety interventions.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§åŸºäºå¤šè§†è§’å¼ é‡åˆ†è§£çš„æ¡†æ¶ï¼Œä»å¤šåœ°ç‚¹é“è·¯é“å£è§†é¢‘ä¸­è‡ªåŠ¨æå–å¹¶æ¯”è¾ƒä¸‰é˜¶æ®µï¼ˆæ¥è¿‘/ç­‰å¾…/æ¸…ç©ºï¼‰çš„é©¾é©¶è¡Œä¸ºç­¾åï¼Œä»¥å‘ç°è·¨åœ°ç‚¹å…±äº«çš„æ½œåœ¨è¡Œä¸ºæ¨¡å¼ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿé“å£å®‰å…¨åˆ†æå¤šä¸ºé€ç‚¹ç ”ç©¶ï¼Œéš¾ä»¥ç³»ç»Ÿæ€§å‘ç°ä¸åŒåœ°ç‚¹ä¹‹é—´å¯è¿ç§»çš„å…±æ€§è¡Œä¸ºè§„å¾‹ï¼Œä»è€Œé™åˆ¶è§„æ¨¡åŒ–ã€é’ˆå¯¹æ€§çš„å®‰å…¨å¹²é¢„è®¾è®¡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†è§†é¢‘æŒ‰æ¥è¿‘ã€ç­‰å¾…ã€æ¸…ç©ºä¸‰é˜¶æ®µåˆ‡åˆ†ï¼Œå¹¶ç”¨TimeSformeræå–å„é˜¶æ®µåµŒå…¥è¡¨ç¤ºï¼›æ„å»ºé˜¶æ®µç‰¹å®šçš„ç›¸ä¼¼åº¦çŸ©é˜µåï¼Œé‡‡ç”¨éè´Ÿå¯¹ç§°CPå¼ é‡åˆ†è§£æŒ–æ˜å…·æœ‰æ—¶é—´é˜¶æ®µç­¾åçš„æ½œåœ¨è¡Œä¸ºç»„ä»¶ï¼Œå¹¶åœ¨ç»„ä»¶ç©ºé—´ä¸­å¯è§†åŒ–èšç±»å…³ç³»ã€‚

**ä¸»è¦ç»“è®º**ï¼šç»“æœæ˜¾ç¤ºé“å£â€œåœ°ç‚¹â€å¯¹è¡Œä¸ºæ¨¡å¼çš„å†³å®šæ€§å¼ºäºâ€œæ—¶é—´æ®µâ€ï¼Œä¸”æ¥è¿‘é˜¶æ®µçš„è¡Œä¸ºç‰¹å¾æœ€å…·åŒºåˆ†åº¦ï¼›å­¦ä¹ åˆ°çš„ç»„ä»¶ç©ºé—´å‘ˆç°æ˜æ˜¾çš„åŸºäºåœ°ç‚¹çš„èšç±»ï¼Œä¸€äº›é“å£å½¢æˆç‹¬ç‰¹çš„è¡Œä¸ºç°‡ï¼Œå¯ç”¨äºæŒ‰è¡Œä¸ºç›¸ä¼¼æ€§åˆ†ç»„ä»¥æ”¯æŒæ›´ç²¾å‡†çš„å®‰å…¨å¹²é¢„ã€‚

**å…³é”®è¯**ï¼šé“è·¯é“å£å®‰å…¨, é©¾é©¶è¡Œä¸ºåˆ†æ, è§†é¢‘è¡Œä¸ºç‰¹å¾, å¤šè§†è§’å¼ é‡åˆ†è§£, éè´Ÿå¯¹ç§°CPåˆ†è§£, ç›¸ä¼¼åº¦çŸ©é˜µæ„å»º, æ—¶åºé˜¶æ®µå»ºæ¨¡, æ½œåœ¨è¡Œä¸ºç»„ä»¶, ä½ç½®é©±åŠ¨èšç±»

**è¯„åˆ†**ï¼š26

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16057v2) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16057v2.pdf)

---

## [13. Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053v1)

**ä½œè€…**ï¼šMehrab Beikzadeh, Yasaman Asadollah Salmanpour, Ashima Suvarna ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºä¸€ç§é¢å‘ä¸ªæ€§åŒ–å¿ƒç†æ²»ç–—å¯¹è¯çš„å¤šç›®æ ‡å¯¹é½æ¡†æ¶ï¼ˆMODPOï¼‰ï¼Œåœ¨åŒä¸€æ¨¡å‹ä¸­æ›´å¥½åœ°å¹³è¡¡åŒç†å¿ƒä¸ä¸´åºŠå®‰å…¨ç­‰å¤šé¡¹æ²»ç–—ç›®æ ‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¯¹é½æ–¹æ³•å¤šå°†åŒç†å¿ƒã€å®‰å…¨ç­‰ç›®æ ‡åˆ†å¼€å•ç‹¬ä¼˜åŒ–ï¼Œå®¹æ˜“å‡ºç°â€œé«˜åŒç†å¿ƒä½†ä½å®‰å…¨â€ç­‰å¤±è¡¡ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³æ‚£è€…åå¥½ä¸ä¸´åºŠçº¦æŸã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¯¹335åæœ‰å¿ƒç†å¥åº·ç»å†çš„å—è®¿è€…æ”¶é›†å¤šç»´åº¦åå¥½æ’åºï¼Œåˆ†åˆ«è®­ç»ƒæ¶µç›–åŒç†å¿ƒã€å®‰å…¨ã€ç§¯æå€¾å¬ã€è‡ªä¸»æ”¹å˜ã€ä¿¡ä»»/å…³ç³»ã€æ‚£è€…è‡ªä¸»æ€§å…­é¡¹æ ‡å‡†çš„å¥–åŠ±æ¨¡å‹ï¼Œå¹¶åŸºäºç›´æ¥åå¥½ä¼˜åŒ–æ„å»ºå¤šç›®æ ‡DPOï¼Œä¸å•ç›®æ ‡ä¼˜åŒ–ã€SFTå’Œå‚æ•°åˆå¹¶ç­‰æ–¹æ³•ç³»ç»Ÿå¯¹æ¯”ã€‚

**ä¸»è¦ç»“è®º**ï¼šå¤šç›®æ ‡DPOåœ¨åŒç†å¿ƒä¸å®‰å…¨ç­‰æŒ‡æ ‡ä¸Šå–å¾—æ›´å‡è¡¡çš„ç»“æœï¼ˆå¦‚77.6%åŒç†å¿ƒã€62.6%å®‰å…¨ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå•ç›®æ ‡ä¼˜åŒ–çš„å¤±è¡¡è¡¨ç°ï¼›ä»¥â€œæ²»ç–—ç»´åº¦â€å¯¹é½æ¯”é€šç”¨æ²Ÿé€šåŸåˆ™æå‡çº¦17.2%ï¼Œä¸”ç›²æµ‹ä¸´åºŠåŒ»ç”Ÿæ›´åå¥½MODPOï¼ŒLLMè¯„ä¼°å™¨ä¸åŒ»ç”Ÿä¸€è‡´æ€§æ¥è¿‘åŒ»ç”Ÿé—´ä¸€è‡´æ€§ã€‚

**å…³é”®è¯**ï¼šå¤šç›®æ ‡å¯¹é½, ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰, å¥–åŠ±æ¨¡å‹, åå¥½å­¦ä¹ , å¿ƒç†æ²»ç–—å¯¹è¯, ä¸ªæ€§åŒ–å¿ƒç†å¥åº·, ä¸´åºŠå®‰å…¨, ä¸»åŠ¨å€¾å¬, æ‚£è€…è‡ªä¸»æ€§, ä¸´åºŠè¯„æµ‹ä¸€è‡´æ€§

**è¯„åˆ†**ï¼š44

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16053v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16053v1.pdf)

---

## [14. AI-CARE: Carbon-Aware Reporting Evaluation Metric for AI Models](https://arxiv.org/abs/2602.16042v2)

**ä½œè€…**ï¼šKC Santosh, Srikanth Baride, Rodrigue Rizk  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

As machine learning (ML) continues its rapid expansion, the environmental cost of model training and inference has become a critical societal concern. Existing benchmarks overwhelmingly focus on standard performance metrics such as accuracy, BLEU, or mAP, while largely ignoring energy consumption and carbon emissions. This single-objective evaluation paradigm is increasingly misaligned with the practical requirements of large-scale deployment, particularly in energy-constrained environments such as mobile devices, developing regions, and climate-aware enterprises. In this paper, we propose AI-CARE, an evaluation tool for reporting energy consumption, and carbon emissions of ML models. In addition, we introduce the carbon-performance tradeoff curve, an interpretable tool that visualizes the Pareto frontier between performance and carbon cost. We demonstrate, through theoretical analysis and empirical validation on representative ML workloads, that carbon-aware benchmarking changes the relative ranking of models and encourages architectures that are simultaneously accurate and environmentally responsible. Our proposal aims to shift the research community toward transparent, multi-objective evaluation and align ML progress with global sustainability goals. The tool and documentation are available at https://github.com/USD-AI-ResearchLab/ai-care.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šAI-CARE æå‡ºä¸€ç§å°†èƒ½è€—ä¸ç¢³æ’çº³å…¥æ¨¡å‹è¯„æµ‹ä¸æŠ¥å‘Šçš„å·¥å…·ï¼Œå¹¶ç”¨â€œç¢³-æ€§èƒ½æƒè¡¡æ›²çº¿â€å±•ç¤ºæ€§èƒ½ä¸ç¢³æˆæœ¬çš„å¸•ç´¯æ‰˜æœ€ä¼˜å…³ç³»ï¼Œæ¨åŠ¨å¤šç›®æ ‡å¯æŒç»­è¯„ä¼°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰ ML åŸºå‡†ä¸»è¦å…³æ³¨å‡†ç¡®ç‡ç­‰å•ä¸€æ€§èƒ½æŒ‡æ ‡ï¼Œå¿½è§†è®­ç»ƒ/æ¨ç†çš„èƒ½è€—ä¸ç¢³æ’ï¼Œå¯¼è‡´åœ¨èƒ½æºå—é™æˆ–å¼ºè°ƒæ°”å€™è´£ä»»çš„çœŸå®éƒ¨ç½²åœºæ™¯ä¸­è¯„ä¼°å¤±çœŸã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…è®¾è®¡ AI-CARE ç”¨äºç»Ÿä¸€è®°å½•ä¸æŠ¥å‘Šæ¨¡å‹çš„èƒ½è€—å’Œç¢³æ’ï¼Œå¹¶æå‡ºç¢³-æ€§èƒ½æƒè¡¡æ›²çº¿ä»¥å¯è§†åŒ–æ€§èƒ½ä¸ç¢³æˆæœ¬çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼Œä»è€Œè¿›è¡Œç¢³æ„ŸçŸ¥çš„æ¨¡å‹å¯¹æ¯”ä¸æ’åã€‚

**ä¸»è¦ç»“è®º**ï¼šç†è®ºä¸å®éªŒè¡¨æ˜ï¼Œå¼•å…¥ç¢³æ„ŸçŸ¥åŸºå‡†ä¼šæ”¹å˜æ¨¡å‹ç›¸å¯¹æ’åï¼Œå¹¶æ¿€åŠ±åŒæ—¶å…¼é¡¾å‡†ç¡®æ€§ä¸ç¯å¢ƒè´£ä»»çš„æ¶æ„é€‰æ‹©ï¼Œä»è€Œä¿ƒä½¿ç¤¾åŒºèµ°å‘é€æ˜çš„å¤šç›®æ ‡è¯„ä¼°ã€‚

**å…³é”®è¯**ï¼šç¢³æ„ŸçŸ¥è¯„æµ‹, èƒ½è€—è®¡é‡, ç¢³æ’æ”¾æ ¸ç®—, å¤šç›®æ ‡è¯„ä¼°, å¸•ç´¯æ‰˜å‰æ²¿, æ€§èƒ½-ç¢³æƒè¡¡æ›²çº¿, æ¨¡å‹åŸºå‡†æµ‹è¯•, ç»¿è‰²AI, è®­ç»ƒä¸æ¨ç†æˆæœ¬, æ¨¡å‹æ’åé‡è¯„ä¼°

**è¯„åˆ†**ï¼š29

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16042v2) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16042v2.pdf)

---

## [15. MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching](https://arxiv.org/abs/2602.16020v1)

**ä½œè€…**ï¼šCheng Zeng, Harry W. Sullivan, Thomas Egg ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cond-mat.mtrl-sci  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-17

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Molecular crystal structure prediction represents a grand challenge in computational chemistry due to large sizes of constituent molecules and complex intra- and intermolecular interactions. While generative modeling has revolutionized structure discovery for molecules, inorganic solids, and metal-organic frameworks, extending such approaches to fully periodic molecular crystals is still elusive. Here, we present MolCrystalFlow, a flow-based generative model for molecular crystal structure prediction. The framework disentangles intramolecular complexity from intermolecular packing by embedding molecules as rigid bodies and jointly learning the lattice matrix, molecular orientations, and centroid positions. Centroids and orientations are represented on their native Riemannian manifolds, allowing geodesic flow construction and graph neural network operations that respects geometric symmetries. We benchmark our model against state-of-the-art generative models for large-size periodic crystals and rule-based structure generation methods on two open-source molecular crystal datasets. We demonstrate an integration of MolCrystalFlow model with universal machine learning potential to accelerate molecular crystal structure prediction, paving the way for data-driven generative discovery of molecular crystals.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMolCrystalFlow æå‡ºä¸€ç§åŸºäºæµåŒ¹é…çš„ç”Ÿæˆæ¨¡å‹ï¼Œå°†åˆ†å­è§†ä½œåˆšä½“å¹¶è”åˆç”Ÿæˆæ™¶æ ¼ä¸åˆ†å­å †ç§¯ï¼Œä»è€Œå®ç°å‘¨æœŸæ€§åˆ†å­æ™¶ä½“ç»“æ„é¢„æµ‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåˆ†å­æ™¶ä½“ç»“æ„é¢„æµ‹å› åˆ†å­å°ºå¯¸å¤§ã€åˆ†å­å†…/åˆ†å­é—´ç›¸äº’ä½œç”¨å¤æ‚è€Œå›°éš¾ï¼Œç°æœ‰ç”Ÿæˆæ¨¡å‹éš¾ä»¥ç›´æ¥æ‰©å±•åˆ°å®Œå…¨å‘¨æœŸçš„åˆ†å­æ™¶ä½“ã€‚ä½œè€…å¸Œæœ›ç”¨æ•°æ®é©±åŠ¨çš„ç”Ÿæˆå¼æ–¹æ³•ï¼Œåœ¨ä¿æŒå‡ ä½•å¯¹ç§°ä¸å‘¨æœŸæ€§çš„å‰æä¸‹é«˜æ•ˆæ¢ç´¢å¯è¡Œæ™¶ä½“ç»“æ„ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†åˆ†å­å†…è‡ªç”±åº¦ä¸åˆ†å­é—´å †ç§¯åˆ†ç¦»ï¼šæŠŠæ¯ä¸ªåˆ†å­åµŒå…¥ä¸ºåˆšä½“ï¼Œè”åˆå­¦ä¹ æ™¶æ ¼çŸ©é˜µã€åˆ†å­å–å‘å’Œè´¨å¿ƒä½ç½®ï¼›å¹¶åœ¨è´¨å¿ƒ/å–å‘çš„åŸç”Ÿé»æ›¼æµå½¢ä¸Šæ„é€ æµ‹åœ°â€œæµåŒ¹é…â€ï¼Œç»“åˆå›¾ç¥ç»ç½‘ç»œè¿›è¡Œæ»¡è¶³å¯¹ç§°æ€§çš„ç­‰å˜å»ºæ¨¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ä¸¤ä¸ªå¼€æºåˆ†å­æ™¶ä½“æ•°æ®é›†ä¸Šï¼ŒMolCrystalFlow ç›¸æ¯”ç°æœ‰ç”Ÿæˆæ¨¡å‹ä¸è§„åˆ™æ³•è¡¨ç°æ›´ä¼˜ï¼›ä¸é€šç”¨æœºå™¨å­¦ä¹ åŠ¿èƒ½ç»“åˆå¯åŠ é€Ÿç»“æ„é¢„æµ‹æµç¨‹ï¼Œå±•ç¤ºäº†ç”¨äºåˆ†å­æ™¶ä½“ç”Ÿæˆå‘ç°çš„å¯è¡Œè·¯å¾„ã€‚

**å…³é”®è¯**ï¼šåˆ†å­æ™¶ä½“ç»“æ„é¢„æµ‹, å‘¨æœŸæ€§æ™¶ä½“ç”Ÿæˆ, æµåŒ¹é…ç”Ÿæˆæ¨¡å‹, æµå¼ç”Ÿæˆå»ºæ¨¡, åˆšä½“åˆ†å­åµŒå…¥, æ™¶æ ¼çŸ©é˜µå­¦ä¹ , åˆ†å­å–å‘å»ºæ¨¡, è´¨å¿ƒä½ç½®å»ºæ¨¡, é»æ›¼æµå½¢è¡¨ç¤º, æµ‹åœ°æµæ„é€ , å›¾ç¥ç»ç½‘ç»œ, æœºå™¨å­¦ä¹ åŠ¿èƒ½

**è¯„åˆ†**ï¼š29

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.16020v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.16020v1.pdf)

---

