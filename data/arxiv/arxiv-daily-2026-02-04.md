# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-04

> å…± 30 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (17 ç¯‡)
- [cs.CV](#csCV) (7 ç¯‡)
- [cs.CL](#csCL) (3 ç¯‡)
- [cs.AI](#csAI) (3 ç¯‡)

---

## cs.AI

## [1. Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837v1)

**ä½œè€…**ï¼šZhaotian Weng, Antonis Antoniades, Deepak Nathani ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¾¤ä½“è¿›åŒ–ä»£ç†ï¼ˆGEAï¼‰æ¡†æ¶ï¼Œé€šè¿‡ç»éªŒå…±äº«å®ç°å¼€æ”¾å¼è‡ªæˆ‘æ”¹è¿›ï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰è‡ªæˆ‘è¿›åŒ–ä»£ç†å—é™äºé¢„å®šä¹‰æ¶æ„ï¼Œæ— æ³•é«˜æ•ˆåˆ©ç”¨æ¢ç´¢å¤šæ ·æ€§ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°æ–¹æ³•ä»¥ä¿ƒè¿›è‡ªä¸»è¿›åŒ–å’Œèƒ½åŠ›æå‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šGEAå°†ä»£ç†è§†ä¸ºåŸºæœ¬çš„è¿›åŒ–å•å…ƒï¼Œé€šè¿‡ç¾¤ä½“å†…çš„æ˜¾æ€§ç»éªŒå…±äº«å’Œé‡ç”¨ï¼Œå…‹æœäº†æ ‘çŠ¶è¿›åŒ–ç»“æ„çš„å±€é™æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šGEAåœ¨å¤šä¸ªç¼–ç åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å°†æ—©æœŸæ¢ç´¢å¤šæ ·æ€§è½¬åŒ–ä¸ºé•¿æœŸè¿›å±•ï¼Œå¹¶åœ¨ä¸åŒç¼–ç æ¨¡å‹ä¸­å±•ç¤ºå‡ºæ›´å¼ºçš„è½¬ç§»æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è¯**ï¼šè‡ªæˆ‘æ”¹è¿›, ä»£ç†, ç»éªŒå…±äº«, è¿›åŒ–, æœºå™¨å­¦ä¹ , ç¼–ç åŸºå‡†, ç»“æ„è®¾è®¡, è¿›åŒ–å•å…ƒ, æ€§èƒ½æå‡, GEA, agent

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04837v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04837v1.pdf)

---

## [2. Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836v1)

**ä½œè€…**ï¼šHaosen Ge, Hamsa Bastani, Osbert Bastani  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡è´¨ç–‘AIèƒ½åŠ›æ˜¯å¦å‘ˆæŒ‡æ•°å¢é•¿ï¼Œæå‡ºç°æœ‰æ•°æ®æ”¯æŒçš„æ¨¡å‹ä¸METRæŠ¥å‘Šä¸åŒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€AIèƒ½åŠ›çš„å¿«é€Ÿæå‡ï¼Œç†è§£å…¶å¢é•¿æ¨¡å¼å¯¹å®‰å…¨æ€§å’ŒåŠ³åŠ¨åŠ›å¸‚åœºå…·æœ‰é‡è¦æ„ä¹‰ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæœ¬æ–‡é‡‡ç”¨æ‹Ÿåˆsigmoidæ›²çº¿çš„æ–¹æ³•ï¼Œåˆ†æAIèƒ½åŠ›çš„åŸºç¡€ä¸æ¨ç†èƒ½åŠ›ï¼Œå¹¶æå‡ºæ›´å¤æ‚çš„æ¨¡å‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜AIèƒ½åŠ›çš„æ‹ç‚¹å·²è¿‡å»ï¼Œæœªæ¥å°†è¡¨ç°å‡ºä¸åŒçš„å¢é•¿æ¨¡å¼ï¼Œç°æœ‰çš„æŒ‡æ•°å¢é•¿é¢„æµ‹å­˜åœ¨è„†å¼±æ€§ã€‚

**å…³é”®è¯**ï¼šAIèƒ½åŠ›, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, æ¨¡å‹è¯„ä¼°, åŠ³åŠ¨åŠ›å¸‚åœº, å®‰å…¨æ€§é—®é¢˜, æ¨ç†èƒ½åŠ›, å¤æ‚æ¨¡å‹, é¢„æµ‹æ¨¡å‹

**è¯„åˆ†**ï¼š42

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04836v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04836v1.pdf)

---

## [3. Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813v1)

**ä½œè€…**ï¼šShubham Vatsal, Harsh Dubey, Aditi Singh  
**åˆ†ç±»**ï¼šcs.AI, cs.CY  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸ƒç»´åˆ†ç±»æ³•ï¼Œç”¨äºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ»ç–—ä¿å¥ä»£ç†çš„èƒ½åŠ›ï¼Œæ­ç¤ºäº†å½“å‰æ–‡çŒ®ä¸­çš„èƒ½åŠ›ä¸å‡è¡¡ç°è±¡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å·²æœ‰ç ”ç©¶æ˜¾ç¤ºLLMä»£ç†åœ¨åŒ»ç–—é¢†åŸŸçš„å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥ç³»ç»Ÿè¯„ä¼°å…¶èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å›é¡¾49é¡¹ç ”ç©¶ï¼Œä½¿ç”¨ä¸ƒç»´åˆ†ç±»æ³•å¯¹èƒ½åŠ›è¿›è¡Œé‡åŒ–åˆ†æï¼Œå¹¶è¿ç”¨æ˜ç¡®çš„çº³å…¥å’Œæ’é™¤æ ‡å‡†åŠæ ‡ç­¾è§„åˆ™è¿›è¡Œæ˜ å°„ã€‚

**ä¸»è¦ç»“è®º**ï¼šåˆ†æç»“æœæ˜¾ç¤ºï¼ŒçŸ¥è¯†ç®¡ç†ä¸­çš„å¤–éƒ¨çŸ¥è¯†æ•´åˆè¾ƒä¸ºå¸¸è§ï¼Œè€Œé€‚åº”ä¸å­¦ä¹ ä¸­çš„æ¼‚ç§»æ£€æµ‹å’Œç¼“è§£åˆ™æä¸ºç¨€ç¼ºï¼Œæ•´ä½“ä¸Šä¿¡æ¯ä¸­å¿ƒèƒ½åŠ›åœ¨æ ¸å¿ƒä»»åŠ¡ä¸­å ä¸»å¯¼åœ°ä½ã€‚

**å…³é”®è¯**ï¼šæ™ºèƒ½ä»£ç†, å¤§è¯­è¨€æ¨¡å‹, åŒ»ç–—, çŸ¥è¯†ç®¡ç†, äº¤äº’æ¨¡å¼, è‡ªé€‚åº”å­¦ä¹ , å¤šä»£ç†è®¾è®¡, ä¿¡æ¯ä¸­å¿ƒèƒ½åŠ›, ä»»åŠ¡è§„åˆ’, llm

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04813v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04813v1.pdf)

---

## cs.CL

## [4. CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation](https://arxiv.org/abs/2602.04856v1)

**ä½œè€…**ï¼šZhao Tong, Chunlin Gong, Yiping Zhang ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake news generation, even when a model rejects a harmful request, its Chain-of-Thought (CoT) reasoning may still internally contain and propagate unsafe narratives. To analyze this phenomenon, we introduce a unified safety-analysis framework that systematically deconstructs CoT generation across model layers and evaluates the role of individual attention heads through Jacobian-based spectral metrics. Within this framework, we introduce three interpretable measures: stability, geometry, and energy to quantify how specific attention heads respond or embed deceptive reasoning patterns. Extensive experiments on multiple reasoning-oriented LLMs show that the generation risk rise significantly when the thinking mode is activated, where the critical routing decisions concentrated in only a few contiguous mid-depth layers. By precisely identifying the attention heads responsible for this divergence, our work challenges the assumption that refusal implies safety and provides a new understanding perspective for mitigating latent reasoning risks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå‡æ–°é—»æ—¶ï¼Œå³ä½¿æ‹’ç»æœ‰å®³è¯·æ±‚ï¼Œå…¶æ€ç»´é“¾æ¨ç†ä»å¯èƒ½ä¼ æ’­ä¸å®‰å…¨çš„å™äº‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶è€…è´¨ç–‘ä¼ ç»Ÿå‡è®¾ï¼Œå³æ‹’ç»å“åº”å¯ä»¥ä¿è¯æ•´ä¸ªè¿‡ç¨‹çš„å®‰å…¨æ¨ç†ï¼Œç‰¹åˆ«æ˜¯åœ¨å‡æ–°é—»ç”Ÿæˆçš„èƒŒæ™¯ä¸‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºä¸€ä¸ªç»Ÿä¸€çš„å®‰å…¨åˆ†ææ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°è§£æ„æ€ç»´é“¾ç”Ÿæˆï¼Œå¹¶é€šè¿‡é›…å¯æ¯”è°±åº¦é‡è¯„ä¼°ä¸ªåˆ«æ³¨æ„åŠ›å¤´çš„ä½œç”¨ï¼Œä½¿ç”¨ç¨³å®šæ€§ã€å‡ ä½•å’Œèƒ½é‡ç­‰å¯è§£é‡Šæ€§åº¦é‡æ¥é‡åŒ–æ¬ºéª—æ€§æ¨ç†æ¨¡å¼çš„åµŒå…¥ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜ï¼Œæ€ç»´æ¨¡å¼æ¿€æ´»æ—¶ç”Ÿæˆé£é™©æ˜¾è‘—ä¸Šå‡ï¼Œå…³é”®çš„è·¯ç”±å†³ç­–é›†ä¸­åœ¨å°‘æ•°ä¸­å±‚ï¼ŒæŒ‘æˆ˜äº†æ‹’ç»å³å®‰å…¨çš„å‡è®¾ï¼Œå¹¶ä¸ºå‡è½»æ½œåœ¨æ¨ç†é£é™©æä¾›äº†æ–°è§†è§’ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ¨¡å‹, å¤§è¯­è¨€æ¨¡å‹, ç”Ÿæˆæ–°é—», é€»è¾‘æ¨ç†, æ³¨æ„åŠ›æœºåˆ¶, å®‰å…¨åˆ†æ, Chain-of-Thought, æ¨¡å‹å±‚çº§, åå‘ä¼ æ’­, é£é™©è¯„ä¼°

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04856v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04856v1.pdf)

---

## [5. Decomposed Prompting Does Not Fix Knowledge Gaps, But Helps Models Say "I Don't Know"](https://arxiv.org/abs/2602.04853v1)

**ä½œè€…**ï¼šDhruv Madhwal, Lyuxin David Zhang, Dan Roth ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language models often struggle to recognize their knowledge limits in closed-book question answering, leading to confident hallucinations. While decomposed prompting is typically used to improve accuracy, we investigate its impact on reliability. We evaluate three task-equivalent prompting regimes: Direct, Assistive, and Incremental, across different model scales and multi-hop QA benchmarks. We find that although accuracy gains from decomposition diminish in frontier models, disagreements between prompting regimes remain highly indicative of potential errors. Because factual knowledge is stable while hallucinations are stochastic, cross-regime agreement provides a precise signal of internal uncertainty. We leverage this signal to implement a training-free abstention policy that requires no retrieval or fine-tuning. Our results show that disagreement-based abstention outperforms standard uncertainty baselines as an error detector, improving both F1 and AUROC across settings. This demonstrates that decomposition-based prompting can serve as a practical diagnostic probe for model reliability in closed-book QA.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šåˆ†è§£æç¤ºå¹¶ä¸èƒ½è§£å†³çŸ¥è¯†ç¼ºå£ï¼Œä½†èƒ½å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°è¡¨è¾¾ä¸ç¡®å®šæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨é—­å·é—®ç­”ä¸­å¸¸å¸¸æ— æ³•è¯†åˆ«çŸ¥è¯†çš„å±€é™æ€§ï¼Œå¯¼è‡´è‡ªä¿¡çš„è™šæ„å›ç­”ï¼Œå› æ­¤éœ€è¦æé«˜æ¨¡å‹çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶è¯„ä¼°äº†ç›´æ¥ã€è¾…åŠ©å’Œå¢é‡ä¸‰ç§ä»»åŠ¡ç­‰æ•ˆçš„æç¤ºæ–¹å¼ï¼Œåˆ†æå…¶å¯¹æ¨¡å‹å‡†ç¡®æ€§å’Œå†…éƒ¨ä¸ç¡®å®šæ€§çš„å½±å“ã€‚

**ä¸»è¦ç»“è®º**ï¼šåŸºäºä¸ä¸€è‡´æ€§çš„æ‹’ç»ç­–ç•¥åœ¨æ£€æµ‹é”™è¯¯ä¸Šä¼˜äºä¼ ç»Ÿçš„ä¸ç¡®å®šæ€§åŸºçº¿ï¼Œè¯æ˜äº†åˆ†è§£æç¤ºå¯ä»¥ä½œä¸ºæ¨¡å‹å¯é æ€§çš„æœ‰æ•ˆè¯Šæ–­å·¥å…·ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, çŸ¥è¯†é™åˆ¶, é—®ç­”, æç¤ºç­–ç•¥, å‡†ç¡®æ€§, å¯é æ€§, è®­ç»ƒ-free, ä¸ç¡®å®šæ€§, æ¨¡å‹è¯„ä¼°, multi-hop QA, rag

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04853v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04853v1.pdf)

---

## [6. SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization](https://arxiv.org/abs/2602.04811v1)

**ä½œè€…**ï¼šJiarui Yuan, Tailin Jin, Weize Chen ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring "Closed-Book Training" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSE-Benchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è‡ªæˆ‘è¿›åŒ–ä¸çŸ¥è¯†å†…åŒ–èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ç¯å¢ƒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨è§£å†³è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›è¯„ä¼°ä¸­çš„çŸ¥è¯†çº ç¼ å’Œæ¨ç†å¤æ‚æ€§é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å°†NumPyåº“æ··æ·†ä¸ºä¼ªæ–°åŒ…å¹¶éšæœºåŒ–æ ‡è¯†ç¬¦ï¼Œè®­ç»ƒä»£ç†åœ¨æ²¡æœ‰æ–‡æ¡£çš„æƒ…å†µä¸‹å®Œæˆç¼–ç ä»»åŠ¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶å‘ç°å…³é—­ä¹¦æœ¬è®­ç»ƒæ›´æœ‰æ•ˆï¼Œæ ‡å‡†å¼ºåŒ–å­¦ä¹ æ— æ³•å®Œå…¨å†…åŒ–æ–°çŸ¥è¯†ï¼Œè€Œè‡ªæˆ‘å¯¹å¼ˆç»“åˆSFTèƒ½å¤Ÿä¿ƒè¿›å†…åŒ–ã€‚

**å…³é”®è¯**ï¼šè‡ªæˆ‘è¿›åŒ–, çŸ¥è¯†å†…åŒ–, ä»£ç†, ç»ˆèº«å­¦ä¹ , è®­ç»ƒ, è¯„ä¼°, ç¼–ç ä»»åŠ¡, è‡ªæˆ‘ç”Ÿæˆä»»åŠ¡, SFT

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04811v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04811v1.pdf)

---

## cs.CV

## [7. CoWTracker: Tracking by Warping instead of Correlation](https://arxiv.org/abs/2602.04877v1)

**ä½œè€…**ï¼šZihang Lai, Eldar Insafutdinov, Edgar Sucar ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ç¨ å¯†ç‚¹è·Ÿè¸ªå™¨CoWTrackerï¼Œé€šè¿‡å˜å½¢è€Œéç›¸å…³æ€§åŒ¹é…æ¥æé«˜æ•ˆç‡å’Œæ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„ç¨ å¯†ç‚¹è·Ÿè¸ªæ–¹æ³•ä¾èµ–äºæˆæœ¬ä½“ç§¯ï¼Œå¯¼è‡´åœ¨ç©ºé—´åˆ†è¾¨ç‡ä¸‹çš„å¤æ‚åº¦è¿‡é«˜ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCoWTrackeré€šè¿‡åŸºäºå½“å‰ä¼°è®¡çš„å˜å½¢æ¥è¿­ä»£ç²¾ç‚¼è½¨è¿¹ä¼°è®¡ï¼Œå¹¶ç»“åˆå˜å‹å™¨æ¶æ„è¿›è¡Œè”åˆæ—¶ç©ºæ¨ç†ï¼Œä»¥å»ºç«‹é•¿è·ç¦»å¯¹åº”å…³ç³»ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¨¡å‹åœ¨æ ‡å‡†ç¨ å¯†ç‚¹è·Ÿè¸ªåŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒæ—¶åœ¨å…‰æµä¼°è®¡æ–¹é¢ä¹Ÿè¶…è¿‡äº†ä¸€äº›ä¸“é—¨çš„æ–¹æ³•ï¼Œæ˜¾ç¤ºäº†å˜å½¢æ¶æ„åœ¨è¿™ä¸¤ä¸ªé¢†åŸŸçš„ç»Ÿä¸€æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , è®¡ç®—æœºè§†è§‰, å˜æ¢å™¨, ç‰¹å¾åŒ¹é…, å…‰æµä¼°è®¡, dense point tracking, spatiotemporal reasoning, optical flow, è½¨è¿¹ä¼°è®¡, transformer

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04877v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04877v1.pdf)

---

## [8. PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation](https://arxiv.org/abs/2602.04876v1)

**ä½œè€…**ï¼šJiahao Zhan, Zizhang Li, Hong-Xing Yu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šPerpetualWonderæ˜¯ä¸€ä¸ªæ··åˆç”Ÿæˆæ¨¡æ‹Ÿå™¨ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆé•¿æœŸã€åŸºäºåŠ¨ä½œçš„4Dåœºæ™¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰æ–¹æ³•æ— æ³•å®ç°é•¿æœŸçš„ã€åŸºäºåŠ¨ä½œçš„åœºæ™¯ç”Ÿæˆï¼Œå› ä¸ºç‰©ç†çŠ¶æ€ä¸è§†è§‰è¡¨ç°è„±èŠ‚ï¼Œå½±å“åç»­äº¤äº’çš„ç”Ÿæˆä¼˜åŒ–ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šPerpetualWonderå¼•å…¥äº†é¦–ä¸ªçœŸæ­£çš„é—­ç¯ç³»ç»Ÿï¼Œé‡‡ç”¨ç»Ÿä¸€è¡¨ç¤ºæ³•å»ºç«‹ç‰©ç†çŠ¶æ€ä¸è§†è§‰åŸå§‹å…ƒç´ ä¹‹é—´çš„åŒå‘è”ç³»ï¼Œå¹¶é€šè¿‡å¤šè§†è§’ç›‘ç£æœºåˆ¶è§£å†³ä¼˜åŒ–æ¨¡ç³Šæ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼ŒPerpetualWonderèƒ½å¤Ÿä»å•ä¸€å›¾åƒæˆåŠŸæ¨¡æ‹Ÿå¤æ‚çš„å¤šæ­¥äº¤äº’ï¼Œä¿æŒç‰©ç†åˆç†æ€§å’Œè§†è§‰ä¸€è‡´æ€§ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ¨¡å‹, ç”Ÿæˆæ¨¡æ‹Ÿå™¨, é•¿æœŸé¢„æµ‹, 4Dåœºæ™¯ç”Ÿæˆ, ç‰©ç†çŠ¶æ€, è§†è§‰è¡¨ç¤º, åé¦ˆæœºåˆ¶, å¤šè§†è§’ç›‘ç£, äººæœºäº¤äº’, generative

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04876v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04876v1.pdf)

---

## [9. LitS: A novel Neighborhood Descriptor for Point Clouds](https://arxiv.org/abs/2602.04838v1)

**ä½œè€…**ï¼šJonatan B. Bastos, Francisco F. Rivera, Oscar G. Lorenzo ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é‚»åŸŸæè¿°ç¬¦LitSï¼Œç”¨äºå‡†ç¡®è¡¨å¾ç‚¹äº‘çš„å±€éƒ¨å‡ ä½•ç‰¹å¾ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€3Dæ‰«ææŠ€æœ¯çš„å‘å±•ï¼Œç‚¹äº‘åœ¨å¤šä¸ªç§‘å­¦å’ŒæŠ€æœ¯é¢†åŸŸä¸­å˜å¾—è‡³å…³é‡è¦ï¼Œåˆ†æè¿™äº›æ•°æ®éœ€è¦æœ‰æ•ˆçš„é‚»åŸŸæè¿°ç¬¦ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šLitSæ˜¯å•ä½åœ†ä¸Šçš„åˆ†æ®µå¸¸æ•°å‡½æ•°ï¼Œèƒ½å¤Ÿè®°å½•ç‚¹çš„å‘¨å›´ç¯å¢ƒï¼Œå¹¶é€šè¿‡è¯„ä¼°ç‰¹å®šæ–¹å‘çš„ä¿¡æ¯æ¥æ•æ‰é‚»åŸŸç‰¹å¾ã€‚

**ä¸»è¦ç»“è®º**ï¼šLitSæ˜¯ä¸€ç§çµæ´»çš„é‚»åŸŸæè¿°ç¬¦ï¼Œé€‚åº”å¤šç§ç‚¹äº‘ç±»å‹ï¼Œå¹¶èƒ½æœ‰æ•ˆå¤„ç†å¸¸è§çš„æ•°æ®é—®é¢˜ï¼Œå¦‚å¯†åº¦å˜åŒ–å’Œå™ªå£°ã€‚

**å…³é”®è¯**ï¼šç‚¹äº‘, é‚»åŸŸæè¿°ç¬¦, 3Dæ‰«æ, å‡ ä½•ç‰¹å¾, LitS, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , è¯­ä¹‰æœç´¢, è‡ªé€‚åº”ç®—æ³•, æ•°æ®åˆ†æ, rag

**è¯„åˆ†**ï¼š58

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04838v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04838v1.pdf)

---

## [10. Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization](https://arxiv.org/abs/2602.04820v1)

**ä½œè€…**ï¼šFarzia Hossain, Samanta Ghosh, Shahida Begum ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ çš„æŒ‡ç”²ç–¾ç—…åˆ†ç±»æ¨¡å‹ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒå’ŒSHAPå¯è§†åŒ–æå‡å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šäººç±»æŒ‡ç”²ç–¾ç—…åœ¨å„å¹´é¾„æ®µæ™®éå­˜åœ¨ï¼Œæ—©æœŸæ£€æµ‹ä¸å‡†ç¡®è¯Šæ–­å¯¹å¥åº·è‡³å…³é‡è¦ï¼Œä½†ç”±äºç–¾ç—…ç±»å‹é—´çš„è§†è§‰å·®å¼‚ï¼Œåˆ†ç±»ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å››ç§CNNæ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šé‡‡ç”¨å¯¹æŠ—è®­ç»ƒå¢å¼ºæ¨¡å‹é²æ£’æ€§ï¼ŒåŒæ—¶åˆ©ç”¨SHAPå¯è§†åŒ–é‡è¦ç‰¹å¾ä»¥å¢åŠ æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šInceptionV3æ¨¡å‹åœ¨æ‰€æœ‰æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡è¾¾åˆ°95.57%ï¼Œè¯¥ç³»ç»Ÿå¯ä¸ºåŒ»ç”Ÿæä¾›æœ‰æ•ˆæ”¯æŒï¼Œæé«˜æŒ‡ç”²ç–¾ç—…çš„è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , å·ç§¯ç¥ç»ç½‘ç»œ, è§†è§‰åˆ†ç±», å¯¹æŠ—è®­ç»ƒ, Grad-CAM, è‡ªåŠ¨åŒ–è¯Šæ–­, åŒ»å­¦å›¾åƒåˆ†æ, ç‰¹å¾é‡è¦æ€§, machine learning

**è¯„åˆ†**ï¼š52

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04820v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04820v1.pdf)

---

## [11. XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas](https://arxiv.org/abs/2602.04819v1)

**ä½œè€…**ï¼šAqsa Sultana, Rayan Afsar, Ahmed Rahu ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šXtraLight-MedMambaæ˜¯ä¸€ç§è¶…è½»é‡çº§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œèƒ½é«˜æ•ˆåˆ†ç±»è‚¿ç˜¤æ€§ç®¡è…ºç˜¤ï¼Œå‡†ç¡®ç‡è¾¾97.18%ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨å¸¸è§„ç»“è‚ é•œç­›æŸ¥ä¸­ï¼Œå‡†ç¡®è¯„ä¼°å‰ç™Œæ€§æ¯è‚‰çš„é£é™©å¯¹äºé™ä½ç»“ç›´è‚ ç™Œé£é™©è‡³å…³é‡è¦ï¼Œä½†ä½çº§åˆ«å¼‚å‹å¢ç”Ÿçš„ä¸»è§‚ç—…ç†è¯„ä¼°ä»å­˜åœ¨å±€é™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæœ¬ç ”ç©¶æå‡ºXtraLight-MedMambaæ¡†æ¶ï¼Œç»“åˆConvNextæµ…å±‚ç‰¹å¾æå–å™¨ä¸å¹¶è¡Œè§†è§‰Mambaï¼Œæœ‰æ•ˆå»ºæ¨¡é•¿çŸ­è·ç¦»ä¾èµ–ï¼Œé›†æˆç©ºé—´å’Œé€šé“æ³¨æ„åŠ›æ¨¡å—ä»¥å¢å¼ºå¤šå°ºåº¦ç‰¹å¾æå–ã€‚

**ä¸»è¦ç»“è®º**ï¼šXtraLight-MedMambaåœ¨ä½çº§åˆ«ç®¡è…ºç˜¤æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå˜å‹å™¨å’Œä¼ ç»ŸMambaæ¶æ„ï¼Œæ˜¾ç¤ºå‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œæ›´å°‘çš„å‚æ•°ä½¿ç”¨ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , æœºå™¨å­¦ä¹ , ç¥ç»ç½‘ç»œ, å›¾åƒåˆ†ç±», ä½çº§åˆ«è…ºç˜¤, é£é™©åˆ†å±‚, æ•°å­—ç—…ç†, ç‰¹å¾æå–, å¤šå°ºåº¦ç‰¹å¾, deep learning

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04819v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04819v1.pdf)

---

## [12. X2HDR: HDR Image Generation in a Perceptually Uniform Space](https://arxiv.org/abs/2602.04814v1)

**ä½œè€…**ï¼šRonghuan Wu, Wanchao Su, Kede Ma ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.GR  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing pretrained diffusion models can be easily adapted to HDR generation without retraining from scratch. A key challenge is that HDR images are natively represented in linear RGB, whose intensity and color statistics differ substantially from those of sRGB-encoded LDR images. This gap, however, can be effectively bridged by converting HDR inputs into perceptually uniform encodings (e.g., using PU21 or PQ). Empirically, we find that LDR-pretrained variational autoencoders (VAEs) reconstruct PU21-encoded HDR inputs with fidelity comparable to LDR data, whereas linear RGB inputs cause severe degradations. Motivated by this finding, we describe an efficient adaptation strategy that freezes the VAE and finetunes only the denoiser via low-rank adaptation in a perceptually uniform space. This results in a unified computational method that supports both text-to-HDR synthesis and single-image RAW-to-HDR reconstruction. Experiments demonstrate that our perceptually encoded adaptation consistently improves perceptual fidelity, text-image alignment, and effective dynamic range, relative to previous techniques.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡æ„ŸçŸ¥ç»Ÿä¸€ç©ºé—´å®ç°HDRå›¾åƒç”Ÿæˆçš„æ–°æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆæé«˜HDRç”Ÿæˆçš„è§†è§‰ä¿çœŸåº¦ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€HDRæ ¼å¼å’Œæ˜¾ç¤ºå±çš„æ™®åŠï¼Œç°æœ‰å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨HDRç”Ÿæˆä¸Šå—åˆ°å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„é™åˆ¶ï¼Œå› æ­¤éœ€è¦ä¸€ç§æœ‰æ•ˆçš„é€‚åº”ç­–ç•¥ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å°†HDRè¾“å…¥è½¬æ¢ä¸ºæ„ŸçŸ¥ç»Ÿä¸€ç¼–ç ï¼ˆå¦‚PU21æˆ–PQï¼‰ï¼Œå†»ç»“å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ï¼Œå¹¶ä»…å¾®è°ƒå»å™ªå™¨ï¼Œä»è€Œå®ç°LDRé¢„è®­ç»ƒæ¨¡å‹çš„HDRç”Ÿæˆé€‚åº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æ„ŸçŸ¥ä¿çœŸåº¦ã€æ–‡æœ¬ä¸å›¾åƒå¯¹é½åŠæœ‰æ•ˆåŠ¨æ€èŒƒå›´æ–¹é¢å‡ä¼˜äºä¹‹å‰çš„æŠ€æœ¯ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆå›¾åƒ, é«˜åŠ¨æ€èŒƒå›´, é¢„è®­ç»ƒæ¨¡å‹, è§†è§‰æ„ŸçŸ¥, ä½ç§©é€‚åº”, å›¾åƒé‡å»º, ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ, å˜åˆ†è‡ªç¼–ç å™¨, perceptually uniform encoding, diffusion

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04814v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04814v1.pdf)

---

## [13. Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention](https://arxiv.org/abs/2602.04789v1)

**ä½œè€…**ï¼šChengtao Lv, Yumeng Shi, Yushi Huang ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \textsc{Light Forcing}, the \textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, $1.2{\sim}1.3\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \textsc{Light Forcing} further achieves a $2.3\times$ speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at \href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åä¸ºLight Forcingçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æå‡è‡ªå›å½’è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„æ•ˆç‡å’Œè´¨é‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„ç¨€ç–æ³¨æ„åŠ›è§£å†³æ–¹æ¡ˆåœ¨è‡ªå›å½’æ¨¡å‹ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå¯¹ç”Ÿæˆå—çš„å­¤ç«‹è€ƒè™‘å’Œæœªå……åˆ†åˆ©ç”¨è¿‡å»ä¿¡æ¯çš„ä¸Šä¸‹æ–‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šLight Forcingå¼•å…¥äº†å—æ„ŸçŸ¥å¢é•¿æœºåˆ¶å’Œåˆ†å±‚ç¨€ç–æ³¨æ„åŠ›ç­–ç•¥ï¼Œä»¥å®šé‡ä¼°è®¡æ¯å—çš„è´¡çŒ®å¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç»§æ‰¿å…ˆå‰çš„çŸ¥è¯†ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒLight Forcingåœ¨ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ï¼Œå¹¶åœ¨RTX 5090 GPUä¸Šå®ç°äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚

**å…³é”®è¯**ï¼šç¨€ç–æ³¨æ„åŠ›, è‡ªå›å½’è§†é¢‘ç”Ÿæˆ, ç”Ÿæˆæ¨¡å‹, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ç»“æ„åŒ–ç¨€ç–, é€å±‚æ©ç é€‰æ‹©, é€Ÿåº¦æå‡, FP8é‡åŒ–, diffusion

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04789v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04789v1.pdf)

---

## cs.LG

## [14. Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883v1)

**ä½œè€…**ï¼šYanru Qu, Cheng-Yen Hsieh, Zaixiang Zheng ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, q-bio.BM, q-bio.QM  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åä¸ºè›‹ç™½è´¨è‡ªå›å½’å»ºæ¨¡ï¼ˆPARï¼‰çš„å¤šå°ºåº¦æ¡†æ¶ï¼Œç”¨äºè›‹ç™½è´¨éª¨æ¶çš„ç”Ÿæˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ›å…‰åå·®é—®é¢˜ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè›‹ç™½è´¨ç»“æ„ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œçµæ´»æ€§å¯¹äºç”Ÿç‰©å­¦å’Œè¯ç‰©è®¾è®¡è‡³å…³é‡è¦ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°çš„æ¡†æ¶æ¥æå‡ç»“æ„ç”Ÿæˆçš„è´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šPARæ¡†æ¶é€šè¿‡å¤šå°ºåº¦ä¸‹é‡‡æ ·ã€åŸºäºè‡ªå›å½’çš„å˜æ¢å™¨å’Œæµå¼è§£ç å™¨æ¥å®ç°è›‹ç™½è´¨éª¨æ¶çš„ç”Ÿæˆï¼ŒåŒæ—¶é‡‡ç”¨å™ªå£°ä¸Šä¸‹æ–‡å­¦ä¹ å’Œè°ƒåº¦é‡‡æ ·æ¥å…‹æœæ›å…‰åå·®ã€‚

**ä¸»è¦ç»“è®º**ï¼šPARåœ¨æ— æ¡ä»¶ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿå­¦ä¹ è›‹ç™½è´¨åˆ†å¸ƒå¹¶ç”Ÿæˆé«˜è´¨é‡çš„éª¨æ¶ï¼Œå±•ç¤ºå‡ºå¼ºå¤§çš„é›¶-shot æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºäººç±»æç¤ºçš„æ¡ä»¶ç”Ÿæˆã€‚

**å…³é”®è¯**ï¼šè›‹ç™½è´¨, è‡ªå›å½’æ¨¡å‹, å¤šå°ºåº¦, ç”Ÿæˆ, å˜æ¢å™¨, ç»“æ„ç”Ÿæˆ, æ¡ä»¶åµŒå…¥, è®­ç»ƒ, ç”Ÿæˆè´¨é‡, æ— ç›‘ç£å­¦ä¹ , transformer

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04883v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04883v1.pdf)

---

## [15. Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870v1)

**ä½œè€…**ï¼šChenwei Cui, Rockwell Jackson, Benjamin Joseph Herrera ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°æ¶æ„Multi-Head LatentMoEå’ŒHead Parallelï¼Œæ˜¾è‘—é™ä½äº†ç¨€ç–ä¸“å®¶æ¨¡å‹çš„é€šä¿¡æˆæœ¬å’Œä¸å¹³è¡¡é—®é¢˜ï¼ŒåŒæ—¶åŠ é€Ÿè®­ç»ƒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜ï¼Œç¨€ç–Mixture of Experts (MoE)é€šè¿‡æ¡ä»¶è®¡ç®—æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†ç°æœ‰çš„ä¸“å®¶å¹¶è¡Œæ–¹æ³•å­˜åœ¨é€šä¿¡æˆæœ¬å’Œè´Ÿè½½ä¸å¹³è¡¡ç­‰é™åˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†Multi-Head LatentMoEå’ŒHead Parallelæ¶æ„ï¼Œå®ç°äº†ä¸æ¿€æ´»ä¸“å®¶æ•°é‡æ— å…³çš„O(1)é€šä¿¡æˆæœ¬ï¼Œé‡‡ç”¨IOæ„ŸçŸ¥è·¯ç”±å’Œä¸“å®¶è®¡ç®—åŠ é€Ÿè®­ç»ƒã€‚

**ä¸»è¦ç»“è®º**ï¼šä¸ä¸“å®¶å¹¶è¡Œçš„MoEç›¸æ¯”ï¼ŒMulti-Head LatentMoEå’ŒHead Parallelè®­ç»ƒé€Ÿåº¦æé«˜äº†1.61å€ï¼Œä¸”åœ¨æ€§èƒ½ä¸Šä¿æŒä¸€è‡´ï¼Œä½¿å¤šäº¿å‚æ•°åŸºç¡€æ¨¡å‹çš„ç ”ç©¶æ›´åŠ å¯åŠã€‚

**å…³é”®è¯**ï¼šå¤šå¤´, LatentMoE, MoE, ä¸“å®¶å¹¶è¡Œ, è®­ç»ƒåŠ é€Ÿ, ç¨€ç–æ··åˆä¸“å®¶, è´Ÿè½½å‡è¡¡, ç¡®å®šæ€§é€šä¿¡, è¯­ä¹‰æœç´¢, æ·±åº¦å­¦ä¹ , agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04870v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04870v1.pdf)

---

## [16. CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868v1)

**ä½œè€…**ï¼šYannick Denker, Alexander Gepperth  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCRoSSæ˜¯ä¸€ä¸ªæ–°é¢–çš„æŒç»­å¼ºåŒ–å­¦ä¹ åŸºå‡†å¥—ä»¶ï¼Œä¸“ä¸ºå¤šä»»åŠ¡å’ŒçœŸå®ç‰©ç†æ¨¡æ‹Ÿçš„æœºå™¨äººè€Œè®¾è®¡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæŒç»­å¼ºåŒ–å­¦ä¹ éœ€è¦æ™ºèƒ½ä½“åœ¨å­¦ä¹ æ–°ä»»åŠ¡çš„åŒæ—¶ä¿æŒå¯¹å·²å­¦ç­–ç•¥çš„è®°å¿†ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªé«˜ä»»åŠ¡å¤šæ ·æ€§å’ŒçœŸå®ç‰©ç†æ¨¡æ‹Ÿçš„åŸºå‡†ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCRoSSåŸºäºGazeboæ¨¡æ‹Ÿå™¨ï¼Œåˆ©ç”¨ä¸¤ç§æœºå™¨äººå¹³å°ï¼ˆå·®åŠ¨é©±åŠ¨æœºå™¨äººå’Œä¸ƒå…³èŠ‚æœºæ¢°è‡‚ï¼‰è¿›è¡Œå¤šç§ä»»åŠ¡çš„è¯„ä¼°ï¼Œå¹¶æä¾›äº†æ˜“äºæ‰©å±•çš„å®¹å™¨åŒ–è®¾ç½®ä»¥ç¡®ä¿å¯å¤ç°æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šCRoSSä½œä¸ºä¸€ä¸ªå¯æ‰©å±•ä¸”å¯å¤ç°çš„åŸºå‡†ï¼Œé€‚åˆç”¨äºæœºå™¨äººé¢†åŸŸçš„æŒç»­å¼ºåŒ–å­¦ä¹ ç ”ç©¶ï¼Œæ”¯æŒå¤šç§ä¼ æ„Ÿå™¨çš„ä½¿ç”¨ã€‚

**å…³é”®è¯**ï¼šæŒç»­å­¦ä¹ , å¼ºåŒ–å­¦ä¹ , æœºå™¨äººæ¨¡æ‹Ÿ, ä»»åŠ¡å¤šæ ·æ€§, Gazebo, ä»£ç†, æ·±åº¦å­¦ä¹ , æ§åˆ¶ç®—æ³•, kinematics, ç‰©ç†ä»¿çœŸ, agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04868v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04868v1.pdf)

---

## [17. Subliminal Effects in Your Data: A General Mechanism via Log-Linearity](https://arxiv.org/abs/2602.04863v1)

**ä½œè€…**ï¼šIshaq Aden-Ali, Noah Golowich, Allen Liu ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CL, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.   We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡Logit-Linear-Selectionæ–¹æ³•æ­ç¤ºæ•°æ®é›†ä¸­éšå«çš„æ½œåœ¨æ•ˆåº”çš„æœºåˆ¶ï¼Œè¿›è€Œå½±å“å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡Œä¸ºã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒçš„å¤æ‚æ€§å¢åŠ ï¼Œç†è§£æ•°æ®é›†å¯¹æ¨¡å‹å±æ€§çš„å½±å“å˜å¾—è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®é›†ä¼ é€’ä¸å¯ç›´æ¥è§‚å¯Ÿä¿¡å·çš„æƒ…å†µä¸‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¼•å…¥Logit-Linear-Selectionï¼ˆLLSï¼‰æ–¹æ³•ï¼Œä»¥é€‰æ‹©é€šç”¨åå¥½æ•°æ®é›†çš„å­é›†ï¼Œä»è€Œå‘ç°æ•°æ®é›†ä¸­æ½œåœ¨çš„éšå«æ•ˆåº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šæ‰€æå‡ºçš„æ–¹æ³•åœ¨ä¸åŒæ¨¡å‹æ¶æ„ä¸Šå‡èƒ½ä¿æŒå…¶æ•ˆæœï¼Œè¯æ˜äº†å…¶æ™®éæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚

**å…³é”®è¯**ï¼šæ½œåœ¨æ•ˆåº”, æ•°æ®é›†, å¤§è¯­è¨€æ¨¡å‹, LLM, Logit-Linear-Selection, éšè—æ•ˆæœ, è®­ç»ƒæ–¹æ³•, æ¨¡å‹è¡Œä¸º, æ•°æ®é€‰æ‹©, è¯­è¨€å“åº”

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04863v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04863v1.pdf)

---

## [18. From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures](https://arxiv.org/abs/2602.04861v1)

**ä½œè€…**ï¼šRyan Liu, Eric Qu, Tobias Kreiman ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cond-mat.mtrl-sci, cs.AI, physics.chem-ph  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an "in-the-loop" model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡BSCTï¼Œæ—¨åœ¨é€šè¿‡æ£€æµ‹é‡å­åŠ¿èƒ½é¢å…‰æ»‘æ€§æ¥æŒ‡å¯¼æœºå™¨å­¦ä¹ åŸå­é—´åŠ¿çš„è®¾è®¡ä¸ä¼˜åŒ–ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„æœºå™¨å­¦ä¹ åŸå­é—´åŠ¿è¯„ä¼°æ–¹æ³•æ•ˆç‡ä½ä¸”ä¸»è¦é›†ä¸­åœ¨å¹³è¡¡æ€ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆæ•æ‰æ½œåœ¨çš„ç‰©ç†é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºçš„BSCTé€šè¿‡æ§åˆ¶é”®å˜å½¢æ¥æ¢æµ‹åŠ¿èƒ½é¢å…‰æ»‘æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ä¸è¿ç»­æ€§ã€äººå·¥æå°å€¼å’Œè™šå‡åŠ›ï¼ŒåŒæ—¶æˆæœ¬è¿œä½äºä¼ ç»Ÿçš„åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿã€‚

**ä¸»è¦ç»“è®º**ï¼šé€šè¿‡åŸºäºBSCTçš„ç³»ç»Ÿä¼˜åŒ–ï¼Œæ‰€è®¾è®¡çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸ä»…é™ä½äº†ä¼ ç»Ÿçš„èƒ½é‡/åŠ›å›å½’è¯¯å·®ï¼Œè¿˜å®ç°äº†ç¨³å®šçš„åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿå’Œå¯é çš„åŸå­æ€§è´¨é¢„æµ‹ï¼Œè¯æ˜äº†BSCTåœ¨æ¨¡å‹è®¾è®¡ä¸­çš„é‡è¦æ€§ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , é‡å­åŠ¿èƒ½é¢, æ·±åº¦å­¦ä¹ , å˜æ¢å™¨, æ¨¡å‹è®¾è®¡, è¿­ä»£ä¼˜åŒ–, åˆ†å­åŠ¨åŠ›å­¦, å¹³æ»‘æ€§è¯„ä¼°, ç‰©ç†æŒ‘æˆ˜, machine learning

**è¯„åˆ†**ï¼š68

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04861v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04861v1.pdf)

---

## [19. The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852v1)

**ä½œè€…**ï¼šPhilipp Nazari, T. Konstantin Rusch  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç§©çš„çº¿æ€§æ³¨æ„åŠ›çŠ¶æ€ç®€åŒ–æ–¹æ³•ï¼Œé€šè¿‡ç»“æ„æ€§ä¿®å‰ªå’Œç†è®ºåˆ†æï¼Œæ˜¾è‘—å‡å°‘æ¨¡å‹çŠ¶æ€å¤§å°ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçº¿æ€§æ³¨æ„åŠ›æ¨¡å‹çš„è®­ç»ƒçŠ¶æ€å¸¸è¡¨ç°å‡ºä½ç§©ç»“æ„ï¼Œè¡¨æ˜å…¶æœªå……åˆ†åˆ©ç”¨æ¨¡å‹å®¹é‡ï¼Œå¯¼è‡´æ£€ç´¢é”™è¯¯å¢åŠ ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¡¬ä»¶æ„ŸçŸ¥æ–¹æ³•ï¼Œé€šè¿‡ç»“æ„æ€§ä¿®å‰ªå…³é”®å’ŒæŸ¥è¯¢çŸ©é˜µï¼Œç»“åˆåŸºäºç§©æ­ç¤ºQRåˆ†è§£çš„ç»“æ„åŒ–ä¿®å‰ªç­–ç•¥ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ä»…è½»å¾®å¢åŠ å›°æƒ‘åº¦çš„æƒ…å†µä¸‹ï¼Œå»é™¤50%çš„æŸ¥è¯¢å’Œå…³é”®é€šé“ï¼Œæå‡æ¨¡å‹æ•ˆç‡ã€‚

**å…³é”®è¯**ï¼šçº¿æ€§æ³¨æ„åŠ›, ä½ç§©ç»“æ„, æ£€ç´¢è¯¯å·®, ç¡¬ä»¶æ„ŸçŸ¥, ç»“æ„åŒ–å‰ªæ, CUDA, QRåˆ†è§£, æ¨¡å‹å‹ç¼©, æ€§èƒ½ä¼˜åŒ–, retrieval

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04852v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04852v1.pdf)

---

## [20. Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821v1)

**ä½œè€…**ï¼šJoydeep Chandra, Satyam Kumar Navneet, Aleksandr Algazinov ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\% coverage efficiency, controls FDR at 4.1\% under verified dependence, and improves safety rate to 95.2\% compared to 69\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSTREAM-RLçš„åŸå¸‚äº¤é€šæ§åˆ¶æ¡†æ¶ï¼Œåˆ©ç”¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„é¢„æµ‹å’Œå¼ºåŒ–å­¦ä¹ æé«˜äº¤é€šç®¡ç†çš„å®‰å…¨æ€§å’Œæ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåŸå¸‚äº¤é€šç®¡ç†éœ€è¦èƒ½å¤Ÿé¢„æµ‹æœªæ¥çŠ¶å†µã€æ£€æµ‹å¼‚å¸¸å¹¶é‡‡å–å®‰å…¨æªæ–½çš„ç³»ç»Ÿï¼ŒåŒæ—¶æä¾›å¯é æ€§ä¿è¯ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šSTREAM-RLæ¡†æ¶ç»“åˆäº†ä¸‰ç§æ–°ç®—æ³•ï¼Œåˆ†åˆ«æ˜¯åŸºäºä¸ç¡®å®šæ€§çš„è‡ªé€‚åº”ç¬¦åˆé¢„æµ‹ã€ç¬¦åˆæ®‹å·®æµç½‘ç»œå’Œä¸ç¡®å®šæ€§å¼•å¯¼çš„å®‰å…¨ä¸–ç•Œæ¨¡å‹å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒSTREAM-RLåœ¨è¦†ç›–æ•ˆç‡ã€å®‰å…¨ç‡å’Œå¥–åŠ±ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨çœŸå®äº¤é€šæ•°æ®ä¸­çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è¯**ï¼šåŸå¸‚äº¤é€šç®¡ç†, ä¸ç¡®å®šæ€§é¢„æµ‹, å¼ºåŒ–å­¦ä¹ , æµç½‘ç»œ, å®‰å…¨æ§åˆ¶, é¢„æµ‹ä¸ç¡®å®šæ€§, è‡ªé€‚åº”æ¨¡å‹, anomaly detection, STREAM-RL, agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04821v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04821v1.pdf)

---

## [21. Beyond Rewards in Reinforcement Learning for Cyber Defence](https://arxiv.org/abs/2602.04809v1)

**ä½œè€…**ï¼šElizabeth Bates, Chris Hicks, Vasilios Mavroudis  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ¢è®¨äº†ç¨€ç–å¥–åŠ±åœ¨ç½‘ç»œé˜²å¾¡ä¸­çš„åº”ç”¨ï¼Œè¡¨æ˜å…¶æ¯”å¯†é›†å¥–åŠ±æ›´èƒ½æœ‰æ•ˆè®­ç»ƒå®‰å…¨ä»£ç†å¹¶é™ä½é£é™©ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€è‡ªåŠ¨åŒ–ç½‘ç»œé˜²å¾¡ä»£ç†çš„å…´èµ·ï¼Œç ”ç©¶å¦‚ä½•ä¼˜åŒ–å¥–åŠ±å‡½æ•°ä»¥æå‡å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§å˜å¾—å°¤ä¸ºé‡è¦ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¯¹ä¸åŒå¥–åŠ±å‡½æ•°çš„ç»“æ„è¿›è¡Œè¯„ä¼°ï¼Œç»“åˆå¤šç§ç½‘ç»œç¯å¢ƒå’ŒRLç®—æ³•ï¼Œä½¿ç”¨åˆ›æ–°çš„çœŸå®æ€§è¯„ä¼°æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚

**ä¸»è¦ç»“è®º**ï¼šç¨€ç–å¥–åŠ±åœ¨ç›®æ ‡å¯¹é½å’Œé¢‘ç¹é­é‡çš„æƒ…å†µä¸‹ï¼Œä¸ä»…æé«˜äº†è®­ç»ƒçš„å¯é æ€§ï¼Œè¿˜èƒ½å¤Ÿç”Ÿæˆæ›´ç¬¦åˆç½‘ç»œé˜²å¾¡ç›®æ ‡çš„ä½é£é™©ç­–ç•¥ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , å¼ºåŒ–å­¦ä¹ , è‡ªä¸»ä»£ç†, ç½‘ç»œé˜²å¾¡, å¥–åŠ±å‡½æ•°, ç¨€ç–å¥–åŠ±, æ”¿ç­–æ¢¯åº¦, è¡Œä¸ºç‰¹å¾, ç½‘ç»œå®‰å…¨, å¤æ‚ç¯å¢ƒ, agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04809v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04809v1.pdf)

---

## [22. Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning](https://arxiv.org/abs/2602.04807v1)

**ä½œè€…**ï¼šWolfgang Maass, Sabine Janzen, Prajvi Saxena ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ç”Ÿç‰©å¯å‘çš„Afferentå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡é€‚åº”æ€§å†…éƒ¨é£é™©ä¿¡å·ä¿ƒè¿›æŸä¼¤é¿å…å­¦ä¹ ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨é€šè¿‡ç”Ÿç‰©ç³»ç»Ÿçš„å¯å‘ï¼Œæå‡æŸä¼¤é¿å…å­¦ä¹ çš„æ•ˆç‡å’Œé€‚åº”æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè¯¥æ¡†æ¶é‡‡ç”¨ä¸¤çº§æ¶æ„ï¼Œå¤–å±‚é€šè¿‡è¿›åŒ–ä¼˜åŒ–å‘ç°æœ‰æ•ˆçš„æ„ŸçŸ¥æ¶æ„ï¼Œå†…å±‚ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæŸä¼¤é¿å…ç­–ç•¥ã€‚

**ä¸»è¦ç»“è®º**ï¼šCATåŸºäºè¿›åŒ–çš„æ¶æ„åœ¨æ•ˆç‡å’Œå¹´é¾„é²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äºæ‰‹å·¥è®¾è®¡çš„åŸºçº¿ï¼Œä¸”èƒ½å¤Ÿå®ç°å¹´é¾„ä¾èµ–çš„è¡Œä¸ºé€‚åº”ã€‚

**å…³é”®è¯**ï¼šç”Ÿç‰©å¯å‘æ¨¡å‹, é€‚åº”æ€§, é£é™©ä¿¡å·, å¼ºåŒ–å­¦ä¹ , è¿›åŒ–ä¼˜åŒ–, è®¡ç®—æ€§ä¼ å…¥è½¨è¿¹, æ”¿ç­–å­¦ä¹ , ç”Ÿç‰©æœºæ¢°æ•°å­—åŒèƒèƒ, age-robustness, damage-avoidance, context

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04807v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04807v1.pdf)

---

## [23. Maximum-Volume Nonnegative Matrix Factorization](https://arxiv.org/abs/2602.04795v1)

**ä½œè€…**ï¼šOlivier Vu Thanh, Nicolas Gillis  
**åˆ†ç±»**ï¼šcs.LG, eess.SP, math.NA, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éè´ŸçŸ©é˜µåˆ†è§£æ–¹æ³•â€”â€”æœ€å¤§ä½“ç§¯éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆMaxVol NMFï¼‰ï¼Œé€šè¿‡æœ€å¤§åŒ–çŸ©é˜µHçš„ä½“ç§¯æ¥æé«˜ç¨€ç–åˆ†è§£çš„æ•ˆæœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„æœ€å°ä½“ç§¯éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆMinVol NMFï¼‰åœ¨å™ªå£°ç¯å¢ƒä¸‹è¡¨ç°ä¸ä½³ï¼Œå› æ­¤éœ€è¦æ¢ç´¢æ–°çš„æ–¹æ³•ä»¥æä¾›æ›´ç¨³å®šå’Œå¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†MaxVol NMFæ–¹æ³•ï¼Œæ—¨åœ¨æœ€å¤§åŒ–çŸ©é˜µHçš„ä½“ç§¯ï¼Œå¹¶ä¸”è¯æ˜äº†å…¶åœ¨æ— å™ªå£°æ¡ä»¶ä¸‹çš„å¯è¯†åˆ«æ€§ï¼ŒåŒæ—¶æä¾›äº†ä¸¤ç§æ±‚è§£ç®—æ³•åŠå…¶å½’ä¸€åŒ–å˜ä½“ã€‚

**ä¸»è¦ç»“è®º**ï¼šMaxVol NMFåœ¨æå–ç¨€ç–åˆ†è§£æ–¹é¢æ›´æœ‰æ•ˆï¼Œå¹¶ä¸”ä¸MinVol NMFç›¸æ¯”ï¼Œå…¶è§£å†³æ–¹æ¡ˆå¯¹åº”äºå°†æ•°æ®åˆ—èšç±»ä¸ºä¸ç›¸äº¤çš„ç°‡ï¼Œé¿å…äº†ç§©ç¼ºé™·ã€‚

**å…³é”®è¯**ï¼šéè´ŸçŸ©é˜µåˆ†è§£, æ•°æ®åµŒå…¥, æœºå™¨å­¦ä¹ , ç¨€ç–åˆ†è§£, èšç±», MaxVol NMF, æœ€å°ä½“ç§¯ NMF, å™ªå£°å¤„ç†, è¶…å…‰è°±è§£æ··åˆ, embedding

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04795v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04795v1.pdf)

---

## [24. Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation](https://arxiv.org/abs/2602.04785v1)

**ä½œè€…**ï¼šCongjing Zhang, Ryan Feng Lin, Ruoxuan Bao ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºTeam-then-Trim (T$^2$) çš„æ¡†æ¶ï¼Œé€šè¿‡åä½œçš„LLMå›¢é˜Ÿå’Œä¸¥æ ¼çš„æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹åˆæˆé«˜è´¨é‡çš„è¡¨æ ¼æ•°æ®ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šé«˜è´¨é‡çš„è¡¨æ ¼æ•°æ®è·å–é€šå¸¸åŠ³åŠ¨å¯†é›†ä¸”æˆæœ¬é«˜ï¼Œç°æœ‰æ•°æ®é›†å­˜åœ¨ä¸¥é‡ä¸è¶³ï¼Œè¿«åˆ‡éœ€è¦æœ‰æ•ˆçš„ç”Ÿæˆæ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šT$^2$æ¡†æ¶å°†è¡¨æ ¼æ•°æ®ç”Ÿæˆè§†ä¸ºåˆ¶é€ è¿‡ç¨‹ï¼Œé€šè¿‡ä¸“ä¸šåŒ–çš„LLMå›¢é˜Ÿä¾ç…§é¢†åŸŸçŸ¥è¯†é€æ­¥ç”Ÿæˆæ•°æ®ç»„ä»¶ï¼Œå¹¶åœ¨å¤šä¸ªç»´åº¦ä¸Šè¿›è¡Œè´¨é‡è¯„ä¼°ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®è¯ç»“æœè¡¨æ˜ï¼ŒT$^2$åœ¨ç”Ÿæˆé«˜è´¨é‡è¡¨æ ¼æ•°æ®æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ¡†æ¶, è¡¨æ ¼æ•°æ®, å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹, æ•°æ®è´¨é‡æ§åˆ¶, ååŒç”Ÿæˆ, å¤šé˜¶æ®µè¯„ä¼°, æœºå™¨å­¦ä¹ åº”ç”¨, åˆä½œå›¢é˜Ÿ, machine learning

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04785v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04785v1.pdf)

---

## [25. Dynamical Regimes of Multimodal Diffusion Models](https://arxiv.org/abs/2602.04780v1)

**ä½œè€…**ï¼šEmil Albrychiewicz, AndrÃ©s Franco Valiente, Li-Ching Chen  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œæ­ç¤ºäº†å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åŠ¨æ€æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡è€¦åˆçš„Ornstein-Uhlenbeckè¿‡ç¨‹åˆ†æäº†äº¤äº’æ—¶é—´å°ºåº¦çš„è°±å±‚æ¬¡ç»“æ„ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡æ‰©æ•£ç”Ÿæˆæ¨¡å‹åœ¨åˆæˆé«˜ç»´æ•°æ®æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å¤šæ¨¡æ€ç”Ÿæˆçš„ç†è®ºæœºåˆ¶ä»ä¸æ¸…æ¥šï¼Œå› æ­¤éœ€è¦æ·±å…¥ç ”ç©¶å…¶èƒŒåçš„åŠ¨æ€è§„å¾‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡ç ”ç©¶è€¦åˆçš„Ornstein-Uhlenbeckè¿‡ç¨‹ï¼Œåˆ©ç”¨éå¹³è¡¡ç»Ÿè®¡ç‰©ç†å­¦ä¸­çš„åŠ¨æ€ç›¸å˜ç†è®ºï¼Œåˆ†æä¸åŒæ—¶é—´å°ºåº¦ä¸‹çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶æ¨å¯¼å‡ºç›¸åº”çš„åˆ†ææ¡ä»¶ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè€¦åˆå¼ºåº¦ä½œä¸ºè°±æ»¤æ³¢å™¨ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¼ºåˆ¶æ‰§è¡Œå¯è°ƒçš„æ—¶é—´å±‚æ¬¡ï¼Œè¿™ä¸ºå¤šæ¨¡æ€ç”Ÿæˆæä¾›äº†æ–°çš„æ—¶é—´ä¾èµ–è€¦åˆè°ƒåº¦ç­–ç•¥ã€‚

**å…³é”®è¯**ï¼šå¤šæ¨¡æ€, æ‰©æ•£æ¨¡å‹, ç”Ÿæˆæ¨¡å‹, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, äº¤äº’æ—¶é—´å°ºåº¦, åŒæ­¥é—´éš™, ç»Ÿè®¡ç‰©ç†, è®­ç»ƒå®éªŒ, MNIST, generative

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04780v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04780v1.pdf)

---

## [26. Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification](https://arxiv.org/abs/2602.04775v1)

**ä½œè€…**ï¼šYuqi Li, Matthew M. Engelhard  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§é’ˆå¯¹åŒºé—´å€¼é¢„æµ‹çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥ROCæ¡†æ¶ï¼Œå¹¶å¼•å…¥äº†æ–°çš„è¯„ä¼°æŒ‡æ ‡AUC_Lå’ŒAUC_Uï¼Œä»¥ä¼˜åŒ–å†³ç­–è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§å¤„ç†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨é«˜é£é™©é¢„æµ‹ä¸­ï¼Œé€šè¿‡åŒºé—´å€¼é¢„æµ‹é‡åŒ–ä¸ç¡®å®šæ€§å¯¹äºå¯é å†³ç­–è‡³å…³é‡è¦ï¼Œç°æœ‰çš„AUCå·¥å…·æ— æ³•æœ‰æ•ˆæ•æ‰è¿™ç§ä¸ç¡®å®šæ€§å¯¹æ’åæ€§èƒ½çš„å½±å“ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥ROCæ¡†æ¶ï¼ŒåŒ…å«å¯¹ROCå¹³é¢çš„ä¸‰åŒºåŸŸåˆ†è§£ï¼Œå¹¶å¼•å…¥ä¸¤ä¸ªæ–°æŒ‡æ ‡AUC_Lå’ŒAUC_Uï¼Œä»¥æ”¯æŒé€‰æ‹©æ€§é¢„æµ‹å’Œä¼˜åŒ–ä¸ç¡®å®šæ€§å¤„ç†ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒéªŒè¯äº†æ‰€ææ¡†æ¶çš„æ­£ç¡®æ€§å’Œå®ç”¨æ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„ä¼°å’Œå†³ç­–ä¸­çš„æœ‰æ•ˆåº”ç”¨ã€‚

**å…³é”®è¯**ï¼šä¸ç¡®å®šæ€§åˆ†ç±», é¢„æµ‹æ¨¡å‹, ROCæ›²çº¿, AUC, interval-valued predictions, é€‰æ‹©æ€§é¢„æµ‹, æ’åºæ€§èƒ½, å¯é æ€§ä¼˜åŒ–, å®éªŒéªŒè¯, å†³ç­–æ”¯æŒ, rag

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04775v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04775v1.pdf)

---

## [27. Generative Modeling via Drifting](https://arxiv.org/abs/2602.04770v1)

**ä½œè€…**ï¼šMingyang Deng, He Li, Tianhong Li ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Generative modeling can be formulated as learning a mapping f such that its pushforward distribution matches the data distribution. The pushforward behavior can be carried out iteratively at inference time, for example in diffusion and flow-based models. In this paper, we propose a new paradigm called Drifting Models, which evolve the pushforward distribution during training and naturally admit one-step inference. We introduce a drifting field that governs the sample movement and achieves equilibrium when the distributions match. This leads to a training objective that allows the neural network optimizer to evolve the distribution. In experiments, our one-step generator achieves state-of-the-art results on ImageNet at 256 x 256 resolution, with an FID of 1.54 in latent space and 1.61 in pixel space. We hope that our work opens up new opportunities for high-quality one-step generation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿæˆå»ºæ¨¡æ–¹æ³•ï¼Œå³æ¼‚ç§»æ¨¡å‹ï¼Œé€šè¿‡è®­ç»ƒä¸­æ¼”åŒ–æ¨å‰åˆ†å¸ƒå®ç°é«˜è´¨é‡çš„ä¸€æ­¥ç”Ÿæˆã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå½“å‰ç”Ÿæˆæ¨¡å‹åœ¨æ¨å‰åˆ†å¸ƒåŒ¹é…æ•°æ®åˆ†å¸ƒæ—¶å­˜åœ¨æ•ˆç‡å’Œè´¨é‡çš„æŒ‘æˆ˜ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°æ–¹æ³•æ¥æ”¹è¿›è¿™ä¸€è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æå‡ºäº†ä¸€ä¸ªæ¼‚ç§»åœºï¼Œé€šè¿‡æ§åˆ¶æ ·æœ¬ç§»åŠ¨æ¥æ¼”åŒ–æ¨å‰åˆ†å¸ƒï¼Œå¹¶åœ¨è®­ç»ƒä¸­å®ç°åˆ†å¸ƒçš„å¹³è¡¡ï¼Œä»è€Œä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼Œæå‡ºçš„ä¸€æ­¥ç”Ÿæˆå™¨åœ¨ImageNetæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¼€å¯äº†é«˜è´¨é‡ä¸€æ­¥ç”Ÿæˆçš„æ–°æœºä¼šã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ¨¡å‹, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, ç”Ÿæˆ, æ¼‚ç§»æ¨¡å‹, è®­ç»ƒç›®æ ‡, ä¸€æ­¥æ¨ç†, å›¾åƒç”Ÿæˆ, ImageNet, neural network

**è¯„åˆ†**ï¼š67

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04770v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04770v1.pdf)

---

## [28. Billion-Scale Graph Foundation Models](https://arxiv.org/abs/2602.04768v1)

**ä½œè€…**ï¼šMaya Bechler-Speicher, Yoel Gottlieb, Andrey Isakov ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†GraphBFFï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåäº¿å‚æ•°è§„æ¨¡å›¾åŸºç¡€æ¨¡å‹çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¼‚æ„å¤§è§„æ¨¡å›¾æ•°æ®ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å›¾ç»“æ„æ•°æ®åœ¨å¤šä¸ªå…³é”®åº”ç”¨ä¸­çš„é‡è¦æ€§ä¸æ–­æå‡ï¼Œå¦‚ä½•å°†å¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„æˆåŠŸç»éªŒæ‰©å±•åˆ°å›¾æ•°æ®ä¸Šæˆä¸ºä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šGraphBFFæ¡†æ¶ç»“åˆäº†GraphBFF Transformeræ¶æ„ï¼Œæä¾›äº†é¢„è®­ç»ƒå’Œå¾®è°ƒçš„å…·ä½“æ–¹æ³•è®ºï¼Œèƒ½å¤Ÿå¤„ç†åäº¿è§„æ¨¡çš„å›¾æ•°æ®ã€‚

**ä¸»è¦ç»“è®º**ï¼šGraphBFFåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œçš„ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„é›¶-shotå’Œå°‘-shotæ€§èƒ½ï¼Œè¡¨æ˜è¯¥æ¡†æ¶ä¸ºå›¾å­¦ä¹ æä¾›äº†å®ç”¨çš„åŸºç¡€æ¨¡å‹æ„å»ºæ–¹æ¡ˆã€‚

**å…³é”®è¯**ï¼šå›¾ç¥ç»ç½‘ç»œ, ç”Ÿæˆæ¨¡å‹, é¢„è®­ç»ƒ, å¾®è°ƒ, Transformer, å›¾æ•°æ®, å¤§è§„æ¨¡æ¨¡å‹, ä»»åŠ¡è¯„ä¼°, é›¶æ ·æœ¬å­¦ä¹ 

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04768v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04768v1.pdf)

---

## [29. Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763v1)

**ä½œè€…**ï¼šRui Liu, Pratap Tokekar, Ming Lin  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•A2MAMLï¼Œæ—¨åœ¨å¤„ç†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä¼˜åŒ–å¤šæ¨¡æ€åˆä½œã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ™®åŠï¼Œå¼‚æ„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨å¸¦æ¥äº†æ„ŸçŸ¥èƒ½åŠ›çš„æå‡ï¼Œä½†ä¹Ÿå¼•å…¥äº†ç‰¹å®šæ¨¡æ€å’Œä»£ç†ç›¸å…³çš„ä¸ç¡®å®šæ€§ï¼Œé™åˆ¶äº†ç³»ç»Ÿåœ¨ä¼ æ„Ÿå™¨æŸåæƒ…å†µä¸‹çš„é²æ£’æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šA2MAMLé€šè¿‡å°†æ¯ä¸ªæ¨¡æ€ç‰¹å¾å»ºæ¨¡ä¸ºå¸¦æœ‰ä¸ç¡®å®šæ€§é¢„æµ‹çš„éšæœºä¼°è®¡ï¼Œä¸»åŠ¨é€‰æ‹©å¯é çš„ä»£ç†-æ¨¡æ€å¯¹ï¼Œå¹¶é€šè¿‡è´å¶æ–¯é€†æ–¹å·®åŠ æƒèšåˆä¿¡æ¯ï¼Œå®ç°ç»†ç²’åº¦çš„æ¨¡æ€çº§èåˆã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨åä½œäº‹æ•…æ£€æµ‹çš„å®éªŒä¸­ï¼ŒA2MAMLåœ¨äº‹æ•…æ£€æµ‹ç‡ä¸Šæ¯”å•ä»£ç†å’Œåˆä½œåŸºçº¿é«˜å‡ºæœ€å¤š18.7%ã€‚

**å…³é”®è¯**ï¼šå¤šæ™ºèƒ½ä½“, å¤šæ¨¡æ€å­¦ä¹ , ä¸ç¡®å®šæ€§, ååŒå·¥ä½œ, æ¨¡æ€èåˆ, agent, Bayesian, äº‹æ•…æ£€æµ‹, è‡ªåŠ¨é©¾é©¶

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04763v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04763v1.pdf)

---

## [30. A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates](https://arxiv.org/abs/2602.04757v1)

**ä½œè€…**ï¼šYuchen Ye, Zixuan Qi, Shixuan Li ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-04

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åŒé˜¶æ®µTransUNetæ¡†æ¶ï¼Œèåˆå¤šæºé™æ°´æ•°æ®ä»¥æé«˜é™æ°´ä¼°è®¡çš„å‡†ç¡®æ€§å’Œæç«¯å¤©æ°”äº‹ä»¶çš„æ£€æµ‹èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤šæºé™æ°´äº§å“åœ¨ç©ºé—´å¼‚è´¨æ€§åå·®å’Œæç«¯å¤©æ°”ä¼°è®¡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨æ°´æ–‡æ°”å€™ç›‘æµ‹ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¼€å‘äº†ä¸€ä¸ªåŒé˜¶æ®µçš„TransUNetæ¨¡å‹ï¼Œå…¶ä¸­ç¬¬ä¸€é˜¶æ®µé€šè¿‡åˆ†ç±»å™¨ä¼°è®¡é™æ°´å‘ç”Ÿæ¦‚ç‡ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡å›å½’å™¨ç»“åˆå¤šç§ç‰©ç†é¢„æµ‹å› å­ä¼°è®¡é™æ°´é‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¡†æ¶åœ¨å­£èŠ‚æ€§è¡¨ç°å’Œæç«¯é™æ°´äº‹ä»¶æ£€æµ‹ä¸Šä¼˜äºä¼ ç»Ÿæ¨¡å‹ï¼Œä¸”åœ¨æ•°æ®ç¨€ç¼ºåŒºåŸŸæ˜¾ç¤ºå‡ºè‰¯å¥½çš„é€‚ç”¨æ€§ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , å¤šæºé™æ°´, TransUNet, æœºå™¨å­¦ä¹ , é¢„æµ‹æ¨¡å‹, æ•°æ®èåˆ, æç«¯äº‹ä»¶æ£€æµ‹, è¯­ä¹‰æœç´¢, äººæœºåä½œ, deep learning

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.04757v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.04757v1.pdf)

---

