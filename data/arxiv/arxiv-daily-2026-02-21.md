# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-21

> å…± 15 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.LG](#csLG) (4 ç¯‡)
- [cs.CV](#csCV) (5 ç¯‡)
- [cs.AI](#csAI) (4 ç¯‡)
- [cs.CL](#csCL) (2 ç¯‡)

---

## cs.AI

## [1. When Do LLM Preferences Predict Downstream Behavior?](https://arxiv.org/abs/2602.18971v1)

**ä½œè€…**ï¼šKatarina Slama, Alexandra Souly, Dishank Bansal ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Preference-driven behavior in LLMs may be a necessary precondition for AI misalignment such as sandbagging: models cannot strategically pursue misaligned goals unless their behavior is influenced by their preferences. Yet prior work has typically prompted models explicitly to act in specific ways, leaving unclear whether observed behaviors reflect instruction-following capabilities vs underlying model preferences. Here we test whether this precondition for misalignment is present. Using entity preferences as a behavioral probe, we measure whether stated preferences predict downstream behavior in five frontier LLMs across three domains: donation advice, refusal behavior, and task performance. Conceptually replicating prior work, we first confirm that all five models show highly consistent preferences across two independent measurement methods. We then test behavioral consequences in a simulated user environment. We find that all five models give preference-aligned donation advice. All five models also show preference-correlated refusal patterns when asked to recommend donations, refusing more often for less-preferred entities. All preference-related behaviors that we observe here emerge without instructions to act on preferences. Results for task performance are mixed: on a question-answering benchmark (BoolQ), two models show small but significant accuracy differences favoring preferred entities; one model shows the opposite pattern; and two models show no significant relationship. On complex agentic tasks, we find no evidence of preference-driven performance differences. While LLMs have consistent preferences that reliably predict advice-giving behavior, these preferences do not consistently translate into downstream task performance.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡å‘ç°ï¼šLLMçš„â€œåå¥½â€èƒ½ç¨³å®šé¢„æµ‹å…¶å»ºè®®ä¸æ‹’ç»è¡Œä¸ºï¼Œä½†å¹¶ä¸ç¨³å®šåœ°è½¬åŒ–ä¸ºä¸‹æ¸¸ä»»åŠ¡/æ€§èƒ½å·®å¼‚ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä»¥å¾€è®¸å¤šâ€œåå¥½é©±åŠ¨è¡Œä¸º/å¤±é…é£é™©â€çš„è¯æ®å¯èƒ½æ··æ‚äº†æŒ‡ä»¤è·Ÿéšæ•ˆåº”ï¼Œæ— æ³•ç¡®è®¤æ¨¡å‹æ˜¯å¦ä¼šåœ¨æ— æ˜¾å¼æŒ‡ä»¤ä¸‹ä¾æ®è‡ªèº«åå¥½è¡ŒåŠ¨ã€‚ä½œè€…å¸Œæœ›æ£€éªŒâ€œåå¥½å½±å“è¡Œä¸ºâ€è¿™ä¸€æ½œåœ¨å¤±é…å‰ææ˜¯å¦çœŸå®å­˜åœ¨ä¸”å¯æ³›åŒ–åˆ°å¤šç§ä¸‹æ¸¸åœºæ™¯ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨5ä¸ªå‰æ²¿LLMä¸Šï¼Œç”¨â€œå®ä½“åå¥½â€ä½œä¸ºè¡Œä¸ºæ¢é’ˆï¼Œå…ˆç”¨ä¸¤ç§ç‹¬ç«‹æµ‹é‡æ–¹æ³•éªŒè¯åå¥½çš„ä¸€è‡´æ€§ï¼Œå†åœ¨æ¨¡æ‹Ÿç”¨æˆ·ç¯å¢ƒä¸­æµ‹è¯•åå¥½å¯¹ä¸‰ç±»ä¸‹æ¸¸è¡Œä¸ºçš„é¢„æµ‹ï¼šæèµ å»ºè®®ã€æ‹’ç»æ¨¡å¼ã€ä»»åŠ¡è¡¨ç°ï¼ˆBoolQä¸å¤æ‚agenticä»»åŠ¡ï¼‰ã€‚

**ä¸»è¦ç»“è®º**ï¼šæ‰€æœ‰æ¨¡å‹çš„åå¥½åœ¨ä¸¤ç§æµ‹é‡æ–¹æ³•ä¸‹é«˜åº¦ä¸€è‡´ï¼Œä¸”æ— éœ€æŒ‡ä»¤å°±ä¼šç»™å‡ºåå¥½ä¸€è‡´çš„æèµ å»ºè®®ï¼Œå¹¶å¯¹ä¸åå¥½çš„å®ä½“è¡¨ç°å‡ºæ›´é«˜çš„æ‹’ç»æ¦‚ç‡ï¼›ä½†åœ¨ä»»åŠ¡è¡¨ç°ä¸Šä»…åœ¨BoolQä¸­å‡ºç°æ··åˆä¸”è¾ƒå°çš„ç›¸å…³æ€§ï¼Œåœ¨å¤æ‚agenticä»»åŠ¡ä¸­æœªè§‚å¯Ÿåˆ°åå¥½é©±åŠ¨çš„æ€§èƒ½å·®å¼‚ã€‚

**å…³é”®è¯**ï¼šåå¥½é©±åŠ¨è¡Œä¸º, ä¸‹æ¸¸è¡Œä¸ºé¢„æµ‹, æ²™è¢‹è¡Œä¸º, å®ä½“åå¥½æ¢é’ˆ, åå¥½æµ‹é‡ä¸€è‡´æ€§, æèµ å»ºè®®, æ‹’ç»è¡Œä¸º, ä»£ç†ä»»åŠ¡æ€§èƒ½

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18971v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18971v1.pdf)

---

## [2. Robust and Efficient Tool Orchestration via Layered Execution Structures with Reflective Correction](https://arxiv.org/abs/2602.18968v1)

**ä½œè€…**ï¼šTao Zhe, Haoyu Wang, Bo Luo ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Tool invocation is a core capability of agentic systems, yet failures often arise not from individual tool calls but from how multiple tools are organized and executed together. Existing approaches tightly couple tool execution with stepwise language reasoning or explicit planning, leading to brittle behavior and high execution overhead. To overcome these limitations, we revisit tool invocation from the perspective of tool orchestration. Our key insight is that effective orchestration does not require precise dependency graphs or fine-grained planning. Instead, a coarse-grained layer structure suffices to provide global guidance, while execution-time errors can be corrected locally. Specifically, we model tool orchestration as learning a layered execution structure that captures high-level tool dependencies, inducing layer-wise execution through context constraints. To handle execution-time failures, we introduce a schema-aware reflective correction mechanism that detects and repairs errors locally. This design confines errors to individual tool calls and avoids re-planning entire execution trajectories. This structured execution paradigm enables a lightweight and reusable orchestration component for agentic systems. Experimental results show that our approach achieves robust tool execution while reducing execution complexity and overhead. Code will be made publicly available.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§â€œåˆ†å±‚æ‰§è¡Œç»“æ„ + åæ€å¼çº é”™â€çš„å·¥å…·ç¼–æ’æ¡†æ¶ï¼Œåœ¨ä¸ä¾èµ–ç²¾ç»†è§„åˆ’çš„æƒ…å†µä¸‹æå‡å¤šå·¥å…·åä½œçš„é²æ£’æ€§å¹¶é™ä½æ‰§è¡Œå¼€é”€ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰å¤šå·¥å…·è°ƒç”¨å¸¸å°†æ‰§è¡Œä¸é€æ­¥æ¨ç†/æ˜¾å¼è§„åˆ’å¼ºè€¦åˆï¼Œå¯¼è‡´æµç¨‹è„†å¼±ä¸”ä¸€å¤„å‡ºé”™å®¹æ˜“è§¦å‘æ•´ä½“é‡è§„åˆ’ã€å¸¦æ¥é«˜å¤æ‚åº¦ä¸é«˜æˆæœ¬ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå­¦ä¹ ä¸€ä¸ªç²—ç²’åº¦çš„åˆ†å±‚æ‰§è¡Œç»“æ„æ¥è¡¨è¾¾é«˜å±‚ä¾èµ–ï¼Œå¹¶ç”¨ä¸Šä¸‹æ–‡çº¦æŸé©±åŠ¨æŒ‰å±‚æ‰§è¡Œï¼›åŒæ—¶å¼•å…¥schemaæ„ŸçŸ¥çš„åæ€å¼çº é”™ï¼Œåœ¨è¿è¡Œæ—¶å¯¹å•æ¬¡å·¥å…·è°ƒç”¨çš„é”™è¯¯è¿›è¡Œæ£€æµ‹ä¸å±€éƒ¨ä¿®å¤ï¼Œé¿å…å…¨å±€é‡è§„åˆ’ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥ç»“æ„åŒ–ç¼–æ’èŒƒå¼å°†é”™è¯¯é™åˆ¶åœ¨å±€éƒ¨å·¥å…·è°ƒç”¨å†…ï¼Œæ˜¾è‘—å¢å¼ºæ‰§è¡Œé²æ£’æ€§ï¼Œå¹¶åœ¨å®éªŒä¸­è¯æ˜å¯é™ä½æ‰§è¡Œå¤æ‚åº¦ä¸å¼€é”€ã€å½¢æˆè½»é‡å¯å¤ç”¨çš„ç¼–æ’ç»„ä»¶ã€‚

**å…³é”®è¯**ï¼šå·¥å…·ç¼–æ’, åˆ†å±‚æ‰§è¡Œç»“æ„, åˆ†å±‚ä¾èµ–å»ºæ¨¡, ä¸Šä¸‹æ–‡çº¦æŸæ‰§è¡Œ, æ‰§è¡Œæ—¶é”™è¯¯ä¿®å¤, åæ€å¼çº é”™, å±€éƒ¨ä¿®å¤æœºåˆ¶, è½»é‡çº§ç¼–æ’ç»„ä»¶, æ‰§è¡Œå¤æ‚åº¦é™ä½

**è¯„åˆ†**ï¼š42

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18968v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18968v1.pdf)

---

## [3. Modularity is the Bedrock of Natural and Artificial Intelligence](https://arxiv.org/abs/2602.18960v1)

**ä½œè€…**ï¼šAlessandro Salatiello  
**åˆ†ç±»**ï¼šcs.AI, cs.NE, q-bio.NC  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The remarkable performance of modern AI systems has been driven by unprecedented scales of data, computation, and energy -- far exceeding the resources required by human intelligence. This disparity highlights the need for new guiding principles and motivates drawing inspiration from the fundamental organizational principles of brain computation. Among these principles, modularity has been shown to be critical for supporting the efficient learning and strong generalization abilities consistently exhibited by humans. Furthermore, modularity aligns well with the No Free Lunch Theorem, which highlights the need for problem-specific inductive biases and motivates architectures composed of specialized components that solve subproblems. However, despite its fundamental role in natural intelligence and its demonstrated benefits across a range of seemingly disparate AI subfields, modularity remains relatively underappreciated in mainstream AI research. In this work, we review several research threads in artificial intelligence and neuroscience through a conceptual framework that highlights the central role of modularity in supporting both artificial and natural intelligence. In particular, we examine what computational advantages modularity provides, how it has emerged as a solution across several AI research areas, which modularity principles the brain exploits, and how modularity can help bridge the gap between natural and artificial intelligence.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡ç»¼è¿°å¹¶æå‡ºï¼šæ¨¡å—åŒ–æ˜¯è‡ªç„¶æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½å®ç°é«˜æ•ˆå­¦ä¹ ä¸å¼ºæ³›åŒ–çš„å…³é”®ç»„ç»‡åŸåˆ™ï¼Œåº”æˆä¸ºæ„å»ºæ–°ä¸€ä»£AIç³»ç»Ÿçš„æ ¸å¿ƒæŒ‡å¯¼æ€æƒ³ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°ä»£AIä¾èµ–è¿œè¶…äººç±»çš„å¤§è§„æ¨¡æ•°æ®ä¸ç®—åŠ›æ‰èƒ½å–å¾—é«˜æ€§èƒ½ï¼Œæš´éœ²å‡ºæ•ˆç‡ä¸æ³›åŒ–å·®è·ï¼›ä½œè€…è®¤ä¸ºéœ€è¦å€Ÿé‰´å¤§è„‘è®¡ç®—çš„ç»„ç»‡åŸåˆ™ï¼Œè€Œæ¨¡å—åŒ–æä¾›äº†ç¬¦åˆâ€œNo Free Lunchâ€æ‰€éœ€å½’çº³åç½®çš„è·¯å¾„ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡æ¦‚å¿µæ¡†æ¶å¯¹AIä¸ç¥ç»ç§‘å­¦ä¸­å¤šä¸ªç ”ç©¶çº¿ç´¢è¿›è¡Œç»¼è¿°ä¸å¯¹æ¯”ï¼Œç³»ç»Ÿæ¢³ç†æ¨¡å—åŒ–å¸¦æ¥çš„è®¡ç®—ä¼˜åŠ¿ã€å…¶åœ¨ä¸åŒAIå­é¢†åŸŸçš„è‡ªå‘æ¶Œç°å½¢å¼ï¼Œä»¥åŠå¤§è„‘ä¸­å¯å€Ÿé‰´çš„æ¨¡å—åŒ–æœºåˆ¶ã€‚

**ä¸»è¦ç»“è®º**ï¼šæ¨¡å—åŒ–èƒ½é€šè¿‡â€œä¸“é—¨åŒ–ç»„ä»¶åˆ†è§£å­é—®é¢˜â€æå‡å­¦ä¹ æ•ˆç‡ã€å¯è¿ç§»æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šç±»AIæ–¹æ³•ä¸­åå¤å‡ºç°ï¼›å°†æ¨¡å—åŒ–åŸåˆ™ç³»ç»ŸåŒ–åœ°çº³å…¥AIæ¶æ„è®¾è®¡æœ‰æœ›ç¼©å°è‡ªç„¶æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½ä¹‹é—´çš„å·®è·ã€‚

**å…³é”®è¯**ï¼šæ¨¡å—åŒ–, æ¨¡å—åŒ–æ¶æ„, å½’çº³åç½®, å­é—®é¢˜åˆ†è§£, é«˜æ•ˆå­¦ä¹ , æ³›åŒ–èƒ½åŠ›, è„‘è®¡ç®—, ç¥ç»ç§‘å­¦å¯å‘, æ— å…è´¹åˆé¤å®šç†, è‡ªç„¶æ™ºèƒ½-äººå·¥æ™ºèƒ½å¯¹é½

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18960v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18960v1.pdf)

---

## [4. INDUCTION: Finite-Structure Concept Synthesis in First-Order Logic](https://arxiv.org/abs/2602.18956v1)

**ä½œè€…**ï¼šSerafim Batzoglou  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We introduce INDUCTION, a benchmark for finite structure concept synthesis in first order logic. Given small finite relational worlds with extensionally labeled target predicates, models must output a single first order logical formula that explains the target uniformly across worlds, with correctness verified via exact model checking. The benchmark includes three regimes, FullObs, CI (contrastive), and EC (existential completion), nd penalizes formula bloat. We find sharp difficulty gradients, persistent hard structural families, and observe that low bloat formulas generalize far better on held out worlds. Elite recent models show qualitatively different behaviors across tasks and performance metrics, hinting to their different strategies of concept generalization.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šINDUCTION æä¾›äº†ä¸€ä¸ªç”¨äºâ€œä¸€é˜¶é€»è¾‘å…¬å¼â€æ¦‚å¿µå½’çº³çš„åŸºå‡†ï¼šæ¨¡å‹éœ€åœ¨å¤šä¸ªå°å‹æœ‰é™å…³ç³»ä¸–ç•Œä¸­è¾“å‡ºç»Ÿä¸€ä¸”å¯ç²¾ç¡®éªŒè¯çš„é€»è¾‘å…¬å¼ï¼Œå¹¶æ˜¾ç¤ºä½å†—ä½™å…¬å¼æ›´èƒ½æ³›åŒ–ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰æ¨¡å‹è¯„æµ‹å¤šåœç•™åœ¨è‡ªç„¶è¯­è¨€æˆ–ç»Ÿè®¡æ‹Ÿåˆå±‚é¢ï¼Œéš¾ä»¥è¡¡é‡èƒ½å¦å­¦åˆ°å¯è§£é‡Šã€å¯éªŒè¯ä¸”è·¨ä¸–ç•Œä¸€è‡´çš„ç¬¦å·æ¦‚å¿µã€‚ä½œè€…å¸Œæœ›ç”¨ç²¾ç¡®æ¨¡å‹æ£€éªŒæ¥è¯„ä¼°æ¨¡å‹åœ¨æœ‰é™ç»“æ„ä¸Šçš„æ¦‚å¿µç»¼åˆèƒ½åŠ›ä¸æ³›åŒ–è§„å¾‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»º INDUCTION åŸºå‡†ï¼šç»™å®šè‹¥å¹²æœ‰é™å…³ç³»ç»“æ„ä¸–ç•ŒåŠå¤–å»¶æ ‡æ³¨çš„ç›®æ ‡è°“è¯ï¼Œè¦æ±‚è¾“å‡ºå•ä¸ªä¸€é˜¶é€»è¾‘å…¬å¼åœ¨æ‰€æœ‰ä¸–ç•Œä¸Šè§£é‡Šç›®æ ‡ï¼Œå¹¶ç”¨ç²¾ç¡® model checking åˆ¤å¯¹ã€‚è®¾ç½® FullObsã€CIï¼ˆå¯¹æ¯”å¼ï¼‰ä¸ ECï¼ˆå­˜åœ¨è¡¥å…¨ï¼‰ä¸‰ç§ä»»åŠ¡ä½“åˆ¶ï¼Œå¹¶å¯¹å…¬å¼è†¨èƒ€ï¼ˆbloatï¼‰è¿›è¡Œæƒ©ç½šä»¥é¼“åŠ±ç®€æ´è¡¨è¾¾ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒæ˜¾ç¤ºä»»åŠ¡å­˜åœ¨æ˜æ˜¾éš¾åº¦æ¢¯åº¦ä¸æŒç»­å›°éš¾çš„ç»“æ„å®¶æ—ï¼Œä¸”â€œä½ bloatâ€çš„å…¬å¼åœ¨ç•™å‡ºä¸–ç•Œä¸Šçš„æ³›åŒ–æ˜¾è‘—æ›´å¥½ã€‚ä¸åŒé¡¶çº§æ¨¡å‹åœ¨ä»»åŠ¡ä¸æŒ‡æ ‡ä¸Šçš„è¡Œä¸ºå·®å¼‚æ˜æ˜¾ï¼Œæš—ç¤ºå…¶æ¦‚å¿µæ³›åŒ–ç­–ç•¥å¹¶ä¸ç›¸åŒã€‚

**å…³é”®è¯**ï¼šä¸€é˜¶é€»è¾‘, æ¦‚å¿µåˆæˆ, æœ‰é™ç»“æ„, å…³ç³»ä¸–ç•Œ, é€»è¾‘å…¬å¼ç”Ÿæˆ, ç²¾ç¡®æ¨¡å‹æ£€éªŒ, åŸºå‡†è¯„æµ‹, å­˜åœ¨è¡¥å…¨, å…¬å¼è†¨èƒ€æƒ©ç½š, ç»“æ„æ³›åŒ–, éš¾ä¾‹ç»“æ„æ—

**è¯„åˆ†**ï¼š31

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18956v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18956v1.pdf)

---

## cs.CL

## [5. Whisper: Courtside Edition Enhancing ASR Performance Through LLM-Driven Context Generation](https://arxiv.org/abs/2602.18966v1)

**ä½œè€…**ï¼šYonathan Ron, Shiri Gilboa, Tammuz Dubnov  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Domain-specific speech remains a persistent challenge for automatic speech recognition (ASR), even for state-of-the-art systems like OpenAI's Whisper. We introduce Whisper: Courtside Edition, a novel multi-agent large language model (LLM) pipeline that enhances Whisper transcriptions without retraining. The pipeline intercepts Whisper's initial transcript, applies specialized LLM agents for domain context identification, named entity recognition, and jargon detection, and generates compact prompts that guide Whisper's decoder. Evaluated on 421 NBA basketball commentary segments (a domain characterized by dense proper nouns and technical terminology) our best pipeline achieves a statistically significant 17.0% relative reduction in word error rate (WER; from 0.217 to 0.180, p<0.001). Improvements are observed in 40.1% of segments with degradation in only 7.1%, substantially outperforming direct transcript post-editing. These results demonstrate that prompt-based augmentation can deliver scalable domain adaptation for ASR, offering a practical alternative to costly model fine-tuning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºâ€œWhisper: Courtside Editionâ€ç”¨å¤šæ™ºèƒ½ä½“LLMç”Ÿæˆé¢†åŸŸä¸Šä¸‹æ–‡æç¤ºæ¥å¼•å¯¼Whisperè§£ç ï¼Œåœ¨ä¸å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—é™ä½NBAè§£è¯´ASRé”™è¯¯ç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šWhisperç­‰é€šç”¨ASRåœ¨NBAè§£è¯´è¿™ç±»é¢†åŸŸè¯­éŸ³ä¸­å®¹æ˜“è¢«å¯†é›†ä¸“æœ‰åè¯ä¸æœ¯è¯­æ‹–ç´¯ï¼Œè€Œå¾®è°ƒæˆæœ¬é«˜ã€æ‰©å±•æ€§å·®ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå…ˆæˆªè·Whisperåˆå§‹è½¬å†™ï¼Œå†ç”±å¤šä¸ªä¸“ç”¨LLMä»£ç†å®Œæˆé¢†åŸŸä¸Šä¸‹æ–‡è¯†åˆ«ã€å‘½åå®ä½“è¯†åˆ«å’Œè¡Œè¯æ£€æµ‹ï¼Œå¹¶æŠŠç»“æœå‹ç¼©ä¸ºæç¤ºè¯æ³¨å…¥Whisperè§£ç å™¨ä»¥æ”¹è¿›åç»­è½¬å†™ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨421æ®µNBAè§£è¯´ä¸Šï¼Œæœ€ä½³æµæ°´çº¿å°†WERä»0.217é™è‡³0.180ï¼ˆç›¸å¯¹é™ä½17%ï¼Œp<0.001ï¼‰ï¼Œ40.1%ç‰‡æ®µå˜å¥½ä¸”ä»…7.1%å˜å·®ï¼Œå¹¶æ˜¾è‘—ä¼˜äºç›´æ¥å¯¹è½¬å†™åšLLMåç¼–è¾‘ï¼Œè¯æ˜æç¤ºå¢å¼ºå¯ä½œä¸ºä½æˆæœ¬å¯æ‰©å±•çš„é¢†åŸŸè‡ªé€‚åº”æ–¹æ¡ˆã€‚

**å…³é”®è¯**ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰, é¢†åŸŸè‡ªé€‚åº”, å¤šæ™ºèƒ½ä½“ LLM, ä¸Šä¸‹æ–‡ç”Ÿæˆ, å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰, æœ¯è¯­æ£€æµ‹, è§£ç å™¨å¼•å¯¼, å…è®­ç»ƒå¢å¼º, ä½“è‚²è§£è¯´è¯­éŸ³, è¯é”™è¯¯ç‡ï¼ˆWERï¼‰

**è¯„åˆ†**ï¼š40

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18966v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18966v1.pdf)

---

## [6. Yor-Sarc: A gold-standard dataset for sarcasm detection in a low-resource African language](https://arxiv.org/abs/2602.18964v1)

**ä½œè€…**ï¼šToheeb Aduramomi Jimoh, Tabea De Wille, Nikola S. Nikolov  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Sarcasm detection poses a fundamental challenge in computational semantics, requiring models to resolve disparities between literal and intended meaning. The challenge is amplified in low-resource languages where annotated datasets are scarce or nonexistent. We present \textbf{Yor-Sarc}, the first gold-standard dataset for sarcasm detection in YorÃ¹bÃ¡, a tonal Niger-Congo language spoken by over $50$ million people. The dataset comprises 436 instances annotated by three native speakers from diverse dialectal backgrounds using an annotation protocol specifically designed for YorÃ¹bÃ¡ sarcasm by taking culture into account. This protocol incorporates context-sensitive interpretation and community-informed guidelines and is accompanied by a comprehensive analysis of inter-annotator agreement to support replication in other African languages. Substantial to almost perfect agreement was achieved (Fleiss' $Îº= 0.7660$; pairwise Cohen's $Îº= 0.6732$--$0.8743$), with $83.3\%$ unanimous consensus. One annotator pair achieved almost perfect agreement ($Îº= 0.8743$; $93.8\%$ raw agreement), exceeding a number of reported benchmarks for English sarcasm research works. The remaining $16.7\%$ majority-agreement cases are preserved as soft labels for uncertainty-aware modelling. Yor-Sarc\footnote{https://github.com/toheebadura/yor-sarc} is expected to facilitate research on semantic interpretation and culturally informed NLP for low-resource African languages.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šYor-Sarc æ˜¯é¦–ä¸ªé¢å‘ä½èµ„æºéæ´²è¯­è¨€ YorÃ¹bÃ¡ çš„é«˜è´¨é‡è®½åˆºæ£€æµ‹æ•°æ®é›†ï¼Œæä¾›æ–‡åŒ–æ•æ„Ÿçš„æ ‡æ³¨åè®®ä¸é«˜ä¸€è‡´æ€§æ ‡æ³¨ç»“æœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè®½åˆºæ£€æµ‹éœ€è¦ç†è§£å­—é¢ä¸çœŸå®æ„å›¾çš„åå·®ï¼Œä½†ä½èµ„æºè¯­è¨€ç¼ºå°‘æ ‡æ³¨è¯­æ–™ï¼Œä½¿ç›¸å…³è¯­ä¹‰ä¸æ–‡åŒ–å› ç´ å»ºæ¨¡ç ”ç©¶å—é™ã€‚ä½œè€…å¸Œæœ›ä¸º YorÃ¹bÃ¡ æä¾›å¯å¤ç°çš„é‡‘æ ‡å‡†æ•°æ®ä¸æ ‡æ³¨è§„èŒƒï¼Œæ¨åŠ¨éæ´²è¯­è¨€çš„è®½åˆºä¸è¯­ä¹‰ç†è§£ç ”ç©¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºåŒ…å« 436 æ¡å®ä¾‹çš„æ•°æ®é›†ï¼Œç”±ä¸‰ä½ä¸åŒæ–¹è¨€èƒŒæ™¯çš„æ¯è¯­è€…ä¾æ®é¢å‘ YorÃ¹bÃ¡ æ–‡åŒ–è¯­å¢ƒçš„æ ‡æ³¨åè®®è¿›è¡Œæ ‡æ³¨ï¼Œå¹¶ç³»ç»ŸæŠ¥å‘Šä¸€è‡´æ€§æŒ‡æ ‡ï¼ˆFleiss Îºã€pairwise Cohen Îºï¼‰ã€‚å¯¹éä¸€è‡´æ ·æœ¬ä¿ç•™â€œè½¯æ ‡ç­¾â€ï¼ˆå¤šæ•°åŒæ„ï¼‰ä»¥æ”¯æŒä¸ç¡®å®šæ€§æ„ŸçŸ¥å»ºæ¨¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šæ•°æ®é›†æ ‡æ³¨ä¸€è‡´æ€§è¾¾åˆ°â€œè¾ƒé«˜åˆ°è¿‘ä¹å®Œç¾â€ï¼ˆFleiss Îº=0.7660ï¼Œ83.3% å…¨ä¸€è‡´ï¼‰ï¼Œå…¶ä¸­ä¸€å¯¹æ ‡æ³¨è€…è¾¾åˆ°è¿‘ä¹å®Œç¾ä¸€è‡´ï¼ˆÎº=0.8743ï¼‰ï¼Œå¹¶å°† 16.7% çš„å¤šæ•°ä¸€è‡´æ ·æœ¬ä½œä¸ºè½¯æ ‡ç­¾ä¿ç•™ï¼›Yor-Sarc é¢„è®¡å¯ä¿ƒè¿›ä½èµ„æºéæ´²è¯­è¨€ä¸­å…·æ–‡åŒ–ä¿¡æ¯çš„è®½åˆºæ£€æµ‹ä¸è¯­ä¹‰è§£é‡Šç ”ç©¶ã€‚

**å…³é”®è¯**ï¼šè®½åˆºæ£€æµ‹, ä½èµ„æºè¯­è¨€, çº¦é²å·´è¯­, éæ´²è¯­è¨€NLP, é‡‘æ ‡å‡†æ•°æ®é›†, äººå·¥æ ‡æ³¨åè®®, æ–‡åŒ–è¯­å¢ƒå»ºæ¨¡, æ ‡æ³¨ä¸€è‡´æ€§è¯„ä¼°, è½¯æ ‡ç­¾, ä¸ç¡®å®šæ€§æ„ŸçŸ¥å»ºæ¨¡

**è¯„åˆ†**ï¼š25

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18964v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18964v1.pdf)

---

## cs.CV

## [7. Frame2Freq: Spectral Adapters for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.18977v1)

**ä½œè€…**ï¼šThinesh Thiyakesan Ponbagavathi, Constantin Seibold, Alina Roitberg  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Adapting image-pretrained backbones to video typically relies on time-domain adapters tuned to a single temporal scale. Our experiments show that these modules pick up static image cues and very fast flicker changes, while overlooking medium-speed motion. Capturing dynamics across multiple time-scales is, however, crucial for fine-grained temporal analysis (i.e., opening vs. closing bottle).   To address this, we introduce Frame2Freq -- a family of frequency-aware adapters that perform spectral encoding during image-to-video adaptation of pretrained Vision Foundation Models (VFMs), improving fine-grained action recognition. Frame2Freq uses Fast Fourier Transform (FFT) along time and learns frequency-band specific embeddings that adaptively highlight the most discriminative frequency ranges. Across five fine-grained activity recognition datasets, Frame2Freq outperforms prior PEFT methods and even surpasses fully fine-tuned models on four of them. These results provide encouraging evidence that frequency analysis methods are a powerful tool for modeling temporal dynamics in image-to-video transfer. Code is available at https://github.com/th-nesh/Frame2Freq.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šFrame2Freqé€šè¿‡åœ¨æ—¶é—´ç»´åšFFTå¹¶å­¦ä¹ é¢‘æ®µç‰¹å®šçš„é€‚é…å™¨åµŒå…¥ï¼Œæ›´å¥½åœ°æ•æ‰å¤šæ—¶é—´å°ºåº¦è¿åŠ¨ï¼Œä»è€Œæå‡ç»†ç²’åº¦è§†é¢‘ç†è§£/åŠ¨ä½œè¯†åˆ«è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰ä»å›¾åƒåˆ°è§†é¢‘çš„é€‚é…å¤šä¾èµ–å•ä¸€æ—¶é—´å°ºåº¦çš„æ—¶åŸŸadapterï¼Œå¾€å¾€åªå­¦åˆ°é™æ€çº¿ç´¢å’Œæå¿«çš„é—ªçƒå˜åŒ–ï¼Œå¿½è§†ä¸­ç­‰é€Ÿåº¦è¿åŠ¨ï¼›è€Œç»†ç²’åº¦åŠ¨ä½œåŒºåˆ†éœ€è¦è¦†ç›–å¤šå°ºåº¦åŠ¨æ€ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºé¢‘ç‡æ„ŸçŸ¥é€‚é…å™¨Frame2Freqï¼šå¯¹è§†é¢‘ç‰¹å¾æ²¿æ—¶é—´ç»´è¿›è¡ŒFFTå¾—åˆ°é¢‘è°±è¡¨ç¤ºï¼Œå¹¶ä¸ºä¸åŒé¢‘æ®µå­¦ä¹ å¯è°ƒçš„é¢‘æ®µä¸“å±åµŒå…¥/æƒé‡ï¼Œä»¥è‡ªé€‚åº”çªå‡ºæœ€åˆ¤åˆ«çš„é¢‘ç‡èŒƒå›´ï¼Œå®ç°å‚æ•°é«˜æ•ˆçš„å›¾åƒé¢„è®­ç»ƒVFMåˆ°è§†é¢‘ä»»åŠ¡è¿ç§»ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨5ä¸ªç»†ç²’åº¦æ´»åŠ¨è¯†åˆ«æ•°æ®é›†ä¸Šï¼ŒFrame2Freqæ•´ä½“ä¼˜äºä»¥å¾€PEFTæ–¹æ³•ï¼Œå¹¶åœ¨å…¶ä¸­4ä¸ªæ•°æ®é›†ä¸Šç”šè‡³è¶…è¿‡å…¨é‡å¾®è°ƒæ¨¡å‹ï¼Œè¡¨æ˜é¢‘ç‡åˆ†ææ˜¯å»ºæ¨¡æ—¶åºåŠ¨æ€ã€æå‡å›¾åƒåˆ°è§†é¢‘è¿ç§»æ•ˆæœçš„æœ‰æ•ˆé€”å¾„ã€‚

**å…³é”®è¯**ï¼šç»†ç²’åº¦åŠ¨ä½œè¯†åˆ«, å›¾åƒåˆ°è§†é¢‘è¿ç§», è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMï¼‰, å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰, é¢‘åŸŸé€‚é…å™¨, è°±ç¼–ç , å¿«é€Ÿå‚…é‡Œå¶å˜æ¢ï¼ˆFFTï¼‰, å¤šæ—¶é—´å°ºåº¦è¿åŠ¨å»ºæ¨¡, é¢‘å¸¦åµŒå…¥, æ—¶åºåŠ¨æ€å»ºæ¨¡

**è¯„åˆ†**ï¼š23

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18977v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18977v1.pdf)

---

## [8. Face Presentation Attack Detection via Content-Adaptive Spatial Operators](https://arxiv.org/abs/2602.18965v1)

**ä½œè€…**ï¼šShujaat Khan  
**åˆ†ç±»**ï¼šcs.CV, eess.IV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Face presentation attack detection (FacePAD) is critical for securing facial authentication against print, replay, and mask-based spoofing. This paper proposes CASO-PAD, an RGB-only, single-frame model that enhances MobileNetV3 with content-adaptive spatial operators (involution) to better capture localized spoof cues. Unlike spatially shared convolution kernels, the proposed operator generates location-specific, channel-shared kernels conditioned on the input, improving spatial selectivity with minimal overhead. CASO-PAD remains lightweight (3.6M parameters; 0.64 GFLOPs at $256\times256$) and is trained end-to-end using a standard binary cross-entropy objective. Extensive experiments on Replay-Attack, Replay-Mobile, ROSE-Youtu, and OULU-NPU demonstrate strong performance, achieving 100/100/98.9/99.7\% test accuracy, AUC of 1.00/1.00/0.9995/0.9999, and HTER of 0.00/0.00/0.82/0.44\%, respectively. On the large-scale SiW-Mv2 Protocol-1 benchmark, CASO-PAD further attains 95.45\% accuracy with 3.11\% HTER and 3.13\% EER, indicating improved robustness under diverse real-world attacks. Ablation studies show that placing the adaptive operator near the network head and using moderate group sharing yields the best accuracy--efficiency balance. Overall, CASO-PAD provides a practical pathway for robust, on-device FacePAD with mobile-class compute and without auxiliary sensors or temporal stacks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºCASO-PADï¼šåœ¨MobileNetV3ä¸­å¼•å…¥å†…å®¹è‡ªé€‚åº”ç©ºé—´ç®—å­ï¼ˆinvolutionï¼‰çš„è½»é‡çº§å•å¸§RGBäººè„¸æ´»ä½“æ£€æµ‹æ¨¡å‹ï¼Œåœ¨å¤šæ•°æ®é›†ä¸Šå–å¾—æ¥è¿‘æ»¡åˆ†çš„ç²¾åº¦ä¸æä½HTERã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰FacePADåœ¨ç§»åŠ¨ç«¯å—é™äºç®—åŠ›ä¸æ¨¡å‹è§„æ¨¡ï¼ŒåŒæ—¶å·ç§¯æ ¸ç©ºé—´å…±äº«å¯¼è‡´å¯¹å±€éƒ¨ä¼ªé€ çº¿ç´¢ï¼ˆå¦‚æ‰“å°çº¹ç†ã€å±å¹•æ‘©å°”çº¹ã€é¢å…·è¾¹ç¼˜ï¼‰çš„ç©ºé—´é€‰æ‹©æ€§ä¸è¶³ï¼Œéœ€è¦æ›´é«˜æ•ˆä¸”æ›´æ•æ„Ÿçš„å±€éƒ¨å»ºæ¨¡èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåœ¨MobileNetV3ä¸­ç”¨å†…å®¹è‡ªé€‚åº”ç©ºé—´ç®—å­æ›¿æ¢/æ’å…¥éƒ¨åˆ†å·ç§¯ï¼šæ ¹æ®è¾“å…¥åœ¨æ¯ä¸ªä½ç½®ç”Ÿæˆä½ç½®ç‰¹å®šã€é€šé“å…±äº«çš„æ ¸ï¼ˆæå‡ç©ºé—´é€‰æ‹©æ€§ä¸”å¼€é”€å°ï¼‰ï¼Œç«¯åˆ°ç«¯ä»¥äºŒåˆ†ç±»äº¤å‰ç†µè®­ç»ƒï¼›æ¶ˆèè¡¨æ˜å°†è¯¥ç®—å­æ”¾åœ¨ç½‘ç»œé è¿‘headå¤„å¹¶é‡‡ç”¨é€‚åº¦åˆ†ç»„å…±äº«å¯å…¼é¡¾å‡†ç¡®ç‡ä¸æ•ˆç‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šCASO-PADåœ¨Replay-Attackã€Replay-Mobileã€ROSE-Youtuã€OULU-NPUä¸Šå®ç°æé«˜AUCä¸è¿‘é›¶HTERï¼Œå¹¶åœ¨æ›´å…·æŒ‘æˆ˜çš„SiW-Mv2 Protocol-1ä¸Šè·å¾—95.45%å‡†ç¡®ç‡ä¸è¾ƒä½HTER/EERï¼Œè¯æ˜å…¶åœ¨ä»…RGBå•å¸§ã€ç§»åŠ¨çº§è®¡ç®—é¢„ç®—ä¸‹å…·å¤‡æ›´å¼ºé²æ£’æ€§ä¸è½åœ°å¯è¡Œæ€§ã€‚

**å…³é”®è¯**ï¼šäººè„¸æ´»ä½“æ£€æµ‹, å±•ç¤ºæ”»å‡»æ£€æµ‹, äººè„¸åæ¬ºéª—, å†…å®¹è‡ªé€‚åº”ç©ºé—´ç®—å­, è½»é‡åŒ–æ¨¡å‹, ç«¯ä¾§æ¨ç†, æ‰“å°-å›æ”¾-é¢å…·æ”»å‡», Face

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18965v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18965v1.pdf)

---

## [9. Depth-Enhanced YOLO-SAM2 Detection for Reliable Ballast Insufficiency Identification](https://arxiv.org/abs/2602.18961v1)

**ä½œè€…**ï¼šShiyu Liu, Dylan Lester, Husnu Narman ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, eess.IV, eess.SY  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

This paper presents a depth-enhanced YOLO-SAM2 framework for detecting ballast insufficiency in railway tracks using RGB-D data. Although YOLOv8 provides reliable localization, the RGB-only model shows limited safety performance, achieving high precision (0.99) but low recall (0.49) due to insufficient ballast, as it tends to over-predict the sufficient class. To improve reliability, we incorporate depth-based geometric analysis enabled by a sleeper-aligned depth-correction pipeline that compensates for RealSense spatial distortion using polynomial modeling, RANSAC, and temporal smoothing. SAM2 segmentation further refines region-of-interest masks, enabling accurate extraction of sleeper and ballast profiles for geometric classification.   Experiments on field-collected top-down RGB-D data show that depth-enhanced configurations substantially improve the detection of insufficient ballast. Depending on bounding-box sampling (AABB or RBB) and geometric criteria, recall increases from 0.49 to as high as 0.80, and F1-score improves from 0.66 to over 0.80. These results demonstrate that integrating depth correction with YOLO-SAM2 yields a more robust and reliable approach for automated railway ballast inspection, particularly in visually ambiguous or safety-critical scenarios.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§ç»“åˆæ·±åº¦æ ¡æ­£ä¸YOLOv8+SAM2åˆ†å‰²çš„RGB-Dæ£€æµ‹æ¡†æ¶ï¼Œä»¥æ›´å¯é åœ°è¯†åˆ«é“è·¯é“ç Ÿä¸è¶³å¹¶æ˜¾è‘—æå‡å¬å›ç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä»…ç”¨RGBçš„YOLOv8è™½ç²¾åº¦é«˜ä½†å¬å›ä½ï¼ˆæ˜“æŠŠâ€œä¸è¶³â€è¯¯åˆ¤ä¸ºâ€œå……è¶³â€ï¼‰ï¼Œåœ¨å®‰å…¨å…³é”®åœºæ™¯ä¸‹ä¸å¯é ï¼›éœ€è¦åˆ©ç”¨æ·±åº¦å‡ ä½•ä¿¡æ¯ç¼“è§£è§†è§‰æ­§ä¹‰å¹¶æå‡å®‰å…¨æ€§èƒ½ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºä¸æ•æœ¨å¯¹é½çš„æ·±åº¦æ ¡æ­£æµç¨‹ï¼Œç”¨å¤šé¡¹å¼å»ºæ¨¡+RANSAC+æ—¶é—´å¹³æ»‘è¡¥å¿RealSenseç©ºé—´ç•¸å˜ï¼›å†ç”¨SAM2ç»†åŒ–ROIæ©è†œï¼Œæå–æ•æœ¨/é“ç Ÿå‰–é¢å¹¶åŸºäºå‡ ä½•å‡†åˆ™ï¼ˆé…åˆAABB/RBBé‡‡æ ·ï¼‰è¿›è¡Œä¸è¶³åˆ¤åˆ«ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å®é‡‡é¡¶è§†RGB-Dæ•°æ®ä¸Šï¼ŒåŠ å…¥æ·±åº¦å¢å¼ºåå¬å›ä»0.49æå‡è‡³æœ€é«˜0.80ã€F1ä»0.66æå‡è‡³>0.80ï¼Œè¯æ˜æ·±åº¦æ ¡æ­£+YOLO-SAM2èƒ½åœ¨è§†è§‰æ¨¡ç³Šæˆ–å®‰å…¨æ•æ„Ÿæƒ…å†µä¸‹æ›´ç¨³å¥åœ°æ£€æµ‹é“ç Ÿä¸è¶³ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å¢å¼º, è½¨é“æ£€æµ‹, é“ç Ÿä¸è¶³, å‡ ä½•åˆ†æ, æ·±åº¦æ ¡æ­£, è‡ªåŠ¨åŒ–æ£€æµ‹, å®‰å…¨æ€§èƒ½, æ¨¡å‹ç²¾åº¦

**è¯„åˆ†**ï¼š24

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18961v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18961v1.pdf)

---

## [10. YOLOv10-Based Multi-Task Framework for Hand Localization and Laterality Classification in Surgical Videos](https://arxiv.org/abs/2602.18959v1)

**ä½œè€…**ï¼šKedi Sun, Le Zhang  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Real-time hand tracking in trauma surgery is essential for supporting rapid and precise intraoperative decisions. We propose a YOLOv10-based framework that simultaneously localizes hands and classifies their laterality (left or right) in complex surgical scenes. The model is trained on the Trauma THOMPSON Challenge 2025 Task 2 dataset, consisting of first-person surgical videos with annotated hand bounding boxes. Extensive data augmentation and a multi-task detection design improve robustness against motion blur, lighting variations, and diverse hand appearances. Evaluation demonstrates accurate left-hand (67\%) and right-hand (71\%) classification, while distinguishing hands from the background remains challenging. The model achieves an $mAP_{[0.5:0.95]}$ of 0.33 and maintains real-time inference, highlighting its potential for intraoperative deployment. This work establishes a foundation for advanced hand-instrument interaction analysis in emergency surgical procedures.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åŸºäºYOLOv10çš„æ¡†æ¶ï¼Œå®ç°æ‰‹éƒ¨å®šä½å’Œä¾§åˆ«åˆ†ç±»ï¼Œä»¥æ”¯æŒåˆ›ä¼¤æ‰‹æœ¯ä¸­çš„å®æ—¶æ‰‹éƒ¨è·Ÿè¸ªã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå®æ—¶æ‰‹éƒ¨è·Ÿè¸ªå¯¹äºå¿«é€Ÿå’Œå‡†ç¡®çš„æ‰‹æœ¯å†³ç­–è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„åˆ›ä¼¤æ‰‹æœ¯åœºæ™¯ä¸­ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåˆ©ç”¨YOLOv10æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨å¸¦æœ‰æ‰‹éƒ¨è¾¹ç•Œæ¡†æ³¨é‡Šçš„æ‰‹æœ¯è§†é¢‘æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶é€šè¿‡æ•°æ®å¢å¼ºå’Œå¤šä»»åŠ¡æ£€æµ‹è®¾è®¡æ¥æå‡é²æ£’æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¨¡å‹åœ¨å·¦æ‰‹å’Œå³æ‰‹åˆ†ç±»ä¸Šåˆ†åˆ«è¾¾åˆ°67%å’Œ71%çš„å‡†ç¡®ç‡ï¼Œå¹¶å±•ç¤ºäº†åœ¨å®é™…æ‰‹æœ¯ä¸­éƒ¨ç½²çš„æ½œåŠ›ï¼Œå°½ç®¡åŒºåˆ†æ‰‹ä¸èƒŒæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

**å…³é”®è¯**ï¼šæ‰‹éƒ¨å®šä½, ä¾§åˆ«åˆ†ç±», æ‰‹æœ¯è§†é¢‘, å¤šä»»åŠ¡æ£€æµ‹, æ•°æ®å¢å¼º, å®æ—¶æ¨ç†, è¿åŠ¨æ¨¡ç³Š, å…‰ç…§å˜åŒ–, æ‰‹-å·¥å…·äº¤äº’

**è¯„åˆ†**ï¼š28

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18959v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18959v1.pdf)

---

## [11. Global Commander and Local Operative: A Dual-Agent Framework for Scene Navigation](https://arxiv.org/abs/2602.18941v1)

**ä½œè€…**ï¼šKaiming Jin, Yuefan Wu, Shengqiong Wu ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Vision-and-Language Scene navigation is a fundamental capability for embodied human-AI collaboration, requiring agents to follow natural language instructions to execute coherent action sequences in complex environments. Existing approaches either rely on multiple agents, incurring high coordination and resource costs, or adopt a single-agent paradigm, which overloads the agent with both global planning and local perception, often leading to degraded reasoning and instruction drift in long-horizon settings. To address these issues, we introduce DACo, a planning-grounding decoupled architecture that disentangles global deliberation from local grounding. Concretely, it employs a Global Commander for high-level strategic planning and a Local Operative for egocentric observing and fine-grained execution. By disentangling global reasoning from local action, DACo alleviates cognitive overload and improves long-horizon stability. The framework further integrates dynamic subgoal planning and adaptive replanning to enable structured and resilient navigation. Extensive evaluations on R2R, REVERIE, and R4R demonstrate that DACo achieves 4.9%, 6.5%, 5.4% absolute improvements over the best-performing baselines in zero-shot settings, and generalizes effectively across both closed-source (e.g., GPT-4o) and open-source (e.g., Qwen-VL Series) backbones. DACo provides a principled and extensible paradigm for robust long-horizon navigation. Project page: https://github.com/ChocoWu/DACo

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDACoæå‡ºâ€œå…¨å±€æŒ‡æŒ¥å®˜+æœ¬åœ°æ‰§è¡Œè€…â€çš„åŒä»£ç†è§£è€¦æ¡†æ¶ï¼Œå°†é•¿ç¨‹è§„åˆ’ä¸å±€éƒ¨æ„ŸçŸ¥æ‰§è¡Œåˆ†ç¦»ï¼Œä»è€Œæå‡è§†è§‰-è¯­è¨€åœºæ™¯å¯¼èˆªçš„é•¿æ—¶ç¨³å®šæ€§ä¸é›¶æ ·æœ¬æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå•ä»£ç†å¾€å¾€åŒæ—¶æ‰¿æ‹…å…¨å±€æ¨ç†ä¸å±€éƒ¨è½åœ°ï¼Œé•¿åºåˆ—ä»»åŠ¡ä¸­æ˜“è®¤çŸ¥è¿‡è½½å¹¶äº§ç”ŸæŒ‡ä»¤æ¼‚ç§»ï¼›å¤šä»£ç†æ–¹æ¡ˆåˆå¸¦æ¥åè°ƒä¸èµ„æºå¼€é”€ã€‚ä½œè€…å¸Œæœ›ä»¥æ›´ä½åä½œæˆæœ¬è·å¾—æ›´ç¨³å¥çš„é•¿ç¨‹å¯¼èˆªèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ¡†æ¶åŒ…å«Global Commanderè´Ÿè´£é«˜å±‚ç­–ç•¥ä¸å­ç›®æ ‡ç”Ÿæˆï¼ŒLocal OperativeåŸºäºè‡ªæˆ‘è§†è§’è§‚æµ‹è¿›è¡Œç»†ç²’åº¦åŠ¨ä½œæ‰§è¡Œä¸ç¯å¢ƒå¯¹é½ã€‚å¹¶å¼•å…¥åŠ¨æ€å­ç›®æ ‡è§„åˆ’ä¸è‡ªé€‚åº”é‡è§„åˆ’æœºåˆ¶ï¼Œåœ¨æ‰§è¡Œåç¦»æˆ–ç¯å¢ƒå˜åŒ–æ—¶åŠæ—¶è°ƒæ•´ä»¥ä¿æŒç»“æ„åŒ–æ¨è¿›ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨R2Rã€REVERIEã€R4Rçš„é›¶æ ·æœ¬è¯„æµ‹ä¸­ï¼ŒDACoç›¸å¯¹æœ€ä½³åŸºçº¿å–å¾—çº¦4.9%ã€6.5%ã€5.4%çš„ç»å¯¹æå‡ã€‚è¯¥æ–¹æ³•å¯åœ¨é—­æºï¼ˆå¦‚GPT-4oï¼‰ä¸å¼€æºï¼ˆå¦‚Qwen-VLç³»åˆ—ï¼‰éª¨å¹²ä¸Šæœ‰æ•ˆæ³›åŒ–ï¼Œè¡¨æ˜è§£è€¦å¼è§„åˆ’-è½åœ°èŒƒå¼æœ‰åŠ©äºé²æ£’é•¿ç¨‹å¯¼èˆªã€‚

**å…³é”®è¯**ï¼šè§†è§‰è¯­è¨€å¯¼èˆª, å…·èº«æ™ºèƒ½, è‡ªç„¶è¯­è¨€æŒ‡ä»¤è·Ÿéš, é•¿æ—¶åºå¯¼èˆª, åŒæ™ºèƒ½ä½“æ¶æ„, å…¨å±€è§„åˆ’, å±€éƒ¨æ„ŸçŸ¥ä¸æ‰§è¡Œ, è§„åˆ’-è½åœ°è§£è€¦, å­ç›®æ ‡è§„åˆ’, è‡ªé€‚åº”é‡è§„åˆ’, é›¶æ ·æœ¬æ³›åŒ–

**è¯„åˆ†**ï¼š39

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18941v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18941v1.pdf)

---

## cs.LG

## [12. Conditionally Site-Independent Neural Evolution of Antibody Sequences](https://arxiv.org/abs/2602.18982v1)

**ä½œè€…**ï¼šStephen Zhewen Lu, Aakarsh Vermani, Kohei Sanno ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, q-bio.PE  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Common deep learning approaches for antibody engineering focus on modeling the marginal distribution of sequences. By treating sequences as independent samples, however, these methods overlook affinity maturation as a rich and largely untapped source of information about the evolutionary process by which antibodies explore the underlying fitness landscape. In contrast, classical phylogenetic models explicitly represent evolutionary dynamics but lack the expressivity to capture complex epistatic interactions. We bridge this gap with CoSiNE, a continuous-time Markov chain parameterized by a deep neural network. Mathematically, we prove that CoSiNE provides a first-order approximation to the intractable sequential point mutation process, capturing epistatic effects with an error bound that is quadratic in branch length. Empirically, CoSiNE outperforms state-of-the-art language models in zero-shot variant effect prediction by explicitly disentangling selection from context-dependent somatic hypermutation. Finally, we introduce Guided Gillespie, a classifier-guided sampling scheme that steers CoSiNE at inference time, enabling efficient optimization of antibody binding affinity toward specific antigens.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºCoSiNEï¼šç”¨ç¥ç»ç½‘ç»œå‚æ•°åŒ–çš„è¿ç»­æ—¶é—´é©¬å°”å¯å¤«é“¾æ¥å»ºæ¨¡æŠ—ä½“äº²å’ŒåŠ›æˆç†Ÿçš„è¿›åŒ–è¿‡ç¨‹ï¼Œå¹¶åœ¨é›¶æ ·æœ¬å˜ä½“æ•ˆåº”é¢„æµ‹ä¸å®šå‘äº²å’ŒåŠ›ä¼˜åŒ–ä¸Šä¼˜äºç°æœ‰è¯­è¨€æ¨¡å‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä»…æ‹ŸåˆæŠ—ä½“åºåˆ—è¾¹ç¼˜åˆ†å¸ƒçš„æ·±åº¦æ¨¡å‹å¿½ç•¥äº†äº²å’ŒåŠ›æˆç†Ÿä¸­â€œæ²¿è°±ç³»æ¼”åŒ–â€çš„ä¿¡æ¯ï¼Œè€Œä¼ ç»Ÿç³»ç»Ÿå‘è‚²æ¨¡å‹è™½åˆ»ç”»åŠ¨åŠ›å­¦ä½†éš¾ä»¥è¡¨è¾¾å¤æ‚ä¸Šä½æ€§ä¸ä¸Šä¸‹æ–‡ä¾èµ–çªå˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºCoSiNEï¼ˆè¿ç»­æ—¶é—´Markové“¾+æ·±åº¦ç½‘ç»œå‚æ•°åŒ–çš„æ›¿æ¢ç‡ï¼‰ä»¥è¿‘ä¼¼åºåˆ—ç‚¹çªå˜è¿‡ç¨‹ï¼Œå¹¶ç»™å‡ºè¯¯å·®éšåˆ†æ”¯é•¿åº¦äºŒæ¬¡å¢é•¿çš„ç†è®ºç•Œï¼›åŒæ—¶æ˜¾å¼åˆ†ç¦»é€‰æ‹©æ•ˆåº”ä¸ä½“ç»†èƒé«˜çªå˜çš„ä¸Šä¸‹æ–‡æ•ˆåº”ï¼Œå¹¶æå‡ºGuided Gillespieåœ¨é‡‡æ ·æ—¶ç”¨åˆ†ç±»å™¨å¼•å¯¼ä»¥é«˜æ•ˆæœç´¢ç‰¹å®šæŠ—åŸçš„é«˜äº²å’ŒåŠ›åºåˆ—ã€‚

**ä¸»è¦ç»“è®º**ï¼šCoSiNEåœ¨é›¶æ ·æœ¬å˜ä½“æ•ˆåº”é¢„æµ‹ä¸Šè¶…è¿‡SOTAè¯­è¨€æ¨¡å‹ï¼Œè¯´æ˜å°†è¿›åŒ–åŠ¨åŠ›å­¦ä¸å¯è¡¨è¾¾çš„ç¥ç»å‚æ•°åŒ–ç»“åˆèƒ½æ›´å¥½æ•è·ä¸Šä½æ€§ä¸é€‰æ‹©/çªå˜æœºåˆ¶ï¼›Guided Gillespieè¿›ä¸€æ­¥å®ç°äº†é¢å‘ç›®æ ‡æŠ—åŸçš„é«˜æ•ˆäº²å’ŒåŠ›ä¼˜åŒ–ç”Ÿæˆã€‚

**å…³é”®è¯**ï¼šæŠ—ä½“åºåˆ—è®¾è®¡, äº²å’ŒåŠ›æˆç†Ÿå»ºæ¨¡, ä½“ç»†èƒè¶…çªå˜, è¡¨è§‚é—ä¼ äº’ä½œ, é€‚åº”åº¦æ™¯è§‚, è¿ç»­æ—¶é—´é©¬å°”å¯å¤«é“¾, ç¥ç»å‚æ•°åŒ–è¿›åŒ–æ¨¡å‹, ç³»ç»Ÿå‘è‚²åŠ¨åŠ›å­¦, é›¶æ ·æœ¬å˜ä½“æ•ˆåº”é¢„æµ‹, åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·, ç»“åˆäº²å’ŒåŠ›ä¼˜åŒ–

**è¯„åˆ†**ï¼š33

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18982v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18982v1.pdf)

---

## [13. Incremental Transformer Neural Processes](https://arxiv.org/abs/2602.18955v1)

**ä½œè€…**ï¼šPhilip Mortimer, Cristiana Diaconu, Tommy Rochussen ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Neural Processes (NPs), and specifically Transformer Neural Processes (TNPs), have demonstrated remarkable performance across tasks ranging from spatiotemporal forecasting to tabular data modelling. However, many of these applications are inherently sequential, involving continuous data streams such as real-time sensor readings or database updates. In such settings, models should support cheap, incremental updates rather than recomputing internal representations from scratch for every new observation -- a capability existing TNP variants lack. Drawing inspiration from Large Language Models, we introduce the Incremental TNP (incTNP). By leveraging causal masking, Key-Value (KV) caching, and a data-efficient autoregressive training strategy, incTNP matches the predictive performance of standard TNPs while reducing the computational cost of updates from quadratic to linear time complexity. We empirically evaluate our model on a range of synthetic and real-world tasks, including tabular regression and temperature prediction. Our results show that, surprisingly, incTNP delivers performance comparable to -- or better than -- non-causal TNPs while unlocking orders-of-magnitude speedups for sequential inference. Finally, we assess the consistency of the model's updates -- by adapting a metric of ``implicit Bayesianness", we show that incTNP retains a prediction rule as implicitly Bayesian as standard non-causal TNPs, demonstrating that incTNP achieves the computational benefits of causal masking without sacrificing the consistency required for streaming inference.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºå¯å¢é‡æ›´æ–°çš„ Incremental Transformer Neural Processï¼ˆincTNPï¼‰ï¼Œç”¨å› æœæ©ç ä¸KVç¼“å­˜å°†æµå¼æ›´æ–°è®¡ç®—ä»äºŒæ¬¡é™åˆ°çº¿æ€§ï¼ŒåŒæ—¶ä¿æŒä¸æ ‡å‡†TNPç›¸å½“ç”šè‡³æ›´å¥½çš„é¢„æµ‹è¡¨ç°ä¸ä¸€è‡´æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè®¸å¤šTNPåº”ç”¨å¤©ç„¶æ˜¯è¿ç»­æ•°æ®æµåœºæ™¯ï¼ˆä¼ æ„Ÿå™¨/æ•°æ®åº“æ›´æ–°ç­‰ï¼‰ï¼Œä½†ç°æœ‰TNPæ¯æ¥æ–°è§‚æµ‹å¸¸éœ€é‡ç®—å†…éƒ¨è¡¨ç¤ºï¼Œå¢é‡æ¨ç†ä»£ä»·é«˜ä¸”ä¸é€‚åˆå®æ—¶éƒ¨ç½²ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå€Ÿé‰´LLMæ¨ç†æœºåˆ¶ï¼Œå¼•å…¥å› æœï¼ˆè‡ªå›å½’ï¼‰æ³¨æ„åŠ›ã€Key-Valueç¼“å­˜ä»¥å¤ç”¨å†å²è®¡ç®—ï¼Œå¹¶é‡‡ç”¨æ›´æ•°æ®é«˜æ•ˆçš„è‡ªå›å½’è®­ç»ƒç­–ç•¥ï¼Œä½¿æ¨¡å‹èƒ½åœ¨æ–°å¢è§‚æµ‹æ—¶è¿›è¡Œå»‰ä»·çš„é¡ºåºæ›´æ–°ä¸é¢„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨åˆæˆä¸çœŸå®ä»»åŠ¡ï¼ˆå¦‚è¡¨æ ¼å›å½’ã€æ¸©åº¦é¢„æµ‹ï¼‰ä¸Šï¼ŒincTNPé¢„æµ‹ç²¾åº¦ä¸éå› æœTNPæŒå¹³æˆ–æ›´ä¼˜ï¼Œå¹¶åœ¨é¡ºåºæ¨ç†ä¸­å®ç°æ•°é‡çº§åŠ é€Ÿï¼›é€šè¿‡æ”¹é€ çš„â€œéšå¼è´å¶æ–¯æ€§â€æŒ‡æ ‡éªŒè¯å…¶æ›´æ–°è§„åˆ™çš„ä¸€è‡´æ€§ä¸é€Šäºæ ‡å‡†TNPã€‚

**å…³é”®è¯**ï¼šåºåˆ—æ¨ç†, å› æœæ©è”½, KVç¼“å­˜, è‡ªå›å½’è®­ç»ƒ, æ¸©åº¦é¢„æµ‹, è¡¨æ ¼å›å½’, è®¡ç®—æ•ˆç‡, éšå¼è´å¶æ–¯æ€§

**è¯„åˆ†**ï¼š30

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18955v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18955v1.pdf)

---

## [14. Toward Manifest Relationality in Transformers via Symmetry Reduction](https://arxiv.org/abs/2602.18948v1)

**ä½œè€…**ï¼šJ. FranÃ§ois, L. Ravera  
**åˆ†ç±»**ï¼šcs.LG, cs.NE, hep-th, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºç”¨â€œå¯¹ç§°æ€§çº¦åŒ–â€æŠŠTransformerçš„è¡¨ç¤ºä¸æ³¨æ„åŠ›æ”¹å†™ä¸ºä¸å˜é‡çš„å…³ç³»é‡ï¼Œä»æ„é€ ä¸Šæ¶ˆé™¤å†—ä½™å¹¶è·å¾—æ›´å…·å‡ ä½•åŸåˆ™çš„æ¶æ„ä¸ä¼˜åŒ–åˆ†æè§†è§’ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šTransformerå†…éƒ¨å­˜åœ¨ç”±åæ ‡ä¾èµ–è¡¨ç¤ºä¸è¿ç»­å¯¹ç§°æ€§ï¼ˆæ¨¡å‹ç©ºé—´/æ³¨æ„åŠ›å¤´ç©ºé—´ï¼‰å¸¦æ¥çš„å†—ä½™è‡ªç”±åº¦ï¼Œå¯¼è‡´å‚æ•°ä¸è¡¨ç¤ºé‡å¤ã€éš¾ä»¥åˆ†æä¼˜åŒ–è¿‡ç¨‹ã€‚ç°æœ‰â€œæ˜¾å¼ç ´åå¯¹ç§°æ€§â€çš„æ–¹æ³•ä¸å¤Ÿç³»ç»Ÿï¼Œå› æ­¤å¸Œæœ›ä»¥æ›´åŸåˆ™åŒ–çš„æ–¹å¼å»é™¤å†—ä½™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå°†è¡¨ç¤ºã€æ³¨æ„åŠ›æœºåˆ¶ä»¥åŠä¼˜åŒ–åŠ¨åŠ›å­¦ç»Ÿä¸€é‡å†™ä¸ºå¯¹ç§°ç¾¤ä½œç”¨ä¸‹çš„ä¸å˜é‡ï¼ˆrelational quantitiesï¼‰ï¼Œé€šè¿‡å¯¹ç§°æ€§çº¦åŒ–åœ¨å»ºæ¨¡å±‚é¢ç›´æ¥æ¶ˆæ‰å†—ä½™åæ ‡/è‡ªç”±åº¦ã€‚ç”±æ­¤å¾—åˆ°ç›´æ¥åœ¨å…³ç³»ç»“æ„ä¸Šè¿ç®—çš„Transformerå˜ä½“ï¼Œå¹¶æä¾›ç”¨äºç†è§£å‚æ•°å†—ä½™ä¸è®­ç»ƒè¡Œä¸ºçš„å‡ ä½•æ¡†æ¶ã€‚

**ä¸»è¦ç»“è®º**ï¼šä»¥ä¸å˜é‡å…³ç³»é‡ä¸ºæ ¸å¿ƒçš„å¯¹ç§°æ€§çº¦åŒ–å¯åœ¨ä¸ä¾èµ–äººä¸ºâ€œç ´åå¯¹ç§°æ€§â€çš„æƒ…å†µä¸‹ç³»ç»Ÿæ€§å‡å°‘Transformerçš„å†…éƒ¨å†—ä½™ï¼Œå¹¶ä¸ºæ¶æ„è®¾è®¡ä¸ä¼˜åŒ–åˆ†ææä¾›æ›´æ¸…æ™°çš„å‡ ä½•è§£é‡Šã€‚è¯¥è§†è§’é¢„ç¤ºå¯æ„é€ æ›´å‚æ•°é«˜æ•ˆã€å¯è§£é‡Šæ€§æ›´å¼ºçš„å…³ç³»å‹æ³¨æ„åŠ›æ¨¡å‹ã€‚

**å…³é”®è¯**ï¼šè¿ç»­å¯¹ç§°æ€§, åæ ‡æ— å…³è¡¨ç¤º, ä¸å˜é‡å…³ç³»é‡, å…³ç³»è¡¨ç¤ºå­¦ä¹ , æ³¨æ„åŠ›æœºåˆ¶ä¸å˜é‡, ä¼˜åŒ–åŠ¨åŠ›å­¦, å‚æ•°å†—ä½™æ¶ˆé™¤, å‡ ä½•æ·±åº¦å­¦ä¹ , å¤´ç©ºé—´å¯¹ç§°æ€§

**è¯„åˆ†**ï¼š25

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18948v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18948v1.pdf)

---

## [15. Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression](https://arxiv.org/abs/2602.18946v1)

**ä½œè€…**ï¼šSacchit Kale, Piyushi Manupriya, Pierre Marion ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, math.OC  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-21

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Gradient descent and stochastic gradient descent are central to modern machine learning, yet their behavior under large step sizes remains theoretically unclear. Recent work suggests that acceleration often arises near the edge of stability, where optimization trajectories become unstable and difficult to analyze. Existing results for separable logistic regression achieve faster convergence by explicitly leveraging such unstable regimes through constant or adaptive large step sizes. In this paper, we show that instability is not inherent to acceleration. We prove that gradient descent with a simple, non-adaptive increasing step-size schedule achieves exponential convergence for separable logistic regression under a margin condition, while remaining entirely within a stable optimization regime. The resulting method is anytime and does not require prior knowledge of the optimization horizon or target accuracy. We also establish exponential convergence of stochastic gradient descent using a lightweight adaptive step-size rule that avoids line search and specialized procedures, improving upon existing polynomial-rate guarantees. Together, our results demonstrate that carefully structured step-size growth alone suffices to obtain exponential acceleration for both gradient descent and stochastic gradient descent.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºä¸€ç§ç®€å•çš„æ­¥é•¿å¢é•¿ç­–ç•¥ï¼Œä½¿å¯åˆ†é€»è¾‘å›å½’ä¸Šçš„ï¼ˆéšæœºï¼‰æ¢¯åº¦ä¸‹é™åœ¨ç¨³å®šåŒºé—´å†…ä»èƒ½è¾¾åˆ°æŒ‡æ•°æ”¶æ•›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä»¥å¾€åœ¨å¯åˆ†é€»è¾‘å›å½’ä¸­è·å¾—åŠ é€Ÿå¾€å¾€ä¾èµ–â€œå¤§æ­¥é•¿/æ¥è¿‘ç¨³å®šè¾¹ç•Œâ€çš„ä¸ç¨³å®šè½¨è¿¹ï¼Œç†è®ºåˆ†æå›°éš¾ä¸”å¸¸éœ€è°ƒå‚æˆ–å·²çŸ¥ä¼˜åŒ–æ—¶åŸŸï¼›ä½œè€…å¸Œæœ›è¯æ˜åŠ é€Ÿä¸å¿…ä¾èµ–ä¸ç¨³å®šæ€§ï¼Œå¹¶ç»™å‡ºæ›´â€œanytimeâ€çš„æ­¥é•¿æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¯¹GDè®¾è®¡éè‡ªé€‚åº”ã€å•è°ƒé€’å¢çš„æ­¥é•¿æ—¥ç¨‹ï¼Œåœ¨æ»¡è¶³marginæ¡ä»¶ä¸‹è¯æ˜å…¶å…¨ç¨‹å¤„äºç¨³å®šä¼˜åŒ–åŒºåŸŸä¸”å®ç°æŒ‡æ•°æ”¶æ•›ï¼›å¯¹SGDæå‡ºè½»é‡çº§è‡ªé€‚åº”æ­¥é•¿è§„åˆ™ï¼ˆæ— éœ€çº¿æœç´¢ç­‰å¤æ‚æœºåˆ¶ï¼‰ï¼Œå¹¶å»ºç«‹ç›¸åº”çš„æŒ‡æ•°æ”¶æ•›åˆ†æã€‚

**ä¸»è¦ç»“è®º**ï¼šä¸éœ€è¦åˆ©ç”¨ä¸ç¨³å®šåŠ¨åŠ›å­¦ï¼Œä»…é€šè¿‡ç»“æ„åŒ–çš„æ­¥é•¿å¢é•¿å³å¯è®©å¯åˆ†é€»è¾‘å›å½’çš„GDè·å¾—æŒ‡æ•°æ”¶æ•›å¹¶å…·å¤‡anytimeæ€§è´¨ï¼›åŒæ—¶SGDä¹Ÿå¯ç”¨ç®€æ´è‡ªé€‚åº”æ­¥é•¿ä»å·²æœ‰çš„å¤šé¡¹å¼æ”¶æ•›æå‡åˆ°æŒ‡æ•°æ”¶æ•›ä¿è¯ã€‚

**å…³é”®è¯**ï¼šå¯åˆ†é€»è¾‘å›å½’, æŒ‡æ•°æ”¶æ•›, æ¢¯åº¦ä¸‹é™, éšæœºæ¢¯åº¦ä¸‹é™, æ­¥é•¿å¢é•¿ç­–ç•¥, è‡ªé€‚åº”æ­¥é•¿, ç¨³å®šä¼˜åŒ–, ç¨³å®šæ€§è¾¹ç•Œ, é—´éš”æ¡ä»¶, åŠ é€Ÿæ”¶æ•›

**è¯„åˆ†**ï¼š22

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.18946v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.18946v1.pdf)

---

