# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-07

> å…± 30 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ðŸ“‘ ç›®å½•

<<<<<<< HEAD
- [cs.LG](#csLG) (13 ç¯‡)
- [cs.AI](#csAI) (5 ç¯‡)
- [cs.CV](#csCV) (8 ç¯‡)
=======
- [cs.CV](#csCV) (6 ç¯‡)
- [cs.LG](#csLG) (18 ç¯‡)
- [cs.AI](#csAI) (2 ç¯‡)
>>>>>>> c7131d2 (Backfill recent data and stabilize unified fetch workflow)
- [cs.CL](#csCL) (4 ç¯‡)

---

## cs.AI

<<<<<<< HEAD
## [1. DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching](https://arxiv.org/abs/2602.06039v1)

**ä½œè€…**ï¼šYuxing Lu, Yucheng Hu, Xukai Zhao ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMulti-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly match...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šAgent Reasoning via Semantic Matching, agent systems built from prompted large language models can improve multi, agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06039v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06039v1.pdf)

---

## [2. Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023v1)

**ä½œè€…**ï¼šChristopher A. McClurg, Alan R. Wagner  
**åˆ†ç±»**ï¼šcs.AI, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šVirtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity....

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šwhich typically require many training episodes. To address this challenge, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06023v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06023v1.pdf)

---

## [3. AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008v1)

**ä½œè€…**ï¼šXianyang Liu, Shangding Gu, Dawn Song  
**åˆ†ç±»**ï¼šcs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šLarge language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šAgenticPay: A Multi, Agent LLM Negotiation System for Buyer, Large language model (LLM), based agents are increasingly expected to negotiate, and transact autonomously, mediated economic interaction among multiple agents. We introduce AgenticPay, agent buyer, seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product, round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many, weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long, establishing AgenticPay as a foundation for studying agentic commerce and language, based market interaction. Code and dataset are available at the link: https://github.com/SafeRL, Lab/AgenticPay.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06008v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06008v1.pdf)

---

## [4. Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000v1)

**ä½œè€…**ï¼šAli Shendabadi, Parnia Izadirad, Mostafa Salehi ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSpeech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for do...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šSpeech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods, Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre, trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, trained ASR system, head Attentive Average Pooling and QKV Pooling

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06000v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06000v1.pdf)

---

## [5. Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins](https://arxiv.org/abs/2602.05983v1)

**ä½œè€…**ï¼šKreÅ¡imir KuÅ¡iÄ‡, Vinny Cahill, Ivana Dusparic  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate predicted traffic conditions in addition to real-time observations. Due to the spatio-temporal complexity and the time-variant, non-linear nature of traffic dynamics, predicting motorway traffic remains a difficult problem. Sequence-based deep-learning models offer clear advantages over classical machine learning and statistical models in capturing long-range, temporal dependencies in time-series traffic data, yet limitations in forecasting accuracy and model complexity point to the need for further improvements. To improve motorway traffic forecasting, this paper introduces a Geographically-aware Transformer-based Traffic Forecasting GATTF model, which exploits the geographical relationships between distributed sensors using their mutual information (MI). The model has been evaluated using real-time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer, without increasing model complexity.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šThe operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a pro...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šaware Transformer, twin technology in motorway traffic management depends on the availability of a continuous flow of high, predicting motorway traffic remains a difficult problem. Sequence, learning models offer clear advantages over classical machine learning and statistical models in capturing long, time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05983v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05983v1.pdf)
=======
## [1. Agentic Uncertainty Reveals Agentic Overconfidence](https://arxiv.org/abs/2602.06948v1)

**ä½œè€…**ï¼šJean Kaddour, Srijan Patel, GbÃ¨tondji Dovonon ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šç ”ç©¶å‘çŽ°AIä»£ç†åœ¨ä»»åŠ¡æˆåŠŸé¢„æµ‹ä¸Šè¡¨çŽ°å‡ºè¿‡åº¦è‡ªä¿¡ï¼Œé¢„æ‰§è¡Œè¯„ä¼°çš„æ•ˆæžœä¼˜äºŽåŽæ‰§è¡Œå›žé¡¾ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæŽ¢è®¨AIä»£ç†åœ¨æ‰§è¡Œä»»åŠ¡æ—¶æ˜¯å¦èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æˆåŠŸæ¦‚çŽ‡ï¼Œä»¥ç†è§£å…¶å†³ç­–è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡åœ¨ä»»åŠ¡æ‰§è¡Œå‰ã€ä¸­ã€åŽæ”¶é›†æˆåŠŸæ¦‚çŽ‡ä¼°è®¡ï¼Œè¯„ä¼°ä»£ç†çš„è‡ªä¿¡ç¨‹åº¦ã€‚

**ä¸»è¦ç»“è®º**ï¼šå°½ç®¡ä¸€äº›ä»£ç†çš„æˆåŠŸçŽ‡ä»…ä¸º22%ï¼Œä½†ä»–ä»¬é¢„æµ‹çš„æˆåŠŸçŽ‡é«˜è¾¾77%ï¼›è€Œä¸”ï¼Œå‰æœŸè¯„ä¼°åœ¨ä¿¡æ¯è¾ƒå°‘çš„æƒ…å†µä¸‹é€šå¸¸èƒ½æ›´å¥½åœ°åŒºåˆ†æˆåŠŸä¸Žå¦ã€‚

**å…³é”®è¯**ï¼šæ™ºèƒ½ä»£ç†, ä»£ç†ä¸ç¡®å®šæ€§, ä»»åŠ¡æ‰§è¡Œ, æˆåŠŸæ¦‚çŽ‡, é¢„æ‰§è¡Œè¯„ä¼°, å¯¹æŠ—æç¤º, è¯„ä¼°æ ¡å‡†, agentic overconfidence, human-in-the-loop

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06948v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06948v1.pdf)

---

## [2. AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855v1)

**ä½œè€…**ï¼šAlisia Lupidi, Bhavul Gauri, Thomas Simon Foster ç­‰ 37 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šAIRS-Benchæ˜¯ä¸€ä¸ªé’ˆå¯¹å‰æ²¿AIç ”ç©¶ç§‘å­¦ä»£ç†çš„ä»»åŠ¡å¥—ä»¶ï¼ŒåŒ…å«20ä¸ªæ¥è‡ªé¢†å…ˆæœºå™¨å­¦ä¹ è®ºæ–‡çš„ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°æ™ºèƒ½ä½“åœ¨ç§‘å­¦ç ”ç©¶ç”Ÿå‘½å‘¨æœŸä¸­çš„èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡åž‹ä»£ç†åœ¨ç§‘å­¦ç ”ç©¶ä¸­çš„æ½œåŠ›é€æ­¥æ˜¾çŽ°ï¼Œæ€¥éœ€ä¸€ä¸ªæ ‡å‡†åŒ–çš„åŸºå‡†æ¥åŠ é€Ÿè¿™ä¸€é¢†åŸŸçš„å‘å±•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIRS-Benchæä¾›å¤šæ ·åŒ–çš„ä»»åŠ¡æ ¼å¼ï¼Œæ¶µç›–è¯­è¨€å»ºæ¨¡ã€æ•°å­¦ã€ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰é¢†åŸŸï¼Œæ”¯æŒæ–°ä»»åŠ¡çš„è½»æ¾é›†æˆå’Œä¸åŒæ™ºèƒ½ä½“æ¡†æž¶çš„æ¯”è¾ƒã€‚

**ä¸»è¦ç»“è®º**ï¼šå°½ç®¡åœ¨å››é¡¹ä»»åŠ¡ä¸­æ™ºèƒ½ä½“è¶…è¶Šäº†äººç±»çš„æœ€å¥½è¡¨çŽ°ï¼Œä½†åœ¨å…¶ä»–åå…­é¡¹ä»»åŠ¡ä¸­ä»æœªè¾¾åˆ°äººç±»æ°´å¹³ï¼Œè¡¨æ˜ŽAIRS-Benchä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚

**å…³é”®è¯**ï¼šLLM, agent, machine learning, æ·±åº¦å­¦ä¹ , è‡ªä¸»ä»£ç†, ä»»åŠ¡è¯„ä¼°, å®žéªŒåˆ†æž, è¿­ä»£ä¼˜åŒ–, ç§‘å­¦ç ”ç©¶

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06855v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06855v1.pdf)
>>>>>>> c7131d2 (Backfill recent data and stabilize unified fetch workflow)

---

## cs.CL

<<<<<<< HEAD
## [6. Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025v1)

**ä½œè€…**ï¼šHaozhen Zhang, Haodong Yue, Tao Feng ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMemory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be ...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šTier Routing for Runtime Agent Memory, Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, a runtime agent memory framework for explicit, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06025v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06025v1.pdf)

---

## [7. A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies](https://arxiv.org/abs/2602.06015v1)

**ä½œè€…**ï¼šPanagiotis Kaliosis, Adithya V Ganesan, Oscar N. E. Kjell ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šLarge language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, ...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šA Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies, Large language models (LLMs) are increasingly being used in a zero, art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open, gpt, shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06015v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06015v1.pdf)

---

## [8. DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs](https://arxiv.org/abs/2602.05992v1)

**ä½œè€…**ï¼šLizhuo Luo, Shenggui Li, Yonggang Wen ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDiffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucia...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šDSB: Dynamic Sliding Block Scheduling for Diffusion LLMs, Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, a training, free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05992v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05992v1.pdf)

---

## [9. Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space](https://arxiv.org/abs/2602.05971v1)

**ä½œè€…**ï¼šFelipe D. Toro-HernÃ¡ndez, Jesuino Vieira Filho, Rodrigo M. Cabral-Carvalho  
**åˆ†ç±»**ï¼šcs.CL, cs.LG, q-bio.NC  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSemantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we i...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šCharacterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, spanning different property generation tasks: Neurodegenerative, and in German. Across these contexts, cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05971v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05971v1.pdf)
=======
## [3. Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs](https://arxiv.org/abs/2602.06920v1)

**ä½œè€…**ï¼šSamir Abdaljalil, Parichit Sharma, Erchin Serpedin ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency is difficult to maintain. While recent models show strong performance on English-centric benchmarks, their behavior across languages, tasks, and hallucination types is not yet well understood. In this work, we introduce Halluverse-M^3, a dataset designed to enable systematic analysis of hallucinations across multiple languages, multiple generation tasks, and multiple hallucination categories. Halluverse-M^3 covers four languages, English, Arabic, Hindi, and Turkish, and supports two generation tasks: question answering and dialogue summarization. The dataset explicitly distinguishes between entity-level, relation-level, and sentence-level hallucinations. Hallucinated outputs are constructed through a controlled editing process and validated by human annotators, ensuring clear alignment between original content and hallucinated generations. Using this dataset, we evaluate a diverse set of contemporary open-source and proprietary language models on fine-grained hallucination detection. Our results show that question answering is consistently easier than dialogue summarization, while sentence-level hallucinations remain challenging even for the strongest models. Performance is highest in English and degrades in lower-resource languages, with Hindi exhibiting the lowest detection accuracy. Overall, Halluverse-M^3 provides a realistic and challenging benchmark for studying hallucinations in multilingual, multi-task settings. We release the dataset to support future research on hallucination detection and mitigation\footnote{https://huggingface.co/datasets/sabdalja/HalluVerse-M3}.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šHalluverse-M^3æ˜¯ä¸€ä¸ªå¤šä»»åŠ¡å¤šè¯­è¨€çš„æ•°æ®é›†ï¼Œæ—¨åœ¨ç³»ç»Ÿåˆ†æžå¤§åž‹è¯­è¨€æ¨¡åž‹ä¸­çš„å¹»è§‰çŽ°è±¡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨å¤šè¯­è¨€å’Œç”Ÿæˆä»»åŠ¡ä¸­çš„å¹»è§‰é—®é¢˜ä¾ç„¶ä¸¥é‡ï¼Œå°¤å…¶æ˜¯åœ¨ç¡®ä¿äº‹å®žä¸€è‡´æ€§æ–¹é¢éœ€è¦æ›´å¤šç ”ç©¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè¯¥æ•°æ®é›†è¦†ç›–è‹±è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€å°åœ°è¯­å’ŒåœŸè€³å…¶è¯­ï¼Œæ”¯æŒé—®ç­”å’Œå¯¹è¯æ‘˜è¦ä¸¤ç§ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶é€šè¿‡æŽ§åˆ¶ç¼–è¾‘å’Œäººç±»æ³¨é‡ŠéªŒè¯å¹»è§‰è¾“å‡ºã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜Žï¼Œé—®ç­”ä»»åŠ¡çš„å¹»è§‰æ£€æµ‹ç›¸å¯¹å®¹æ˜“ï¼Œè€Œå¥å­çº§å¹»è§‰æ£€æµ‹ä¾ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¸”åœ¨ä½Žèµ„æºè¯­è¨€ä¸­è¡¨çŽ°è¾ƒå·®ï¼Œå°åœ°è¯­çš„æ£€æµ‹å‡†ç¡®çŽ‡æœ€ä½Žã€‚

**å…³é”®è¯**ï¼šå¤šä»»åŠ¡, å¤šè¯­è¨€, LLM, ç”Ÿæˆ, å¹»è§‰æ£€æµ‹, æ•°æ®é›†, å¯¹è¯æ‘˜è¦, é—®ç­”, è¯­è¨€æ¨¡åž‹, è¯„ä¼°

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06920v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06920v1.pdf)

---

## [4. Uncovering Cross-Objective Interference in Multi-Objective Alignment](https://arxiv.org/abs/2602.06869v1)

**ä½œè€…**ï¼šYining Lu, Meng Jiang  
**åˆ†ç±»**ï¼šcs.CL, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

We study a persistent failure mode in multi-objective alignment for large language models (LLMs): training improves performance on only a subset of objectives while causing others to degrade. We formalize this phenomenon as cross-objective interference and conduct the first systematic study across classic scalarization algorithms, showing that interference is pervasive and exhibits strong model dependence.   To explain this phenomenon, we derive a local covariance law showing that an objective improves at first order when its reward exhibits positive covariance with the scalarized score. We extend this analysis to clipped surrogate objectives used in modern alignment, demonstrating that the covariance law remains valid under mild conditions despite clipping. Building on this analysis, we propose Covariance Targeted Weight Adaptation (CTWA), a plug-and-play method that maintains positive covariance between objective rewards and the training signal to effectively mitigate cross-objective interference. Finally, we complement these local improvement conditions with a global convergence analysis under the Polyak--Åojasiewicz condition, establishing when non-convex scalarized optimization achieves global convergence and how cross-objective interference depends on specific model geometric properties.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡ç ”ç©¶äº†å¤šç›®æ ‡å¯¹é½ä¸­å­˜åœ¨çš„äº¤å‰ç›®æ ‡å¹²æ‰°çŽ°è±¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ä»¥å‡å°‘è¿™ç§å¹²æ‰°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§è¯­è¨€æ¨¡åž‹çš„å‘å±•ï¼Œå¤šç›®æ ‡å¯¹é½ä¸­çš„æ€§èƒ½æå‡å¾€å¾€åªåœ¨éƒ¨åˆ†ç›®æ ‡ä¸Šæœ‰æ•ˆï¼Œè€Œå¯¼è‡´å…¶ä»–ç›®æ ‡æ€§èƒ½ä¸‹é™ï¼Œå› æ­¤éœ€è¦æ·±å…¥ç†è§£å’Œè§£å†³è¿™ä¸€é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæˆ‘ä»¬æå‡ºäº†åæ–¹å·®ç›®æ ‡åŠ æƒé€‚åº”ï¼ˆCTWAï¼‰æ–¹æ³•ï¼Œé€šè¿‡ä¿æŒç›®æ ‡å¥–åŠ±ä¸Žè®­ç»ƒä¿¡å·ä¹‹é—´çš„æ­£åæ–¹å·®æ¥å‡è½»äº¤å‰ç›®æ ‡å¹²æ‰°ï¼ŒåŒæ—¶è¿›è¡Œäº†å±€éƒ¨å’Œå…¨å±€æ”¶æ•›åˆ†æžã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜Žï¼Œäº¤å‰ç›®æ ‡å¹²æ‰°æ™®éå­˜åœ¨ä¸”ä¾èµ–äºŽæ¨¡åž‹å‡ ä½•ç‰¹æ€§ï¼Œé€šè¿‡CTWAæ–¹æ³•å¯ä»¥æœ‰æ•ˆæ”¹å–„å¤šç›®æ ‡å¯¹é½çš„æ•´ä½“æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šå¤šç›®æ ‡å¯¹é½, å¤§è¯­è¨€æ¨¡åž‹, äº¤å‰ç›®æ ‡å¹²æ‰°, å¥–åŠ±æ¨¡åž‹, åæ–¹å·®æ³•åˆ™, Covariance Targeted Weight Adaptation, è®­ç»ƒä¿¡å·, éžå‡¸ä¼˜åŒ–, æ¨¡åž‹å‡ ä½•ç‰¹æ€§, llm

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06869v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06869v1.pdf)

---

## [5. SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks](https://arxiv.org/abs/2602.06854v1)

**ä½œè€…**ï¼šMingqian Feng, Xiaodong Liu, Weiwei Yang ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average $80.1\%$ ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSEMAæ˜¯ä¸€ä¸ªç®€å•é«˜æ•ˆçš„æ¡†æž¶ï¼Œä¸“æ³¨äºŽå¤šè½®è¶Šç‹±æ”»å‡»ï¼Œè¶…è¶Šäº†çŽ°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤šè½®è¶Šç‹±æ”»å‡»åæ˜ äº†å®‰å…¨å¯¹é½èŠå¤©æœºå™¨äººçš„çœŸå®žå¨èƒæ¨¡åž‹ï¼Œä½†çŽ°æœ‰æ–¹æ³•åœ¨æŽ¢ç´¢å¤æ‚æ€§å’Œæ„å›¾æ¼‚ç§»æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šSEMAåŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šè‡ªæˆ‘è°ƒèŠ‚çš„é¢„å¡«å……å’ŒåŸºäºŽæ„å›¾æ¼‚ç§»çš„å¼ºåŒ–å­¦ä¹ ï¼Œæ—¨åœ¨ç”Ÿæˆæœ‰æ•ˆçš„å¤šè½®å¯¹æŠ—æç¤ºã€‚

**ä¸»è¦ç»“è®º**ï¼šSEMAåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡åž‹ä¸Šå®žçŽ°äº†æœ€å…ˆè¿›çš„æ”»å‡»æˆåŠŸçŽ‡ï¼Œæä¾›äº†å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹å®‰å…¨æ€§çš„å¼ºæœ‰åŠ›æµ‹è¯•ï¼Œå¹¶æ”¯æŒè‡ªåŠ¨åŒ–çš„çº¢é˜Ÿæ“ä½œã€‚

**å…³é”®è¯**ï¼šå¤šè½®æ”»å‡», ç”Ÿæˆå¯¹æŠ—, å¼ºåŒ–å­¦ä¹ , å¤šæ™ºèƒ½ä½“, æ„å›¾é¢„æµ‹, è‡ªé€‚åº”å­¦ä¹ , è¯­ä¹‰æœç´¢, æ¨¡åž‹å®‰å…¨, SEMA, llm

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06854v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06854v1.pdf)

---

## [6. The Representational Geometry of Number](https://arxiv.org/abs/2602.06843v1)

**ä½œè€…**ï¼šZhimin Hu, Lanhao Niu, Sashank Varma  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

A central question in cognitive science is whether conceptual representations converge onto a shared manifold to support generalization, or diverge into orthogonal subspaces to minimize task interference. While prior work has discovered evidence for both, a mechanistic account of how these properties coexist and transform across tasks remains elusive. We propose that representational sharing lies not in the concepts themselves, but in the geometric relations between them. Using number concepts as a testbed and language models as high-dimensional computational substrates, we show that number representations preserve a stable relational structure across tasks. Task-specific representations are embedded in distinct subspaces, with low-level features like magnitude and parity encoded along separable linear directions. Crucially, we find that these subspaces are largely transformable into one another via linear mappings, indicating that representations share relational structure despite being located in distinct subspaces. Together, these results provide a mechanistic lens of how language models balance the shared structure of number representation with functional flexibility. It suggests that understanding arises when task-specific transformations are applied to a shared underlying relational structure of conceptual representations.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè¯¥ç ”ç©¶æŽ¢è®¨äº†æ•°å­—æ¦‚å¿µçš„è¡¨å¾å‡ ä½•ç»“æž„ï¼Œæ­ç¤ºäº†ä»»åŠ¡ç‰¹å®šè¡¨å¾å¦‚ä½•åœ¨å‡ ä½•å…³ç³»ä¸­å…±äº«ç»“æž„ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶è®¤çŸ¥ç§‘å­¦ä¸­æ¦‚å¿µè¡¨å¾åœ¨ä»»åŠ¡é—´çš„å…±äº«ä¸Žå¹²æ‰°é—®é¢˜ï¼Œå¯»æ±‚ç†è§£å…¶æœºåˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šåˆ©ç”¨æ•°å­—æ¦‚å¿µå’Œè¯­è¨€æ¨¡åž‹ï¼Œåˆ†æžå…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨å¾ç¨³å®šæ€§åŠå‡ ä½•å…³ç³»ã€‚

**ä¸»è¦ç»“è®º**ï¼šä»»åŠ¡ç‰¹å®šè¡¨å¾åœ¨ä¸åŒå­ç©ºé—´ä¸­å…·æœ‰å¯å˜æ¢æ€§ï¼Œè¡¨æ˜Žå°½ç®¡ä½äºŽä¸åŒå­ç©ºé—´ï¼Œå®ƒä»¬ä¹‹é—´ä¾ç„¶å…±äº«å…³ç³»ç»“æž„ã€‚

**å…³é”®è¯**ï¼šè¡¨ç¤ºå‡ ä½•, æ¦‚å¿µè¡¨ç¤º, å…±äº«æµå½¢, ä»»åŠ¡å¹²æ‰°, è¯­è¨€æ¨¡åž‹, æ•°å­—æ¦‚å¿µ, å…³ç³»ç»“æž„, ä»»åŠ¡ç‰¹å®šè¡¨ç¤º, åµŒå…¥ç©ºé—´, çº¿æ€§æ˜ å°„, agent

**è¯„åˆ†**ï¼š55

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06843v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06843v1.pdf)
>>>>>>> c7131d2 (Backfill recent data and stabilize unified fetch workflow)

---

## cs.CV

<<<<<<< HEAD
## [10. Thinking with Geometry: Active Geometry Integration for Spatial Reasoning](https://arxiv.org/abs/2602.06037v1)

**ä½œè€…**ï¼šHaoyuan Li, Qihang Cao, Tao Tang ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Recent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, which often induces semantic-geometry misalignment and redundant signals. We propose GeoThinker, a framework that shifts the paradigm from passive fusion to active perception. Instead of feature mixing, GeoThinker enables the model to selectively retrieve geometric evidence conditioned on its internal reasoning demands. GeoThinker achieves this through Spatial-Grounded Fusion applied at carefully selected VLM layers, where semantic visual priors selectively query and integrate task-relevant geometry via frame-strict cross-attention, further calibrated by Importance Gating that biases per-frame attention toward task-relevant structures. Comprehensive evaluation results show that GeoThinker sets a new state-of-the-art in spatial intelligence, achieving a peak score of 72.6 on the VSI-Bench. Furthermore, GeoThinker demonstrates robust generalization and significantly improved spatial perception across complex downstream scenarios, including embodied referring and autonomous driving. Our results indicate that the ability to actively integrate spatial structures is essential for next-generation spatial intelligence. Code can be found at https://github.com/Li-Hao-yuan/GeoThinker.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šRecent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passiv...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šRecent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, including embodied referring and autonomous driving. Our results indicate that the ability to actively integrate spatial structures is essential for next

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06037v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06037v1.pdf)

---

## [11. InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions](https://arxiv.org/abs/2602.06035v1)

**ä½œè€…**ï¼šSirui Xu, Samuel Schulter, Morteza Ziyadi ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.GR, cs.RO  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Humans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, and manipulation can emerge naturally from underlying physical and motor priors. Scaling such priors is key to enabling humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. To this end, we introduce InterPrior, a scalable framework that learns a unified generative controller through large-scale imitation pretraining and post-training by reinforcement learning. InterPrior first distills a full-reference imitation expert into a versatile, goal-conditioned variational policy that reconstructs motion from multimodal observations and high-level intent. While the distilled policy reconstructs training behaviors, it does not generalize reliably due to the vast configuration space of large-scale human-object interactions. To address this, we apply data augmentation with physical perturbations, and then perform reinforcement learning finetuning to improve competence on unseen goals and initializations. Together, these steps consolidate the reconstructed latent skills into a valid manifold, yielding a motion prior that generalizes beyond the training data, e.g., it can incorporate new behaviors such as interactions with unseen objects. We further demonstrate its effectiveness for user-interactive control and its potential for real robot deployment.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šHumans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, a...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šInterPrior: Scaling Generative Control for Physics, manipulation skills across diverse contexts while maintaining physically coherent whole, a scalable framework that learns a unified generative controller through large, scale imitation pretraining and post, training by reinforcement learning. InterPrior first distills a full, level intent. While the distilled policy reconstructs training behaviors, yielding a motion prior that generalizes beyond the training data

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06035v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06035v1.pdf)

---

## [12. V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval](https://arxiv.org/abs/2602.06034v1)

**ä½œè€…**ï¼šDongyang Chen, Chaoyang Wang, Dezhao SU ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMultimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šDriven Agentic Reasoning for Universal Multimodal Retrieval, Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain, existing approaches remain largely language, grained visual evidence, driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V, Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence, gathering retrieval agent, aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average)

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06034v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06034v1.pdf)

---

## [13. Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation](https://arxiv.org/abs/2602.06032v1)

**ä½œè€…**ï¼šDavid Shavin, Sagie Benaim  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Vision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this end, we introduce Splat and Distill, a framework that instills robust 3D awareness into 2D VFMs by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. Given 2D features produced by a teacher model, our method first lifts these features into an explicit 3D Gaussian representation, in a feedforward manner. These 3D features are then ``splatted" onto novel viewpoints, producing a set of novel 2D feature maps used to supervise the student model, ``distilling" geometrically grounded knowledge. By replacing slow per-scene optimization of prior work with our feed-forward lifting approach, our framework avoids feature-averaging artifacts, creating a dynamic learning process where the teacher's consistency improves alongside that of the student. We conduct a comprehensive evaluation on a suite of downstream tasks, including monocular depth estimation, surface normal estimation, multi-view correspondence, and semantic segmentation. Our method significantly outperforms prior works, not only achieving substantial gains in 3D awareness but also enhancing the underlying semantic richness of 2D features. Project page is available at https://davidshavin4.github.io/Splat-and-Distill/

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šVision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this e...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šaveraging artifacts, not only achieving substantial gains in 3D awareness but also enhancing the underlying semantic richness of 2D features. Project page is available at https://davidshavin4.github.io/Splat

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06032v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06032v1.pdf)

---

## [14. Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028v1)

**ä½œè€…**ï¼šShuo Chen, Cong Wei, Sun Sun ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šRecent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frame...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šContext Forcing: Consistent Autoregressive Video Generation with Long Context, attempting to train a long, context student using a short, context (memoryless) teacher. In these frameworks, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long, context student via a long, context teacher. By ensuring the teacher is aware of the full generation history, enabling the robust training of models capable of long, we introduce a context management system that transforms the linearly growing context into a \textbf{Slow, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds, RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06028v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06028v1.pdf)

---

## [15. GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?](https://arxiv.org/abs/2602.06013v1)

**ä½œè€…**ï¼šRuihang Li, Leigang Qu, Jingxu Zhang ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide spectrum of visual generation tasks. Our analysis reveals that this paradigm is limited due to stochastic inconsistency and poor alignment with human perception. To resolve these limitations, we introduce GenArena, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human-aligned evaluation. Crucially, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off-the-shelf open-source models to outperform top-tier proprietary models. Notably, our method boosts evaluation accuracy by over 20% and achieves a Spearman correlation of 0.86 with the authoritative LMArena leaderboard, drastically surpassing the 0.36 correlation of pointwise methods. Based on GenArena, we benchmark state-of-the-art visual generation models across diverse tasks, providing the community with a rigorous and automated evaluation standard for visual generation.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šThe rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematica...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šwe systematically investigate the reliability of the prevailing absolute pointwise scoring standard, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06013v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06013v1.pdf)

---

## [16. RISE-Video: Can Video Generators Decode Implicit World Rules?](https://arxiv.org/abs/2602.05986v1)

**ä½œè€…**ï¼šMingxin Liu, Shuran Ma, Shibei Meng ç­‰ 12 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: \textit{Reasoning Alignment}, \textit{Temporal Consistency}, \textit{Physical Rationality}, and \textit{Visual Quality}. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šWhile generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge thi...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šWhile generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human, art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, simulating generative models.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05986v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05986v1.pdf)

---

## [17. LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation](https://arxiv.org/abs/2602.05966v1)

**ä½œè€…**ï¼šMirlan Karimov, Teodora Spasojevic, Markus Braun ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, limiting their utility as scalable and generalizable data engines. In this work, we propose Localized Semantic Alignment (LSA), a simple yet effective framework for fine-tuning pre-trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground-truth and generated video clips. Specifically, we compare the output of an off-the-shelf feature extraction model between the ground-truth and generated video clips localized around dynamic objects inducing a semantic feature consistency loss. We fine-tune the base model by combining this loss with the standard diffusion loss. The model fine-tuned for a single epoch with our novel loss outperforms the baselines in common video generation evaluation metrics. To further test the temporal consistency in generated videos we adapt two additional metrics from object detection task, namely mAP and mIoU. Extensive experiments on nuScenes and KITTI datasets show the effectiveness of our approach in enhancing temporal consistency in video generation without the need for external control signals during inference and any computational overheads.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šControllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inferenc...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šControllable video generation has emerged as a versatile tool for autonomous driving, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground, tune the base model by combining this loss with the standard diffusion loss. The model fine

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05966v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05966v1.pdf)
=======
## [7. MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images](https://arxiv.org/abs/2602.06965v1)

**ä½œè€…**ï¼šAnkan Deria, Komal Kumar, Adinath Madhavrao Dukre ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO's broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šMedMOæ˜¯ä¸€ä¸ªä¸“æ³¨äºŽåŒ»å­¦å›¾åƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼Œé’ˆå¯¹åŒ»å­¦é¢†åŸŸçš„ç‰¹å®šéœ€æ±‚è¿›è¡Œä¼˜åŒ–å’Œè®­ç»ƒã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„æŠ€æœ¯è¿…é€Ÿå‘å±•ï¼Œä½†åœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨ä»ç„¶å—åˆ°é¢†åŸŸè¦†ç›–ã€æ¨¡æ€å¯¹é½å’ŒåŸºç¡€æŽ¨ç†ç­‰é—®é¢˜çš„é™åˆ¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šMedMOé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒæ–¹æ¡ˆï¼ŒåŒ…æ‹¬è·¨æ¨¡æ€é¢„è®­ç»ƒã€åŸºäºŽå¤šä»»åŠ¡çš„æŒ‡ä»¤è°ƒä¼˜å’Œç»“åˆäº‹å®žæ£€æŸ¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œä»¥å¢žå¼ºæ¨¡åž‹çš„ç©ºé—´å¯¹é½å’ŒæŽ¨ç†èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šMedMOåœ¨å¤šä¸ªåŒ»å­¦ä»»åŠ¡å’Œæ¨¡æ€ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œæ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’Œç©ºé—´æŽ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨æ”¾å°„å­¦ã€çœ¼ç§‘å­¦å’Œç—…ç†æ˜¾å¾®é•œç­‰é¢†åŸŸå±•çŽ°äº†å¹¿æ³›çš„è·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šå¤šæ¨¡æ€, å¤§è¯­è¨€æ¨¡åž‹, åŒ»å­¦å›¾åƒ, å¼ºåŒ–å­¦ä¹ , è¯­ä¹‰ç†è§£, MedMO, åŒ»å­¦åŸºç¡€æ¨¡åž‹, ä»»åŠ¡ç›‘ç£, ç©ºé—´æŽ¨ç†, è·¨æ¨¡æ€å¯¹é½, ml

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06965v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06965v1.pdf)

---

## [8. CineScene: Implicit 3D as Effective Scene Representation for Cinematic Video Generation](https://arxiv.org/abs/2602.06959v1)

**ä½œè€…**ï¼šKaiyi Huang, Yukun Huang, Yu Li ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Cinematic video production requires control over scene-subject composition and camera movement, but live-action shooting remains costly due to the need for constructing physical sets. To address this, we introduce the task of cinematic video generation with decoupled scene context: given multiple images of a static environment, the goal is to synthesize high-quality videos featuring dynamic subject while preserving the underlying scene consistency and following a user-specified camera trajectory. We present CineScene, a framework that leverages implicit 3D-aware scene representation for cinematic video generation. Our key innovation is a novel context conditioning mechanism that injects 3D-aware features in an implicit way: By encoding scene images into visual representations through VGGT, CineScene injects spatial priors into a pretrained text-to-video generation model by additional context concatenation, enabling camera-controlled video synthesis with consistent scenes and dynamic subjects. To further enhance the model's robustness, we introduce a simple yet effective random-shuffling strategy for the input scene images during training. To address the lack of training data, we construct a scene-decoupled dataset with Unreal Engine 5, containing paired videos of scenes with and without dynamic subjects, panoramic images representing the underlying static scene, along with their camera trajectories. Experiments show that CineScene achieves state-of-the-art performance in scene-consistent cinematic video generation, handling large camera movements and demonstrating generalization across diverse environments.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCineSceneæå‡ºäº†ä¸€ç§åŸºäºŽéšå¼3Dåœºæ™¯è¡¨ç¤ºçš„æ¡†æž¶ï¼Œç”¨äºŽåˆæˆåŠ¨æ€ä¸»é¢˜çš„é«˜è´¨é‡ç”µå½±è§†é¢‘ï¼Œä¿æŒåœºæ™¯ä¸€è‡´æ€§å¹¶æ”¯æŒç”¨æˆ·æŒ‡å®šçš„æ‘„åƒæœºè½¨è¿¹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç”µå½±è§†é¢‘åˆ¶ä½œéœ€è¦æŽ§åˆ¶åœºæ™¯å’Œæ‘„åƒæœºè¿åŠ¨ï¼Œä½†ä¼ ç»Ÿçš„å®žæ‹æˆæœ¬é«˜ï¼ŒäºŸéœ€ä¸€ç§æ–°çš„ç”Ÿæˆæ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCineSceneé€šè¿‡å°†åœºæ™¯å›¾åƒç¼–ç ä¸ºè§†è§‰è¡¨ç¤ºï¼Œç»“åˆä¸Šä¸‹æ–‡æ¡ä»¶æœºåˆ¶ï¼Œå®žçŽ°äº†å¯¹é¢„è®­ç»ƒæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡åž‹çš„éšå¼3Dç‰¹å¾æ³¨å…¥ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCineSceneåœ¨åœºæ™¯ä¸€è‡´çš„ç”µå½±è§†é¢‘ç”Ÿæˆä¸­è¡¨çŽ°ä¼˜è¶Šï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤§èŒƒå›´æ‘„åƒæœºè¿åŠ¨ï¼Œå¹¶å…·å¤‡è·¨çŽ¯å¢ƒçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šå…³é”®è¯ï¼šæ·±åº¦å­¦ä¹ , ç”Ÿæˆ, 3Dåœºæ™¯, è§†é¢‘ç”Ÿæˆ, è¯­ä¹‰æœç´¢, è§†è§‰è¡¨ç¤º, é¢„è®­ç»ƒæ¨¡åž‹, åœºæ™¯ä¸€è‡´æ€§, åŠ¨æ€ä¸»ä½“, rag

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06959v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06959v1.pdf)

---

## [9. Reliable Mislabel Detection for Video Capsule Endoscopy Data](https://arxiv.org/abs/2602.06938v1)

**ä½œè€…**ï¼šJulia Werner, Julius Oexle, Oliver Bause ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The classification performance of deep neural networks relies strongly on access to large, accurately annotated datasets. In medical imaging, however, obtaining such datasets is particularly challenging since annotations must be provided by specialized physicians, which severely limits the pool of annotators. Furthermore, class boundaries can often be ambiguous or difficult to define which further complicates machine learning-based classification. In this paper, we want to address this problem and introduce a framework for mislabel detection in medical datasets. This is validated on the two largest, publicly available datasets for Video Capsule Endoscopy, an important imaging procedure for examining the gastrointestinal tract based on a video stream of lowresolution images. In addition, potentially mislabeled samples identified by our pipeline were reviewed and re-annotated by three experienced gastroenterologists. Our results show that the proposed framework successfully detects incorrectly labeled data and results in an improved anomaly detection performance after cleaning the datasets compared to current baselines.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ¡†æž¶ç”¨äºŽæ£€æµ‹è§†é¢‘èƒ¶å›Šå†…çª¥é•œæ•°æ®ä¸­çš„é”™è¯¯æ ‡ç­¾ï¼Œå¹¶åœ¨æ¸…æ´—æ•°æ®åŽæé«˜äº†å¼‚å¸¸æ£€æµ‹æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåŒ»å­¦å½±åƒä¸­çš„æ ‡æ³¨æ•°æ®èŽ·å–å›°éš¾ï¼Œä¸”æ ‡æ³¨å¸¸å¸¸å­˜åœ¨æ¨¡ç³Šæ€§ï¼Œå½±å“æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„åˆ†ç±»è¡¨çŽ°ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè®ºæ–‡ä¸­å¼•å…¥äº†ä¸€ç§è¯¯æ ‡æ£€æµ‹æ¡†æž¶ï¼Œå¹¶åœ¨ä¸¤ä¸ªå¤§åž‹å…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œé€šè¿‡ä¸‰ä½ç»éªŒä¸°å¯Œçš„èƒƒè‚ ç—…ä¸“å®¶å¯¹æ½œåœ¨è¯¯æ ‡æ ·æœ¬è¿›è¡Œå¤å®¡å’Œé‡æ–°æ ‡æ³¨ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶æœ‰æ•ˆæ£€æµ‹ä¸æ­£ç¡®æ ‡è®°çš„æ•°æ®ï¼Œå¹¶åœ¨æ¸…æ´—æ•°æ®åŽæ˜¾è‘—æé«˜äº†å¼‚å¸¸æ£€æµ‹çš„æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥žç»ç½‘ç»œ, åŒ»å­¦å½±åƒ, è§†é¢‘èƒ¶å›Šå†…çª¥é•œ, å¼‚å¸¸æ£€æµ‹, æ•°æ®æ¸…æ´—, æœºå™¨å­¦ä¹ , åˆ†ç±»æ€§èƒ½, åŒ»ç–—æ•°æ®, machine learning

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06938v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06938v1.pdf)

---

## [10. RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing](https://arxiv.org/abs/2602.06871v1)

**ä½œè€…**ï¼šMohammadreza Salehi, Mehdi Noroozi, Luca Morreale ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Instructional video editing applies edits to an input video using only text prompts, enabling intuitive natural-language control. Despite rapid progress, most methods still require fixed-length inputs and substantial compute. Meanwhile, autoregressive video generation enables efficient variable-length synthesis, yet remains under-explored for video editing. We introduce a causal, efficient video editing model that edits variable-length videos frame by frame. For efficiency, we start from a 2D image-to-image (I2I) diffusion model and adapt it to video-to-video (V2V) editing by conditioning the edit at time step t on the model's prediction at t-1. To leverage videos' temporal redundancy, we propose a new I2I diffusion forward process formulation that encourages the model to predict the residual between the target output and the previous prediction. We call this Residual Flow Diffusion Model (RFDM), which focuses the denoising process on changes between consecutive frames. Moreover, we propose a new benchmark that better ranks state-of-the-art methods for editing tasks. Trained on paired video data for global/local style transfer and object removal, RFDM surpasses I2I-based methods and competes with fully spatiotemporal (3D) V2V models, while matching the compute of image models and scaling independently of input video length. More content can be found in: https://smsd75.github.io/RFDM_page/

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šRFDMæ˜¯ä¸€ç§é«˜æ•ˆçš„å› æžœè§†é¢‘ç¼–è¾‘æ¨¡åž‹ï¼Œé€šè¿‡æ®‹å·®æµæ‰©æ•£æ–¹æ³•å®žçŽ°å¯¹å¯å˜é•¿åº¦è§†é¢‘çš„é€å¸§ç¼–è¾‘ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿè§†é¢‘ç¼–è¾‘æ–¹æ³•ä¾èµ–å›ºå®šé•¿åº¦è¾“å…¥ä¸”è®¡ç®—é‡å¤§ï¼Œè€Œè‡ªå›žå½’è§†é¢‘ç”Ÿæˆå°šæœªå……åˆ†æŽ¢ç´¢ç”¨äºŽè§†é¢‘ç¼–è¾‘ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šRFDMä»Ž2Då›¾åƒæ‰©æ•£æ¨¡åž‹å‡ºå‘ï¼Œé€šè¿‡é¢„æµ‹ç›®æ ‡è¾“å‡ºä¸Žå‰ä¸€é¢„æµ‹ä¹‹é—´çš„æ®‹å·®è¿›è¡Œè§†é¢‘åˆ°è§†é¢‘çš„ç¼–è¾‘ã€‚

**ä¸»è¦ç»“è®º**ï¼šRFDMåœ¨å…¨å±€/å±€éƒ¨é£Žæ ¼è½¬ç§»å’Œç‰©ä½“åŽ»é™¤ä»»åŠ¡ä¸Šè¶…è¶Šäº†åŸºäºŽå›¾åƒçš„æ–¹æ³•ï¼Œå¹¶ä¸Žå…¨æ—¶ç©ºV2Væ¨¡åž‹ç›¸ç«žäº‰ï¼ŒåŒæ—¶è®¡ç®—é‡ä¸Žå›¾åƒæ¨¡åž‹ç›¸å½“ã€‚

**å…³é”®è¯**ï¼šæ®‹å·®æµæ‰©æ•£æ¨¡åž‹, è§†é¢‘ç¼–è¾‘, è‡ªç„¶è¯­è¨€æŽ§åˆ¶, å˜é‡é•¿åº¦, æ—¶åºå†—ä½™, ç”Ÿæˆæ¨¡åž‹, æ·±åº¦å­¦ä¹ , é¢„æµ‹æ¨¡åž‹, ç¼–è¾‘ä»»åŠ¡, è®¡ç®—æ•ˆçŽ‡, diffusion

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06871v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06871v1.pdf)

---

## [11. Parameters as Experts: Adapting Vision Models with Dynamic Parameter Routing](https://arxiv.org/abs/2602.06862v1)

**ä½œè€…**ï¼šMeng Lou, Stanley Yu, Yizhou Yu  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Adapting pre-trained vision models using parameter-efficient fine-tuning (PEFT) remains challenging, as it aims to achieve performance comparable to full fine-tuning using a minimal number of trainable parameters. When applied to complex dense prediction tasks, existing methods exhibit limitations, including input-agnostic modeling and redundant cross-layer representations. To this end, we propose AdaRoute, a new adapter-style method featuring a simple mixture-of-experts (MoE) architecture. Specifically, we introduce shared expert centers, where each expert is a trainable parameter matrix. During a feedforward pass, each AdaRoute module in the network dynamically generates weight matrices tailored for the current module via a simple dynamic parameter routing mechanism, which selectively aggregates parameter matrices in the corresponding expert center. Dynamic weight matrices in AdaRoute modules facilitate low-rank adaptation in an input-dependent manner, thus generating more customized and powerful feature representations. Moreover, since AdaRoute modules across multiple network layers share the same expert center, they improve feature diversity by promoting implicit cross-layer feature interaction. Extensive experiments demonstrate the superiority of AdaRoute on diverse vision tasks, including semantic segmentation, object detection and instance segmentation, and panoptic segmentation. Code will be available at: https://bit.ly/3NZcr0H.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é€‚åº”æ€§æ–¹æ³•AdaRouteï¼Œé€šè¿‡åŠ¨æ€å‚æ•°è·¯ç”±æ”¹è¿›è§†è§‰æ¨¡åž‹çš„å‚æ•°æ•ˆçŽ‡ï¼Œæ˜¾è‘—æå‡äº†å¤šç§è§†è§‰ä»»åŠ¡çš„è¡¨çŽ°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨å¤æ‚çš„å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•å­˜åœ¨è¾“å…¥æ— å…³å»ºæ¨¡å’Œå†—ä½™è·¨å±‚è¡¨ç¤ºçš„å±€é™æ€§ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆæ¥æé«˜æ€§èƒ½ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šAdaRouteé‡‡ç”¨æ··åˆä¸“å®¶æž¶æž„ï¼ŒåŠ¨æ€ç”Ÿæˆä¸Žå½“å‰æ¨¡å—ç›¸åŒ¹é…çš„æƒé‡çŸ©é˜µï¼Œå¹¶é€šè¿‡å…±äº«ä¸“å®¶ä¸­å¿ƒä¿ƒè¿›è·¨å±‚ç‰¹å¾äº¤äº’ï¼Œä»Žè€Œå®žçŽ°è¾“å…¥ç›¸å…³çš„ä½Žç§©é€‚åº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šå¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒAdaRouteåœ¨è¯­ä¹‰åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ç­‰å¤šç§è§†è§‰ä»»åŠ¡ä¸­è¡¨çŽ°ä¼˜è¶Šï¼Œè¯æ˜Žäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , è§†è§‰æ¨¡åž‹, åŠ¨æ€å‚æ•°è·¯ç”±, é€‚åº”æ€§, è®­ç»ƒå‚æ•°, ç‰¹å¾è¡¨ç¤º, è¯­ä¹‰åˆ†å‰², ç›®æ ‡æ£€æµ‹, å®žä¾‹åˆ†å‰², agent

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06862v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06862v1.pdf)

---

## [12. Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping](https://arxiv.org/abs/2602.06850v1)

**ä½œè€…**ï¼šChao Zhou, Tianyi Wei, Yiling Chen ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI, cs.MM  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

While modern text-to-image models excel at prompt-based generation, they often lack the fine-grained control necessary for specific user requirements like spatial layouts or subject appearances. Multi-condition control addresses this, yet its integration into Diffusion Transformers (DiTs) is bottlenecked by the conventional ``concatenate-and-attend'' strategy, which suffers from quadratic computational and memory overhead as the number of conditions scales. Our analysis reveals that much of this cross-modal interaction is spatially or semantically redundant. To this end, we propose Position-aligned and Keyword-scoped Attention (PKA), a highly efficient framework designed to eliminate these redundancies. Specifically, Position-Aligned Attention (PAA) linearizes spatial control by enforcing localized patch alignment, while Keyword-Scoped Attention (KSA) prunes irrelevant subject-driven interactions via semantic-aware masking. To facilitate efficient learning, we further introduce a Conditional Sensitivity-Aware Sampling (CSAS) strategy that reweights the training objective towards critical denoising phases, drastically accelerating convergence and enhancing conditional fidelity. Empirically, PKA delivers a 10.0$\times$ inference speedup and a 5.1$\times$ VRAM saving, providing a scalable and resource-friendly solution for high-fidelity multi-conditioned generation.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡ä½ç½®å¯¹é½å’Œå…³é”®è¯èŒƒå›´æŽ§åˆ¶æ¥æé«˜å¤šæ¡ä»¶ç”Ÿæˆæ¨¡åž‹çš„æ•ˆçŽ‡ï¼Œæ˜¾è‘—é™ä½Žè®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçŽ°ä»£æ–‡æœ¬ç”Ÿæˆæ¨¡åž‹åœ¨æ»¡è¶³ç”¨æˆ·ç‰¹å®šéœ€æ±‚ï¼ˆå¦‚ç©ºé—´å¸ƒå±€å’Œä¸»é¢˜å¤–è§‚ï¼‰æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè€Œå¤šæ¡ä»¶æŽ§åˆ¶çš„æ•´åˆå—åˆ°ä¼ ç»Ÿç­–ç•¥çš„é™åˆ¶ï¼Œå¯¼è‡´è®¡ç®—å’Œå†…å­˜å¼€é”€è¿‡å¤§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä½ç½®å¯¹é½æ³¨æ„åŠ›ï¼ˆPAAï¼‰å’Œå…³é”®è¯èŒƒå›´æ³¨æ„åŠ›ï¼ˆKSAï¼‰ä¸¤ä¸ªæ–°æœºåˆ¶ï¼Œä»¥æ¶ˆé™¤å†—ä½™çš„è·¨æ¨¡æ€äº¤äº’ï¼Œå¹¶é€šè¿‡æ¡ä»¶æ•æ„Ÿé‡‡æ ·ï¼ˆCSASï¼‰ç­–ç•¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šé€šè¿‡å®žéªŒï¼ŒPKAæ¡†æž¶å®žçŽ°äº†10å€çš„æŽ¨ç†é€Ÿåº¦æå‡å’Œ5.1å€çš„æ˜¾å­˜èŠ‚çœï¼Œä¸ºé«˜ä¿çœŸå¤šæ¡ä»¶ç”Ÿæˆæä¾›äº†å¯æ‰©å±•ä¸”èµ„æºå‹å¥½çš„è§£å†³æ–¹æ¡ˆã€‚

**å…³é”®è¯**ï¼šå¤šæ¡ä»¶æŽ§åˆ¶, æ–‡æœ¬ç”Ÿæˆ, æ‰©æ•£å˜æ¢å™¨, ä½ç½®å¯¹é½æ³¨æ„åŠ›, å…³é”®å­—èŒƒå›´æ³¨æ„åŠ›, è¯­ä¹‰æŽ©è”½, é«˜æ•ˆå­¦ä¹ , è®­ç»ƒç›®æ ‡, èµ„æºå‹å¥½, diffusion

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06850v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06850v1.pdf)
>>>>>>> c7131d2 (Backfill recent data and stabilize unified fetch workflow)

---

## cs.LG

<<<<<<< HEAD
## [18. Shared LoRA Subspaces for almost Strict Continual Learning](https://arxiv.org/abs/2602.06043v1)

**ä½œè€…**ï¼šPrakhar Kaushik, Ankit Vaidya, Shravan Chaudhari ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, facilitating forward knowledge transfer, while minimizing catastrophic interference. This approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task-specific LoRA adapters, supporting scalable, asynchronous continual learning. Experiments across image classification, natural language understanding, 3D pose estimation, and text-to-image generation validate its effectiveness, making Share a practical and scalable solution for lifelong learning in large-scale AI systems.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šAdapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. W...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šAdapting large pretrained models to new tasks efficiently and continually is crucial for real, world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task, scale AI systems.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06043v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06043v1.pdf)

---

## [19. Pseudo-Invertible Neural Networks](https://arxiv.org/abs/2602.06042v1)

**ä½œè€…**ï¼šYamit Ehrlich, Nimrod Berman, Assaf Shocher  
**åˆ†ç±»**ï¼šcs.LG, cs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The Moore-Penrose Pseudo-inverse (PInv) serves as the fundamental solution for linear systems. In this paper, we propose a natural generalization of PInv to the nonlinear regime in general and to neural networks in particular. We introduce Surjective Pseudo-invertible Neural Networks (SPNN), a class of architectures explicitly designed to admit a tractable non-linear PInv. The proposed non-linear PInv and its implementation in SPNN satisfy fundamental geometric properties. One such property is null-space projection or "Back-Projection", $x' = x + A^\dagger(y-Ax)$, which moves a sample $x$ to its closest consistent state $x'$ satisfying $Ax=y$. We formalize Non-Linear Back-Projection (NLBP), a method that guarantees the same consistency constraint for non-linear mappings $f(x)=y$ via our defined PInv. We leverage SPNNs to expand the scope of zero-shot inverse problems. Diffusion-based null-space projection has revolutionized zero-shot solving for linear inverse problems by exploiting closed-form back-projection. We extend this method to non-linear degradations. Here, "degradation" is broadly generalized to include any non-linear loss of information, spanning from optical distortions to semantic abstractions like classification. This approach enables zero-shot inversion of complex degradations and allows precise semantic control over generative outputs without retraining the diffusion prior.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šThe Moore-Penrose Pseudo-inverse (PInv) serves as the fundamental solution for linear systems. In this paper, we propose a natural generalization of PInv to the nonlinear regime in general and to neur...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šInvertible Neural Networks, we propose a natural generalization of PInv to the nonlinear regime in general and to neural networks in particular. We introduce Surjective Pseudo, invertible Neural Networks (SPNN), a method that guarantees the same consistency constraint for non, linear mappings $f(x)=y$ via our defined PInv. We leverage SPNNs to expand the scope of zero, shot inverse problems. Diffusion, shot inversion of complex degradations and allows precise semantic control over generative outputs without retraining the diffusion prior.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06042v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06042v1.pdf)

---

## [20. Can vision language models learn intuitive physics from interaction?](https://arxiv.org/abs/2602.06033v1)

**ä½œè€…**ï¼šLuca M. Schulze Buschoff, Konstantinos Voudouris, Can Demircan ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Pre-trained vision language models do not have good intuitions about the physical world. Recent work has shown that supervised fine-tuning can improve model performance on simple physical tasks. However, fine-tuned models do not appear to learn robust physical rules that can generalize to new contexts. Based on research in cognitive science, we hypothesize that models need to interact with an environment to properly learn its physical dynamics. We train models that learn through interaction with the environment using reinforcement learning. While learning from interaction allows models to improve their within-task performance, it fails to produce models with generalizable physical intuitions. We find that models trained on one task do not reliably generalize to related tasks, even if the tasks share visual statistics and physical principles, and regardless of whether the models are trained through interaction.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šPre-trained vision language models do not have good intuitions about the physical world. Recent work has shown that supervised fine-tuning can improve model performance on simple physical tasks. Howev...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼štrained vision language models do not have good intuitions about the physical world. Recent work has shown that supervised fine, tuned models do not appear to learn robust physical rules that can generalize to new contexts. Based on research in cognitive science, we hypothesize that models need to interact with an environment to properly learn its physical dynamics. We train models that learn through interaction with the environment using reinforcement learning. While learning from interaction allows models to improve their within, it fails to produce models with generalizable physical intuitions. We find that models trained on one task do not reliably generalize to related tasks, and regardless of whether the models are trained through interaction.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06033v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06033v1.pdf)

---

## [21. Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference](https://arxiv.org/abs/2602.06029v1)

**ä½œè€…**ï¼šYingke Li, Anjali Parashar, Enlu Zhou ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šActive inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a ...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šActive inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision, making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, minimizing agents, regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic, pragmatic trade

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06029v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06029v1.pdf)

---

## [22. Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering](https://arxiv.org/abs/2602.06022v1)

**ä½œè€…**ï¼šMiranda Muqing Miao, Young-Min Cho, Lyle Ungar  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimize proxies for correctness rather than correctness itself. We introduce CORAL (Correctness-Optimized Residual Activation Lens), a regularized inference-time steering method that captures distributed correctness signals from model internal activations using weight-decay MLP probes. We evaluate CORAL across three 7B-parameter models and find that it consistently improves accuracy by 10\% and expected calibration error (ECE) by 50\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held-out benchmarks (ARC-Challenge, HellaSwag, Math-MC, OpenBookQA), averaging 14\% accuracy improvements and 49\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute-efficient, transferable, and calibration-aware approach to improve MCQA performance during inference.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šLarge language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is ex...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šLarge language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference, decay MLP probes. We evaluate CORAL across three 7B, parameter models and find that it consistently improves accuracy by 10\% and expected calibration error (ECE) by 50\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held, averaging 14\% accuracy improvements and 49\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06022v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06022v1.pdf)

---

## [23. Mechanisms of AI Protein Folding in ESMFold](https://arxiv.org/abs/2602.06020v1)

**ä½œè€…**ï¼šKevin Lu, Jannik Brinkmann, Stefan Huber ç­‰ 7 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, q-bio.BM  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions on model latents, we identify two computational stages in the folding trunk. In the first stage, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second stage, late blocks develop pairwise spatial features: distance and contact information accumulate in the pairwise representation. We demonstrate that the mechanisms underlying structural decisions of ESMFold can be localized, traced through interpretable representations, and manipulated with strong causal effects.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šHow do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions o...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šMechanisms of AI Protein Folding in ESMFold, How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second stage, late blocks develop pairwise spatial features: distance and contact information accumulate in the pairwise representation. We demonstrate that the mechanisms underlying structural decisions of ESMFold can be localized

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06020v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06020v1.pdf)

---

## [24. Optimism Stabilizes Thompson Sampling for Adaptive Inference](https://arxiv.org/abs/2602.06014v1)

**ä½œè€…**ï¼šShunxing Yan, Han Zhong  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, math.OC, math.ST, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \emph{optimism} as a key mechanism for restoring \emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \citep{halder2025stable} is stable for any $K \ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šThompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fai...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šyet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06014v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06014v1.pdf)

---

## [25. On Computation and Reinforcement Learning](https://arxiv.org/abs/2602.05999v1)

**ä½œè€…**ï¼šRaj Ghugare, MichaÅ‚ Bortkiewicz, Alicja Ziarko ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

How does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, still benefit from additional compute? The standard RL framework does not provide a language to answer these questions formally. Empirically, deep RL policies are often parameterized as neural networks with static architectures, conflating the amount of compute and the number of parameters. In this paper, we formalize compute bounded policies and prove that policies which use more compute can solve problems and generalize to longer-horizon tasks that are outside the scope of policies with less compute. Building on prior work in algorithmic learning and model-free planning, we propose a minimal architecture that can use a variable amount of compute. Our experiments complement our theory. On a set 31 different tasks spanning online and offline RL, we show that $(1)$ this architecture achieves stronger performance simply by using more compute, and $(2)$ stronger generalization on longer-horizon test tasks compared to standard feedforward networks or deep residual network using up to 5 times more parameters.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šHow does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, still benefit from additional compute? The standa...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šHow does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, deep RL policies are often parameterized as neural networks with static architectures

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05999v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05999v1.pdf)

---

## [26. Orthogonal Self-Attention](https://arxiv.org/abs/2602.05996v1)

**ä½œè€…**ï¼šLeo Zhang, James Martens  
**åˆ†ç±»**ï¼šcs.LG, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Softmax Self-Attention (SSA) is a key component of Transformer architectures. However, when utilised within skipless architectures, which aim to improve representation learning, recent work has highlighted the inherent instability of SSA due to inducing rank collapse and poorly-conditioned Jacobians. In this work, we design a novel attention mechanism: Orthogonal Self-Attention (OSA), which aims to bypass these issues with SSA, in order to allow for (non-causal) Transformers without skip connections and normalisation layers to be more easily trained. In particular, OSA parametrises the attention matrix to be orthogonal via mapping a skew-symmetric matrix, formed from query-key values, through the matrix exponential. We show that this can be practically implemented, by exploiting the low-rank structure of our query-key values, resulting in the computational complexity and memory cost of OSA scaling linearly with sequence length. Furthermore, we derive an initialisation scheme for which we prove ensures that the Jacobian of OSA is well-conditioned.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSoftmax Self-Attention (SSA) is a key component of Transformer architectures. However, when utilised within skipless architectures, which aim to improve representation learning, recent work has highli...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šAttention (SSA) is a key component of Transformer architectures. However, which aim to improve representation learning, which aims to bypass these issues with SSA, causal) Transformers without skip connections and normalisation layers to be more easily trained. In particular

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05996v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05996v1.pdf)

---

## [27. Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps](https://arxiv.org/abs/2602.05993v1)

**ä½œè€…**ï¼šPeter Holderrieth, Douglas Chen, Luca Eyring ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an afterthought, and redesign the model for adaptability. We propose "Diamond Maps", stochastic flow map models that enable efficient and accurate alignment to arbitrary rewards at inference time. Diamond Maps amortize many simulation steps into a single-step sampler, like flow maps, while preserving the stochasticity required for optimal reward alignment. This design makes search, sequential Monte Carlo, and guidance scalable by enabling efficient and consistent estimation of the value function. Our experiments show that Diamond Maps can be learned efficiently via distillation from GLASS Flows, achieve stronger reward alignment performance, and scale better than existing methods. Our results point toward a practical route to generative models that can be rapidly adapted to arbitrary preferences and constraints at inference time.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šFlow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We ...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šFlow and diffusion models produce high, but adapting them to user preferences or constraints post, training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, and scale better than existing methods. Our results point toward a practical route to generative models that can be rapidly adapted to arbitrary preferences and constraints at inference time.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05993v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05993v1.pdf)

---

## [28. Clifford Kolmogorov-Arnold Networks](https://arxiv.org/abs/2602.05977v1)

**ä½œè€…**ï¼šMatthias Wolff, Francesco Alesiani, Christof Duhme ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering, and is validated in synthetic and physics inspired tasks.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šWe introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi M...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼ša flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05977v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05977v1.pdf)

---

## [29. Inverse Depth Scaling From Most Layers Being Similar](https://arxiv.org/abs/2602.05970v1)

**ä½œè€…**ï¼šYizhou Liu, Sara Kangaslahti, Ziming Liu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, math.DS, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Neural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely proportional to depth in LLMs, probably due to functionally similar layers reducing error through ensemble averaging rather than compositional learning or discretizing smooth dynamics. This regime is inefficient yet robust and may arise from the architectural bias of residual networks and target functions incompatible with smooth dynamics. The findings suggest that improving LLM efficiency may require architectural innovations to encourage compositional use of depth.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šNeural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how dep...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šNeural scaling laws relate loss to model size in large language models (LLMs), requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely proportional to depth in LLMs, probably due to functionally similar layers reducing error through ensemble averaging rather than compositional learning or discretizing smooth dynamics. This regime is inefficient yet robust and may arise from the architectural bias of residual networks and target functions incompatible with smooth dynamics. The findings suggest that improving LLM efficiency may require architectural innovations to encourage compositional use of depth.

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05970v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05970v1.pdf)

---

## [30. A Hybrid Data-Driven Algorithm for Real-Time Friction Force Estimation in Hydraulic Cylinders](https://arxiv.org/abs/2602.05967v1)

**ä½œè€…**ï¼šMohamad Amin Jamshidi, Mehrbod Zarifi, Zolfa Anvari ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, eess.SY  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-05

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Hydraulic systems are widely utilized in industrial applications due to their high force generation, precise control, and ability to function in harsh environments. Hydraulic cylinders, as actuators in these systems, apply force and position through the displacement of hydraulic fluid, but their operation is significantly influenced by friction force. Achieving precision in hydraulic cylinders requires an accurate friction model under various operating conditions. Existing analytical models, often derived from experimental tests, necessitate the identification or estimation of influencing factors but are limited in adaptability and computational efficiency. This research introduces a data-driven, hybrid algorithm based on Long Short-Term Memory (LSTM) networks and Random Forests for nonlinear friction force estimation. The algorithm effectively combines feature detection and estimation processes using training data acquired from an experimental hydraulic test setup. It achieves a consistent and stable model error of less than 10% across diverse operating conditions and external load variations, ensuring robust performance in complex situations. The computational cost of the algorithm is 1.51 milliseconds per estimation, making it suitable for real-time applications. The proposed method addresses the limitations of analytical models by delivering high precision and computational efficiency. The algorithm's performance is validated through detailed analysis and experimental results, including direct comparisons with the LuGre model. The comparison highlights that while the LuGre model offers a theoretical foundation for friction modeling, its performance is limited by its inability to dynamically adjust to varying operational conditions of the hydraulic cylinder, further emphasizing the advantages of the proposed hybrid approach in real-time applications.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šHydraulic systems are widely utilized in industrial applications due to their high force generation, precise control, and ability to function in harsh environments. Hydraulic cylinders, as actuators i...

**ç ”ç©¶åŠ¨æœº**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**æ ¸å¿ƒæ–¹æ³•**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**ä¸»è¦ç»“è®º**ï¼šAIæœåŠ¡ä¸å¯ç”¨

**å…³é”®è¯**ï¼šTerm Memory (LSTM) networks and Random Forests for nonlinear friction force estimation. The algorithm effectively combines feature detection and estimation processes using training data acquired from an experimental hydraulic test setup. It achieves a consistent and stable model error of less than 10% across diverse operating conditions and external load variations, time applications. The proposed method addresses the limitations of analytical models by delivering high precision and computational efficiency. The algorithm's performance is validated through detailed analysis and experimental results

**è¯„åˆ†**ï¼š0

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.05967v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.05967v1.pdf)
=======
## [13. Learning a Generative Meta-Model of LLM Activations](https://arxiv.org/abs/2602.06964v1)

**ä½œè€…**ï¼šGrace Luo, Jiahai Feng, Trevor Darrell ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative models offer an alternative: they can uncover structure without such assumptions and act as priors that improve intervention fidelity. We explore this direction by training diffusion models on one billion residual stream activations, creating "meta-models" that learn the distribution of a network's internal states. We find that diffusion loss decreases smoothly with compute and reliably predicts downstream utility. In particular, applying the meta-model's learned prior to steering interventions improves fluency, with larger gains as loss decreases. Moreover, the meta-model's neurons increasingly isolate concepts into individual units, with sparse probing scores that scale as loss decreases. These results suggest generative meta-models offer a scalable path toward interpretability without restrictive structural assumptions. Project page: https://generative-latent-prior.github.io.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç”Ÿæˆæ€§å…ƒæ¨¡åž‹ï¼Œé€šè¿‡è®­ç»ƒæ‰©æ•£æ¨¡åž‹åˆ†æžç¥žç»ç½‘ç»œæ¿€æ´»ï¼Œæä¾›æ›´å¥½çš„å¯è§£é‡Šæ€§å’Œå¹²é¢„æ•ˆæžœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçŽ°æœ‰çš„ç¥žç»ç½‘ç»œæ¿€æ´»åˆ†æžæ–¹æ³•ä¾èµ–äºŽä¸¥æ ¼çš„ç»“æž„å‡è®¾ï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ï¼Œå› æ­¤éœ€è¦æŽ¢ç´¢ç”Ÿæˆæ¨¡åž‹ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶é€šè¿‡åœ¨åäº¿ä¸ªæ®‹å·®æµæ¿€æ´»ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡åž‹ï¼Œåˆ›å»ºå­¦ä¹ ç½‘ç»œå†…éƒ¨çŠ¶æ€åˆ†å¸ƒçš„â€œå…ƒæ¨¡åž‹â€ã€‚

**ä¸»è¦ç»“è®º**ï¼šç”Ÿæˆæ€§å…ƒæ¨¡åž‹æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„å¯è§£é‡Šæ€§è·¯å¾„ï¼Œæ— éœ€é™åˆ¶æ€§çš„ç»“æž„å‡è®¾ï¼ŒåŒæ—¶åœ¨å¹²é¢„ä¸­æ˜¾è‘—æé«˜æµç•…åº¦ã€‚

**å…³é”®è¯**ï¼šç”Ÿæˆæ¨¡åž‹, ç¥žç»ç½‘ç»œ, æ·±åº¦å­¦ä¹ , æ¿€æ´»åˆ†æž, å…ƒæ¨¡åž‹, æ‰©æ•£æ¨¡åž‹, ç»“æž„å‡è®¾, ä»‹å…¥å¿ å®žåº¦, æ¦‚å¿µéš”ç¦», ç¨€ç–æŽ¢æµ‹è¯„åˆ†, neural network

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06964v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06964v1.pdf)

---

## [14. Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine](https://arxiv.org/abs/2602.06955v1)

**ä½œè€…**ï¼šReza E. Fazel, Arash Bakhtiary, Siavash A. Bigdeli  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature selection, and preprocessing refinement. Rather than relying on conventional sampling techniques that may introduce bias or cause information loss, the optimized EBM achieves an effective balance between accuracy and interpretability, enabling precise detection of fraudulent transactions while providing actionable insights into feature importance and interaction effects. Furthermore, the Taguchi method is employed to optimize both the sequence of data scalers and model hyperparameters, ensuring robust, reproducible, and systematically validated performance improvements. Experimental evaluation on benchmark credit card data yields an ROC-AUC of 0.983, surpassing prior EBM baselines (0.975) and outperforming Logistic Regression, Random Forest, XGBoost, and Decision Tree models. These results highlight the potential of interpretable machine learning and data-driven optimization for advancing trustworthy fraud analytics in financial systems.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šé€šè¿‡ä¼˜åŒ–çš„å¯è§£é‡Šå¢žå¼ºæœºå™¨ï¼Œæ”¹è¿›ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ä»¥åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå–å¾—äº†ä¼˜å¼‚çš„é¢„æµ‹æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹é¢ä¸´ç±»åˆ«ä¸å¹³è¡¡çš„æŒ‘æˆ˜ï¼Œè¿™å½±å“äº†é¢„æµ‹çš„å¯é æ€§ï¼Œå› æ­¤éœ€è¦æ”¹è¿›æ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºŽå¯è§£é‡Šå¢žå¼ºæœºå™¨çš„ä¼˜åŒ–å·¥ä½œæµç¨‹ï¼Œé€šè¿‡ç³»ç»Ÿçš„è¶…å‚æ•°è°ƒä¼˜ã€ç‰¹å¾é€‰æ‹©å’Œé¢„å¤„ç†æ”¹è¿›ï¼Œæ¥æé«˜æ¨¡åž‹çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¼˜åŒ–åŽçš„EBMåœ¨ä¿¡ç”¨å¡æ•°æ®é›†ä¸Šå®žçŽ°äº†0.983çš„ROC-AUCï¼Œè¶…è¶Šäº†ä¹‹å‰çš„åŸºçº¿å’Œå…¶ä»–æ¨¡åž‹ï¼Œå±•ç¤ºäº†å¯è§£é‡Šæœºå™¨å­¦ä¹ åœ¨é‡‘èžæ¬ºè¯ˆåˆ†æžä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹, è§£é‡Šæ€§å¢žå¼ºæœºå™¨, æœºå™¨å­¦ä¹ , ç‰¹å¾é€‰æ‹©, æ•°æ®é¢„å¤„ç†, æ¨¡åž‹ä¼˜åŒ–, é€æ˜Žæ€§, é¢„æµ‹å¯é æ€§, ROC-AUC, æ•°æ®é©±åŠ¨ä¼˜åŒ–, machine learning

**è¯„åˆ†**ï¼š56

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06955v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06955v1.pdf)

---

## [15. Endogenous Resistance to Activation Steering in Language Models](https://arxiv.org/abs/2602.06941v1)

**ä½œè€…**ï¼šAlex McKenzie, Keenan Pepper, Stijn Servaes ç­‰ 9 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Large language models can resist task-misaligned activation steering during inference, sometimes recovering mid-generation to produce improved responses even when steering remains active. We term this Endogenous Steering Resistance (ESR). Using sparse autoencoder (SAE) latents to steer model activations, we find that Llama-3.3-70B shows substantial ESR, while smaller models from the Llama-3 and Gemma-2 families exhibit the phenomenon less frequently. We identify 26 SAE latents that activate differentially during off-topic content and are causally linked to ESR in Llama-3.3-70B. Zero-ablating these latents reduces the multi-attempt rate by 25%, providing causal evidence for dedicated internal consistency-checking circuits. We demonstrate that ESR can be deliberately enhanced through both prompting and training: meta-prompts instructing the model to self-monitor increase the multi-attempt rate by 4x for Llama-3.3-70B, and fine-tuning on self-correction examples successfully induces ESR-like behavior in smaller models. These findings have dual implications: ESR could protect against adversarial manipulation but might also interfere with beneficial safety interventions that rely on activation steering. Understanding and controlling these resistance mechanisms is important for developing transparent and controllable AI systems. Code is available at github.com/agencyenterprise/endogenous-steering-resistance.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šå¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­è¡¨çŽ°å‡ºå†…ç”ŸæŠ—å¹²æ‰°èƒ½åŠ›ï¼Œå³ä½¿åœ¨å¹²æ‰°æŒç»­å­˜åœ¨æ—¶ä¹Ÿèƒ½è‡ªæˆ‘ä¿®æ­£ä»¥æå‡å“åº”è´¨é‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶è¯­è¨€æ¨¡åž‹åœ¨ä»»åŠ¡ä¸ä¸€è‡´çš„æƒ…å†µä¸‹å¦‚ä½•æŠµæŠ—æ¿€æ´»å¼•å¯¼ï¼Œä»¥ç†è§£å…¶å†…ç”ŸæŠ—å¹²æ‰°æœºåˆ¶çš„é‡è¦æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡ä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨æ½œå˜é‡æ¥å¼•å¯¼æ¨¡åž‹æ¿€æ´»ï¼Œåˆ†æžä¸åŒæ¨¡åž‹åœ¨é¢å¯¹ç¦»é¢˜å†…å®¹æ—¶çš„æ¿€æ´»å·®å¼‚ã€‚

**ä¸»è¦ç»“è®º**ï¼šå‘çŽ°å†…ç”ŸæŠ—å¹²æ‰°èƒ½åŠ›ä¸ä»…å¯èƒ½é˜²æ­¢æ¶æ„æ“æŽ§ï¼Œè¿˜å¯èƒ½å¹²æ‰°ä¾èµ–æ¿€æ´»å¼•å¯¼çš„å®‰å…¨å¹²é¢„æŽªæ–½ï¼Œå¼ºè°ƒç†è§£å’ŒæŽ§åˆ¶è¿™äº›æœºåˆ¶çš„é‡è¦æ€§ã€‚

**å…³é”®è¯**ï¼šå†…ç”ŸæŠ—æ¿€æ´»å¼•å¯¼, è¯­è¨€æ¨¡åž‹, å¤§åž‹è¯­è¨€æ¨¡åž‹, è‡ªç›‘æŽ§, ç¨€ç–è‡ªç¼–ç å™¨, è‡ªæˆ‘ä¿®æ­£, æ¿€æ´»å¼•å¯¼, å†…éƒ¨ä¸€è‡´æ€§æ£€æŸ¥, å¤šæ¬¡å°è¯•, é€æ˜Žå¯æŽ§AI

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06941v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06941v1.pdf)

---

## [16. From Core to Detail: Unsupervised Disentanglement with Entropy-Ordered Flows](https://arxiv.org/abs/2602.06940v1)

**ä½œè€…**ï¼šDaniel Galperin, Ullrich KÃ¶the  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Learning unsupervised representations that are both semantically meaningful and stable across runs remains a central challenge in modern representation learning. We introduce entropy-ordered flows (EOFlows), a normalizing-flow framework that orders latent dimensions by their explained entropy, analogously to PCA's explained variance. This ordering enables adaptive injective flows: after training, one may retain only the top C latent variables to form a compact core representation while the remaining variables capture fine-grained detail and noise, with C chosen flexibly at inference time rather than fixed during training. EOFlows build on insights from Independent Mechanism Analysis, Principal Component Flows and Manifold Entropic Metrics. We combine likelihood-based training with local Jacobian regularization and noise augmentation into a method that scales well to high-dimensional data such as images. Experiments on the CelebA dataset show that our method uncovers a rich set of semantically interpretable features, allowing for high compression and strong denoising.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ æ–¹æ³•EOFlowsï¼Œé€šè¿‡ç†µæŽ’åºçš„æµæ¨¡åž‹æœ‰æ•ˆæå–è¯­ä¹‰ç‰¹å¾å’Œç»†èŠ‚ä¿¡æ¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåœ¨æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ ä¸­ï¼ŒèŽ·å–è¯­ä¹‰æ˜Žç¡®ä¸”ç¨³å®šçš„è¡¨ç¤ºæ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šEOFlowsé€šè¿‡ç†µæŽ’åºçš„æ­£åˆ™åŒ–æµæ¡†æž¶ï¼Œå¯¹æ½œåœ¨ç»´åº¦è¿›è¡ŒæŽ’åºï¼Œä»¥å®žçŽ°è‡ªé€‚åº”çš„æ³¨å…¥æµï¼Œå¹¶ç»“åˆå±€éƒ¨é›…å¯æ¯”æ­£åˆ™åŒ–å’Œå™ªå£°å¢žå¼ºï¼Œé€‚ç”¨äºŽé«˜ç»´æ•°æ®ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®žéªŒç»“æžœè¡¨æ˜Žï¼ŒEOFlowsèƒ½å¤Ÿå‘çŽ°ä¸°å¯Œçš„è¯­ä¹‰ç‰¹å¾ï¼Œå®žçŽ°é«˜åŽ‹ç¼©çŽ‡å’Œå¼ºåŽ»å™ªèƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šæ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ , æ¦‚çŽ‡æµ, æ½œåœ¨å˜é‡, ç‰¹å¾æå–, é«˜ç»´æ•°æ®, å™ªå£°å¢žå¼º, EOFlows, Jacobianæ­£åˆ™åŒ–, agent

**è¯„åˆ†**ï¼š66

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06940v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06940v1.pdf)

---

## [17. Cochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics](https://arxiv.org/abs/2602.06939v1)

**ä½œè€…**ï¼šZuyuan Zhang, Sizhe Tang, Tian Lan  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Non-Markovian dynamics are commonly found in real-world environments due to long-range dependencies, partial observability, and memory effects. The Bellman equation that is the central pillar of Reinforcement learning (RL) becomes only approximately valid under Non-Markovian. Existing work often focus on practical algorithm designs and offer limited theoretical treatment to address key questions, such as what dynamics are indeed capturable by the Bellman framework and how to inspire new algorithm classes with optimal approximations. In this paper, we present a novel topological viewpoint on temporal-difference (TD) based RL. We show that TD errors can be viewed as 1-cochain in the topological space of state transitions, while Markov dynamics are then interpreted as topological integrability. This novel view enables us to obtain a Hodge-type decomposition of TD errors into an integrable component and a topological residual, through a Bellman-de Rham projection. We further propose HodgeFlow Policy Search (HFPS) by fitting a potential network to minimize the non-integrable projection residual in RL, achieving stability/sensitivity guarantees. In numerical evaluations, HFPS is shown to significantly improve RL performance under non-Markovian.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‹“æ‰‘è§†è§’æ¥ç†è§£éžé©¬å°”å¯å¤«åŠ¨æ€ä¸‹çš„æ—¶åºå·®åˆ†ä¿¡å·ï¼Œå¹¶æå‡ºäº†HodgeFlowæ”¿ç­–æœç´¢ç®—æ³•ä»¥æ”¹å–„å¼ºåŒ–å­¦ä¹ æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶è€…å¸Œæœ›è§£å†³éžé©¬å°”å¯å¤«åŠ¨æ€ä¸‹å¼ºåŒ–å­¦ä¹ çš„ç†è®ºå’Œç®—æ³•å±€é™æ€§ï¼ŒæŽ¢ç´¢Bellmanæ¡†æž¶çš„é€‚ç”¨æ€§å’Œæ–°ç®—æ³•çš„çµæ„Ÿã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å°†æ—¶åºå·®åˆ†è¯¯å·®è§†ä¸ºçŠ¶æ€è½¬æ¢çš„1-å…±é“¾ï¼Œåˆ©ç”¨Bellman-de RhamæŠ•å½±è¿›è¡ŒHodgeç±»åž‹åˆ†è§£ï¼Œæå‡ºäº†ä¸€ç§æœ€å°åŒ–éžå¯ç§¯æŠ•å½±æ®‹å·®çš„HodgeFlowæ”¿ç­–æœç´¢ç®—æ³•ã€‚

**ä¸»è¦ç»“è®º**ï¼šHFPSåœ¨æ•°å€¼è¯„ä¼°ä¸­æ˜¾ç¤ºå‡ºåœ¨éžé©¬å°”å¯å¤«çŽ¯å¢ƒä¸‹æ˜¾è‘—æé«˜äº†å¼ºåŒ–å­¦ä¹ çš„æ€§èƒ½ï¼Œå¹¶æä¾›äº†ç¨³å®šæ€§å’Œæ•æ„Ÿæ€§ä¿è¯ã€‚

**å…³é”®è¯**ï¼šå¼ºåŒ–å­¦ä¹ , éžé©¬å°”å¯å¤«åŠ¨æ€, æ—¶åºå·®åˆ†, Bellmanæ–¹ç¨‹, HodgeFlowç­–ç•¥æœç´¢, çŠ¶æ€è½¬ç§», é¡¶ç‚¹ç©ºé—´, æ½œåœ¨ç½‘ç»œ, ç¨³å®šæ€§ä¿éšœ

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06939v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06939v1.pdf)

---

## [18. Robustness Beyond Known Groups with Low-rank Adaptation](https://arxiv.org/abs/2602.06924v1)

**ä½œè€…**ï¼šAbinitha Gourabathina, Hyewon Jeong, Teya Bergamaschi ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Deep learning models trained to optimize average accuracy often exhibit systematic failures on particular subpopulations. In real world settings, the subpopulations most affected by such disparities are frequently unlabeled or unknown, thereby motivating the development of methods that are performant on sensitive subgroups without being pre-specified. However, existing group-robust methods typically assume prior knowledge of relevant subgroups, using group annotations for training or model selection. We propose Low-rank Error Informed Adaptation (LEIA), a simple two-stage method that improves group robustness by identifying a low-dimensional subspace in the representation space where model errors concentrate. LEIA restricts adaptation to this error-informed subspace via a low-rank adjustment to the classifier logits, directly targeting latent failure modes without modifying the backbone or requiring group labels. Using five real-world datasets, we analyze group robustness under three settings: (1) truly no knowledge of subgroup relevance, (2) partial knowledge of subgroup relevance, and (3) full knowledge of subgroup relevance. Across all settings, LEIA consistently improves worst-group performance while remaining fast, parameter-efficient, and robust to hyperparameter choice.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§ä½Žç§©è¯¯å·®ä¿¡æ¯é€‚åº”æ–¹æ³•ï¼ˆLEIAï¼‰ï¼Œä»¥æé«˜æ¨¡åž‹åœ¨æœªçŸ¥å­ç¾¤ä½“ä¸Šçš„é²æ£’æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçŽ°æœ‰çš„ç¾¤ä½“é²æ£’æ€§æ–¹æ³•é€šå¸¸éœ€è¦å…ˆéªŒçŸ¥è¯†ï¼Œè€Œè®¸å¤šåœ¨çŽ°å®žä¸–ç•Œä¸­å—å½±å“çš„å­ç¾¤ä½“å¾€å¾€æ˜¯æœªçŸ¥æˆ–æœªæ ‡è®°çš„ï¼Œå› æ­¤éœ€è¦å¼€å‘ä¸ä¾èµ–äºŽç¾¤ä½“æ ‡ç­¾çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šLEIAé€šè¿‡è¯†åˆ«è¡¨ç¤ºç©ºé—´ä¸­æ¨¡åž‹é”™è¯¯é›†ä¸­çš„ä½Žç»´å­ç©ºé—´ï¼Œé‡‡ç”¨ä½Žç§©è°ƒæ•´åˆ†ç±»å™¨çš„logitsæ¥å®žçŽ°è‡ªé€‚åº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨ä¸‰ç§ä¸åŒçš„çŸ¥è¯†è®¾ç½®ä¸‹ï¼ŒLEIAåœ¨æ”¹å–„æœ€å·®ç¾¤ä½“è¡¨çŽ°çš„åŒæ—¶ï¼Œä¿æŒäº†å¿«é€Ÿã€å‚æ•°é«˜æ•ˆå’Œå¯¹è¶…å‚æ•°é€‰æ‹©çš„é²æ£’æ€§ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ä½Žç§©é€‚åº”, æ¨¡åž‹é²æ£’æ€§, ç¾¤ä½“æ•æ„Ÿæ€§, è¡¨ç¤ºç©ºé—´, é”™è¯¯ä¿¡æ¯é€‚åº”, subgroup relevance, æ€§èƒ½ä¼˜åŒ–, é€‚åº”æ€§è°ƒæ•´, deep learning

**è¯„åˆ†**ï¼š63

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06924v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06924v1.pdf)

---

## [19. From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers](https://arxiv.org/abs/2602.06923v1)

**ä½œè€…**ï¼šZiming Liu, Sophia Sanborn, Surya Ganguli ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, physics.class-ph  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on "world models" -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous "AI Physicist" approaches have successfully recovered such laws, they typically rely on strong, domain-specific priors that effectively "bake in" the physics. Conversely, Vafa et al. recently showed that generic Transformers fail to acquire these world models, achieving high predictive accuracy without capturing the underlying physical laws. We bridge this gap by systematically introducing three minimal inductive biases. We show that ensuring spatial smoothness (by formulating prediction as continuous regression) and stability (by training with noisy contexts to mitigate error accumulation) enables generic Transformers to surpass prior failures and learn a coherent Keplerian world model, successfully fitting ellipses to planetary trajectories. However, true physical insight requires a third bias: temporal locality. By restricting the attention window to the immediate past -- imposing the simple assumption that future states depend only on the local state rather than a complex history -- we force the model to abandon curve-fitting and discover Newtonian force representations. Our results demonstrate that simple architectural choices determine whether an AI becomes a curve-fitter or a physicist, marking a critical step toward automated scientific discovery.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šé€šè¿‡å¼•å…¥ç®€å•çš„å½’çº³åå·®ï¼Œç ”ç©¶è¡¨æ˜Žé€šç”¨Transformerå¯ä»¥å­¦ä¹ ç‰©ç†è§„å¾‹ï¼Œè¶…è¶Šä¼ ç»Ÿçš„é¢„æµ‹èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨æŽ¢ç´¢é€šç”¨AIæž¶æž„æ˜¯å¦èƒ½å¤Ÿè¶…è¶Šç®€å•é¢„æµ‹ï¼Œå‘çŽ°å®‡å®™çš„ç‰©ç†æ³•åˆ™ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¼•å…¥ç©ºé—´å¹³æ»‘æ€§ã€ç¨³å®šæ€§å’Œæ—¶é—´å±€éƒ¨æ€§ä¸‰ä¸ªå½’çº³åå·®ï¼Œæ”¹å–„Transformeråœ¨å­¦ä¹ ä¸–ç•Œæ¨¡åž‹æ—¶çš„è¡¨çŽ°ã€‚

**ä¸»è¦ç»“è®º**ï¼šç®€å•çš„æž¶æž„é€‰æ‹©å†³å®šäº†AIæ˜¯æˆä¸ºæ›²çº¿æ‹Ÿåˆè€…è¿˜æ˜¯ç‰©ç†å­¦å®¶ï¼Œä¸ºè‡ªåŠ¨åŒ–ç§‘å­¦å‘çŽ°é“ºå¹³äº†é“è·¯ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , å˜æ¢å™¨, ä¸–ç•Œæ¨¡åž‹, ç‰©ç†æ³•åˆ™, ä»£ç†, è‡ªä¸»æ™ºèƒ½, ç©ºé—´å¹³æ»‘æ€§, æ—¶åŸŸå±€éƒ¨æ€§, é¢„æµ‹æ¨¡åž‹, è®­ç»ƒä¼˜åŒ–, agent

**è¯„åˆ†**ï¼š56

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06923v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06923v1.pdf)

---

## [20. Revisiting the Generic Transformer: Deconstructing a Strong Baseline for Time Series Foundation Models](https://arxiv.org/abs/2602.06909v1)

**ä½œè€…**ï¼šYunshi Wen, Wesley M. Gifford, Chandra Reddy ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The recent surge in Time Series Foundation Models has rapidly advanced the field, yet the heterogeneous training setups across studies make it difficult to attribute improvements to architectural innovations versus data engineering. In this work, we investigate the potential of a standard patch Transformer, demonstrating that this generic architecture achieves state-of-the-art zero-shot forecasting performance using a straightforward training protocol. We conduct a comprehensive ablation study that covers model scaling, data composition, and training techniques to isolate the essential ingredients for high performance. Our findings identify the key drivers of performance, while confirming that the generic architecture itself demonstrates excellent scalability. By strictly controlling these variables, we provide comprehensive empirical results on model scaling across multiple dimensions. We release our open-source model and detailed findings to establish a transparent, reproducible baseline for future research.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æŽ¢è®¨äº†ä¸€ç§æ ‡å‡†è¡¥ä¸Transformeråœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ä¼˜è¶Šè¡¨çŽ°ï¼Œæä¾›äº†é«˜æ•ˆçš„è®­ç»ƒåè®®å’Œå…¨é¢çš„æ¶ˆèžç ”ç©¶ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹çš„å¿«é€Ÿå‘å±•ï¼Œç ”ç©¶ä¸­å¼‚æž„çš„è®­ç»ƒè®¾ç½®ä½¿å¾—å¾ˆéš¾åŒºåˆ†æž¶æž„åˆ›æ–°ä¸Žæ•°æ®å·¥ç¨‹çš„è´¡çŒ®ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶é‡‡ç”¨æ ‡å‡†è¡¥ä¸Transformerï¼Œè¿›è¡Œå…¨é¢çš„æ¶ˆèžç ”ç©¶ï¼Œæ¶µç›–æ¨¡åž‹æ‰©å±•ã€æ•°æ®ç»„æˆå’Œè®­ç»ƒæŠ€æœ¯ï¼Œä»¥è¯†åˆ«é«˜æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œé€šç”¨æž¶æž„åœ¨æ€§èƒ½ä¸Šå…·æœ‰ä¼˜è¶Šçš„å¯æ‰©å±•æ€§ï¼Œå¹¶é€šè¿‡ä¸¥æ ¼æŽ§åˆ¶å˜é‡æä¾›äº†å„ç»´åº¦æ¨¡åž‹æ‰©å±•çš„å®žè¯ç»“æžœï¼Œå‘å¸ƒäº†å¼€æºæ¨¡åž‹å’Œè¯¦ç»†å‘çŽ°ä»¥æ”¯æŒæœªæ¥ç ”ç©¶ã€‚

**å…³é”®è¯**ï¼šæ—¶é—´åºåˆ—, Transformer, åŸºçº¿æ¨¡åž‹, é¢„æµ‹æ€§èƒ½, æ¨¡åž‹ç¼©æ”¾, æ•°æ®ç»„åˆ, è®­ç»ƒæŠ€æœ¯, æ·±åº¦å­¦ä¹ , ç”Ÿæˆæ¨¡åž‹

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06909v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06909v1.pdf)

---

## [21. A first realization of reinforcement learning-based closed-loop EEG-TMS](https://arxiv.org/abs/2602.06907v1)

**ä½œè€…**ï¼šDania Humaidan, Jiahua Xu, Jing Chen ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Background: Transcranial magnetic stimulation (TMS) is a powerful tool to investigate neurophysiology of the human brain and treat brain disorders. Traditionally, therapeutic TMS has been applied in a one-size-fits-all approach, disregarding inter- and intra-individual differences. Brain state-dependent EEG-TMS, such as coupling TMS with a pre-specified phase of the sensorimotor mu-rhythm, enables the induction of differential neuroplastic effects depending on the targeted phase. But this approach is still user-dependent as it requires defining an a-priori target phase. Objectives: To present a first realization of a machine-learning-based, closed-loop real-time EEG-TMS setup to identify user-independently the individual mu-rhythm phase associated with high- vs. low-corticospinal excitability states. Methods: We applied EEG-TMS to 25 participants targeting the supplementary motor area-primary motor cortex network and used a reinforcement learning algorithm to identify the mu-rhythm phase associated with high- vs. low corticospinal excitability. We employed linear mixed effects models and Bayesian analysis to determine effects of reinforced learning on corticospinal excitability indexed by motor evoked potential amplitude, and functional connectivity indexed by the imaginary part of resting-state EEG coherence. Results: Reinforcement learning effectively identified the mu-rhythm phase associated with high- vs. low-excitability states, and their repetitive stimulation resulted in long-term increases vs. decreases in functional connectivity in the stimulated sensorimotor network. Conclusions: We demonstrated for the first time the feasibility of closed-loop EEG-TMS in humans, a critical step towards individualized treatment of brain disorders.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶é¦–æ¬¡å®žçŽ°äº†åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„é—­çŽ¯EEG-TMSç³»ç»Ÿï¼Œä¸ºä¸ªæ€§åŒ–è„‘éƒ¨ç–¾ç—…æ²»ç–—æä¾›äº†æ–°æ€è·¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„TMSæ²»ç–—æ–¹æ³•å¿½è§†äº†ä¸ªä½“å·®å¼‚ï¼Œç ”ç©¶æ—¨åœ¨é€šè¿‡EEG-TMSæŠ€æœ¯æå‡æ²»ç–—çš„ä¸ªæ€§åŒ–å’Œæœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶å¯¹25åå‚ä¸Žè€…åº”ç”¨EEG-TMSï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¯†åˆ«ä¸Žé«˜ä½Žçš®å±‚è„Šé«“å…´å¥‹æ€§çŠ¶æ€ç›¸å…³çš„muèŠ‚å¾‹ç›¸ä½ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜Žï¼Œå¼ºåŒ–å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«muèŠ‚å¾‹ç›¸ä½ï¼Œå¹¶é€šè¿‡é‡å¤åˆºæ¿€æ”¹å–„åŠŸèƒ½è¿žæŽ¥æ€§ï¼Œä¸ºä¸ªæ€§åŒ–è„‘éƒ¨ç–¾ç—…æ²»ç–—å¥ å®šäº†åŸºç¡€ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , å¼ºåŒ–å­¦ä¹ , EEG-TMS, ç¥žç»ç½‘ç»œ, é—­çŽ¯ç³»ç»Ÿ, å®žæ—¶ç›‘æµ‹, ä¸ªæ€§åŒ–æ²»ç–—, åŠŸèƒ½è¿žæŽ¥æ€§, mu-rhythm, agent

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06907v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06907v1.pdf)

---

## [22. Parameter-free Dynamic Regret: Time-varying Movement Costs, Delayed Feedback, and Memory](https://arxiv.org/abs/2602.06902v1)

**ä½œè€…**ï¼šEmmanuel Esposito, Andrew Jacobsen, Hao Qiu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

In this paper, we study dynamic regret in unconstrained online convex optimization (OCO) with movement costs. Specifically, we generalize the standard setting by allowing the movement cost coefficients $Î»_t$ to vary arbitrarily over time. Our main contribution is a novel algorithm that establishes the first comparator-adaptive dynamic regret bound for this setting, guaranteeing $\widetilde{\mathcal{O}}(\sqrt{(1+P_T)(T+\sum_t Î»_t)})$ regret, where $P_T$ is the path length of the comparator sequence over $T$ rounds. This recovers the optimal guarantees for both static and dynamic regret in standard OCO as a special case where $Î»_t=0$ for all rounds. To demonstrate the versatility of our results, we consider two applications: OCO with delayed feedback and OCO with time-varying memory. We show that both problems can be translated into time-varying movement costs, establishing a novel reduction specifically for the delayed feedback setting that is of independent interest. A crucial observation is that the first-order dependence on movement costs in our regret bound plays a key role in enabling optimal comparator-adaptive dynamic regret guarantees in both settings.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°ç®—æ³•ï¼Œä¸ºåŠ¨æ€åœ¨çº¿å‡¸ä¼˜åŒ–ä¸­çš„æ—¶é—´å˜åŒ–ç§»åŠ¨æˆæœ¬æä¾›äº†å‚æ•°è‡ªé€‚åº”åŠ¨æ€é—æ†¾ç•Œé™ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶åŠ¨æ€é—æ†¾åœ¨ä¸å—é™çš„åœ¨çº¿å‡¸ä¼˜åŒ–ä¸­çš„åº”ç”¨ï¼Œä»¥æ›´å¥½åœ°å¤„ç†æ—¶é—´å˜åŒ–çš„ç§»åŠ¨æˆæœ¬å’Œå»¶è¿Ÿåé¦ˆé—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å¼•å…¥å¯å˜çš„ç§»åŠ¨æˆæœ¬ç³»æ•°ï¼Œè®¾è®¡äº†ä¸€ç§æ–°ç®—æ³•ï¼Œå»ºç«‹äº†ç¬¬ä¸€ä¸ªé€‚åº”æ¯”è¾ƒå™¨çš„åŠ¨æ€é—æ†¾ç•Œé™ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥ç®—æ³•èƒ½å¤Ÿåœ¨å¤šç§åº”ç”¨ä¸­ï¼ˆå¦‚å»¶è¿Ÿåé¦ˆå’Œæ—¶é—´å˜åŒ–è®°å¿†ï¼‰å®žçŽ°æœ€ä¼˜çš„åŠ¨æ€é—æ†¾ä¿è¯ï¼Œå¹¶ä¸”åœ¨é™æ€å’ŒåŠ¨æ€é—æ†¾çš„ç‰¹æ®Šæƒ…å†µä¸‹ä¹Ÿæ¢å¤äº†æœ€ä½³ä¿è¯ã€‚

**å…³é”®è¯**ï¼šåŠ¨æ€åŽæ‚”, åœ¨çº¿å‡¸ä¼˜åŒ–, è¿åŠ¨æˆæœ¬, å»¶è¿Ÿåé¦ˆ, è®°å¿†, ç®—æ³•, è‡ªé€‚åº”, è¿åŠ¨æˆæœ¬ç³»æ•°, æ— çº¦æŸä¼˜åŒ–, æ·±åº¦å­¦ä¹ , agent

**è¯„åˆ†**ï¼š58

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06902v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06902v1.pdf)

---

## [23. Supercharging Simulation-Based Inference for Bayesian Optimal Experimental Design](https://arxiv.org/abs/2602.06900v1)

**ä½œè€…**ï¼šSamuel Klein, Willie Neiswanger, Daniel Ratner ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI, cs.IT, cs.NE, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Bayesian optimal experimental design (BOED) seeks to maximize the expected information gain (EIG) of experiments. This requires a likelihood estimate, which in many settings is intractable. Simulation-based inference (SBI) provides powerful tools for this regime. However, existing work explicitly connecting SBI and BOED is restricted to a single contrastive EIG bound. We show that the EIG admits multiple formulations which can directly leverage modern SBI density estimators, encompassing neural posterior, likelihood, and ratio estimation. Building on this perspective, we define a novel EIG estimator using neural likelihood estimation. Further, we identify optimization as a key bottleneck of gradient based EIG maximization and show that a simple multi-start parallel gradient ascent procedure can substantially improve reliability and performance. With these innovations, our SBI-based BOED methods are able to match or outperform by up to $22\%$ existing state-of-the-art approaches across standard BOED benchmarks.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽæ¨¡æ‹ŸæŽ¨æ–­çš„è´å¶æ–¯æœ€ä¼˜å®žéªŒè®¾è®¡çš„æ–°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å®žéªŒä¿¡æ¯å¢žç›Šçš„ä¼°è®¡å’Œä¼˜åŒ–æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè´å¶æ–¯æœ€ä¼˜å®žéªŒè®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–å®žéªŒçš„é¢„æœŸä¿¡æ¯å¢žç›Šï¼Œä½†çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚çš„ä¼¼ç„¶ä¼°è®¡æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› æ­¤éœ€è¦æ–°çš„æ–¹æ³•æ¥æé«˜æ•ˆçŽ‡å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å®šä¹‰æ–°çš„ä¿¡æ¯å¢žç›Šä¼°è®¡å™¨ï¼Œå¹¶é‡‡ç”¨å¤šèµ·å§‹å¹¶è¡Œæ¢¯åº¦ä¸Šå‡æ–¹æ³•ï¼Œæœ¬æ–‡æœ‰æ•ˆåœ°è¿žæŽ¥äº†æ¨¡æ‹ŸæŽ¨æ–­ä¸Žè´å¶æ–¯æœ€ä¼˜å®žéªŒè®¾è®¡ï¼Œåˆ©ç”¨çŽ°ä»£å¯†åº¦ä¼°è®¡å·¥å…·æ¥ä¼˜åŒ–å®žéªŒè®¾è®¡ã€‚

**ä¸»è¦ç»“è®º**ï¼šé€šè¿‡è¿™äº›åˆ›æ–°ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨æ ‡å‡†çš„è´å¶æ–¯æœ€ä¼˜å®žéªŒè®¾è®¡åŸºå‡†æµ‹è¯•ä¸­èƒ½å¤Ÿä¸ŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ç›¸åŒ¹é…æˆ–è¶…è¶Šï¼Œæå‡äº†æ€§èƒ½è¾¾22%ã€‚

**å…³é”®è¯**ï¼šè´å¶æ–¯æœ€ä¼˜å®žéªŒè®¾è®¡, æœŸæœ›ä¿¡æ¯å¢žç›Š, æ¨¡æ‹ŸæŽ¨æ–­, ç¥žç»ç½‘ç»œ, æ¢¯åº¦ä¼˜åŒ–, å¤šèµ·å§‹å¹¶è¡Œæ¢¯åº¦ä¸Šå‡, æ€§èƒ½æå‡, å¯é æ€§, EIGæœ€å¤§åŒ–, rag

**è¯„åˆ†**ï¼š65

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06900v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06900v1.pdf)

---

## [24. Sample Complexity of Causal Identification with Temporal Heterogeneity](https://arxiv.org/abs/2602.06899v1)

**ä½œè€…**ï¼šAmeya Rathod, Sujay Belsare, Salvik Krishna Nautiyal ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Recovering a unique causal graph from observational data is an ill-posed problem because multiple generating mechanisms can lead to the same observational distribution. This problem becomes solvable only by exploiting specific structural or distributional assumptions. While recent work has separately utilized time-series dynamics or multi-environment heterogeneity to constrain this problem, we integrate both as complementary sources of heterogeneity. This integration yields unified necessary identifiability conditions and enables a rigorous analysis of the statistical limits of recovery under thin versus heavy-tailed noise. In particular, temporal structure is shown to effectively substitute for missing environmental diversity, possibly achieving identifiability even under insufficient heterogeneity. Extending this analysis to heavy-tailed (Student's t) distributions, we demonstrate that while geometric identifiability conditions remain invariant, the sample complexity diverges significantly from the Gaussian baseline. Explicit information-theoretic bounds quantify this cost of robustness, establishing the fundamental limits of covariance-based causal graph recovery methods in realistic non-stationary systems. This work shifts the focus from whether causal structure is identifiable to whether it is statistically recoverable in practice.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶é€šè¿‡æ•´åˆæ—¶é—´åºåˆ—åŠ¨æ€ä¸Žå¤šçŽ¯å¢ƒå¼‚è´¨æ€§ï¼Œæå‡ºäº†ç»Ÿä¸€çš„å› æžœè¯†åˆ«å¿…è¦æ¡ä»¶ï¼Œåˆ†æžäº†ä¸åŒå™ªå£°ä¸‹çš„æ ·æœ¬å¤æ‚æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæ¢å¤å”¯ä¸€çš„å› æžœå›¾æ˜¯ä¸€ä¸ªä¸é€‚å®šçš„é—®é¢˜ï¼Œä¼ ç»Ÿæ–¹æ³•æ— æ³•æœ‰æ•ˆè§£å†³ï¼Œè€Œç‰¹å®šçš„ç»“æž„æˆ–åˆ†å¸ƒå‡è®¾èƒ½å¤Ÿå¸®åŠ©è¯†åˆ«å› æžœå…³ç³»ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæœ¬ç ”ç©¶æ•´åˆäº†æ—¶é—´åºåˆ—åŠ¨æ€ä¸ŽçŽ¯å¢ƒå¼‚è´¨æ€§ï¼Œæå‡ºäº†ç»Ÿä¸€çš„è¯†åˆ«æ¡ä»¶ï¼Œå¹¶é€šè¿‡ä¿¡æ¯è®ºç•Œé™é‡åŒ–äº†åœ¨ä¸åŒå™ªå£°æ¡ä»¶ä¸‹çš„æ ·æœ¬å¤æ‚æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶è¡¨æ˜Žï¼Œæ—¶é—´ç»“æž„å¯ä»¥æœ‰æ•ˆå¼¥è¡¥çŽ¯å¢ƒå¤šæ ·æ€§çš„ç¼ºå¤±ï¼Œå³ä½¿åœ¨å¼‚è´¨æ€§ä¸è¶³çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®žçŽ°å¯è¯†åˆ«æ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†åœ¨é‡å°¾åˆ†å¸ƒä¸‹æ ·æœ¬å¤æ‚æ€§ä¸Žé«˜æ–¯åŸºå‡†çš„æ˜¾è‘—å·®å¼‚ã€‚

**å…³é”®è¯**ï¼šå› æžœè¯†åˆ«, è§‚å¯Ÿæ•°æ®, ç»Ÿè®¡æžé™, æ—¶åºåŠ¨æ€, å¤šçŽ¯å¢ƒå¼‚è´¨æ€§, é‡‡æ ·å¤æ‚åº¦, éžå¹³ç¨³ç³»ç»Ÿ, è¯†åˆ«æ¡ä»¶, ç»“æž„å‡è®¾, ç»Ÿè®¡æ¢å¤, agent

**è¯„åˆ†**ï¼š54

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06899v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06899v1.pdf)

---

## [25. A Cycle-Consistent Graph Surrogate for Full-Cycle Left Ventricular Myocardial Biomechanics](https://arxiv.org/abs/2602.06884v1)

**ä½œè€…**ï¼šSiyu Mu, Wei Xuan Chan, Choon Hwai Yap  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Image-based patient-specific simulation of left ventricular (LV) mechanics is valuable for understanding cardiac function and supporting clinical intervention planning, but conventional finite-element analysis (FEA) is computationally intensive. Current graph-based surrogates do not have full-cycle prediction capabilities, and physics-informed neural networks often struggle to converge on complex cardiac geometries. We present CardioGraphFENet (CGFENet), a unified graph-based surrogate for rapid full-cycle estimation of LV myocardial biomechanics, supervised by a large FEA simulation dataset. The proposed model integrates (i) a global--local graph encoder to capture mesh features with weak-form-inspired global coupling, (ii) a gated recurrent unit-based temporal encoder conditioned on the target volume-time signal to model cycle-coherent dynamics, and (iii) a cycle-consistent bidirectional formulation for both loading and inverse unloading within a single framework. These strategies enable high fidelity with respect to traditional FEA ground truths and produce physiologically plausible pressure-volume loops that match FEA results when coupled with a lumped-parameter model. In particular, the cycle-consistency strategy enables a significant reduction in FEA supervision with only minimal loss in accuracy.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§å¿«é€Ÿå…¨å‘¨æœŸå·¦å¿ƒå®¤å¿ƒè‚Œç”Ÿç‰©åŠ›å­¦ä¼°è®¡çš„å›¾å½¢ä»£ç†æ¨¡åž‹CardioGraphFENetï¼Œå…‹æœäº†ä¼ ç»Ÿæœ‰é™å…ƒåˆ†æžçš„è®¡ç®—è´Ÿæ‹…ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„æœ‰é™å…ƒåˆ†æžåœ¨è¿›è¡Œå·¦å¿ƒå®¤åŠ›å­¦æ¨¡æ‹Ÿæ—¶è®¡ç®—é‡å¤§ï¼Œè€ŒçŽ°æœ‰çš„å›¾å½¢ä»£ç†æ¨¡åž‹ç¼ºä¹å…¨å‘¨æœŸé¢„æµ‹èƒ½åŠ›ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°çš„æ–¹æ³•æ¥æé«˜è®¡ç®—æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCardioGraphFENetç»“åˆäº†å…¨çƒ-å±€éƒ¨å›¾ç¼–ç å™¨ã€åŸºäºŽé—¨æŽ§é€’å½’å•å…ƒçš„æ—¶é—´ç¼–ç å™¨ï¼Œä»¥åŠä¸€ä¸ªå¾ªçŽ¯ä¸€è‡´çš„åŒå‘å…¬å¼ï¼Œä»¥å®žçŽ°å¯¹å·¦å¿ƒå®¤ç”Ÿç‰©åŠ›å­¦çš„å¿«é€Ÿé¢„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¨¡åž‹åœ¨å‡å°‘æœ‰é™å…ƒåˆ†æžç›‘ç£çš„åŒæ—¶ï¼Œä»èƒ½ä¿æŒé«˜ç²¾åº¦ï¼Œå¹¶ç”Ÿæˆä¸Žæœ‰é™å…ƒç»“æžœç›¸åŒ¹é…çš„ç”Ÿç†ä¸Šåˆç†çš„åŽ‹åŠ›-ä½“ç§¯å¾ªçŽ¯ã€‚

**å…³é”®è¯**ï¼šå›¾ç¥žç»ç½‘ç»œ, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , å¾ªçŽ¯ä¸€è‡´æ€§, ç”Ÿç‰©åŠ›å­¦æ¨¡æ‹Ÿ, CardioGraphFENet, å…¨å‘¨æœŸé¢„æµ‹, ç‰©ç†ä¿¡æ¯ç¥žç»ç½‘ç»œ, é«˜ä¿çœŸåº¦, neural network

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06884v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06884v1.pdf)

---

## [26. Vision Transformer Finetuning Benefits from Non-Smooth Components](https://arxiv.org/abs/2602.06883v1)

**ä½œè€…**ï¼šAmbroise Odonnat, Laetitia Chapel, Romain Tavenard ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CV, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The smoothness of the transformer architecture has been extensively studied in the context of generalization, training stability, and adversarial robustness. However, its role in transfer learning remains poorly understood. In this paper, we analyze the ability of vision transformer components to adapt their outputs to changes in inputs, or, in other words, their plasticity. Defined as an average rate of change, it captures the sensitivity to input perturbation; in particular, a high plasticity implies low smoothness. We demonstrate through theoretical analysis and comprehensive experiments that this perspective provides principled guidance in choosing the components to prioritize during adaptation. A key takeaway for practitioners is that the high plasticity of the attention modules and feedforward layers consistently leads to better finetuning performance. Our findings depart from the prevailing assumption that smoothness is desirable, offering a novel perspective on the functional properties of transformers. The code is available at https://github.com/ambroiseodt/vit-plasticity.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šè®ºæ–‡æŽ¢è®¨äº†è§†è§‰å˜æ¢å™¨ç»„ä»¶åœ¨è¿ç§»å­¦ä¹ ä¸­çš„éžå¹³æ»‘æ€§å¦‚ä½•å½±å“å…¶é€‚åº”æ€§å’Œå¾®è°ƒæ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å˜æ¢å™¨æž¶æž„çš„å¹³æ»‘æ€§åœ¨æ³›åŒ–å’Œç¨³å®šæ€§æ–¹é¢å¾—åˆ°äº†å¹¿æ³›ç ”ç©¶ï¼Œä½†å…¶åœ¨è¿ç§»å­¦ä¹ ä¸­çš„ä½œç”¨å°šä¸æ¸…æ¥šã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡ç†è®ºåˆ†æžå’Œå®žéªŒï¼Œç ”ç©¶äº†è§†è§‰å˜æ¢å™¨ç»„ä»¶åœ¨è¾“å…¥å˜åŒ–ä¸‹çš„è¾“å‡ºé€‚åº”èƒ½åŠ›ï¼Œå³å…¶å¡‘æ€§ï¼Œå¹¶åˆ†æžäº†ä¸åŒç»„ä»¶çš„ä¼˜å…ˆçº§ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶å‘çŽ°ï¼Œæ³¨æ„åŠ›æ¨¡å—å’Œå‰é¦ˆå±‚çš„é«˜å¡‘æ€§ä¸€è‡´åœ°å¯¼è‡´æ›´å¥½çš„å¾®è°ƒæ€§èƒ½ï¼ŒæŒ‘æˆ˜äº†å¹³æ»‘æ€§è¢«è§†ä¸ºä¼˜è¶Šæ€§çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚

**å…³é”®è¯**ï¼šè§†è§‰å˜æ¢å™¨, finetuning, é€‚åº”æ€§, ç»„ä»¶é€‰æ‹©, è®­ç»ƒç¨³å®šæ€§, è¿ç§»å­¦ä¹ , transformer, plasticity, æ³¨æ„åŠ›æ¨¡å—, feedforwardå±‚

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06883v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06883v1.pdf)

---

## [27. T-STAR: A Context-Aware Transformer Framework for Short-Term Probabilistic Demand Forecasting in Dock-Based Shared Micro-Mobility](https://arxiv.org/abs/2602.06866v1)

**ä½œè€…**ï¼šJingyi Cheng, GonÃ§alo Homem de Almeida Correia, Oded Cats ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Reliable short-term demand forecasting is essential for managing shared micro-mobility services and ensuring responsive, user-centered operations. This study introduces T-STAR (Two-stage Spatial and Temporal Adaptive contextual Representation), a novel transformer-based probabilistic framework designed to forecast station-level bike-sharing demand at a 15-minute resolution. T-STAR addresses key challenges in high-resolution forecasting by disentangling consistent demand patterns from short-term fluctuations through a hierarchical two-stage structure. The first stage captures coarse-grained hourly demand patterns, while the second stage improves prediction accuracy by incorporating high-frequency, localized inputs, including recent fluctuations and real-time demand variations in connected metro services, to account for temporal shifts in short-term demand. Time series transformer models are employed in both stages to generate probabilistic predictions. Extensive experiments using Washington D.C.'s Capital Bikeshare data demonstrate that T-STAR outperforms existing methods in both deterministic and probabilistic accuracy. The model exhibits strong spatial and temporal robustness across stations and time periods. A zero-shot forecasting experiment further highlights T-STAR's ability to transfer to previously unseen service areas without retraining. These results underscore the framework's potential to deliver granular, reliable, and uncertainty-aware short-term demand forecasts, which enable seamless integration to support multimodal trip planning for travelers and enhance real-time operations in shared micro-mobility services.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šT-STARæ˜¯ä¸€ç§åŸºäºŽå˜åŽ‹å™¨çš„æ¡†æž¶ï¼Œé’ˆå¯¹çŸ­æœŸå…±äº«å¾®å‡ºè¡Œéœ€æ±‚é¢„æµ‹ï¼Œèƒ½å¤Ÿæä¾›é«˜ç²¾åº¦çš„æ¦‚çŽ‡é¢„æµ‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæœ‰æ•ˆçš„çŸ­æœŸéœ€æ±‚é¢„æµ‹å¯¹äºŽç®¡ç†å…±äº«å¾®å‡ºè¡ŒæœåŠ¡è‡³å…³é‡è¦ï¼Œä»¥ç¡®ä¿ç”¨æˆ·ä¸­å¿ƒçš„å“åº”æ“ä½œã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šT-STARé‡‡ç”¨ä¸¤é˜¶æ®µå±‚æ¬¡ç»“æž„ï¼Œç¬¬ä¸€é˜¶æ®µæ•èŽ·ç²—ç²’åº¦çš„å°æ—¶éœ€æ±‚æ¨¡å¼ï¼Œç¬¬äºŒé˜¶æ®µç»“åˆé«˜é¢‘æœ¬åœ°è¾“å…¥ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œä½¿ç”¨æ—¶é—´åºåˆ—å˜åŽ‹å™¨æ¨¡åž‹ç”Ÿæˆæ¦‚çŽ‡é¢„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šT-STARåœ¨ç¡®å®šæ€§å’Œæ¦‚çŽ‡å‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä¸”èƒ½å¤Ÿåœ¨æœªè§æœåŠ¡åŒºåŸŸè¿›è¡Œé›¶-shoté¢„æµ‹ï¼Œå±•ç¤ºäº†å…¶åœ¨çŸ­æœŸéœ€æ±‚é¢„æµ‹ä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šçŸ­æœŸéœ€æ±‚é¢„æµ‹, å…±äº«å¾®å‡ºè¡Œ, transformer, æ¦‚çŽ‡æ¨¡åž‹, æ—¶åºæ¨¡åž‹, é«˜åˆ†è¾¨çŽ‡é¢„æµ‹, T-STAR, å®žæ—¶éœ€æ±‚å˜åŒ–, ç©ºé—´æ—¶é—´é²æ£’æ€§

**è¯„åˆ†**ï¼š62

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06866v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06866v1.pdf)

---

## [28. Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts](https://arxiv.org/abs/2602.06859v1)

**ä½œè€…**ï¼šXinyu Zhao, Qingyun Sun, Jiayi Luo ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Graph Anomaly Detection (GAD) aims to identify irregular patterns in graph data, and recent works have explored zero-shot generalist GAD to enable generalization to unseen graph datasets. However, existing zero-shot GAD methods largely ignore intrinsic geometric differences across diverse anomaly patterns, substantially limiting their cross-domain generalization. In this work, we reveal that anomaly detectability is highly dependent on the underlying geometric properties and that embedding graphs from different domains into a single static curvature space can distort the structural signatures of anomalies. To address the challenge that a single curvature space cannot capture geometry-dependent graph anomaly patterns, we propose GAD-MoRE, a novel framework for zero-shot Generalizable Graph Anomaly Detection with a Mixture of Riemannian Experts architecture. Specifically, to ensure that each anomaly pattern is modeled in the Riemannian space where it is most detectable, GAD-MoRE employs a set of specialized Riemannian expert networks, each operating in a distinct curvature space. To align raw node features with curvature-specific anomaly characteristics, we introduce an anomaly-aware multi-curvature feature alignment module that projects inputs into parallel Riemannian spaces, enabling the capture of diverse geometric characteristics. Finally, to facilitate better generalization beyond seen patterns, we design a memory-based dynamic router that adaptively assigns each input to the most compatible expert based on historical reconstruction performance on similar anomalies. Extensive experiments in the zero-shot setting demonstrate that GAD-MoRE significantly outperforms state-of-the-art generalist GAD baselines, and even surpasses strong competitors that are few-shot fine-tuned with labeled data from the target domain.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šGAD-MoREæ˜¯ä¸€ç§æ–°æ¡†æž¶ï¼Œé€šè¿‡æ··åˆé»Žæ›¼ä¸“å®¶åœ¨ä¸åŒæ›²çŽ‡ç©ºé—´ä¸­å»ºæ¨¡å¼‚å¸¸æ¨¡å¼ï¼Œä»¥å®žçŽ°é›¶-shotå¯æ³›åŒ–çš„å›¾å¼‚å¸¸æ£€æµ‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçŽ°æœ‰çš„é›¶-shotå›¾å¼‚å¸¸æ£€æµ‹æ–¹æ³•å¿½è§†äº†å¼‚å¸¸æ¨¡å¼ä¹‹é—´çš„å‡ ä½•å·®å¼‚ï¼Œé™åˆ¶äº†å…¶è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šGAD-MoREä½¿ç”¨å¤šä¸ªä¸“é—¨çš„é»Žæ›¼ä¸“å®¶ç½‘ç»œï¼Œåœ¨å„è‡ªçš„æ›²çŽ‡ç©ºé—´ä¸­å¤„ç†è¾“å…¥ï¼Œå¹¶å¼•å…¥ä¸€ä¸ªå¤šæ›²çŽ‡ç‰¹å¾å¯¹é½æ¨¡å—ä»¥æ•æ‰å¤šæ ·çš„å‡ ä½•ç‰¹å¾ï¼ŒåŒæ—¶é€šè¿‡è®°å¿†é©±åŠ¨çš„åŠ¨æ€è·¯ç”±å™¨ä¼˜åŒ–è¾“å…¥åˆ†é…ã€‚

**ä¸»è¦ç»“è®º**ï¼šå¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒGAD-MoREåœ¨é›¶-shotè®¾ç½®ä¸‹æ˜¾è‘—è¶…è¿‡äº†çŽ°æœ‰çš„é€šç”¨å›¾å¼‚å¸¸æ£€æµ‹åŸºçº¿ï¼Œç”šè‡³è¶…è¶Šäº†åœ¨ç›®æ ‡é¢†åŸŸè¿›è¡Œå°‘é‡æ ·æœ¬å¾®è°ƒçš„å¼ºç«žäº‰è€…ã€‚

**å…³é”®è¯**ï¼šå›¾ç¥žç»ç½‘ç»œ, é›¶-shot, å¼‚å¸¸æ£€æµ‹, å‡ ä½•ç‰¹æ€§, å¤šæ›²çŽ‡, ç”Ÿæˆæ¨¡åž‹, ç‰¹å¾å¯¹é½, åŠ¨æ€è·¯ç”±, è·¨åŸŸæ³›åŒ–, GAD-MoRE, embedding

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06859v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06859v1.pdf)

---

## [29. Designing a Robust, Bounded, and Smooth Loss Function for Improved Supervised Learning](https://arxiv.org/abs/2602.06858v1)

**ä½œè€…**ï¼šSoumi Mahato, Lineesh M. C  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

The loss function is crucial to machine learning, especially in supervised learning frameworks. It is a fundamental component that controls the behavior and general efficacy of learning algorithms. However, despite their widespread use, traditional loss functions have significant drawbacks when dealing with high-dimensional and outlier-sensitive datasets, which frequently results in reduced performance and slower convergence during training. In this work, we develop a robust, bounded, and smooth (RoBoS-NN) loss function to resolve the aforementioned hindrances. The generalization ability of the loss function has also been theoretically analyzed to rigorously justify its robustness. Moreover, we implement RoboS-NN loss in the framework of a neural network (NN) to forecast time series and present a new robust algorithm named $\mathcal{L}_{\text{RoBoS}}$-NN. To assess the potential of $\mathcal{L}_{\text{RoBoS}}$-NN, we conduct experiments on multiple real-world datasets. In addition, we infuse outliers into data sets to evaluate the performance of $\mathcal{L}_{\text{RoBoS}}$-NN in more challenging scenarios. Numerical results show that $\mathcal{L}_{\text{RoBoS}}$-NN outperforms the other benchmark models in terms of accuracy measures.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é²æ£’ã€æœ‰é™å’Œå¹³æ»‘çš„æŸå¤±å‡½æ•°RoBoS-NNï¼Œä»¥æ”¹å–„ç›‘ç£å­¦ä¹ åœ¨é«˜ç»´å’Œå¼‚å¸¸å€¼æ•æ„Ÿæ•°æ®é›†ä¸Šçš„è¡¨çŽ°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»ŸæŸå¤±å‡½æ•°åœ¨å¤„ç†é«˜ç»´å’Œå¼‚å¸¸å€¼æ•æ„Ÿæ•°æ®æ—¶å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå½±å“äº†å­¦ä¹ ç®—æ³•çš„æ€§èƒ½å’Œæ”¶æ•›é€Ÿåº¦ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¼€å‘RoBoS-NNæŸå¤±å‡½æ•°ï¼Œå¹¶åœ¨ç¥žç»ç½‘ç»œæ¡†æž¶ä¸­å®žçŽ°ï¼Œæå‡ºæ–°çš„ç®—æ³•$	ext{L}_{	ext{RoBoS}}$-NNï¼Œè¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®žéªŒç»“æžœè¡¨æ˜Žï¼Œ$	ext{L}_{	ext{RoBoS}}$-NNåœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†å…¶ä»–åŸºå‡†æ¨¡åž‹ï¼Œè¯æ˜Žäº†å…¶åœ¨æŒ‘æˆ˜æ€§åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§ã€‚

**å…³é”®è¯**ï¼šæœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , ç¥žç»ç½‘ç»œ, æœ‰ç•Œå¹³æ»‘æŸå¤±å‡½æ•°, ç›‘ç£å­¦ä¹ , æ—¶é—´åºåˆ—é¢„æµ‹, é²æ£’ç®—æ³•, å®žéªŒè¯„ä¼°, æ•°æ®é›†, machine learning

**è¯„åˆ†**ï¼š58

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06858v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06858v1.pdf)

---

## [30. Improved Sampling Schedules for Discrete Diffusion Models](https://arxiv.org/abs/2602.06849v1)

**ä½œè€…**ï¼šAlberto Foresti, Mustapha Bounoua, Giulio Franzese ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-06

### ðŸ“„ è®ºæ–‡æ‘˜è¦

Discrete diffusion models have emerged as a powerful paradigm for generative modeling on sequence data; however, the information-theoretic principles governing their reverse processes remain significantly less understood than those of their continuous counterparts. In this work, we bridge this gap by analyzing the reverse process dynamics through the lens of thermodynamic entropy production. We propose the entropy production rate as a rigorous proxy for quantifying information generation, deriving as a byproduct a bound on the Wasserstein distance between intermediate states and the data distribution. Leveraging these insights, we introduce two novel sampling schedules that are uniformly spaced with respect to their corresponding physics-inspired metrics: the Entropic Discrete Schedule (EDS), which is defined by maintaining a constant rate of information gain, and the Wasserstein Discrete Schedule (WDS), which is defined by taking equal steps in terms of the Wasserstein distance. We empirically demonstrate that our proposed schedules significantly outperform state-of-the-art strategies across diverse application domains, including synthetic data, music notation, vision and language modeling, consistently achieving superior performance at a lower computational budget.

### ðŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–°é¢–çš„ç¦»æ•£æ‰©æ•£æ¨¡åž‹é‡‡æ ·ç­–ç•¥ï¼Œä»¥æé«˜ç”Ÿæˆæ¨¡åž‹åœ¨åºåˆ—æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç¦»æ•£æ‰©æ•£æ¨¡åž‹åœ¨ç”Ÿæˆå»ºæ¨¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶åå‘è¿‡ç¨‹çš„ä¿¡æ¯ç†è®ºåŽŸç†å°šä¸å®Œå–„ï¼ŒäºŸéœ€æ·±å…¥ç ”ç©¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡çƒ­åŠ›å­¦ç†µäº§ç”Ÿçš„è§†è§’ï¼Œæœ¬æ–‡æå‡ºäº†ä¿æŒæ’å®šä¿¡æ¯å¢žç›Šçš„ç†µç¦»æ•£è°ƒåº¦ï¼ˆEDSï¼‰å’Œåœ¨Wassersteinè·ç¦»ä¸Šç­‰æ­¥é•¿çš„Wassersteinç¦»æ•£è°ƒåº¦ï¼ˆWDSï¼‰ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æé‡‡æ ·ç­–ç•¥åœ¨å¤šç§åº”ç”¨é¢†åŸŸçš„è¡¨çŽ°æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œä»¥æ›´ä½Žçš„è®¡ç®—é¢„ç®—å®žçŽ°äº†æ›´å¥½çš„æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šç¦»æ•£æ‰©æ•£æ¨¡åž‹, ç”Ÿæˆå»ºæ¨¡, ä¿¡æ¯ç”Ÿæˆ, ç†µäº§ç”ŸçŽ‡, Wassersteinè·ç¦», Entropic Discrete Schedule, Wasserstein Discrete Schedule, è®¡ç®—æ•ˆçŽ‡, è§†è§‰ä¸Žè¯­è¨€å»ºæ¨¡, éŸ³ä¹ç¬¦å·, ml

**è¯„åˆ†**ï¼š60

**è®ºæ–‡é“¾æŽ¥**ï¼š[æŸ¥çœ‹åŽŸæ–‡](https://arxiv.org/abs/2602.06849v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.06849v1.pdf)
>>>>>>> c7131d2 (Backfill recent data and stabilize unified fetch workflow)

---

