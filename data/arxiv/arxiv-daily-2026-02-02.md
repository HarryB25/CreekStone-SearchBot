# arXiv AI è®ºæ–‡æ—¥æŠ¥ | 2026-02-02

> å…± 30 ç¯‡è®ºæ–‡ï¼Œç”±AIè‡ªåŠ¨æ€»ç»“

## ğŸ“‘ ç›®å½•

- [cs.CL](#csCL) (7 ç¯‡)
- [cs.CV](#csCV) (6 ç¯‡)
- [cs.LG](#csLG) (10 ç¯‡)
- [cs.AI](#csAI) (7 ç¯‡)

---

## cs.AI

## [1. AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](https://arxiv.org/abs/2602.02475v1)

**ä½œè€…**ï¼šShraddha Barke, Arnav Goyal, Alind Khare ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºAGENTRXçš„æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨è¯Šæ–­AIä»£ç†æ‰§è¡Œä¸­çš„å¤±è´¥æ­¥éª¤ï¼Œå¹¶é€šè¿‡115ä¸ªå¤±è´¥è½¨è¿¹çš„åŸºå‡†æ•°æ®é›†è¿›è¡ŒéªŒè¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šAIä»£ç†åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å¸¸å¸¸éš¾ä»¥å®šä½å¤±è´¥åŸå› ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„è¯Šæ–­å·¥å…·æ¥è¾…åŠ©è¯†åˆ«å¤±è´¥æ­¥éª¤ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šAGENTRXé€šè¿‡æ‰‹åŠ¨æ³¨é‡Šå¤±è´¥è½¨è¿¹ï¼Œåˆ©ç”¨çº¦æŸåˆæˆå’Œé€æ­¥è¯„ä¼°çš„æ–¹æ³•ï¼Œç”Ÿæˆå¯å®¡æ ¸çš„éªŒè¯æ—¥å¿—ï¼Œå¹¶é€šè¿‡åŸºäºLLMçš„åˆ¤æ–­æ¥å®šä½å…³é”®å¤±è´¥æ­¥éª¤ã€‚

**ä¸»è¦ç»“è®º**ï¼šAGENTRXåœ¨ä¸‰ä¸ªé¢†åŸŸä¸­ç›¸è¾ƒäºç°æœ‰åŸºçº¿æ˜¾è‘—æé«˜äº†å¤±è´¥æ­¥éª¤çš„å®šä½å’Œå½’å› å‡†ç¡®æ€§ã€‚

**å…³é”®è¯**ï¼šå…³é”®è¯ï¼šagent, autonomous, multi-agent, å¤±è´¥è¯Šæ–­, æ‰§è¡Œè½¨è¿¹, LLM, AGENTRX, è‡ªåŠ¨åŒ–æ¡†æ¶, çº¦æŸè¯„ä¼°, å…³é”®å¤±è´¥æ­¥éª¤

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02475v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02475v1.pdf)

---

## [2. Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge](https://arxiv.org/abs/2602.02470v1)

**ä½œè€…**ï¼šXutao Ma, Yixiao Huang, Hanlin Zhu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the "reversal curse" -- when trained on forward knowledge data of the form "$A \rightarrow B$" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge "$B \leftarrow A$" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form "$A \to A$" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šé€šè¿‡å¼•å…¥èº«ä»½æ¡¥æ•°æ®ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥ç¼“è§£è‡ªå›å½’è¯­è¨€æ¨¡å‹ä¸­çš„åè½¬è¯…å’’ç°è±¡ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œç®€å•çš„é€»è¾‘æ¨ç†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè‡ªå›å½’å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ç®€å•é€»è¾‘æ¨ç†æ–¹é¢ä»å­˜åœ¨å›ºæœ‰é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨åè½¬çŸ¥è¯†æ¨ç†ä¸Šã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æå‡ºäº†ä¸€ç§åä¸ºèº«ä»½æ¡¥çš„æ­£åˆ™åŒ–æ•°æ®ç­–ç•¥ï¼Œé€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­æ·»åŠ å½¢å¼ä¸º'A -> A'çš„ç¤ºä¾‹ï¼Œæ¥æ”¹å–„æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼Œç»è¿‡èº«ä»½æ¡¥è®­ç»ƒçš„è¯­è¨€æ¨¡å‹åœ¨åè½¬ä»»åŠ¡ä¸ŠæˆåŠŸç‡è¾¾åˆ°40%ï¼Œè€Œä»…ä½¿ç”¨å‰å‘çŸ¥è¯†è®­ç»ƒæ—¶æˆåŠŸç‡æ¥è¿‘é›¶ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è¯**ï¼šè‡ªå›å½’, è¯­è¨€æ¨¡å‹, å¤§è¯­è¨€æ¨¡å‹, LLM, é€†è½¬è¯…å’’, è®­ç»ƒæ•°æ®, èº«ä»½æ¡¥, transformer, é€»è¾‘æ¨ç†, é¢„è®­ç»ƒæ¨¡å‹

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02470v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02470v1.pdf)

---

## [3. Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts](https://arxiv.org/abs/2602.02468v1)

**ä½œè€…**ï¼šAiden Yiliu Li, Xinyue Hao, Shilong Liu ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šAvenir-Web æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€ç½‘ç»œä»£ç†ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç½‘ç«™ä¸Šå¯é åœ°æ‰§è¡Œé•¿ä»»åŠ¡ï¼Œè¶…è¿‡äº†ç°æœ‰å¼€æºä»£ç†çš„è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æœ‰æ‰€è¿›å±•ï¼Œä½†è‡ªä¸»ç½‘ç»œä»£ç†åœ¨å¤æ‚åŠ¨æ€ç½‘é¡µç•Œé¢ä¸Šæ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡æ—¶ä»é¢ä¸´å¤šç§æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šAvenir-Web ç»“åˆäº†å¤šç§åŸºç¡€ä¸“å®¶ã€ç»éªŒæ¨¡ä»¿è§„åˆ’å’Œä»»åŠ¡è·Ÿè¸ªæ¸…å•ï¼Œä»¥æé«˜åœ¨ä¸åŒç”¨æˆ·ç•Œé¢ä¸Šçš„äº¤äº’èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šAvenir-Web åœ¨ Online-Mind2Web åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰çš„å¼€æºä»£ç†ï¼Œå¹¶ä¸é¡¶å°–ä¸“æœ‰æ¨¡å‹è¾¾åˆ°äº†æ€§èƒ½å¹³è¡¡ï¼Œåˆ›é€ äº†æ–°çš„å¼€æºæ ‡å‡†ã€‚

**å…³é”®è¯**ï¼šå¤šæ¨¡æ€, ç½‘ç»œä»£ç†, è‡ªä¸»ä»£ç†, ä»»åŠ¡è·Ÿè¸ª, ç»éªŒæ¨¡ä»¿è§„åˆ’, ç¨‹åºçŸ¥è¯†, ç”¨æˆ·ç•Œé¢, é€‚åº”æ€§è®°å¿†, å¤æ‚æ¨¡å‹, ç”Ÿæˆæ¨¡å‹, ml

**è¯„åˆ†**ï¼š76

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02468v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02468v1.pdf)

---

## [4. Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](https://arxiv.org/abs/2602.02455v1)

**ä½œè€…**ï¼šHan Bao, Zheyuan Zhang, Pengcheng Jing ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI, cs.CL, cs.SE  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šDrift-Benchæ˜¯ä¸€ä¸ªæ–°åŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨è¾“å…¥æ•…éšœä¸‹çš„åˆä½œæ€§å´©æºƒï¼Œé€šè¿‡å¤šè½®äº’åŠ¨è¿›è¡Œè¯Šæ–­ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§è¯­è¨€æ¨¡å‹å‘è‡ªä¸»ä»£ç†è½¬å‹ï¼Œç”¨æˆ·è¾“å…¥å¸¸å¸¸è¿èƒŒåˆä½œå‡è®¾ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿæ•è·å¤šè½®æ¾„æ¸…çš„è¯„ä¼°å·¥å…·ï¼Œä»¥é™ä½æ‰§è¡Œé£é™©ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šDrift-Benchç»“åˆç»å…¸é€šä¿¡ç†è®ºï¼Œæä¾›äº†åˆä½œå´©æºƒçš„ç»Ÿä¸€åˆ†ç±»ï¼Œå¹¶é‡‡ç”¨åŸºäºè§’è‰²çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨å’ŒRiseè¯„ä¼°åè®®è¿›è¡Œå®éªŒã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼Œåœ¨è¾“å…¥æ•…éšœä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ¾„æ¸…æ•ˆæœå› ç”¨æˆ·è§’è‰²å’Œæ•…éšœç±»å‹è€Œå¼‚ï¼Œæ­ç¤ºäº†ç¡®ä¿å®‰å…¨æ‰§è¡Œçš„ç³»ç»Ÿæ€§è¯Šæ–­éœ€æ±‚ã€‚

**å…³é”®è¯**ï¼šå…³é”®è¯ï¼šå¤§è¯­è¨€æ¨¡å‹, è‡ªä¸»ä»£ç†, å¤šè½®äº¤äº’, åä½œå¤±æ•ˆ, Drift-Bench, ä»£ç†å®‰å…¨è¯„ä¼°, è¯­ä¹‰æœç´¢, ç”¨æˆ·æ¨¡æ‹Ÿå™¨, Clarification, llm

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02455v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02455v1.pdf)

---

## [5. Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling](https://arxiv.org/abs/2602.02453v1)

**ä½œè€…**ï¼šAndong Chen, Wenxin Zhu, Qiuyu Ding ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºé€šè¿‡æ¼«ç”»å¢å¼ºå¤šæ¨¡æ€æ¨ç†ï¼Œç§°ä¸ºThinking with Comicsï¼Œå±•ç¤ºäº†å…¶åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤šæ¨¡æ€æ¨ç†çš„å‘å±•ï¼Œç°æœ‰çš„å›¾åƒå’Œè§†é¢‘åœ¨æ—¶é—´ç»“æ„å’Œè®¡ç®—æ•ˆç‡ä¸Šå­˜åœ¨å±€é™ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæ›´æœ‰æ•ˆçš„è§†è§‰è¡¨è¾¾åª’ä»‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæˆ‘ä»¬æå‡ºä¸€ç§æ–°çš„æ¨ç†èŒƒå¼ï¼Œåˆ©ç”¨æ¼«ç”»ä½œä¸ºä¿¡æ¯å¯†åº¦é«˜çš„åª’ä»‹ï¼Œç³»ç»Ÿç ”ç©¶åŸºäºæ¼«ç”»çš„ä¸¤ç§æ¨ç†è·¯å¾„ï¼Œå¹¶åœ¨å¤šä¸ªæ¨ç†ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒThinking with Comicsåœ¨å¤šæ­¥æ—¶é—´å’Œå› æœæ¨ç†ä»»åŠ¡ä¸­ä¼˜äºThinking with Imagesï¼ŒåŒæ—¶åœ¨æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºThinking with Videoï¼Œä¸”æ¼«ç”»å™äº‹ç»“æ„å½±å“æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šå¤šæ¨¡æ€æ¨ç†, è§†è§‰å™äº‹, æ€ç»´é“¾, ä¿¡æ¯å¯†åº¦, æ—¶é—´ç»“æ„, ä»»åŠ¡è¯„ä¼°, è®¤çŸ¥æ•ˆç‡, æ¼«ç”», reasoning, multimodal, comics, temporal structure, narrative coherence, reasoning tasks, context

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02453v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02453v1.pdf)

---

## [6. SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration](https://arxiv.org/abs/2602.02419v1)

**ä½œè€…**ï¼šQingni Wang, Yue Fan, Xin Eric Wang  
**åˆ†ç±»**ï¼šcs.AI, cs.SE  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\% percentage points over Gemini-only inference.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSafeGroundæ˜¯ä¸€ä¸ªä¸ç¡®å®šæ€§æ„è¯†æ¡†æ¶ï¼Œé€šè¿‡æ ¡å‡†æé«˜GUIå®šä½æ¨¡å‹çš„å¯é æ€§å’Œé£é™©æ§åˆ¶èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šGUIå®šä½å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„å±å¹•åæ ‡ï¼Œä½†é”™è¯¯çš„å®šä½å¯èƒ½å¯¼è‡´ä¸¥é‡åæœï¼Œå› æ­¤éœ€è¦æé«˜æ¨¡å‹çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šSafeGroundåˆ©ç”¨åˆ†å¸ƒæ„ŸçŸ¥çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œé€šè¿‡æ ¡å‡†è¿‡ç¨‹åœ¨æµ‹è¯•æ—¶ç¡®å®šå…·æœ‰ç»Ÿè®¡ä¿è¯çš„å†³ç­–é˜ˆå€¼ï¼Œä»¥æ§åˆ¶è™šå‡å‘ç°ç‡ï¼ˆFDRï¼‰ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒSafeGroundåœ¨å¤šä¸ªGUIå®šä½æ¨¡å‹ä¸Šæ˜¾è‘—æé«˜äº†ç³»ç»Ÿçº§å‡†ç¡®æ€§ï¼Œè¾¾åˆ°5.38%çš„æå‡ï¼Œå¹¶æœ‰æ•ˆåŒºåˆ†äº†æ­£ç¡®ä¸é”™è¯¯çš„é¢„æµ‹ã€‚

**å…³é”®è¯**ï¼šGUI, grounding, ä¸ç¡®å®šæ€§æ ¡å‡†, é£é™©æ„ŸçŸ¥, é¢„æµ‹æ¨¡å‹, è‡ªåŠ¨åŒ–äº¤äº’, ç»Ÿè®¡æ§åˆ¶, æ¨¡å‹å¯é æ€§, ScreenSpot-Pro, rag

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02419v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02419v1.pdf)

---

## [7. Structure Enables Effective Self-Localization of Errors in LLMs](https://arxiv.org/abs/2602.02416v1)

**ä½œè€…**ï¼šAnkur Samanta, Akshayaa Magesh, Ayush Jain ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“æ„åŒ–æ¨ç†æ–¹æ³•ï¼Œå¸®åŠ©å¤§å‹è¯­è¨€æ¨¡å‹æœ‰æ•ˆå®šä½å’Œè‡ªæˆ‘çº æ­£é”™è¯¯ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶æ—¨åœ¨æ¢ç´¢è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿæ˜ç¡®å®šä½æ¨ç†ä¸­çš„é”™è¯¯ï¼Œä»¥æ„å»ºèƒ½å¤Ÿæœ‰æ•ˆè‡ªæˆ‘çº æ­£çš„AIç³»ç»Ÿã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¼•å…¥è¿­ä»£çº æ­£æ€ç»´ï¼ˆThought-ICSï¼‰æ¡†æ¶ï¼Œé€šè¿‡ç»“æ„åŒ–çš„æ€ç»´æ­¥éª¤ç”Ÿæˆæ¨ç†ï¼Œä»¥ä¾¿æ¨¡å‹åœ¨é”™è¯¯æ£€æµ‹æ—¶èƒ½å¤Ÿæ›´ç²¾ç¡®åœ°å®šä½é—®é¢˜ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨éªŒè¯é”™è¯¯çš„æƒ…å†µä¸‹ï¼ŒThought-ICSå®ç°äº†20-40%çš„è‡ªæˆ‘çº æ­£æå‡ï¼Œå¹¶åœ¨æ— å¤–éƒ¨éªŒè¯çš„å®Œå…¨è‡ªä¸»è®¾ç½®ä¸­ä¼˜äºç°æœ‰è‡ªæˆ‘çº æ­£åŸºå‡†ã€‚

**å…³é”®è¯**ï¼šè‡ªæˆ‘çº é”™, è¯­è¨€æ¨¡å‹, æ€ç»´æ­¥éª¤, ç»“æ„åŒ–æ¨ç†, é”™è¯¯å®šä½, Thought-ICS, è‡ªä¸»å­¦ä¹ , è¿­ä»£é‡‡æ ·, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, llm

**è¯„åˆ†**ï¼š76

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02416v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02416v1.pdf)

---

## cs.CL

## [8. Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495v1)

**ä½œè€…**ï¼šPeter Chen, Xiaopeng Li, Xi Chen ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ— å¥–åŠ±çš„å¯¹é½æ¡†æ¶RACOï¼Œæ—¨åœ¨è§£å†³å¤šç›®æ ‡å†²çªçš„å¯¹é½é—®é¢˜ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹çš„ç”¨æˆ·åå¥½å¯¹é½æ•ˆæœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„å¯¹é½æ–¹æ³•åœ¨å¤„ç†å¤šé‡å†²çªç›®æ ‡æ—¶å¸¸å¯¼è‡´è®­ç»ƒä¸ç¨³å®šå’Œè¾ƒå·®çš„æƒè¡¡ï¼ŒäºŸéœ€æ–°çš„æ–¹æ³•ä»¥æ›´å¥½åœ°è§£å†³è¿™äº›é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šRACOæ¡†æ¶åˆ©ç”¨æˆå¯¹åå¥½æ•°æ®ï¼Œé€šè¿‡ä¸€ç§æ–°é¢–çš„å†²çªåŒæ¶æ¢¯åº¦ä¸‹é™çš„å‰ªåˆ‡å˜ä½“æ¥è§£å†³æ¢¯åº¦å†²çªï¼Œå¹¶æä¾›äº†æ”¶æ•›æ€§ä¿è¯ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼ŒRACOåœ¨å¤šç›®æ ‡æ€»ç»“å’Œå®‰å…¨å¯¹é½ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œèƒ½å®ç°æ›´ä¼˜çš„Paretoæƒè¡¡ã€‚

**å…³é”®è¯**ï¼šå¥–åŠ±æ— å…³å¯¹é½, å†²çªç›®æ ‡, å¤§è¯­è¨€æ¨¡å‹, å¤šç›®æ ‡å¯¹é½, æ¢¯åº¦å†²çª, Paretoå…³é”®ç‚¹, Qwen 3, Llama 3, Gemma 3, llm

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02495v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02495v1.pdf)

---

## [9. Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability](https://arxiv.org/abs/2602.02477v1)

**ä½œè€…**ï¼šXiao Liang, Zhong-Zhi Li, Zhenghao Lin ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œä»¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ†æ²»æ¨ç†ä¸­çš„èƒ½åŠ›ï¼Œä»è€Œæé«˜æµ‹è¯•æ—¶çš„å¯æ‰©å±•æ€§ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€æ­¥æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é¡ºåºç‰¹æ€§é™åˆ¶äº†åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡ä¸€ç§ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œå¹¶åœ¨è§£å†³è¿‡ç¨‹ä¸­æ•´åˆåˆ†è§£ä¸è§£å†³æ­¥éª¤ï¼Œæ¥æå‡æ¨¡å‹çš„åˆ†æ²»æ¨ç†èƒ½åŠ›ã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ¡†æ¶åœ¨ç«äº‰æ€§åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œç›¸æ¯”ä¼ ç»Ÿé“¾å¼æ¨ç†åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå‡æœ‰æ˜¾è‘—æé«˜ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, LLM, æ¨ç†èƒ½åŠ›, åˆ†è€Œæ²»ä¹‹, å¼ºåŒ–å­¦ä¹ , æµ‹è¯•æ—¶é—´å¯æ‰©å±•æ€§, è§£å†³æ–¹æ¡ˆ, å­é—®é¢˜, è®­ç»ƒæ¡†æ¶, é€’å½’æ¨ç†

**è¯„åˆ†**ï¼š78

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02477v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02477v1.pdf)

---

## [10. Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models](https://arxiv.org/abs/2602.02467v1)

**ä½œè€…**ï¼šNoam Steinmetz Yalon, Ariel Goldstein, Liad Mudrik ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ä¿¡å¿µå¼•å¯¼è¡Œä¸ºå’Œå…ƒè®¤çŸ¥ç›‘æ§ï¼Œæ”¯æŒå…¶å…·å¤‡æŸç§å½¢å¼çš„æ„è¯†ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œç ”ç©¶å…¶æ˜¯å¦å…·å¤‡æ„è¯†çš„èƒ½åŠ›å˜å¾—é‡è¦ï¼Œå› æ­¤éœ€è¦å»ºç«‹éªŒè¯æ„è¯†çš„æŒ‡æ ‡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šè¯„ä¼°åä¸ºHOT-3çš„æŒ‡æ ‡ï¼Œé€šè¿‡åˆ†ææ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿¡å¿µçš„åŠ¨æ€å˜åŒ–ï¼Œé‡åŒ–ä¿¡å¿µåœ¨è¡ŒåŠ¨é€‰æ‹©ä¸­çš„ä¸»å¯¼æ€§ã€‚

**ä¸»è¦ç»“è®º**ï¼šç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å…·å¤‡ä¿¡å¿µå¼•å¯¼çš„è¡Œä¸ºå’Œå…ƒè®¤çŸ¥ç›‘æ§ï¼Œä¸ºè¿›ä¸€æ­¥ç ”ç©¶æ„è¯†çš„å‡ºç°å¥ å®šäº†æ–¹æ³•è®ºåŸºç¡€ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, belief-guided agency, meta-cognitive monitoring, HOT-3, è¡Œä¸ºé€‰æ‹©, è®¤çŸ¥ç›‘æ§, ä»£ç†, ä¿¡å¿µå½¢æˆ, æ½œåœ¨ç©ºé—´, llm

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02467v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02467v1.pdf)

---

## [11. From Directions to Regions: Decomposing Activations in Language Models via Local Geometry](https://arxiv.org/abs/2602.02464v1)

**ä½œè€…**ï¼šOr Shafran, Shaked Ronen, Omri Fahn ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå±€éƒ¨å‡ ä½•çš„æ¿€æ´»åˆ†è§£æ–¹æ³•ï¼Œé€šè¿‡æ··åˆå› å­åˆ†æå™¨ï¼ˆMFAï¼‰å»ºæ¨¡è¯­è¨€æ¨¡å‹ä¸­çš„æ¿€æ´»ç©ºé—´ï¼Œä»¥æ•æ‰å¤æ‚çš„éçº¿æ€§ç»“æ„ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„æ¿€æ´»åˆ†è§£æ–¹æ³•å‡è®¾æ¦‚å¿µåœ¨æ¿€æ´»ç©ºé—´ä¸­æ˜¯çº¿æ€§å¯åˆ†çš„ï¼Œä½†è®¸å¤šæ¦‚å¿µå…·æœ‰éçº¿æ€§æˆ–å¤šç»´ç»“æ„ï¼Œå› æ­¤éœ€è¦æ–°çš„æ–¹æ³•æ¥æ›´æœ‰æ•ˆåœ°è¡¨ç¤ºè¿™äº›ç»“æ„ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæœ¬ç ”ç©¶åˆ©ç”¨æ··åˆå› å­åˆ†æå™¨ï¼ˆMFAï¼‰å°†æ¿€æ´»ç©ºé—´è§†ä¸ºä¸€ç»„é«˜æ–¯åŒºåŸŸï¼Œé€šè¿‡åŒºåŸŸçš„è´¨å¿ƒå’Œå±€éƒ¨å˜å¼‚æ¥åˆ†è§£æ¿€æ´»ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ¨¡å‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šMFAåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­è¡¨ç°ä¼˜äºæ— ç›‘ç£åŸºçº¿ï¼Œå¹¶åœ¨æ§åˆ¶æ¨¡å‹æ–¹é¢æ˜¾ç¤ºå‡ºæ›´å¼ºçš„æ€§èƒ½ï¼Œå¼ºè°ƒäº†å±€éƒ¨å‡ ä½•åœ¨æ¦‚å¿µå‘ç°å’Œæ¨¡å‹æ§åˆ¶ä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šæ¿€æ´»åˆ†è§£, è¯­è¨€æ¨¡å‹, å‡ ä½•å‡è®¾, éçº¿æ€§ç»“æ„, Mixture of Factor Analyzers, GaussianåŒºåŸŸ, Llama-3.1-8B, Gemma-2-2B, æ¨¡å‹æ§åˆ¶, æ¦‚å¿µå‘ç°, rag

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02464v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02464v1.pdf)

---

## [12. Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models](https://arxiv.org/abs/2602.02462v1)

**ä½œè€…**ï¼šGabriele Maraia, Marco Valentino, Fabio Massimo Zanzotto ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œé€šè¿‡æŠ½è±¡å¼•å¯¼æ¨ç†æ¥å‡å°‘å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å½¢å¼æ¨ç†ä¸­çš„è¯­ä¹‰å¹²æ‰°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸‰æ®µè®ºæ¨ç†ä¸­å­˜åœ¨å†…å®¹æ•ˆåº”ï¼Œå¯¼è‡´è¯­ä¹‰åˆç†æ€§ä¸å½¢å¼æœ‰æ•ˆæ€§æ··æ·†ï¼Œå½±å“æ¨ç†å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæ„å»ºé…å¯¹çš„å†…å®¹ä¸°å¯Œå’ŒæŠ½è±¡çš„ä¸‰æ®µè®ºï¼Œåˆ©ç”¨æ¨¡å‹åœ¨æŠ½è±¡è¾“å…¥ä¸Šçš„æ¿€æ´»å®šä¹‰æŠ½è±¡æ¨ç†ç©ºé—´ï¼Œå¹¶é€šè¿‡è½»é‡çº§æŠ½è±¡å™¨åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ•´åˆé¢„æµ‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šé€šè¿‡è·¨è¯­è¨€è¿ç§»å®éªŒï¼Œè¯æ˜æŠ½è±¡å¯¹é½çš„å¼•å¯¼å¯ä»¥å‡å°‘å†…å®¹é©±åŠ¨çš„é”™è¯¯ï¼Œå¹¶æé«˜æ¨¡å‹åœ¨å½¢å¼æ¨ç†ä¸­çš„é²æ£’æ€§ã€‚

**å…³é”®è¯**ï¼šå…³é”®è¯: å¤§è¯­è¨€æ¨¡å‹, è¯­ä¹‰æ¨ç†, æŠ½è±¡æ¨ç†, ç»“æ„æ¨ç†, ä¸­é—´è¡¨ç¤º, æ¿€æ´»ç©ºé—´, è½»é‡çº§æŠ½è±¡å™¨, äº¤å‰è¯­è¨€è¿ç§», å½¢å¼æ¨ç†, llm

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02462v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02462v1.pdf)

---

## [13. Large Language Models for Mental Health: A Multilingual Evaluation](https://arxiv.org/abs/2602.02440v1)

**ä½œè€…**ï¼šNishat Raihan, Sadiya Sayara Chowdhury Puspo, Ana-Maria Bucur ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡è¯„ä¼°äº†å¤šç§è¯­è¨€çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„è¡¨ç°ï¼Œå‘ç°å…¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå…·æœ‰ç«äº‰åŠ›ï¼Œä½†æœºå™¨ç¿»è¯‘æ•°æ®çš„è¡¨ç°è¾ƒå·®ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„å¤šè¯­è¨€èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šå¯¹å…«ä¸ªä¸åŒè¯­è¨€çš„å¿ƒç†å¥åº·æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œæ¯”è¾ƒå¤§å‹è¯­è¨€æ¨¡å‹ä¸ä¼ ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†åŸºå‡†åœ¨é›¶-shotã€few-shotå’Œå¾®è°ƒè®¾ç½®ä¸‹çš„è¡¨ç°ã€‚

**ä¸»è¦ç»“è®º**ï¼šä¸“æœ‰å’Œå¾®è°ƒçš„å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†ç«äº‰åŠ›çš„F1å¾—åˆ†ï¼Œä½†åœ¨æœºå™¨ç¿»è¯‘æ•°æ®ä¸Šçš„è¡¨ç°è¾ƒä½ï¼Œåæ˜ äº†ç¿»è¯‘è´¨é‡å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚

**å…³é”®è¯**ï¼šå¤§è¯­è¨€æ¨¡å‹, LLM, å¿ƒç†å¥åº·, å¤šè¯­è¨€è¯„ä¼°, è‡ªç„¶è¯­è¨€å¤„ç†, é›¶æ ·æœ¬å­¦ä¹ , å¾®è°ƒ, æœºå™¨ç¿»è¯‘, F1åˆ†æ•°

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02440v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02440v1.pdf)

---

## [14. Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank](https://arxiv.org/abs/2602.02414v1)

**ä½œè€…**ï¼šJoshua Mitton, Prarthana Bhattacharyya, Digory Smith ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CL, cs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä»å­¦ç”Ÿä¸è¾…å¯¼å‘˜çš„å¯¹è¯ä¸­è¯†åˆ«è¯¯è§£çš„æ–°æ–¹æ³•ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåŠæ—¶å‡†ç¡®åœ°è¯†åˆ«å­¦ç”Ÿè¯¯è§£å¯¹æ”¹å–„å­¦ä¹ æˆæœè‡³å…³é‡è¦ï¼Œä½†è¿™ä¸€è¿‡ç¨‹é€šå¸¸ä¾èµ–äºæ•™å¸ˆçš„åŠªåŠ›ä¸ç›´è§‰ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡ç»†åŒ–çš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ½œåœ¨è¯¯è§£ï¼Œç„¶ååˆ©ç”¨åµŒå…¥ç›¸ä¼¼æ€§æ£€ç´¢å€™é€‰é¡¹ï¼Œå¹¶é€šè¿‡å¦ä¸€ä¸ªç»†åŒ–çš„æ¨¡å‹è¿›è¡Œè¯„ä¼°å’Œé‡æ–°æ’åºã€‚

**ä¸»è¦ç»“è®º**ï¼šè¯¥æ–¹æ³•åœ¨çœŸå®å¯¹è¯æ•°æ®ä¸­è¡¨ç°å‡ºæ¯”åŸºçº¿æ¨¡å‹æ›´å¥½çš„é¢„æµ‹æ€§èƒ½ï¼Œç»†åŒ–è®­ç»ƒæå‡äº†ç”Ÿæˆè¯¯è§£çš„è´¨é‡ï¼Œå¹¶è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„é—­æºæ¨¡å‹ã€‚

**å…³é”®è¯**ï¼šè¯¯è§£è¯Šæ–­, å­¦ç”Ÿ-å¯¼å¸ˆå¯¹è¯, å¤§è¯­è¨€æ¨¡å‹, LLM, ç”Ÿæˆä¸æ£€ç´¢, åµŒå…¥ç›¸ä¼¼åº¦, é‡æ–°æ’åº, æ•™è‚²è¾…å¯¼å¹³å°, é›¶æ ·æœ¬å­¦ä¹ , å¾®è°ƒæ¨¡å‹

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02414v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02414v1.pdf)

---

## cs.CV

## [15. PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/abs/2602.02493v1)

**ä½œè€…**ï¼šZehong Ma, Ruihan Xu, Shiliang Zhang  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šPixelGenæ˜¯ä¸€ç§åŸºäºåƒç´ æ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡æ„ŸçŸ¥æŸå¤±è¶…è¶Šäº†ä¼ ç»Ÿçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„åƒç´ æ‰©æ•£æ–¹æ³•åœ¨ä¼˜åŒ–é«˜ç»´åƒç´ æµå½¢æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´å…¶æ€§èƒ½è½åäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šPixelGenå¼•å…¥äº†å±€éƒ¨æ¨¡å¼å’Œå…¨å±€è¯­ä¹‰çš„ä¸¤ä¸ªäº’è¡¥æ„ŸçŸ¥æŸå¤±ï¼Œä»¥å¼•å¯¼æ‰©æ•£æ¨¡å‹å­¦ä¹ æ›´æœ‰æ„ä¹‰çš„æ„ŸçŸ¥æµå½¢ã€‚

**ä¸»è¦ç»“è®º**ï¼šPixelGenåœ¨ImageNet-256ä¸Šå®ç°äº†5.11çš„FIDï¼Œå¹¶åœ¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ‰©å±•æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œç®€æ´æ€§ã€‚

**å…³é”®è¯**ï¼šåƒç´ æ‰©æ•£, PixelGen, ç”Ÿæˆæ¨¡å‹, æ„ŸçŸ¥æŸå¤±, å›¾åƒç”Ÿæˆ, æ·±åº¦å­¦ä¹ , åµŒå…¥, è¯­ä¹‰æœç´¢, ä»£ç†å·¥ä½œæµ, generative

**è¯„åˆ†**ï¼š76

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02493v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02493v1.pdf)

---

## [16. Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](https://arxiv.org/abs/2602.02471v1)

**ä½œè€…**ï¼šEdwin Kys, Febian Febian  
**åˆ†ç±»**ï¼šcs.CV, cs.AI, physics.med-ph  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§åŸºäºSwin U-Netçš„é—¨æ§å¤šå¤´Transformeræ¶æ„ï¼Œé€šè¿‡ç»“åˆæ£€æµ‹å¤´å’Œä¸Šä¸‹æ–‡é›†æˆï¼Œæ˜¾è‘—æé«˜äº†æ”¾å°„æ²»ç–—ä¸­çš„è‡ªåŠ¨åˆ†å‰²æ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿæ·±åº¦å­¦ä¹ è‡ªåŠ¨åˆ†å‰²æ¨¡å‹åœ¨ç¼ºä¹ç›®æ ‡ç»“æ„çš„åˆ‡ç‰‡ä¸­å¸¸äº§ç”Ÿä¸ç¬¦åˆè§£å‰–å­¦çš„å‡é˜³æ€§ï¼Œå½±å“ä¸´åºŠåº”ç”¨çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé‡‡ç”¨äº†é—¨æ§å¤šå¤´Transformeræ¶æ„ï¼Œç»“åˆæ£€æµ‹å¤´è¿›è¡Œåˆ‡ç‰‡çº§ç»“æ„æ£€æµ‹å’Œåƒç´ çº§åˆ†å‰²ï¼Œåˆ©ç”¨TverskyæŸå¤±å‡½æ•°è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚

**ä¸»è¦ç»“è®º**ï¼šæ£€æµ‹é©±åŠ¨çš„é—¨æ§æœºåˆ¶æå‡äº†è‡ªåŠ¨åˆ†å‰²çš„ç¨³å¥æ€§å’Œè§£å‰–å­¦åˆç†æ€§ï¼Œæœ‰æ•ˆå‡å°‘äº†è™šå‡é¢„æµ‹ï¼ŒåŒæ—¶ä¸å½±å“æœ‰æ•ˆåˆ‡ç‰‡çš„åˆ†å‰²è´¨é‡ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , è‡ªåŠ¨åˆ†å‰², Transformer, Swin U-Net, å¤šå¤´æ¨¡å‹, ç»“æ„æ£€æµ‹, èƒŒæ™¯å¢å¼º, TverskyæŸå¤±, ä¸´åºŠåº”ç”¨

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02471v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02471v1.pdf)

---

## [17. UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing](https://arxiv.org/abs/2602.02437v1)

**ä½œè€…**ï¼šDianyi Wang, Chaofan Ma, Feng Han ç­‰ 11 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šUniReasonæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¨ç†æ¡†æ¶ï¼Œé€šè¿‡åŒé‡æ¨ç†èŒƒå¼å°†å›¾åƒç”Ÿæˆä¸ç¼–è¾‘ä»»åŠ¡ç»“åˆèµ·æ¥ï¼Œä»¥æé«˜å¤æ‚åˆæˆä»»åŠ¡çš„è¡¨ç°ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå½“å‰çš„å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤æ‚åˆæˆä»»åŠ¡ä¸­è¡¨ç°æ¬ ä½³ï¼Œé€šå¸¸å°†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸å›¾åƒç¼–è¾‘è§†ä¸ºå­¤ç«‹çš„èƒ½åŠ›ï¼Œè€Œä¸æ˜¯ç›¸äº’å…³è”çš„æ¨ç†æ­¥éª¤ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šUniReasonæ¡†æ¶å°†ç”Ÿæˆè§†ä¸ºå¢å¼ºä¸–ç•ŒçŸ¥è¯†çš„è§„åˆ’ï¼Œå¼•å…¥éšæ€§çº¦æŸï¼Œå¹¶åˆ©ç”¨ç¼–è¾‘èƒ½åŠ›è¿›è¡Œç»†è‡´çš„è§†è§‰ä¿®æ­£ï¼Œä»è€Œç»Ÿä¸€ç”Ÿæˆä¸ç¼–è¾‘ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒUniReasonåœ¨æ¨ç†å¯†é›†çš„åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒæ—¶ä¿æŒäº†å‡ºè‰²çš„ç»¼åˆåˆæˆèƒ½åŠ›ã€‚

**å…³é”®è¯**ï¼šç»Ÿä¸€æ¨ç†, å¤šæ¨¡æ€æ¨¡å‹, ç”Ÿæˆä¸ç¼–è¾‘, æ·±åº¦æ¨ç†, è§†è§‰è‡ªæˆ‘ä¿®æ­£, agentç”Ÿæˆ, çŸ¥è¯†å¢å¼º, å…±äº«è¡¨ç¤º, å¤æ‚åˆæˆä»»åŠ¡, è®¡åˆ’ä¸ç»†åŒ–

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02437v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02437v1.pdf)

---

## [18. SelvaMask: Segmenting Trees in Tropical Forests and Beyond](https://arxiv.org/abs/2602.02426v1)

**ä½œè€…**ï¼šSimon-Olivier Duguay, Hugo Baudchon, Etienne LalibertÃ© ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSelvaMaskæ˜¯ä¸€ä¸ªæ–°æ•°æ®é›†å’Œæ–¹æ³•ï¼Œæ—¨åœ¨æé«˜çƒ­å¸¦æ£®æ—ä¸­æ ‘å† åˆ†å‰²çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç¨ å¯†æ£®æ—ç¯å¢ƒä¸­ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šçƒ­å¸¦æ£®æ—æ˜¯åœ°çƒæ ‘æœ¨ç”Ÿç‰©å¤šæ ·æ€§çš„ä¸»è¦æ –æ¯åœ°ï¼Œå‡†ç¡®è¯†åˆ«æ ‘å† å¯¹äºç ”ç©¶å…¶ç”Ÿæ€åŠŸèƒ½å’Œç¢³å‚¨å­˜è‡³å…³é‡è¦ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªæ¨¡å—åŒ–çš„æ£€æµ‹-åˆ†å‰²ç®¡é“ï¼Œç»“åˆäº†è§†è§‰åŸºç¡€æ¨¡å‹å’Œç‰¹å®šé¢†åŸŸçš„æ£€æµ‹æç¤ºï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„æ ‘å† åˆ†å‰²ã€‚

**ä¸»è¦ç»“è®º**ï¼šSelvaMaskåœ¨çƒ­å¸¦æ£®æ—çš„æ ‘å† åˆ†å‰²ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨å¤–éƒ¨æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œå¹¶å°†å…¬å¼€å‘å¸ƒä»£ç å’Œæ•°æ®é›†ä»¥ä¿ƒè¿›æ£®æ—ç›‘æµ‹ç ”ç©¶ã€‚

**å…³é”®è¯**ï¼šæ ‘æœ¨åˆ†å‰², çƒ­å¸¦æ£®æ—, è¯­ä¹‰åˆ†å‰², æ·±åº¦å­¦ä¹ , è§†è§‰åŸºç¡€æ¨¡å‹, æ£®æ—ç›‘æµ‹, æ¨¡å—åŒ–æ£€æµ‹-åˆ†å‰²ç®¡é“, æ•°æ®é›†, é«˜åˆ†è¾¨ç‡å›¾åƒ, transformer

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02426v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02426v1.pdf)

---

## [19. Catalyst: Out-of-Distribution Detection via Elastic Scaling](https://arxiv.org/abs/2602.02409v1)

**ä½œè€…**ï¼šAbid Hassan, Tuan Ngo, Saad Shafiq ç­‰ 4 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($Î³$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $Î³$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCatalystæ˜¯ä¸€ç§é€šè¿‡å¼¹æ€§ç¼©æ”¾åˆ©ç”¨é¢„æ± åŒ–ç‰¹å¾å›¾çš„åŸå§‹é€šé“ç»Ÿè®¡é‡æ¥æ”¹è¿›å¼‚å¸¸æ£€æµ‹çš„æ–¹æ³•ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„åå¤„ç†æ–¹æ³•è¿‡äºä¾èµ–äºè¾“å‡ºlogitsæˆ–ç‰¹å¾å‘é‡ï¼Œè€Œå¿½è§†äº†é¢„æ± åŒ–ç‰¹å¾å›¾ä¸­çš„ä¸°å¯Œä¿¡å·ï¼Œå¯¼è‡´æ½œåœ¨æ€§èƒ½æŸå¤±ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šCatalystè®¡ç®—è¾“å…¥ä¾èµ–çš„ç¼©æ”¾å› å­ï¼Œå¹¶é€šè¿‡å¼¹æ€§ç¼©æ”¾å°†å…¶ä¸ç°æœ‰åŸºçº¿åˆ†æ•°ç›¸ç»“åˆï¼Œä»è€Œè¿›ä¸€æ­¥ä¼˜åŒ–OODæ£€æµ‹æ•ˆæœã€‚

**ä¸»è¦ç»“è®º**ï¼šCatalyståœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†å¼‚å¸¸æ£€æµ‹æ€§èƒ½ï¼Œå¹¶è¯æ˜äº†é¢„æ± åŒ–ç»Ÿè®¡é‡çš„æ½œåœ¨ä»·å€¼ï¼Œå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œå…¼å®¹æ€§ã€‚

**å…³é”®è¯**ï¼šæ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, OODæ£€æµ‹, Catalyst, å¼¹æ€§ç¼©æ”¾, ç‰¹å¾å›¾, ç»Ÿè®¡ä¿¡æ¯, è¯¯æŠ¥ç‡, KNN, æœºå™¨å­¦ä¹ , ml

**è¯„åˆ†**ï¼š71

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02409v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02409v1.pdf)

---

## [20. ReasonEdit: Editing Vision-Language Models using Human Reasoning](https://arxiv.org/abs/2602.02408v1)

**ä½œè€…**ï¼šJiaxing Qiu, Kaihua Hou, Roxana Daneshjou ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.CV, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šReasonEditæ˜¯ä¸€ç§æ–°é¢–çš„è§†è§‰è¯­è¨€æ¨¡å‹ç¼–è¾‘å·¥å…·ï¼Œå…è®¸ç”¨æˆ·åœ¨ç¼–è¾‘è¿‡ç¨‹ä¸­åˆ©ç”¨äººç±»æ¨ç†ï¼Œä»è€Œæå‡ç¼–è¾‘æ•ˆæœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹ç¼–è¾‘å·¥å…·æœªèƒ½æœ‰æ•ˆå¤„ç†éœ€è¦æ¨ç†çš„ä»»åŠ¡ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°çš„æ–¹æ³•æ¥æ•´åˆäººç±»æ¨ç†ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šReasonEdité€šè¿‡æŒç»­å­˜å‚¨äººç±»æ¨ç†åˆ°ä»£ç æœ¬ï¼Œå¹¶ä½¿ç”¨ä¸€ç§æ–°é¢–çš„æ‹“æ‰‘å¹³è¡¡å¤šæ¨¡æ€åµŒå…¥æ–¹æ³•æ¥æ£€ç´¢ç›¸å…³äº‹å®ï¼Œä»è€Œå®ç°æ¨¡å‹ç¼–è¾‘ã€‚

**ä¸»è¦ç»“è®º**ï¼šReasonEditåœ¨å¤šä¸ªåŸºäºæ¨ç†çš„è§†è§‰é—®ç­”æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç¼–è¾‘æ€§èƒ½ï¼Œè¯æ˜äº†åœ¨ç¼–è¾‘è¿‡ç¨‹ä¸­åˆ©ç”¨äººç±»æ¨ç†æ˜¾è‘—æé«˜äº†ç¼–è¾‘çš„é€šç”¨æ€§ã€‚

**å…³é”®è¯**ï¼šæ¨¡å‹ç¼–è¾‘, è§†è§‰è¯­è¨€æ¨¡å‹, äººç±»æ¨ç†, å¤šæ¨¡æ€åµŒå…¥, ä»£ç æœ¬, è§†è§‰é—®ç­”, çŠ¶æ€æœ€ä¼˜, ReasonEdit, æ¨ç†é‡ç”¨, ç¼–è¾‘æ€§èƒ½, embedding

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02408v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02408v1.pdf)

---

## cs.LG

## [21. RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](https://arxiv.org/abs/2602.02488v1)

**ä½œè€…**ï¼šYinjie Wang, Tianbao Xie, Ke Shen ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šRLAnythingæ˜¯ä¸€ä¸ªé€šè¿‡é—­ç¯ä¼˜åŒ–åŠ¨æ€é”»é€ ç¯å¢ƒã€ç­–ç•¥å’Œå¥–åŠ±æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å­¦ä¹ ä¿¡å·å’Œç³»ç»Ÿæ€§èƒ½ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨æé«˜å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å’Œè‡ªä¸»ä»£ç†åœºæ™¯ä¸­ï¼Œé€šè¿‡åŠ¨æ€é€‚åº”ç¯å¢ƒå’Œä¼˜åŒ–ç­–ç•¥åŠå¥–åŠ±æ¨¡å‹æ¥å¢å¼ºå­¦ä¹ æ•ˆæœã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šRLAnythingç»“åˆäº†é€æ­¥å’Œç»“æœä¿¡å·çš„é›†æˆåé¦ˆè¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œå¹¶é€šè¿‡ä¸€è‡´æ€§åé¦ˆå…±åŒä¼˜åŒ–å¥–åŠ±æ¨¡å‹ï¼Œä»è€Œæå‡è®­ç»ƒæ•ˆæœï¼ŒåŒæ—¶åˆ©ç”¨æ‰¹è¯„è€…åé¦ˆå®ç°ç¯å¢ƒçš„è‡ªåŠ¨é€‚åº”ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒè¡¨æ˜ï¼Œå„ä¸ªç»„æˆéƒ¨åˆ†çš„æ·»åŠ å‡èƒ½ä¸€è‡´æ€§åœ°æ”¹å–„æ•´ä½“ç³»ç»Ÿæ€§èƒ½ï¼ŒRLAnythingåœ¨å¤šé¡¹ä»£è¡¨æ€§ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æå‡ï¼Œä¼˜åŒ–çš„å¥–åŠ±æ¨¡å‹ä¿¡å·è¶…è¶Šäº†ä¾èµ–äººç±»æ ‡ç­¾çš„ç»“æœã€‚

**å…³é”®è¯**ï¼šå¼ºåŒ–å­¦ä¹ , åŠ¨æ€ç¯å¢ƒ, ç­–ç•¥ä¼˜åŒ–, å¥–åŠ±æ¨¡å‹, LLM, agenticåœºæ™¯, åé¦ˆæœºåˆ¶, ç»éªŒå­¦ä¹ , è‡ªåŠ¨åŒ–é€‚åº”

**è¯„åˆ†**ï¼š76

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02488v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02488v1.pdf)

---

## [22. Expanding the Capabilities of Reinforcement Learning via Text Feedback](https://arxiv.org/abs/2602.02482v1)

**ä½œè€…**ï¼šYuda Song, Lili Chen, Fahim Tajwar ç­‰ 8 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šé€šè¿‡ä½¿ç”¨æ–‡æœ¬åé¦ˆï¼Œç ”ç©¶å¦‚ä½•æ‰©å±•å¼ºåŒ–å­¦ä¹ åœ¨å¤§å‹è¯­è¨€æ¨¡å‹åè®­ç»ƒä¸­çš„èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¾èµ–äºå•ä¸€çš„ã€ä¿¡æ¯é‡æœ‰é™çš„å¥–åŠ±ä¿¡å·ï¼Œè€Œæ–‡æœ¬åé¦ˆæä¾›äº†ä¸€ç§æ›´ä¸°å¯Œä½†æˆæœ¬æ›´ä½çš„ç›‘ç£æ–¹å¼ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºäº†ä¸¤ç§æ–¹æ³•ï¼šè‡ªæˆ‘è’¸é¦ï¼ˆRLTF-SDï¼‰ï¼Œé€šè¿‡åŒ¹é…è‡ªèº«åé¦ˆç”Ÿæˆçš„å†…å®¹æ¥è®­ç»ƒå•è½®ç­–ç•¥ï¼›åé¦ˆå»ºæ¨¡ï¼ˆRLTF-FMï¼‰ï¼Œå°†é¢„æµ‹åé¦ˆä½œä¸ºè¾…åŠ©ç›®æ ‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ä¸¤ç§æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºå¼ºåŸºçº¿ï¼Œå±•ç¤ºäº†åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸­ç»“åˆæ–‡æœ¬åé¦ˆçš„æ½œåŠ›ã€‚

**å…³é”®è¯**ï¼šå¼ºåŒ–å­¦ä¹ , æ–‡æœ¬åé¦ˆ, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , è‡ªæˆ‘è’¸é¦, åé¦ˆå»ºæ¨¡, LLM, å¤šè½®RL, ç›‘ç£å­¦ä¹ , è®­ç»ƒä¼˜åŒ–

**è¯„åˆ†**ï¼š76

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02482v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02482v1.pdf)

---

## [23. SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning](https://arxiv.org/abs/2602.02472v1)

**ä½œè€…**ï¼šQifan Yu, Xinyu Ma, Zhijian Zhuo ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.CL  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under $2\times$ width expansion.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šSPARKLINGæ˜¯ä¸€ç§æ–°æ¡†æ¶ï¼Œé€šè¿‡ä¿¡å·ä¿æŠ¤å’Œæ‰“ç ´å¯¹ç§°æ€§ï¼Œå®ç°å®½åº¦æ¸è¿›å­¦ä¹ ä¸­çš„ä¸­æœŸæ‰©å±•ï¼Œæ˜¾è‘—é™ä½è®­ç»ƒæˆæœ¬ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šå°½ç®¡å·²æœ‰ç ”ç©¶æ¢ç´¢æ·±åº¦æ‰©å±•ï¼Œä½†å®½åº¦æ‰©å±•åœ¨è®­ç»ƒä¸­æœŸçš„é‡è¦æ€§å°šæœªå¾—åˆ°å……åˆ†é‡è§†ï¼Œç‰¹åˆ«æ˜¯ä¸ºäº†æœ€å¤§åŒ–è®¡ç®—èŠ‚çœã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šSPARKLINGé€šè¿‡RMSè§„æ¨¡ä¸€è‡´æ€§å®ç°ä¿¡å·ä¿æŠ¤ï¼Œå¹¶é€šè¿‡ä¸å¯¹ç§°ä¼˜åŒ–å™¨çŠ¶æ€é‡ç½®å’Œå­¦ä¹ ç‡é‡æ–°å‡æ¸©æ¥æ‰“ç ´å¯¹ç§°æ€§ï¼Œä»è€Œç¨³å®šæ‰©å±•è¿‡ç¨‹ã€‚

**ä¸»è¦ç»“è®º**ï¼šåœ¨å¤šä¸ªå®½åº¦è½´å’Œä¼˜åŒ–å™¨ç³»åˆ—ä¸Šï¼ŒSPARKLINGåœ¨è®­ç»ƒæ•ˆç‡ä¸Šä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒï¼Œè®­ç»ƒæˆæœ¬é™ä½é«˜è¾¾35%ã€‚

**å…³é”®è¯**ï¼šä¿¡å·ä¿ç•™, å¯¹ç§°æ‰“ç ´, å®½åº¦æ‰©å±•, é€æ­¥å­¦ä¹ , è®­ç»ƒç¨³å®šæ€§, Mixture-of-Experts, RMS-scaleä¸€è‡´æ€§, ä¼˜åŒ–å™¨çŠ¶æ€é‡ç½®, å­¦ä¹ ç‡é‡çƒ­, è®¡ç®—èŠ‚çœ, agent

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02472v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02472v1.pdf)

---

## [24. Conflict-Aware Client Selection for Multi-Server Federated Learning](https://arxiv.org/abs/2602.02458v1)

**ä½œè€…**ï¼šMingwei Hong, Zheng Lin, Zehang Lin ç­‰ 10 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, cs.NI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå†²çªé£é™©é¢„æµ‹çš„å»ä¸­å¿ƒåŒ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–å¤šæœåŠ¡å™¨è”é‚¦å­¦ä¹ ä¸­çš„å®¢æˆ·ç«¯é€‰æ‹©ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„å•æœåŠ¡å™¨è”é‚¦å­¦ä¹ å­˜åœ¨é«˜é€šä¿¡å»¶è¿Ÿå’Œèµ„æºå†²çªé—®é¢˜ï¼Œè€Œå¤šæœåŠ¡å™¨è”é‚¦å­¦ä¹ å´å› å®¢æˆ·ç«¯è¦†ç›–é‡å å’Œé€‰æ‹©ä¸åè°ƒå¯¼è‡´è®­ç»ƒå¤±è´¥ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šä½œè€…æå‡ºäº†ä¸€ç§åä¸ºRL CRPçš„æ¡†æ¶ï¼Œé€šè¿‡åŸºäºç¨€ç–å†å²å®¢æˆ·ç«¯é€‰æ‹©åºåˆ—çš„åˆ†ç±»éšé©¬å°”å¯å¤«æ¨¡å‹æ¥é¢„æµ‹å†²çªï¼Œå¹¶å¼•å…¥å…¬å¹³å¥–åŠ±æœºåˆ¶ä»¥ä¿ƒè¿›é•¿æœŸå‚ä¸ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒRL-CRPæ¡†æ¶æœ‰æ•ˆå‡å°‘äº†æœåŠ¡å™¨é—´çš„å†²çªï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼ŒåŒ…æ‹¬æ”¶æ•›é€Ÿåº¦å’Œé€šä¿¡æˆæœ¬ã€‚

**å…³é”®è¯**ï¼šè”é‚¦å­¦ä¹ , åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ , å®¢æˆ·ç«¯é€‰æ‹©, å¼ºåŒ–å­¦ä¹ , èµ„æºç«äº‰, å¸¦å®½å†²çª, æ¨¡å‹èšåˆ, å¤šæœåŠ¡å™¨, è®­ç»ƒæ•ˆç‡, ç”¨æˆ·éšç§, machine learning

**è¯„åˆ†**ï¼š74

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02458v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02458v1.pdf)

---

## [25. Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization](https://arxiv.org/abs/2602.02451v1)

**ä½œè€…**ï¼šPatrick Cooper, Alvaro Velasquez  
**åˆ†ç±»**ï¼šcs.LG, cs.AI  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p < 0.001, Cohen's d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„å®éªŒè®¾è®¡æ–¹æ³•ACEï¼Œé€šè¿‡ç›´æ¥åå¥½ä¼˜åŒ–å­¦ä¹ å¹²é¢„ç­–ç•¥ï¼Œä»¥æé«˜å› æœå…³ç³»å‘ç°çš„æ•ˆç‡å’Œæ•ˆæœã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šä¼ ç»Ÿçš„å®éªŒè®¾è®¡æ–¹æ³•æ— æ³•æœ‰æ•ˆåˆ©ç”¨ç»éªŒè¿›è¡Œé€‚åº”æ€§å†³ç­–ï¼Œå› æ­¤éœ€è¦ä¸€ç§æ–°æ–¹æ³•æ¥è§£å†³å®éªŒä¸­çš„é¡ºåºå†³ç­–é—®é¢˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šACEé€šè¿‡å°†å®éªŒè®¾è®¡è§†ä¸ºä¸€ä¸ªé¡ºåºç­–ç•¥ï¼Œåˆ©ç”¨ç›´æ¥åå¥½ä¼˜åŒ–ä»æˆå¯¹çš„å¹²é¢„æ¯”è¾ƒä¸­å­¦ä¹ ï¼Œè€Œéä¾èµ–äºä¸ç¨³å®šçš„ç»å¯¹å¥–åŠ±ã€‚

**ä¸»è¦ç»“è®º**ï¼šACEåœ¨å¤šä¸ªåŸºå‡†å®éªŒä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¼˜è¶Šæ€§ï¼Œè¡¨æ˜åå¥½å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆæ¢å¤æœ‰åŸåˆ™çš„å®éªŒç­–ç•¥ï¼Œå¹¶ä»ç»éªŒä¸­æå–ç†è®ºæ”¯æŒã€‚

**å…³é”®è¯**ï¼šå› æœå…³ç³», å®éªŒè®¾è®¡, ä¼˜åŒ–ç­–ç•¥, æ·±åº¦å­¦ä¹ , æœºå™¨å­¦ä¹ , ä»£ç†, é€‚åº”æ€§ç­–ç•¥, åœ¨çº¿å­¦ä¹ , åå¥½ä¼˜åŒ–, ç»éªŒå­¦ä¹ , autonomous

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02451v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02451v1.pdf)

---

## [26. Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation](https://arxiv.org/abs/2602.02445v1)

**ä½œè€…**ï¼šSeo Taek Kong, R. Srikant  
**åˆ†ç±»**ï¼šcs.LG, math.ST  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

This paper derives non-asymptotic error bounds for nonlinear stochastic approximation algorithms in the Wasserstein-$p$ distance. To obtain explicit finite-sample guarantees for the last iterate, we develop a coupling argument that compares the discrete-time process to a limiting Ornstein-Uhlenbeck process. Our analysis applies to algorithms driven by general noise conditions, including martingale differences and functions of ergodic Markov chains. Complementing this result, we handle the convergence rate of the Polyak-Ruppert average through a direct analysis that applies under the same general setting.   Assuming the driving noise satisfies a non-asymptotic central limit theorem, we show that the normalized last iterates converge to a Gaussian distribution in the $p$-Wasserstein distance at a rate of order $Î³_n^{1/6}$, where $Î³_n$ is the step size. Similarly, the Polyak-Ruppert average is shown to converge in the Wasserstein distance at a rate of order $n^{-1/6}$. These distributional guarantees imply high-probability concentration inequalities that improve upon those derived from moment bounds and Markov's inequality. We demonstrate the utility of this approach by considering two applications: (1) linear stochastic approximation, where we explicitly quantify the transition from heavy-tailed to Gaussian behavior of the iterates, thereby bridging the gap between recent finite-sample analyses and asymptotic theory and (2) stochastic gradient descent, where we establish rate of convergence to the central limit theorem.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æ¨å¯¼äº†éçº¿æ€§éšæœºé€¼è¿‘ç®—æ³•åœ¨Wasserstein-$p$è·ç¦»ä¸‹çš„æœ‰é™æ ·æœ¬è¯¯å·®ç•Œé™ï¼Œå±•ç¤ºäº†å…¶æ”¶æ•›æ€§å’Œæµ“åº¦ä¸ç­‰å¼ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç ”ç©¶éçº¿æ€§éšæœºé€¼è¿‘ç®—æ³•çš„æœ‰é™æ ·æœ¬è¡¨ç°ï¼Œä»¥å¡«è¡¥æœ‰é™æ ·æœ¬åˆ†æä¸æ¸è¿›ç†è®ºä¹‹é—´çš„ç©ºç™½ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡æ¯”è¾ƒç¦»æ•£æ—¶é—´è¿‡ç¨‹ä¸æé™Ornstein-Uhlenbeckè¿‡ç¨‹ï¼Œå‘å±•äº†ä¸€ç§è€¦åˆè®ºè¯ï¼Œé€‚ç”¨äºä¸€èˆ¬å™ªå£°æ¡ä»¶ä¸‹çš„ç®—æ³•ã€‚

**ä¸»è¦ç»“è®º**ï¼šç®—æ³•çš„æœ€åè¿­ä»£ä»¥é€Ÿç‡$Î³_n^{1/6}$æ”¶æ•›åˆ°é«˜æ–¯åˆ†å¸ƒï¼ŒåŒæ—¶Polyak-Ruppertå¹³å‡ä»¥é€Ÿç‡$n^{-1/6}$æ”¶æ•›ï¼Œä¸”ç»™å‡ºäº†æ”¹è¿›çš„é«˜æ¦‚ç‡æµ“åº¦ä¸ç­‰å¼ã€‚

**å…³é”®è¯**ï¼šéçº¿æ€§éšæœºé€¼è¿‘, Wassersteinè·ç¦», è¯¯å·®ç•Œé™, æ”¶æ•›é€Ÿç‡, é«˜æ¦‚ç‡æµ“åº¦ä¸ç­‰å¼, è¿­ä»£ç®—æ³•, é©¬å°”å¯å¤«é“¾, éšæœºæ¢¯åº¦ä¸‹é™, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , rag

**è¯„åˆ†**ï¼š72

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02445v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02445v1.pdf)

---

## [27. Maximizing Reliability with Bayesian Optimization](https://arxiv.org/abs/2602.02432v1)

**ä½œè€…**ï¼šJack M. Buckingham, Ivo Couckuyt, Juergen Branke  
**åˆ†ç±»**ï¼šcs.LG, math.OC, stat.ML  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸¤ç§åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ–¹æ³•ï¼Œä»¥æé«˜è®¾è®¡çš„å¯é æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æå°å¤±æ•ˆæ¦‚ç‡çš„æƒ…å†µä¸‹ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šåˆ¶é€ è¿‡ç¨‹ä¸­å­˜åœ¨éœ€è¦æœ€å¤§åŒ–è®¾è®¡å¯é æ€§çš„é—®é¢˜ï¼Œè¯¥é—®é¢˜æ¶‰åŠåˆ°æå°‘å‘ç”Ÿçš„å¤±æ•ˆäº‹ä»¶ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºçš„ä¸¤ç§è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•åˆ†åˆ«åŸºäºæ±¤æ™®æ£®é‡‡æ ·å’ŒçŸ¥è¯†æ¢¯åº¦ï¼Œå¹¶é€šè¿‡é‡è¦æ€§é‡‡æ ·æ¥å¤„ç†æå°çš„å¤±æ•ˆæ¦‚ç‡ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æç«¯å’Œéæç«¯æƒ…å†µä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

**å…³é”®è¯**ï¼šè´å¶æ–¯ä¼˜åŒ–, å¯é æ€§, é»‘ç®±ä¼˜åŒ–, é‡è¦æ€§é‡‡æ ·, é‡‡æ ·æ•ˆç‡, è®¾è®¡ä¼˜åŒ–, å¤±è´¥æ¦‚ç‡, æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , agent

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02432v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02432v1.pdf)

---

## [28. Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization](https://arxiv.org/abs/2602.02425v1)

**ä½œè€…**ï¼šAmaru Caceres Arroyo, Lea Bogensperger, Ahmed Allam ç­‰ 6 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG, q-bio.QM  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šCHASEæ¡†æ¶é€šè¿‡é‡ç”¨é¢„è®­ç»ƒçš„è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼Œå®ç°äº†é«˜æ•ˆçš„è›‹ç™½è´¨é€‚åº”æ€§ä¼˜åŒ–ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šè›‹ç™½è´¨é€‚åº”æ€§ä¼˜åŒ–é¢ä¸´ç€ç»„åˆç©ºé—´å·¨å¤§å’Œé«˜é€‚åº”æ€§å˜ä½“ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•è¡¨ç°ä¸ä½³æˆ–è®¡ç®—æˆæœ¬é«˜ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šé€šè¿‡å°†é¢„è®­ç»ƒè›‹ç™½è´¨è¯­è¨€æ¨¡å‹çš„åµŒå…¥å‹ç¼©åˆ°ç´§å‡‘çš„æ½œåœ¨ç©ºé—´ï¼Œå¹¶è®­ç»ƒæ— åˆ†ç±»å™¨å¼•å¯¼çš„æ¡ä»¶æµåŒ¹é…æ¨¡å‹ï¼ŒCHASEèƒ½å¤Ÿåœ¨ODEé‡‡æ ·æ­¥éª¤ä¸­ç›´æ¥ç”Ÿæˆé«˜é€‚åº”æ€§å˜ä½“ã€‚

**ä¸»è¦ç»“è®º**ï¼šCHASEåœ¨AAVå’ŒGFPè›‹ç™½è®¾è®¡åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”é€šè¿‡åˆæˆæ•°æ®çš„å¼•å¯¼å¯ä»¥è¿›ä¸€æ­¥æå‡åœ¨æ•°æ®å—é™ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šè›‹ç™½è´¨ä¼˜åŒ–, è¯­è¨€æ¨¡å‹, æ½œåœ¨æµ, é«˜é€‚åº”æ€§å˜ä½“, ç”Ÿæˆæ¨¡å‹, CHASE, é¢„è®­ç»ƒ, åµŒå…¥å‹ç¼©, æ¡ä»¶æµåŒ¹é…, æ— åˆ†ç±»å™¨å¼•å¯¼, embedding

**è¯„åˆ†**ï¼š75

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02425v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02425v1.pdf)

---

## [29. Trust Region Continual Learning as an Implicit Meta-Learner](https://arxiv.org/abs/2602.02417v1)

**ä½œè€…**ï¼šZekun Wang, Anant Gupta, Christopher J. MacLellan  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¿¡ä»»åŒºåŸŸæŒç»­å­¦ä¹ æ–¹æ³•ï¼Œç»“åˆç”Ÿæˆé‡æ”¾å’ŒFisheråº¦é‡çº¦æŸï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨è¿ç»­å­¦ä¹ ä¸­çš„æ€§èƒ½å’Œä»»åŠ¡ä¿ç•™èƒ½åŠ›ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šæŒç»­å­¦ä¹ æ—¨åœ¨é¡ºåºè·å–ä»»åŠ¡è€Œä¸å‘ç”Ÿç¾éš¾æ€§é—å¿˜ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨ä»»åŠ¡é‡å è¾ƒå¼±æ—¶é¢ä¸´æ­£åˆ™åŒ–è¿‡åº¦çº¦æŸå’Œé‡æ”¾æ¼‚ç§»çš„æƒè¡¡ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šæå‡ºçš„ä¿¡ä»»åŒºåŸŸæŒç»­å­¦ä¹ æ–¹æ³•é€šè¿‡ç”Ÿæˆé‡æ”¾ä¸Fisheråº¦é‡ä¿¡ä»»åŒºåŸŸçº¦æŸç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§éšå¼å…ƒå­¦ä¹ çš„æ›´æ–°æœºåˆ¶ã€‚

**ä¸»è¦ç»“è®º**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒç”Ÿæˆå’Œæ”¿ç­–æ§åˆ¶ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´å¿«åœ°æ¢å¤æ—©æœŸä»»åŠ¡çš„æ€§èƒ½ã€‚

**å…³é”®è¯**ï¼šä¿¡ä»»åŒºåŸŸæŒç»­å­¦ä¹ , å…ƒå­¦ä¹ , ç”Ÿæˆå›æ”¾, ä»»åŠ¡å¢é‡, æ·±åº¦å­¦ä¹ , æœºå™¨å­¦ä¹ , ç¥ç»ç½‘ç»œ, ä»»åŠ¡ä¼˜åŒ–, æ€§èƒ½ä¿ç•™, ml

**è¯„åˆ†**ï¼š70

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02417v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02417v1.pdf)

---

## [30. Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models](https://arxiv.org/abs/2602.02415v1)

**ä½œè€…**ï¼šVivienne Pelletier, Daniel J. Rivera, Obinna Nwokonkwo ç­‰ 5 ä½ä½œè€…  
**åˆ†ç±»**ï¼šcs.LG  
**å‘å¸ƒæ—¶é—´**ï¼š2026-02-02

### ğŸ“„ è®ºæ–‡æ‘˜è¦

Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets are readily available and can be leveraged to construct a better seed set. We introduce a new method for selecting the seed data set for active learning, Active-Transfer Bagging (ATBagging). ATBagging estimates the informativeness of candidate data point from a Bayesian interpretation of bagged ensemble models by comparing in-bag and out-of-bag predictive distributions from the labeled dataset, yielding an information-gain proxy. To avoid redundant selections, we impose feature-space diversity by sampling a determinantal point process (DPP) whose kernel uses Random Fourier Features and a quality-diversity factorization that incorporates the informativeness scores. This same blended method is used for selection of new data points to collect during the active learning phase. We evaluate ATBagging on four real-world datasets covering both target-transfer and feature-shift scenarios (QM9, ERA5, Forbes 2000, and Beijing PM2.5). Across seed sizes nseed = 10-100, ATBagging improves or ties early active learning and increases area under the learning-curve relative to alternative seed subset selection methodologies in almost all cases, with strongest benefits in low-data regimes. Thus, ATBagging provides a low-cost, high reward means to initiating active learning-based data collection.

### ğŸ¤– AI æ€»ç»“

**ä¸€å¥è¯æ€»ç»“**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ä¸»åŠ¨å­¦ä¹ ç§å­æ•°æ®é€‰æ‹©æ–¹æ³•ATBaggingï¼Œç»“åˆäº†è¿ç§»å­¦ä¹ å’Œè¢‹è£…æ¨¡å‹ï¼Œä»¥æé«˜æ•°æ®è·å–æ•ˆç‡ã€‚

**ç ”ç©¶åŠ¨æœº**ï¼šç°ä»£æœºå™¨å­¦ä¹ ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè€Œä¸»åŠ¨å­¦ä¹ å¯ä»¥é™ä½æ ‡æ³¨æˆæœ¬ï¼Œä½†åˆå§‹ç§å­é›†çš„é€‰æ‹©é€šå¸¸å½±å“æ—©æœŸè¡¨ç°ã€‚

**æ ¸å¿ƒæ–¹æ³•**ï¼šATBaggingé€šè¿‡æ¯”è¾ƒè¢‹å†…å’Œè¢‹å¤–é¢„æµ‹åˆ†å¸ƒæ¥ä¼°è®¡å€™é€‰æ•°æ®ç‚¹çš„ä¿¡æ¯é‡ï¼Œé‡‡ç”¨ç¡®å®šæ€§ç‚¹è¿‡ç¨‹é‡‡æ ·ä»¥é¿å…å†—ä½™é€‰æ‹©ï¼Œå¹¶åœ¨ä¸»åŠ¨å­¦ä¹ é˜¶æ®µé€‰æ‹©æ–°æ•°æ®ç‚¹ã€‚

**ä¸»è¦ç»“è®º**ï¼šATBaggingåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ•°æ®æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æé«˜äº†ä¸»åŠ¨å­¦ä¹ çš„æ—©æœŸæ•ˆæœå’Œå­¦ä¹ æ›²çº¿ä¸‹é¢ç§¯ã€‚

**å…³é”®è¯**ï¼šä¸»åŠ¨å­¦ä¹ , è¿ç§»å­¦ä¹ , æ•°æ®é›†, ä¿¡æ¯å¢ç›Š, ç‰¹å¾é€‰æ‹©, Active-Transfer Bagging, ä½æ•°æ®åœºæ™¯, é¢„æµ‹åˆ†å¸ƒ, å¤šæ ·æ€§é‡‡æ ·, machine learning

**è¯„åˆ†**ï¼š73

**è®ºæ–‡é“¾æ¥**ï¼š[æŸ¥çœ‹åŸæ–‡](https://arxiv.org/abs/2602.02415v1) | [ä¸‹è½½PDF](https://arxiv.org/pdf/2602.02415v1.pdf)

---

